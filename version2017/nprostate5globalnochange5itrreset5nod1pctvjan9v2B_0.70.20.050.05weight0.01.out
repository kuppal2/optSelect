
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/kuppal3/karan_libs/Rlibs")
> library(snow)
Warning message:
package ‘snow’ was built under R version 3.2.5 
> library(e1071)
Warning message:
package ‘e1071’ was built under R version 3.2.5 
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

Warning message:
package ‘pROC’ was built under R version 3.2.5 
> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
Warning message:
package ‘RankAggreg’ was built under R version 3.2.5 
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

Warning message:
package ‘CMA’ was built under R version 3.2.4 
> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

Warning messages:
1: package ‘expm’ was built under R version 3.2.5 
2: package ‘Matrix’ was built under R version 3.2.5 
> 
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> 
> dirloc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/"
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/versionnov2014/OCFS_",args[9],".R",sep="")
> 
> sname<-paste(dirloc,"version2017/OCFS_",args[9],".R",sep="")
> source(sname)
> 
> outloc<-paste(dirloc,"/Datasets/Prostate/OCFSvmay2415_Prostate",args[9],"/",sep="")
> 
> 
> sname<-paste(dirloc,"Datasets/Prostate/Prostate.Rda",sep="")
> load(sname)
> 
> trainm<-Prostate$X
> testm<-Prostate$Xt
> trainclass<-Prostate$Y
> testclass<-Prostate$Yt
> 
> 
> 
> 
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/Prostate/OCFSvmay2415_Prostatevjan92018_v2' already exists
> setwd(outloc)
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/Prostate/OCFSvmay2415_Prostatevjan92018_v2' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> #if(FALSE)
> {
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
[1] "dim of trainm is "
[1]   61 6033
[1]   61 6033
[1] "length of factcols"
[1] 0
[1]   61 6033
[1]   41 6033
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 1 1
Levels: 1 2
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] -0.003043134 -1.127423770 -0.968790494
[1] "norm train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "mean of feat 2"
[1] -0.1220752
[1] "sd of feat 2"
[1] 1.164888
[1] "maxnum is "
[1] 5
[1] "# of genes left after filtering:"
[1]   61 6033
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 6033    1
[1] 6033
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]  478  610  694 3600 3647
                                                          
[1,]  0.3523077 -0.9436425  3.418485  2.9995593 -0.6064776
[2,] -0.8300460  1.1785517 -0.874537 -1.1621560  2.1909283
[3,] -0.2684535 -1.3201326 -0.495250  0.4958446  1.4493698
                                                          
[1,]  2.8785633  0.4530718 -0.9573321 -0.9600797 0.4494994
[2,] -0.8229654  0.4364162 -0.4752287 -1.1504606 0.2482434
[3,] -0.4537037 -1.3101486 -0.8832488  0.7498193 0.6337699
[1] "numgenes selected:5"
[1] "test acc:0.731707317073171"
[1] "test AUC acc:0.7575"
[1] "10 fold train83.6065573770492"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 35  5
         2  1 20
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 14  9
        2  2 16
[1] "train acc:0.901639344262295"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 35  5
         2  1 20
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   61 6033
[1]   61 6033
[1] "length of factcols"
[1] 0
[1]   61 6033
[1]   41 6033
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 1 1
Levels: 1 2
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] -0.003043134 -1.127423770 -0.968790494
[1] "norm train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "mean of feat 2"
[1] -0.1220752
[1] "sd of feat 2"
[1] 1.164888
[1] "maxnum is "
[1] 5
[1] "# of genes left after filtering:"
[1]   61 6033
GeneSelection: iteration 1 
Loaded glmnet 2.0-10


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
3647 3600 2941  914 1003 5159  610  735  966 1113 3002 3208 4073 4316 4331 5158 
  12   10    8    6    6    6    4    4    4    4    4    4    4    4    4    4 
 702 1444 1491 1720 1979 4538 
   2    2    2    2    2    2 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 6033    1
[1] 6033
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]  914 1003 2941 3600 3647
                                                          
[1,] -0.6832863 -1.173464 -0.2274168  2.9995593 -0.6064776
[2,]  1.7123557 -1.048016  0.4726325 -1.1621560  2.1909283
[3,]  1.0313727 -1.059599 -1.1636745  0.4958446  1.4493698
                                                          
[1,] -0.7478173 -0.1275642  0.9749025 -0.9600797 0.4494994
[2,]  1.0224178 -1.0379066 -1.1416733 -1.1504606 0.2482434
[3,] -1.1491934 -0.3221940  0.1145004  0.7498193 0.6337699
[1] "numgenes selected:5"
[1] "test acc:0.536585365853659"
[1] "test AUC acc:0.575"
[1] "10 fold train90.1639344262295"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 35  1
         2  1 24
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 12 15
        2  4 10
[1] "train acc:0.967213114754098"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 35  1
         2  1 24
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   61 6033
[1]   61 6033
[1] "length of factcols"
[1] 0
[1]   61 6033
[1]   41 6033
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 1 1
Levels: 1 2
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] -0.003043134 -1.127423770 -0.968790494
[1] "norm train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "mean of feat 2"
[1] -0.1220752
[1] "sd of feat 2"
[1] 1.164888
[1] "maxnum is "
[1] 5
[1] "# of genes left after filtering:"
[1]   61 6033
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 6033    1
[1] 6033
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]  694  735 3269 3414 3600
                                                         
[1,]  3.418485  3.6118660  1.5840453 1.3389177  2.9995593
[2,] -0.874537 -0.8149619 -0.4444882 0.9190061 -1.1621560
[3,] -0.495250 -0.8291011 -1.1572130 0.2921515  0.4958446
                                                           
[1,] -0.9573321 -0.8645951 -0.9270340 -0.9275835 -0.9600797
[2,] -0.4752287 -0.5544799 -0.9177115  0.9359531 -1.1504606
[3,] -0.8832488 -0.8250375  0.2246608 -0.3545986  0.7498193
[1] "numgenes selected:5"
[1] "test acc:0.609756097560976"
[1] "test AUC acc:0.635"
[1] "10 fold train85.2459016393443"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 33  5
         2  3 20
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 12 12
        2  4 13
[1] "train acc:0.868852459016393"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 33  5
         2  3 20
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   61 6033
[1]   61 6033
[1] "length of factcols"
[1] 0
[1]   61 6033
[1]   41 6033
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 1 1
Levels: 1 2
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] -0.003043134 -1.127423770 -0.968790494
[1] "norm train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "mean of feat 2"
[1] -0.1220752
[1] "sd of feat 2"
[1] 1.164888
[1] "maxnum is "
[1] 5
[1] "# of genes left after filtering:"
[1]   61 6033
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 6033    1
[1] 6033
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]  610  914 2941 3600 3647
                                                           
[1,] -0.9436425 -0.6832863 -0.2274168  2.9995593 -0.6064776
[2,]  1.1785517  1.7123557  0.4726325 -1.1621560  2.1909283
[3,] -1.3201326  1.0313727 -1.1636745  0.4958446  1.4493698
                                                          
[1,]  0.4530718 -0.7478173  0.9749025 -0.9600797 0.4494994
[2,]  0.4364162  1.0224178 -1.1416733 -1.1504606 0.2482434
[3,] -1.3101486 -1.1491934  0.1145004  0.7498193 0.6337699
[1] "numgenes selected:5"
[1] "test acc:0.585365853658537"
[1] "test AUC acc:0.615"
[1] "10 fold train91.8032786885246"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 35  2
         2  1 23
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 12 13
        2  4 12
[1] "train acc:0.950819672131147"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 35  2
         2  1 23
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   61 6033
[1]   61 6033
[1] "length of factcols"
[1] 0
[1]   61 6033
[1]   41 6033
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 1 1
Levels: 1 2
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] -0.003043134 -1.127423770 -0.968790494
[1] "norm train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "mean of feat 2"
[1] -0.1220752
[1] "sd of feat 2"
[1] 1.164888
[1] "maxnum is "
[1] 5
[1] "# of genes left after filtering:"
[1]   61 6033
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 6033    1
[1] 6033
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]  478  610 2941 3600 3647
                                                           
[1,]  0.3523077 -0.9436425 -0.2274168  2.9995593 -0.6064776
[2,] -0.8300460  1.1785517  0.4726325 -1.1621560  2.1909283
[3,] -0.2684535 -1.3201326 -1.1636745  0.4958446  1.4493698
                                                          
[1,]  2.8785633  0.4530718  0.9749025 -0.9600797 0.4494994
[2,] -0.8229654  0.4364162 -1.1416733 -1.1504606 0.2482434
[3,] -0.4537037 -1.3101486  0.1145004  0.7498193 0.6337699
[1] "numgenes selected:5"
[1] "test acc:0.585365853658537"
[1] "test AUC acc:0.5925"
[1] "10 fold train88.5245901639344"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 34  3
         2  2 22
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 10 11
        2  6 14
[1] "train acc:0.918032786885246"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 34  3
         2  2 22
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
There were 32 warnings (use warnings() to see them)
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   61 6033
[1]   61 6033
[1] "length of factcols"
[1] 0
[1]   61 6033
[1]   41 6033
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 1 1
Levels: 1 2
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "orig train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] -0.003043134 -1.127423770 -0.968790494
[1] "norm train matrix"
                                                                         
[1,] -0.54578123 -0.8516873 -0.003043134 -0.1220894  0.8379074 -1.1958825
[2,] -0.83575852  0.6291059 -1.127423770 -1.1274086 -0.1473340 -0.1643465
[3,] -0.84966959  0.4419918 -0.968790494 -0.9000653  0.6839473  1.2117126
[4,] -0.89063254 -0.8549236 -0.771034230 -0.5456977  2.9096575 -1.2019367
[5,]  0.03316544  3.1724275  1.123120513  0.7368656 -0.7237286 -1.1892243
                                                  
[1,] -0.9317487 -1.164679251 -0.5490455  3.8286631
[2,] -0.2824207  0.139743912 -0.8651916  1.6939603
[3,]  0.9594948  0.802991219  4.1367085  3.7328098
[4,]  1.5207587  0.980652255 -0.9775498  1.8656989
[5,] -0.7814362 -0.007724828 -0.3478894 -0.6713824
[1] "mean of feat 2"
[1] -0.1220752
[1] "sd of feat 2"
[1] 1.164888
[1] "maxnum is "
[1] 5
[1] "# of genes left after filtering:"
[1]   61 6033
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
3647 3600 2941  914 1003 5159  610  735  966 1113 3002 3208 4073 4316 4331 5158 
  12   10    8    6    6    6    4    4    4    4    4    4    4    4    4    4 
 702 1444 1491 1720 1979 4538 
   2    2    2    2    2    2 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 6033    5
[1] 6033
[1] "DS index stage 1"
[1] 0.5
[1] "bestgenelist"
 [1]  478  610  694  735  914 1003 2941 3269 3414 3600 3647
                                                                               
[1,]  0.3523077 -0.9436425  3.418485  3.6118660 -0.6832863 -1.173464 -0.2274168
[2,] -0.8300460  1.1785517 -0.874537 -0.8149619  1.7123557 -1.048016  0.4726325
[3,] -0.2684535 -1.3201326 -0.495250 -0.8291011  1.0313727 -1.059599 -1.1636745
                                               
[1,]  1.5840453 1.3389177  2.9995593 -0.6064776
[2,] -0.4444882 0.9190061 -1.1621560  2.1909283
[3,] -1.1572130 0.2921515  0.4958446  1.4493698
                                                                      
[1,]  2.8785633  0.4530718 -0.9573321 -0.8645951 -0.7478173 -0.1275642
[2,] -0.8229654  0.4364162 -0.4752287 -0.5544799  1.0224178 -1.0379066
[3,] -0.4537037 -1.3101486 -0.8832488 -0.8250375 -1.1491934 -0.3221940
                                                          
[1,]  0.9749025 -0.9270340 -0.9275835 -0.9600797 0.4494994
[2,] -1.1416733 -0.9177115  0.9359531 -1.1504606 0.2482434
[3,]  0.1145004  0.2246608 -0.3545986  0.7498193 0.6337699
[1] "numgenes selected:11"
[1] "test acc:0.682926829268293"
[1] "test AUC acc:0.7175"
[1] "10 fold train88.5245901639344"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 36  0
         2  0 25
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 14 11
        2  2 14
[1] "train acc:1"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 36  0
         2  0 25
[1] "DS index stage 1"
[1] 0.5
[1] "KI index stage 1"
[1] 0.4995853
[[1]]
[1] "var478"  "var610"  "var694"  "var3600" "var3647"

[[2]]
[1] "var914"  "var1003" "var2941" "var3600" "var3647"

[[3]]
[1] "var694"  "var735"  "var3269" "var3414" "var3600"

[[4]]
[1] "var610"  "var914"  "var2941" "var3600" "var3647"

[[5]]
[1] "var478"  "var610"  "var2941" "var3600" "var3647"


 Iteration 1 :  Optimal value:  15.2 
 Optimal List:   var610,var914,var3600,var478,var2941 

 Iteration 2 :  Optimal value:  14.4 
 Optimal List:   var478,var914,var2941,var3600,var610 

 Iteration 3 :  Optimal value:  14 
 Optimal List:   var610,var914,var2941,var3600,var1003 

 Iteration 4 :  Optimal value:  13.6 
 Optimal List:   var610,var478,var2941,var3600,var694 

 Iteration 5 :  Optimal value:  12.8 
 Optimal List:   var610,var914,var2941,var3600,var3647 

 Iteration 6 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 7 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 8 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 9 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 10 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 11 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 12 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 
[1] "test acc rank aggreg CE:0.585365853658537"
[1] "test AUC acc rank aggreg CE:0.5925"
[1] "10 fold train rank aggreg res CE88.5245901639344"
[1] "confusion matrix train 10 fold rank aggreg CE"
            nci_y
pred10foldRA  1  2
           1 34  3
           2  2 22
[1] "Num itr RA CE"
[1] 12
[1] "Test BER aggreg CE is"
[1] 0.5925

 Iteration 1 :  Optimal value:  16 
 Optimal List:   var914,var610,var694,var478,var3647 

 Iteration 2 :  Optimal value:  15.6 
 Optimal List:   var610,var694,var914,var3600,var735 

 Iteration 3 :  Optimal value:  15.6 
 Optimal List:   var610,var694,var914,var3600,var735 

 Iteration 4 :  Optimal value:  14.8 
 Optimal List:   var478,var914,var610,var3600,var694 

 Iteration 5 :  Optimal value:  14.8 
 Optimal List:   var478,var914,var610,var3600,var694 

 Iteration 6 :  Optimal value:  14.4 
 Optimal List:   var694,var610,var2941,var3600,var1003 

 Iteration 7 :  Optimal value:  13.6 
 Optimal List:   var478,var2941,var610,var3600,var3647 

 Iteration 8 :  Optimal value:  13.6 
 Optimal List:   var478,var2941,var610,var3600,var3647 

 Iteration 9 :  Optimal value:  13.6 
 Optimal List:   var478,var610,var2941,var3600,var1003 

 Iteration 10 :  Optimal value:  13.6 
 Optimal List:   var478,var610,var2941,var3600,var1003 

 Iteration 11 :  Optimal value:  13.6 
 Optimal List:   var478,var610,var2941,var3600,var1003 

 Iteration 12 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 13 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 14 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 15 :  Optimal value:  12.8 
 Optimal List:   var610,var478,var2941,var3600,var3647 

 Iteration 16 :  Optimal value:  12.8 
 Optimal List:   var610,var914,var2941,var3600,var3647 

 Iteration 17 :  Optimal value:  12.8 
 Optimal List:   var610,var478,var2941,var3600,var3647 

 Iteration 18 :  Optimal value:  12.8 
 Optimal List:   var610,var478,var2941,var3600,var3647 

 Iteration 19 :  Optimal value:  12.8 
 Optimal List:   var610,var478,var2941,var3600,var3647 

 Iteration 20 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 21 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 22 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 23 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 24 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 25 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 26 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 27 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 28 :  Optimal value:  12.8 
 Optimal List:   var610,var914,var2941,var3600,var3647 

 Iteration 29 :  Optimal value:  12.8 
 Optimal List:   var610,var914,var2941,var3600,var3647 

 Iteration 30 :  Optimal value:  12.8 
 Optimal List:   var610,var914,var2941,var3600,var3647 

 Iteration 31 :  Optimal value:  12.8 
 Optimal List:   var610,var478,var2941,var3600,var3647 

 Iteration 32 :  Optimal value:  12.8 
 Optimal List:   var610,var478,var2941,var3600,var3647 

 Iteration 33 :  Optimal value:  12.8 
 Optimal List:   var610,var914,var2941,var3600,var3647 

 Iteration 34 :  Optimal value:  12.8 
 Optimal List:   var610,var478,var2941,var3600,var3647 

 Iteration 35 :  Optimal value:  12.8 
 Optimal List:   var610,var914,var2941,var3600,var3647 

 Iteration 36 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 37 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 38 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 39 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 40 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 41 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 42 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 43 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 44 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 45 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 46 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 47 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 48 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 49 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 50 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 51 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 52 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 53 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 54 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 55 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 56 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 57 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 58 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 59 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 60 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 61 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 62 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 63 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 64 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 

 Iteration 65 :  Optimal value:  12.4 
 Optimal List:   var478,var610,var2941,var3600,var3647 
[1] "test acc rank aggreg GA:0.585365853658537"
[1] "test AUC acc rank aggreg GA:0.5925"
[1] "10 fold train rank aggreg res GA85.2459016393443"
[1] "confusion matrix train 10 fold rank aggreg GA"
            nci_y
pred10foldRA  1  2
           1 34  3
           2  2 22
[1] "Num itr RA GA"
[1] 66
[1] "Test BER aggreg GA is"
[1] 0.5925
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 61 11
> 
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=5,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.01,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=0.8))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 5"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.7"
[1] "weightB: 0.2"
[1] "weightC: 0.05"
[1] "weightD: 0.05"
[1] "featweight.max: 0.01"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.45"
[1] "confusionprob: 0.2"
[1] "leaderprob: 0.25"
[1] "wmax: 1"
[1] "wmin: 1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 5"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 1"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 86.88525
[1] "here"
[1] "s"
[1] 48.8
[1] 61 11
[1] 10
[1] "learning sets: 1"
 [1] 33 53 59 24 17 35  8 14 47  4 30 16 38  7 10 51 52 60 27 43  6 39 46 20  9
[26] 11 32 37 12 22 31 25 36 54 21 55 44  3 34 57 29 49 18 58 19 13 40 48
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -29.47725
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -34.49542
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -36.06081
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 0 0
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "Best fitness updated to:"
[1] -38.02414
[1] "Best solution:"
 [1] 1 1 1 0 1 1 1 1 1 1 1
[1] 10
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "Best fitness updated to:"
[1] -38.44453
[1] "Best solution:"
 [1] 0 0 1 0 1 0 1 0 0 1 1
[1] 5
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "Best fitness updated to:"
[1] -38.97048
[1] "Best solution:"
 [1] 1 1 0 0 1 0 1 1 0 1 1
[1] 7
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 9
 [1] 1 4 2 3 2 1 2 4 2 2 2 3 3 2 1 2 3 1 2 2
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 9
[1] "No change for 6 iterations. Exiting PSO."
[1]  5  6  7  9 11
[1] 1
[1] "##################################"
[1] "Results summary for itr:1"
[1] "number of features selected using population mean"
[1] 5
[1] "number of features selected using current global best"
[1] 5
[1] "feat ind length"
[1] 5
[1] "best accuracy"
[1] 38.97048
[1] "test acc:0.846153846153846"
[1] "##################################"
[1] "learning sets: 2"
 [1] 60 26 18  4 59  3  1 42 13 39 23 21 48 19 36 58  8 11 25 53  5 32 61 17 20
[26] 28 14 56 33 37 40  9  2 43 41 27 38 31 50 35 49 55 46 29 57 51 34 52
[1] "Starting global iteration number : 2"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -41.2446
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -48.61182
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -49.7638
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 0 0
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "Best fitness updated to:"
[1] -55.83805
[1] "Best solution:"
 [1] 0 1 0 0 1 1 0 0 0 1 1
[1] 5
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 10
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 9
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 8
[1] "No change for 6 iterations. Exiting PSO."
[1]  1  2  5 10
[1] 2
[1] "##################################"
[1] "Results summary for itr:2"
[1] "number of features selected using population mean"
[1] 4
[1] "number of features selected using current global best"
[1] 4
[1] "feat ind length"
[1] 4
[1] "best accuracy"
[1] 55.83805
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 3"
 [1] 54 25 58 45 13 43 53 31  1 35 38 56 28  9 48 30 55 49  2 40 41  4 57 46 47
[26] 16 24 10 27 12 23 20 22 18 29  6 21  5  8 59 32 42 26 11 37  3 50 36
[1] "Starting global iteration number : 3"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -36.21021
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -41.10046
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -41.41111
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 0 1 1
[1] 7
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -44.28136
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 1 1 1
[1] 8
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -45.59106
[1] "Best solution:"
 [1] 1 1 1 0 0 1 1 0 1 1 1
[1] 8
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -46.46324
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 1 1 1
[1] 8
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 9
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 9
[1] "No change for 6 iterations. Exiting PSO."
[1]  1  2  4  6  9 10 11
[1] 3
[1] "##################################"
[1] "Results summary for itr:3"
[1] "number of features selected using population mean"
[1] 7
[1] "number of features selected using current global best"
[1] 7
[1] "feat ind length"
[1] 7
[1] "best accuracy"
[1] 46.46324
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 4"
 [1] 24 37 54 57 55 13 33 28  4 52 34 31  3 47 14 30 15 25  7 26 38 50 22 51  9
[26]  8 56 39 35 12 49 16 18  5 23 48 29  2 10 60 46 20 32 27 45 58 44 59
[1] "Starting global iteration number : 4"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -35.68784
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -44.17314
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -46.14435
[1] "Best solution:"
 [1] 0 0 0 1 0 1 1 0 0 1 1
[1] 5
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -46.52377
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 1 1 1
[1] 5
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "Best fitness updated to:"
[1] -47.68482
[1] "Best solution:"
 [1] 0 1 0 0 1 0 0 0 0 1 0
[1] 3
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 9
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 8
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 6
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 7
[1] "No change for 6 iterations. Exiting PSO."
[1]  1  2  6  9 10 11
[1] 4
[1] "##################################"
[1] "Results summary for itr:4"
[1] "number of features selected using population mean"
[1] 6
[1] "number of features selected using current global best"
[1] 6
[1] "feat ind length"
[1] 6
[1] "best accuracy"
[1] 47.68482
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 5"
 [1] 56 19  1 55 33 25 17  2 39 46 58 26 27  4 57 28 60 32 53 37 14 21 12  3 52
[26] 59 41  5 42 36 50  6  8 29 31 16 38 44 22 13 11 49 24 61 48 34  7 47
[1] "Starting global iteration number : 5"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -25.28489
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -40.71052
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -42.69051
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 0 0
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -45.28138
[1] "Best solution:"
 [1] 0 1 0 0 1 1 1 0 0 1 0
[1] 5
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "Best fitness updated to:"
[1] -46.82818
[1] "Best solution:"
 [1] 1 1 0 0 1 1 0 0 0 1 1
[1] 6
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -49.02065
[1] "Best solution:"
 [1] 0 1 0 0 0 1 0 0 0 0 0
[1] 2
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "Best fitness updated to:"
[1] -55.37769
[1] "Best solution:"
 [1] 1 0 1 1 1 1 0 0 1 1 1
[1] 8
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 8
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 8
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 8
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 8
 [1] 1 4 2 3 2 1 2 4 2 2 2 3 3 2 1 2 3 1 2 2
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 7
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 7
[1] "No change for 6 iterations. Exiting PSO."
[1]  2  5 11
[1] 5
[1] "##################################"
[1] "Results summary for itr:5"
[1] "number of features selected using population mean"
[1] 3
[1] "number of features selected using current global best"
[1] 3
[1] "feat ind length"
[1] 3
[1] "best accuracy"
[1] 55.37769
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 6"
 [1] 61  1 40 57  4 59 50 34 56 52 27  8 30 55  3 42 45 35 51 37 33 19  9 38 26
[26] 58  5 24 49 44 25 46 14  6 23 53 39 47 48  7 54 17 32 11 13 29 20 10
[1] "Starting global iteration number : 6"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -43.9726
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -46.9305
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -49.25673
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 0 0
[1] 4
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -49.64934
[1] "Best solution:"
 [1] 0 1 1 0 1 1 1 1 0 1 1
[1] 8
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "Best fitness updated to:"
[1] -50.28854
[1] "Best solution:"
 [1] 1 1 0 1 0 1 0 1 1 0 0
[1] 6
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "Best fitness updated to:"
[1] -51.9723
[1] "Best solution:"
 [1] 1 1 0 1 0 1 1 0 1 1 1
[1] 8
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 11
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 11
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 9
[1] "No change for 6 iterations. Exiting PSO."
[1]  1  2  6  9 10 11
[1] 6
[1] "##################################"
[1] "Results summary for itr:6"
[1] "number of features selected using population mean"
[1] 6
[1] "number of features selected using current global best"
[1] 6
[1] "feat ind length"
[1] 6
[1] "best accuracy"
[1] 51.9723
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 7"
 [1]  5 46 20 14 48 49 44 13 51 43 18 57 33 10  4 39 37  7 40 36 19 31 17 45 26
[26] 28 21 42 47 54  6 38  8 15 55 60 53 22 58 35 24  9 16 27  3 34 25 50
[1] "Starting global iteration number : 7"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -29.40579
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -33.16319
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -35.986
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 0 0
[1] 4
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "Best fitness updated to:"
[1] -37.82281
[1] "Best solution:"
 [1] 1 0 1 1 0 1 1 0 0 0 1
[1] 6
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "Best fitness updated to:"
[1] -39.17066
[1] "Best solution:"
 [1] 0 1 0 0 1 1 1 0 0 1 0
[1] 5
[1] "iteration number: "
[1] 41
[1] "Best fitness updated to:"
[1] -40.24808
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 0 1 1
[1] 4
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 10
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 10
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 10
[1] "No change for 6 iterations. Exiting PSO."
[1]  2  5 10
[1] 7
[1] "##################################"
[1] "Results summary for itr:7"
[1] "number of features selected using population mean"
[1] 3
[1] "number of features selected using current global best"
[1] 3
[1] "feat ind length"
[1] 3
[1] "best accuracy"
[1] 40.24808
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 8"
 [1] 57 21 61 49 23 36 51 48 38 27 20 47  6 25 34 37 15 59 46 56 53 31 40 13 58
[26] 39 35 24 22 54 29 12 14 32 50 45 42 18 60 43  7 19  2 33  9 44 55  4
[1] "Starting global iteration number : 8"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -24.31567
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -41.14416
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -47.76787
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 0 0
[1] 4
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 9
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 10
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 10
[1] "No change for 6 iterations. Exiting PSO."
[1]  4  5  6  7 10 11
[1] 8
[1] "##################################"
[1] "Results summary for itr:8"
[1] "number of features selected using population mean"
[1] 6
[1] "number of features selected using current global best"
[1] 6
[1] "feat ind length"
[1] 6
[1] "best accuracy"
[1] 47.76787
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 9"
 [1] 17 43 36 29  4  7 26 44 34  9 10 14 48 21 33  1 38 42 52 16 60 61 45 53 40
[26] 24 27 32 11 15 20 56 19 18 57 39 41 54 35 37 25 12  5  6 31 22 51  2
[1] "Starting global iteration number : 9"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -27.80682
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -36.10601
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -36.42021
[1] "Best solution:"
 [1] 1 0 0 0 0 0 0 0 0 1 0
[1] 2
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -39.0619
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 1 1 1
[1] 7
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "Best fitness updated to:"
[1] -42.0974
[1] "Best solution:"
 [1] 0 1 1 0 1 1 0 1 0 1 1
[1] 7
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "Best fitness updated to:"
[1] -48.54486
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 1 0 0
[1] 2
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "Best fitness updated to:"
[1] -50.37116
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 0 0 0 1
[1] 4
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 8
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 8
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 8
[1] "No change for 6 iterations. Exiting PSO."
[1]  2  3  4  5 11
[1] 9
[1] "##################################"
[1] "Results summary for itr:9"
[1] "number of features selected using population mean"
[1] 5
[1] "number of features selected using current global best"
[1] 5
[1] "feat ind length"
[1] 5
[1] "best accuracy"
[1] 50.37116
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 10"
 [1] 33 34  7 25 41 40 52 45 39 58 26 31 32  5 35 29 44 43 16 23 56  6 28 24 55
[26] 47 18 30  8 10 37 15 57 59  9 22 42 53 17  4 19  2 61 13 48  3 50 36
[1] "Starting global iteration number : 10"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -30.11269
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -41.42655
[1] "Best solution:"
 [1] 1 0 1 0 0 1 1 1 1 1 1
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -43.18149
[1] "Best solution:"
 [1] 1 0 0 0 0 0 1 1 1 1 1
[1] 6
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -45.17964
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 0 0
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "Best fitness updated to:"
[1] -49.1015
[1] "Best solution:"
 [1] 0 0 1 1 1 0 0 1 1 0 1
[1] 6
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -52.2897
[1] "Best solution:"
 [1] 0 0 1 1 1 0 1 0 0 1 1
[1] 6
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "Best fitness updated to:"
[1] -53.72291
[1] "Best solution:"
 [1] 1 1 1 0 1 0 1 0 0 1 1
[1] 7
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "Best fitness updated to:"
[1] -54.04582
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 0 1 1
[1] 4
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "Best fitness updated to:"
[1] -54.99043
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 0 1 1 1
[1] 6
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "Best fitness updated to:"
[1] -55.20866
[1] "Best solution:"
 [1] 1 1 0 0 1 0 0 0 0 0 1
[1] 4
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
 [1] 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2 3 3
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
 [1] 2 1 4 4 3 3 4 2 1 3 4 1 1 4 2 3 3 1 3 2
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 8
 [1] 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3 3 2 2 2 1
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 9
 [1] 2 2 1 2 1 3 2 2 2 2 2 3 1 3 2 2 1 3 1 2
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 11
[1] "No change for 6 iterations. Exiting PSO."
[1]  2  5  9 11
[1] 10
[1] "##################################"
[1] "Results summary for itr:10"
[1] "number of features selected using population mean"
[1] 4
[1] "number of features selected using current global best"
[1] 4
[1] "feat ind length"
[1] 4
[1] "best accuracy"
[1] 55.20866
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "testacc"
 [1] 0.8461538 1.0000000 0.9230769 0.9230769 1.0000000 1.0000000 0.9230769
 [8] 0.9230769 1.0000000 0.9230769
[1] 0.9461538
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8462  0.9231  0.9231  0.9462  1.0000  1.0000 
[1] 0.05191912
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    1    1    1    0    1    0    0    0     0
 [2,]    0    1    1    1    1    1    1    0    1     1
 [3,]    0    0    0    0    0    0    0    0    1     0
 [4,]    0    0    1    0    0    0    0    1    1     0
 [5,]    1    1    0    0    1    0    1    1    1     1
 [6,]    1    0    1    1    0    1    0    1    0     0
 [7,]    1    0    0    0    0    0    0    1    0     0
 [8,]    0    0    0    0    0    0    0    0    0     0
 [9,]    1    0    1    1    0    1    0    0    0     1
[10,]    0    1    1    1    0    1    1    1    0     0
[11,]    1    0    1    1    1    1    0    1    1     1
[1] "dim of scoring matrix is "
[1] 11 10
[1] "DS index stage 2"
[1] 0.5496407
[1] "KI index stage 2"
[1] -Inf
[1] 1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.000   2.500   5.000   4.455   6.500   8.000 
[1] "Number of features selected in 1 iterations:"
[1] 10
[1] "Number of features selected in 1 iterations:"
[1] 10
[1] 0.9722222 0.8800000
[1] 0.9722222 0.8800000
[1] "accuracy: 78.8453808415709 num_feat:10 fitness:37.0128821708226"
$fitfunc
[1] -37.01288

$cverror
[1] 78.84538

$cvpermerror
[1] 64.91803

$testacc
[1] 98

$reverseacc
[1] 92.61111

[1] -37.01288
[1] "Number of features selected in 2 iterations:"
[1] 9
[1] 0.9722222 0.9200000
[1] 0.9722222 0.9200000
[1] "accuracy: 80.7553246229056 num_feat:9 fitness:38.6516935866124"
$fitfunc
[1] -38.65169

$cverror
[1] 80.75532

$cvpermerror
[1] 64.89596

$testacc
[1] 98

$reverseacc
[1] 94.61111

[1] -38.65169
[1] "Number of features selected in 3 iterations:"
[1] 8
[1] 0.9722222 0.8800000
[1] 0.9722222 0.8800000
[1] "accuracy: 82.6946654391376 num_feat:8 fitness:38.1831109508243"
$fitfunc
[1] -38.18311

$cverror
[1] 82.69467

$cvpermerror
[1] 67.63024

$testacc
[1] 98

$reverseacc
[1] 92.61111

[1] -38.18311
[1] "Number of features selected in 4 iterations:"
[1] 7
[1] 0.9444444 0.9600000
[1] 0.9444444 0.9600000
[1] "accuracy: 86.5568150114439 num_feat:7 fitness:40.3862082190564"
$fitfunc
[1] -40.38621

$cverror
[1] 86.55682

$cvpermerror
[1] 68.54053

$testacc
[1] 96.61111

$reverseacc
[1] 95.22222

[1] -40.38621
[1] "Number of features selected in 5 iterations:"
[1] 6
[1] 0.9444444 0.9600000
[1] 0.9444444 0.9600000
[1] "accuracy: 84.9288464830353 num_feat:6 fitness:37.7949894913339"
$fitfunc
[1] -37.79499

$cverror
[1] 84.92885

$cvpermerror
[1] 70.62789

$testacc
[1] 96.61111

$reverseacc
[1] 95.22222

[1] -37.79499
[1] "Number of features selected in 6 iterations:"
[1] 4
[1] 0.9444444 0.9200000
[1] 0.9444444 0.9200000
[1] "accuracy: 86.4119011474114 num_feat:4 fitness:41.0129843275057"
$fitfunc
[1] -41.01298

$cverror
[1] 86.4119

$cvpermerror
[1] 67.3398

$testacc
[1] 95.22222

$reverseacc
[1] 93.22222

[1] -41.01298
[1] "Number of features selected in 7 iterations:"
[1] 3
[1] 0.9444444 0.9200000
[1] 0.9444444 0.9200000
[1] "accuracy: 92.9404826421079 num_feat:3 fitness:37.8687364135397"
$fitfunc
[1] -37.86874

$cverror
[1] 92.94048

$cvpermerror
[1] 78.95636

$testacc
[1] 95.22222

$reverseacc
[1] 93.22222

[1] -37.86874
[1] "Number of features selected in 8 iterations:"
[1] 2
[1] "accuracy: 1 num_feat:2 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
[1] "Number of features selected in 9 iterations:"
[1] 0
[1] "accuracy: 1 num_feat:0 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
[1] "Number of features selected in 10 iterations:"
[1] 0
[1] "accuracy: 1 num_feat:0 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8462  0.9231  0.9231  0.9462  1.0000  1.0000 
[1] "Number of features selected in 1 iterations:"
[1] 10
[1] "Modified train 10 fold accuracy using train data is "
[1] 86.88525
[1] "Modified train accuracy is "
[1] 0.9836066
[1] "train confusion matrix is "
          trainclass
pred_train  1  2
         1 36  1
         2  0 24
[1] "Train dimension is "
[1] 61 10
[1] "Test dimension is "
[1] 41 10
[1] "Test confusion matrix is "
    
pred  1  2
   1 14 10
   2  2 15
[1] "Test acc is "
[1] 0.7073171
[1] "train 10 fold"
[1] 85.2459
[1] "Test confusion matrix is "
    
pred  1  2
   1 14 10
   2  2 15
[1] "Test acc is "
[1] 0.7073171
[1] "Test AUC:"
[1] 0.7375
[1] "Train acc is "
[1] 0.9836066
[1] "# of features after CMA:"
NULL
[1] "# of features after PSO:"
[1] 61 11
    user   system  elapsed 
 152.935    9.970 4456.823 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> 
> 
> feat_ind<-psores$bestfeatlist
> feat_names<-psores$bestfeatnames
> 
> scoringmatrix<-as.data.frame(psores$scoringmatrix)
> print(scoringmatrix)
   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
1   0  1  1  1  0  1  0  0  0   0
2   0  1  1  1  1  1  1  0  1   1
3   0  0  0  0  0  0  0  0  1   0
4   0  0  1  0  0  0  0  1  1   0
5   1  1  0  0  1  0  1  1  1   1
6   1  0  1  1  0  1  0  1  0   0
7   1  0  0  0  0  0  0  1  0   0
8   0  0  0  0  0  0  0  0  0   0
9   1  0  1  1  0  1  0  0  0   1
10  0  1  1  1  0  1  1  1  0   0
11  1  0  1  1  1  1  0  1  1   1
> print(feat_names[feat_ind])
 [1] "V1"  "V2"  "V3"  "V4"  "V5"  "V6"  "V7"  "V9"  "V10" "V11"
> 
> save(psores,file="psores.Rda")
> print("Complete")
[1] "Complete"
> 
