
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/kuppal3/karan_libs/Rlibs")
> library(snow)
Warning message:
package ‘snow’ was built under R version 3.2.5 
> library(e1071)
Warning message:
package ‘e1071’ was built under R version 3.2.5 
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

Warning message:
package ‘pROC’ was built under R version 3.2.5 
> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
Warning message:
package ‘RankAggreg’ was built under R version 3.2.5 
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

Warning message:
package ‘CMA’ was built under R version 3.2.4 
> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

Warning messages:
1: package ‘expm’ was built under R version 3.2.5 
2: package ‘Matrix’ was built under R version 3.2.5 
> 
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> 
> dirloc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/"
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/versionnov2014/OCFS_",args[9],".R",sep="")
> 
> sname<-paste(dirloc,"version2017/OCFS_",args[9],".R",sep="")
> source(sname)
> 
> outloc<-paste(dirloc,"/Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCER",args[9],"/",sep="")
> 
> 
> sname<-paste(dirloc,"Datasets/MAQCII_BreastCancer/MaqcIIbr.Rda",sep="")
> load(sname)
> 
> trainm<-MaqcIIbr$trainx
> testm<-MaqcIIbr$testx
> trainclass<-MaqcIIbr$trainER #PCRvsRD
> testclass<-MaqcIIbr$testER #PCRvsRD
> 
> trainm<-trainm[,-c(22284)]
> testm<-testm[,-c(22284)]
> trainm<-apply(trainm,2,as.numeric)
> testm<-apply(testm,2,as.numeric)
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvjune102018_v1' already exists
> setwd(outloc)
> 
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvjune102018_v1' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> print("max num")
[1] "max num"
> print(as.numeric(args[10]))
[1] 10
> 
> #if(FALSE)
> {
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  3490  4035  4752  9092  9093  9094 12339 12343 13543 15240
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.0638     10.1763   13.0759     11.1535   10.5793     14.3763
[2,]   11.3553      9.3275   13.7616     10.8437   10.5772     14.0214
[3,]   12.3832      9.9200   12.7360     10.7019   11.1181     14.5222
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.3600   10.8422     12.6474     12.6194
[2,]   13.2925   10.5720     11.7852     11.5534
[3,]   12.3582    9.8482     12.7464     12.7285
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.4052      9.8038   13.8754     11.9413   11.9790     15.0625
[2,]   10.4033      7.9689   11.7217     11.0319   10.8744     14.4978
[3,]    9.8307      7.6789   10.9960      8.8487    8.0211     12.4583
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.5201   11.4301     12.7392     12.5744
[2,]   12.5480   10.2569     10.9092     11.0575
[3,]   11.2917    9.3181     10.6696     11.0769
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.87494745691467"
[1] "10 fold train92.3076923076923"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 44  2
         2  6 78
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  9
        2  4 52
[1] "train acc:0.938461538461538"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 44  2
         2  6 78
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
Loaded glmnet 2.0-10


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
    1  4752 15102  4035     2     3     4  9093     5 12339  3155     6  7147 
   10    10    10     9     8     7     7     7     6     5     4     3     3 
13819 10447 17203     7  1511  9279 11605 
    3     2     2     1     1     1     1 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]     1     2     3     4     5  4035  4752  9093 12339 15102
     1007_s_at 1053_at 117_at  121_at 1255_g_at 204508_s_at 205225_at 209603_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064     10.1763   13.0759   10.5793
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582      9.3275   13.7616   10.5772
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332      9.9200   12.7360   11.1181
     212956_at 215729_s_at
[1,]   13.3600      2.9565
[2,]   13.2925      1.5807
[3,]   12.3582      5.6368
     1007_s_at 1053_at 117_at  121_at 1255_g_at 204508_s_at 205225_at 209603_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327      9.8038   13.8754   11.9790
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568      7.9689   11.7217   10.8744
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579      7.6789   10.9960    8.0211
     212956_at 215729_s_at
[1,]   13.5201      1.9565
[2,]   12.5480      5.3426
[3,]   11.2917      5.3609
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.870323665405633"
[1] "10 fold train94.6153846153846"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 49  0
         2  1 80
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 34  8
        2  5 53
[1] "train acc:0.992307692307692"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 49  0
         2  1 80
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  4035  4536  4556  4752  4967  6280  6325  8667 12583 15102
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]     10.1763   13.2850      2.9025   13.0759      8.6216     12.4854
[2,]      9.3275   14.4107      2.2747   13.7616     10.7598     10.5188
[3,]      9.9200   14.7836      0.9203   12.7360      7.7832     11.6232
     206799_at 209173_at 213201_s_at 215729_s_at
[1,]    3.1490   12.9392      4.2884      2.9565
[2,]   14.9688   14.1501      4.8678      1.5807
[3,]   11.6974   14.5585      8.3652      5.6368
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]      9.8038   14.3747      3.0068   13.8754     10.5785     11.4867
[2,]      7.9689   11.2149      3.3895   11.7217      8.5134      7.4297
[3,]      7.6789    9.8209      4.9401   10.9960      9.3702      5.9013
     206799_at 209173_at 213201_s_at 215729_s_at
[1,]    7.9310   13.2041      7.5478      1.9565
[2,]   10.6196   11.3631      5.0501      5.3426
[3,]    6.2148   11.1800      5.0025      5.3609
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.87494745691467"
[1] "10 fold train96.1538461538462"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 48  0
         2  2 80
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  9
        2  4 52
[1] "train acc:0.984615384615385"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 48  0
         2  2 80
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]    1    2    3    4    5    6    7 4035 4752 9093
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 204508_s_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356     10.1763
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581      9.3275
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061      9.9200
     205225_at 209603_at
[1,]   13.0759   10.5793
[2,]   13.7616   10.5772
[3,]   12.7360   11.1181
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 204508_s_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327  9.2305  8.1481      9.8038
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568  9.1180  8.3105      7.9689
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579  9.3514  8.1214      7.6789
     205225_at 209603_at
[1,]   13.8754   11.9790
[2,]   11.7217   10.8744
[3,]   10.9960    8.0211
[1] "numgenes selected:10"
[1] "test acc:0.89"
[1] "test AUC acc:0.886717108028583"
[1] "10 fold train92.3076923076923"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 46  0
         2  4 80
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 34  6
        2  5 55
[1] "train acc:0.969230769230769"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 46  0
         2  4 80
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  3490  4035  4752  9092  9093  9094 12339 12343 13543 15240
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.0638     10.1763   13.0759     11.1535   10.5793     14.3763
[2,]   11.3553      9.3275   13.7616     10.8437   10.5772     14.0214
[3,]   12.3832      9.9200   12.7360     10.7019   11.1181     14.5222
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.3600   10.8422     12.6474     12.6194
[2,]   13.2925   10.5720     11.7852     11.5534
[3,]   12.3582    9.8482     12.7464     12.7285
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.4052      9.8038   13.8754     11.9413   11.9790     15.0625
[2,]   10.4033      7.9689   11.7217     11.0319   10.8744     14.4978
[3,]    9.8307      7.6789   10.9960      8.8487    8.0211     12.4583
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.5201   11.4301     12.7392     12.5744
[2,]   12.5480   10.2569     10.9092     11.0575
[3,]   11.2917    9.3181     10.6696     11.0769
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.87494745691467"
[1] "10 fold train92.3076923076923"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 44  2
         2  6 78
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  9
        2  4 52
[1] "train acc:0.938461538461538"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 44  2
         2  6 78
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
There were 33 warnings (use warnings() to see them)
> 
> 
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
    1  4752 15102  4035     2     3     4  9093     5 12339  3155     6  7147 
   10    10    10     9     8     7     7     7     6     5     4     3     3 
13819 10447 17203     7  1511  9279 11605 
    3     2     2     1     1     1     1 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     5
[1] 22283
[1] "DS index stage 1"
[1] 0.41
[1] "bestgenelist"
 [1]     1     2     3     4     5     6     7  3490  4035  4536  4556  4752
[13]  4967  6280  6325  8667  9092  9093  9094 12339 12343 12583 13543 15102
[25] 15240
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 203963_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356   12.0638
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581   11.3553
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061   12.3832
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]     10.1763   13.2850      2.9025   13.0759      8.6216     12.4854
[2,]      9.3275   14.4107      2.2747   13.7616     10.7598     10.5188
[3,]      9.9200   14.7836      0.9203   12.7360      7.7832     11.6232
     206799_at 209173_at 209602_s_at 209603_at 209604_s_at 212956_at 212960_at
[1,]    3.1490   12.9392     11.1535   10.5793     14.3763   13.3600   10.8422
[2,]   14.9688   14.1501     10.8437   10.5772     14.0214   13.2925   10.5720
[3,]   11.6974   14.5585     10.7019   11.1181     14.5222   12.3582    9.8482
     213201_s_at 214164_x_at 215729_s_at 215867_x_at
[1,]      4.2884     12.6474      2.9565     12.6194
[2,]      4.8678     11.7852      1.5807     11.5534
[3,]      8.3652     12.7464      5.6368     12.7285
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 203963_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327  9.2305  8.1481   12.4052
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568  9.1180  8.3105   10.4033
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579  9.3514  8.1214    9.8307
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]      9.8038   14.3747      3.0068   13.8754     10.5785     11.4867
[2,]      7.9689   11.2149      3.3895   11.7217      8.5134      7.4297
[3,]      7.6789    9.8209      4.9401   10.9960      9.3702      5.9013
     206799_at 209173_at 209602_s_at 209603_at 209604_s_at 212956_at 212960_at
[1,]    7.9310   13.2041     11.9413   11.9790     15.0625   13.5201   11.4301
[2,]   10.6196   11.3631     11.0319   10.8744     14.4978   12.5480   10.2569
[3,]    6.2148   11.1800      8.8487    8.0211     12.4583   11.2917    9.3181
     213201_s_at 214164_x_at 215729_s_at 215867_x_at
[1,]      7.5478     12.7392      1.9565     12.5744
[2,]      5.0501     10.9092      5.3426     11.0575
[3,]      5.0025     10.6696      5.3609     11.0769
[1] "numgenes selected:25"
[1] "test acc:0.87"
[1] "test AUC acc:0.865699873896595"
[1] "10 fold train95.3846153846154"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 49  1
         2  1 79
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 33  7
        2  6 54
[1] "train acc:0.984615384615385"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 49  1
         2  1 79
[1] "DS index stage 1"
[1] 0.41
[1] "KI index stage 1"
[1] 0.4097351
[[1]]
 [1] "var3490"  "var4035"  "var4752"  "var9092"  "var9093"  "var9094" 
 [7] "var12339" "var12343" "var13543" "var15240"

[[2]]
 [1] "var1"     "var2"     "var3"     "var4"     "var5"     "var4035" 
 [7] "var4752"  "var9093"  "var12339" "var15102"

[[3]]
 [1] "var4035"  "var4536"  "var4556"  "var4752"  "var4967"  "var6280" 
 [7] "var6325"  "var8667"  "var12583" "var15102"

[[4]]
 [1] "var1"    "var2"    "var3"    "var4"    "var5"    "var6"    "var7"   
 [8] "var4035" "var4752" "var9093"

[[5]]
 [1] "var3490"  "var4035"  "var4752"  "var9092"  "var9093"  "var9094" 
 [7] "var12339" "var12343" "var13543" "var15240"


 Iteration 1 :  Optimal value:  58.8 
 Optimal List:   var1,var3490,var3,var4035,var4967,var2,var9093,var13543,var4752,var12339 

 Iteration 2 :  Optimal value:  58.8 
 Optimal List:   var4035,var9094,var9093,var1,var4752,var3,var4536,var4,var12339,var3490 

 Iteration 3 :  Optimal value:  56.8 
 Optimal List:   var4035,var4967,var4752,var3490,var3,var9093,var4,var1,var12339,var5 

 Iteration 4 :  Optimal value:  55.2 
 Optimal List:   var2,var4035,var4752,var9093,var9092,var1,var12339,var13543,var4556,var7 

 Iteration 5 :  Optimal value:  55.2 
 Optimal List:   var3490,var4035,var9093,var4752,var2,var12339,var4,var9094,var8667,var4967 

 Iteration 6 :  Optimal value:  53.6 
 Optimal List:   var4035,var4752,var3490,var2,var9093,var9094,var5,var9092,var12343,var15102 

 Iteration 7 :  Optimal value:  53.2 
 Optimal List:   var3490,var4035,var4752,var2,var5,var9092,var1,var4,var12339,var13543 

 Iteration 8 :  Optimal value:  53.6 
 Optimal List:   var4035,var2,var4752,var3490,var1,var4,var3,var12343,var12339,var13543 

 Iteration 9 :  Optimal value:  53.2 
 Optimal List:   var4035,var2,var4752,var4,var9092,var9093,var3490,var9094,var1,var6 

 Iteration 10 :  Optimal value:  53.2 
 Optimal List:   var4035,var2,var4752,var4,var9093,var5,var12339,var4536,var13543,var15240 

 Iteration 11 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var4,var3,var9094,var12339,var9093,var2,var5 

 Iteration 12 :  Optimal value:  52.4 
 Optimal List:   var4035,var3490,var4752,var2,var9093,var4,var9094,var12339,var3,var6 

 Iteration 13 :  Optimal value:  52 
 Optimal List:   var4035,var1,var2,var4752,var9092,var9093,var9094,var12339,var13543,var3 

 Iteration 14 :  Optimal value:  52 
 Optimal List:   var4035,var1,var4752,var2,var9093,var5,var3490,var12339,var13543,var15240 

 Iteration 15 :  Optimal value:  52 
 Optimal List:   var4035,var2,var4752,var1,var5,var9092,var9093,var12339,var12343,var15240 

 Iteration 16 :  Optimal value:  52 
 Optimal List:   var4035,var1,var4752,var2,var9093,var3,var9094,var12339,var4,var15240 

 Iteration 17 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var2,var9092,var9093,var4,var12339,var12343,var15240 

 Iteration 18 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var3,var9093,var9094,var12339,var9092,var13543,var15240 

 Iteration 19 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var2,var3,var9094,var12339,var9093,var12343,var13543 
[1] "test acc rank aggreg CE:0.87"
[1] "test AUC acc rank aggreg CE:0.870323665405633"
[1] "10 fold train rank aggreg res CE93.0769230769231"
[1] "confusion matrix train 10 fold rank aggreg CE"
            nci_y
pred10foldRA  1  2
           1 46  2
           2  4 78
[1] "Num itr RA CE"
[1] 19
[1] "Test BER aggreg CE is"
[1] 0.8703237

 Iteration 1 :  Optimal value:  61.6 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var9093,var6280,var6325,var4536 

 Iteration 2 :  Optimal value:  61.2 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var9093,var6280,var6325,var15240 

 Iteration 3 :  Optimal value:  60.8 
 Optimal List:   var3490,var4035,var2,var5,var3,var9092,var9093,var6280,var6325,var4536 

 Iteration 4 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 5 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 6 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 7 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 8 :  Optimal value:  58 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var8667,var9093,var15240 

 Iteration 9 :  Optimal value:  58 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var8667,var9093,var15240 

 Iteration 10 :  Optimal value:  57.6 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var9093,var8667,var4,var15240 

 Iteration 11 :  Optimal value:  57.6 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var13543,var9093,var15240 

 Iteration 12 :  Optimal value:  58 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var8667,var9093,var15240 

 Iteration 13 :  Optimal value:  56.8 
 Optimal List:   var4035,var4752,var3,var4,var5,var1,var4556,var8667,var9093,var15240 

 Iteration 14 :  Optimal value:  56.8 
 Optimal List:   var4035,var4752,var3,var4,var5,var1,var4556,var8667,var9093,var15240 

 Iteration 15 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 16 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 17 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 18 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 19 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var15240 

 Iteration 20 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var4752,var5,var3,var1,var9092,var9093,var6325,var15240 

 Iteration 21 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var15240 

 Iteration 22 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 23 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 24 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 25 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 26 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 27 :  Optimal value:  54.8 
 Optimal List:   var3490,var2,var4752,var5,var4035,var3,var9092,var1,var9093,var4 

 Iteration 28 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var9092,var4752,var3,var2,var5,var1,var9093,var12583 

 Iteration 29 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var9092,var4752,var3,var2,var5,var1,var9093,var12583 

 Iteration 30 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var9092,var4752,var3,var2,var5,var1,var9093,var12583 

 Iteration 31 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var2,var9092,var4,var8667,var9093,var15240 

 Iteration 32 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var5,var2,var4,var8667,var9093,var15240 

 Iteration 33 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var9092,var4752,var5,var2,var3,var1,var9093,var15240 

 Iteration 34 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var9092,var4752,var5,var2,var3,var1,var9093,var15240 

 Iteration 35 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var3,var5,var2,var4752,var1,var9093,var15240 

 Iteration 36 :  Optimal value:  54.8 
 Optimal List:   var3490,var4752,var3,var4035,var5,var1,var9093,var2,var6325,var15240 

 Iteration 37 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 38 :  Optimal value:  54.4 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var9093,var2,var6325,var15240 

 Iteration 39 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 40 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var9092,var1,var9093,var15240 

 Iteration 41 :  Optimal value:  53.6 
 Optimal List:   var4035,var3490,var9092,var4752,var3,var2,var12339,var1,var9093,var12583 

 Iteration 42 :  Optimal value:  53.6 
 Optimal List:   var4035,var3490,var9092,var4752,var3,var2,var12339,var1,var9093,var12583 

 Iteration 43 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var4752,var5,var3,var1,var9092,var2,var9093,var15240 

 Iteration 44 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var9092,var1,var9093,var15240 

 Iteration 45 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var9092,var1,var9093,var15240 

 Iteration 46 :  Optimal value:  53.2 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var12339,var1,var9093,var15240 

 Iteration 47 :  Optimal value:  53.2 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var12339,var1,var9093,var15240 

 Iteration 48 :  Optimal value:  52.8 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var1,var9093,var15240 

 Iteration 49 :  Optimal value:  52.8 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var1,var9093,var15240 

 Iteration 50 :  Optimal value:  52.8 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var1,var9093,var15240 

 Iteration 51 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 52 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 53 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 54 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 55 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 56 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 57 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 58 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var12343,var9093,var15240 

 Iteration 59 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var12343,var9093,var15240 

 Iteration 60 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var12343,var9093,var15240 

 Iteration 61 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var3,var5,var2,var12339,var9094,var9093,var15240 

 Iteration 62 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var3,var5,var2,var12339,var9094,var9093,var15240 

 Iteration 63 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 64 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 65 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 66 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 67 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var9093,var1,var15240 

 Iteration 68 :  Optimal value:  52.4 
 Optimal List:   var4035,var3490,var4752,var3,var5,var2,var12339,var1,var9093,var15240 

 Iteration 69 :  Optimal value:  52.4 
 Optimal List:   var4035,var3490,var4752,var4,var3,var2,var12339,var9093,var1,var4536 

 Iteration 70 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var4,var4752,var1,var12339,var2,var9093,var15240 

 Iteration 71 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 72 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 73 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 74 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 75 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 76 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 77 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 78 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 79 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var15240 

 Iteration 80 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var9094 

 Iteration 81 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var9094 

 Iteration 82 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var9094 

 Iteration 83 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 84 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4752,var2,var1,var12339,var9093,var5,var6280 

 Iteration 85 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 86 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4,var4752,var2,var12339,var9093,var1,var15240 

 Iteration 87 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 88 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 89 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var12339,var9093,var5,var15240 

 Iteration 90 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 91 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 92 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 93 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 94 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 95 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 96 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 97 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var4 

 Iteration 98 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var4 

 Iteration 99 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var15240 

 Iteration 100 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var15240 

 Iteration 101 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var5,var9093,var12339,var15240 

 Iteration 102 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9093,var12339,var9092,var1,var4 

 Iteration 103 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var1,var9093,var15102 

 Iteration 104 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var12339,var9093,var5,var4967 

 Iteration 105 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4,var4752,var2,var12339,var9093,var1,var15240 

 Iteration 106 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4,var4752,var2,var12339,var9093,var1,var15240 

 Iteration 107 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 108 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 109 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 110 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 111 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var4 

 Iteration 112 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var4,var3,var2,var12339,var9093,var1,var15240 

 Iteration 113 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var12339,var9093,var5,var9094 

 Iteration 114 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 115 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 116 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var4 

 Iteration 117 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var5,var12339,var9093,var2,var4 

 Iteration 118 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var12339,var9093,var5,var1 

 Iteration 119 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var12339,var9093,var5,var1 

 Iteration 120 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var4 

 Iteration 121 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var2,var12339,var9093,var5,var15240 

 Iteration 122 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var2,var12339,var9093,var5,var15240 

 Iteration 123 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var2,var12339,var9093,var5,var15240 

 Iteration 124 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var12343 

 Iteration 125 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var9093,var12339,var1,var15240 

 Iteration 126 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var9093,var12339,var1,var15240 

 Iteration 127 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9093,var12339,var5,var2,var15240 

 Iteration 128 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9093,var12339,var5,var2,var15240 

 Iteration 129 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 130 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 131 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 132 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 133 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 134 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 135 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 136 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 137 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 138 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 139 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 140 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 141 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 142 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 143 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 144 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 145 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 146 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var9093,var12339,var1,var12343 

 Iteration 147 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9092,var12339,var9093,var2,var13543 

 Iteration 148 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 149 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 150 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 151 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9092,var12339,var9093,var2,var13543 

 Iteration 152 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 153 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 154 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 155 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 156 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var9093,var12339,var1,var13543 

 Iteration 157 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 158 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 159 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 160 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 161 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 162 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 163 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 164 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 165 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 166 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 167 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var9093,var5,var12339,var3,var2,var13543 

 Iteration 168 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 169 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 170 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 171 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 172 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 173 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 174 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9092,var3,var12339,var9093,var9094,var13543 

 Iteration 175 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var13543 

 Iteration 176 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var13543 

 Iteration 177 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var13543 

 Iteration 178 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 179 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 180 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9092,var9093,var12339,var3,var1,var13543 

 Iteration 181 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 182 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 183 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 184 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 185 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 186 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 187 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 
[1] "test acc rank aggreg GA:0.88"
[1] "test AUC acc rank aggreg GA:0.878520386717108"
[1] "10 fold train rank aggreg res GA93.8461538461538"
[1] "confusion matrix train 10 fold rank aggreg GA"
            nci_y
pred10foldRA  1  2
           1 46  0
           2  4 80
[1] "Num itr RA GA"
[1] 188
[1] "Test BER aggreg GA is"
[1] 0.8785204
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 130  25
> 
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=5,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.01,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=0.8))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 5"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.7"
[1] "weightB: 0.2"
[1] "weightC: 0.05"
[1] "weightD: 0.05"
[1] "featweight.max: 0.01"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.45"
[1] "confusionprob: 0.2"
[1] "leaderprob: 0.25"
[1] "wmax: 1"
[1] "wmin: 1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 10"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 10"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 96.15385
[1] "here"
[1] "s"
[1] 104
[1] 130  25
[1] 10
[1] "learning sets: 1"
  [1] 118 110  23 129  33  31  43  24  42  78  54  30  72   6  46  16  83  29
 [19]  18 104  73  71  66  76  90  98  51  74   8 103  13  68  45  32  22  15
 [37] 109   5  17  14  12  96 126  39  95 123  70  19  36  28  82 122 101  55
 [55]  27  85 121  38  75  84 119   4   7 105  37  86 128 125  44  58 116 107
 [73]  62  88 106  61  65  69  25  40  81  93  50  10  11   3 114 100 102  63
 [91]  26   1  52  67  92  41 113  35  64  77  21 130  34   2
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -53.90662
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -55.18794
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -56.13782
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1
[1] 5
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -56.31547
[1] "Best solution:"
 [1] 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1
[1] 17
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 5
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 5
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 5
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 5
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 5
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 5
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 5
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  8 10 11 12 13 14 15 16 17 19 20 21 24 25
[1] 1
[1] "##################################"
[1] "Results summary for itr:1"
[1] "number of features selected using population mean"
[1] 5
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 56.31547
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 2"
  [1]  98  29  46  94  90  31  15 110  18  16 118  22   5   9  51  83  13  17
 [19] 103  45   6  72  42   8  43  71  91  73 129  66  74 117  89 109  32  23
 [37] 104  30 120  49 124  41  55  19  92  81  48  95  50  70 100  36  10 119
 [55]  58 127 102  88  84  86  26  35  34  59  96  85  53  82 125  39  28  56
 [73]  11  25  67   3 123  27 112 114 126  47   4 130 128  62   7  57  44 101
 [91]  12  63  65 106 122  97 113  38  77  21 116  69 121   2
[1] "Starting global iteration number : 2"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -53.02408
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -56.20632
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -56.88659
[1] "Best solution:"
 [1] 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1
[1] 17
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 5
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 5
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 5
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 5
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 5
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 5
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 5
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  8 10 11 12 13 14 15 16 17 19 20 21 24 25
[1] 2
[1] "##################################"
[1] "Results summary for itr:2"
[1] "number of features selected using population mean"
[1] 5
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 56.88659
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 3"
  [1]   9  15  60 110  68  29  66  80  78 104 118 120  49  83  72  42  87  73
 [19]  14  31  74   8  98  94  22  51  76  54 117  17 129  46  23  45  91  89
 [37] 109  43  16   5  55 101  67 123 115  20  25  97  82  59 125  53  39   7
 [55] 114   3   1  85  28  81  50  47  99  40  75 113  19  26 130  34  10  65
 [73]  57 112 128  61  35 111  70 105  69  21 122  58  11  86  41  52 116  38
 [91] 102   2  79  84  64  96 127  62  56  95 100 106   4  93
[1] "Starting global iteration number : 3"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -52.26168
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -54.13454
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -55.10418
[1] "Best solution:"
 [1] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1
[1] 4
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -55.6884
[1] "Best solution:"
 [1] 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1
[1] 17
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 4
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 4
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 4
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 4
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 4
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 4
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 4
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  8 10 11 12 13 14 15 16 17 19 20 21 24 25
[1] 3
[1] "##################################"
[1] "Results summary for itr:3"
[1] "number of features selected using population mean"
[1] 4
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 55.6884
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 4"
  [1] 117  15  60  73  98  66  16  46  87  45   5  18  29 118  31  76 110   9
 [19]  80 104  13 120  90  89  24  94  83  71  51  74  17 109  42  68  30   8
 [37]  22  43  49 103 125  81   1  92  99 108  70  27  26  79   2  77   3 124
 [55] 111  11  39  86  34  48  69  35  82  38 102  63  67  58 123  25  97  20
 [73] 106 114 105  19 122 128  41  12   7 119  28 126  93  59  62 107  37  84
 [91] 116  53  57 101  55  47  61  64  44  88   4 113  50 121
[1] "Starting global iteration number : 4"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -57.88408
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 13
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 13
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 13
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 13
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 13
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 13
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 13
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[1] 4
[1] "##################################"
[1] "Results summary for itr:4"
[1] "number of features selected using population mean"
[1] 13
[1] "number of features selected using current global best"
[1] 25
[1] "feat ind length"
[1] 25
[1] "best accuracy"
[1] 57.88408
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 5"
  [1]  22  90  74 104  60  78  23  16 120  43  13  46   6 118  17  54  32  51
 [19]  30  29   8  18 117  31  94  73  72  83  91 129 110  14  80  87  24  98
 [37] 103  15  76  45  79 116  37  36  52  85  53  48  11  63  75  25  97  61
 [55]  81  10  50  44  82 101  62  56  88 130  64 126 124  35   1  84 123  40
 [73]  27   2  59  67  28  95  41   3  86 107  34 108  58 105 115  93  20  69
 [91] 128  92  21   4  55  99  38   7 111 122 127 112 113  47
[1] "Starting global iteration number : 5"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -49.14945
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -50.86735
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -53.13256
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1
[1] 8
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -53.80544
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1
[1] 8
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 5
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 5
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 5
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 5
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 5
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 5
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 5
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  8 10 11 12 13 14 15 16 17 19 20 21 24 25
[1] 5
[1] "##################################"
[1] "Results summary for itr:5"
[1] "number of features selected using population mean"
[1] 5
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 53.80544
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 6"
  [1]  13   5  17  66  94 103  80  30  14  51  42  76  74  91 117 118 109 104
 [19]  23  29   6  98  43  68  31  71  60 110  45  46  24  73  16  49  18  87
 [37]   8 129  83  22 126  77  67 106   2  20  36  39  55  69 116   1  81 112
 [55]   7  82 101  65 114 105  57  19  61 124   3  86  95  75  58  79 127  41
 [73]  21 111 102 113  11 121  64 128 130  92  37  12  93  47  25   4  84  99
 [91] 107  44 119  35  38  40  48  28 125  34  52  88  85 123
[1] "Starting global iteration number : 6"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -54.41935
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -55.71714
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -56.01952
[1] "Best solution:"
 [1] 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1
[1] 17
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 5
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 5
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 5
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 5
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 5
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 5
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 5
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  8 10 11 12 13 14 15 16 17 19 20 21 24 25
[1] 6
[1] "##################################"
[1] "Results summary for itr:6"
[1] "number of features selected using population mean"
[1] 5
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 56.01952
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 7"
  [1]  98  43  22  68 118  80  15  14  73  13  76  60  49  31  74  17  45  83
 [19]  18  91  30 129 117  23  89 104  24  32  33  87 120 110  16   9 103  66
 [37]  94  51  54   8 107  36 124 108  50 121  86  28   7 102 100  20 130  99
 [55]  55  85  52 105  75  81  62 111  10  44  21  84 122 126  27  59  61  79
 [73]  93  77 114  37 119  35 116  65 106  96  82  26 123 112  92  40  64  69
 [91]  58  95  97  48   3  63 128 101  12  56 113  67  41  88
[1] "Starting global iteration number : 7"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -54.09868
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -54.65165
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 6
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 6
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 6
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 6
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 6
[1] "No change for 6 iterations. Exiting PSO."
[1]  2  9 14 16 20 25
[1] 7
[1] "##################################"
[1] "Results summary for itr:7"
[1] "number of features selected using population mean"
[1] 6
[1] "number of features selected using current global best"
[1] 6
[1] "feat ind length"
[1] 6
[1] "best accuracy"
[1] 54.65165
[1] "test acc:0.884615384615385"
[1] "##################################"
[1] "learning sets: 8"
  [1]  45  73  74   5  17 117 129 103  76  54  72  90 109  51  80 120  78  30
 [19]  14   8  22 118  49  24  18  43  29  23  31 104   9  98  71  89  16  83
 [37]  91 110  68  13 106  50  26 112 123  93  84  99 126 128  57 105 102  63
 [55] 113  85 122  34  39 108   7  36  52  44  10 127  28  64 116  48   3  97
 [73]  41 124  55  12  19  96  69 101 100   1  58  61  79  75  62  27  56  67
 [91]  82  37  40  88  77  25 107 114  81 121  86  21  11  53
[1] "Starting global iteration number : 8"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -50.66069
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 13
[1] "Best fitness updated to:"
[1] -51.60363
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 13
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 13
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 13
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 13
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 13
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 13
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 13
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 13
[1] "No change for 8 iterations. Exiting PSO."
 [1]  2  4  5  6  7 14 16 18 20 23 25
[1] 8
[1] "##################################"
[1] "Results summary for itr:8"
[1] "number of features selected using population mean"
[1] 13
[1] "number of features selected using current global best"
[1] 11
[1] "feat ind length"
[1] 11
[1] "best accuracy"
[1] 51.60363
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 9"
  [1]  66  13  80  31  51  83  98  23  14  43  18  73  49  89  45  78  17 118
 [19] 103   6  16  29  74 104  90 109 120  76  71  15   5   8  72   9  22  94
 [37] 117  32  87  60  26 105  57  77  36  40  86  92  82  11  64  65  19  52
 [55]  84  81 102  93 111  53  56  63 116   7  69  59 107 122  37 113 112  12
 [73]  61  55 108  75 124 100  20  25 127  38 119  70  97 128 106 114  41  99
 [91]  50   3  21 115  85   4  79  39  58  35   2  96  28  67
[1] "Starting global iteration number : 9"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -47.64232
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -50.31765
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -51.16781
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -51.72345
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 9
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 1
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 1
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 1
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 1
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 1
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 1
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 1
[1] "No change for 8 iterations. Exiting PSO."
[1]  8 12 14 15 21
[1] 9
[1] "##################################"
[1] "Results summary for itr:9"
[1] "number of features selected using population mean"
[1] 1
[1] "number of features selected using current global best"
[1] 5
[1] "feat ind length"
[1] 5
[1] "best accuracy"
[1] 51.72345
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 10"
  [1]  90   6  91  32 109  76  17  15 120 118  45 104  23  49  22  31  83 129
 [19]  29  46 110  13  72  54   8  16  74  94  51  68  89  14  60  33  43   9
 [37]  78  71  98  18  61  11  85  84  58  97  64 119  19   3  96  48  10 128
 [55] 116  52  40   4 121 113  86  69  27  25  99  67 108 107 114  63  79 123
 [73] 102  21  77  81  38  65 112  75  62 127  88 101   7 106   1 111  12  55
 [91] 122 126  95  59  35  28  56 124   2 100  44  36  57  92
[1] "Starting global iteration number : 10"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -50.43466
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -53.52424
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0
[1] 9
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -55.31145
[1] "Best solution:"
 [1] 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1
[1] 13
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -55.41772
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1
[1] 6
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 13
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 13
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 13
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 13
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 13
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 13
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 13
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 13
[1] "No change for 8 iterations. Exiting PSO."
 [1]  2  4  5  6  7 14 16 18 20 22 23 25
[1] 10
[1] "##################################"
[1] "Results summary for itr:10"
[1] "number of features selected using population mean"
[1] 13
[1] "number of features selected using current global best"
[1] 12
[1] "feat ind length"
[1] 12
[1] "best accuracy"
[1] 55.41772
[1] "test acc:0.884615384615385"
[1] "##################################"
[1] "testacc"
 [1] 0.9230769 0.9615385 0.9615385 1.0000000 0.9615385 0.9615385 0.8846154
 [8] 0.9615385 0.9615385 0.8846154
[1] 0.9461538
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8846  0.9327  0.9615  0.9462  0.9615  1.0000 
[1] 0.03715738
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1    1    1    1    1    1    0    0    0     0
 [2,]    1    1    1    1    1    1    1    1    0     1
 [3,]    1    1    1    1    1    1    0    0    0     0
 [4,]    0    0    0    1    0    0    0    1    0     1
 [5,]    0    0    0    1    0    0    0    1    0     1
 [6,]    0    0    0    1    0    0    0    1    0     1
 [7,]    0    0    0    1    0    0    0    1    0     1
 [8,]    1    1    1    1    1    1    0    0    1     0
 [9,]    0    0    0    1    0    0    1    0    0     0
[10,]    1    1    1    1    1    1    0    0    0     0
[11,]    1    1    1    1    1    1    0    0    0     0
[12,]    1    1    1    1    1    1    0    0    1     0
[13,]    1    1    1    1    1    1    0    0    0     0
[14,]    1    1    1    1    1    1    1    1    1     1
[15,]    1    1    1    1    1    1    0    0    1     0
[16,]    1    1    1    1    1    1    1    1    0     1
[17,]    1    1    1    1    1    1    0    0    0     0
[18,]    0    0    0    1    0    0    0    1    0     1
[19,]    1    1    1    1    1    1    0    0    0     0
[20,]    1    1    1    1    1    1    1    1    0     1
[21,]    1    1    1    1    1    1    0    0    1     0
[22,]    0    0    0    1    0    0    0    0    0     1
[23,]    0    0    0    1    0    0    0    1    0     1
[24,]    1    1    1    1    1    1    0    0    0     0
[25,]    1    1    1    1    1    1    1    1    0     1
[1] "dim of scoring matrix is "
[1] 25 10
[1] "DS index stage 2"
[1] 0.5890907
[1] "KI index stage 2"
[1] -Inf
[1] 1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   2.00    3.00    6.00    5.76    7.00   10.00 
[1] "Number of features selected in 1 iterations:"
[1] 25
[1] "Number of features selected in 1 iterations:"
[1] 25
[1] 0.98 1.00
[1] 0.98 1.00
[1] "accuracy: 91.9017420289794 num_feat:25 fitness:50.5160949672216"
$fitfunc
[1] -50.51609

$cverror
[1] 91.90174

$cvpermerror
[1] 60.0503

$testacc
[1] 98.375

$reverseacc
[1] 99

[1] -50.51609
[1] "Number of features selected in 2 iterations:"
[1] 25
[1] 0.98 1.00
[1] 0.98 1.00
[1] "accuracy: 91.9017420289794 num_feat:25 fitness:50.5160949672216"
$fitfunc
[1] -50.51609

$cverror
[1] 91.90174

$cvpermerror
[1] 60.0503

$testacc
[1] 98.375

$reverseacc
[1] 99

[1] -50.51609
[1] "Number of features selected in 3 iterations:"
[1] 23
[1] 0.96 1.00
[1] 0.96 1.00
[1] "accuracy: 92.4100868362125 num_feat:23 fitness:55.1289547596876"
$fitfunc
[1] -55.12895

$cverror
[1] 92.41009

$cvpermerror
[1] 53.7623

$testacc
[1] 97.375

$reverseacc
[1] 98

[1] -55.12895
[1] "Number of features selected in 4 iterations:"
[1] 17
[1] 0.96 1.00
[1] 0.96 1.00
[1] "accuracy: 92.4100868362125 num_feat:17 fitness:55.0827085142055"
$fitfunc
[1] -55.08271

$cverror
[1] 92.41009

$cvpermerror
[1] 54.17122

$testacc
[1] 97.375

$reverseacc
[1] 98

[1] -55.08271
[1] "Number of features selected in 5 iterations:"
[1] 17
[1] 0.96 1.00
[1] 0.96 1.00
[1] "accuracy: 92.4100868362125 num_feat:17 fitness:55.0827085142055"
$fitfunc
[1] -55.08271

$cverror
[1] 92.41009

$cvpermerror
[1] 54.17122

$testacc
[1] 97.375

$reverseacc
[1] 98

[1] -55.08271
[1] "Number of features selected in 6 iterations:"
[1] 17
[1] 0.96 1.00
[1] 0.96 1.00
[1] "accuracy: 92.4100868362125 num_feat:17 fitness:55.0827085142055"
$fitfunc
[1] -55.08271

$cverror
[1] 92.41009

$cvpermerror
[1] 54.17122

$testacc
[1] 97.375

$reverseacc
[1] 98

[1] -55.08271
[1] "Number of features selected in 7 iterations:"
[1] 9
[1] 0.9000 0.9875
[1] 0.9000 0.9875
[1] "accuracy: 90.8328122260577 num_feat:9 fitness:51.5337133455371"
$fitfunc
[1] -51.53371

$cverror
[1] 90.83281

$cvpermerror
[1] 56.99949

$testacc
[1] 94.75

$reverseacc
[1] 94.375

[1] -51.53371
[1] "Number of features selected in 8 iterations:"
[1] 5
[1] 0.88 0.95
[1] 0.88 0.95
[1] "accuracy: 89.6254934979778 num_feat:5 fitness:56.0018103493829"
$fitfunc
[1] -56.00181

$cverror
[1] 89.62549

$cvpermerror
[1] 49.4533

$testacc
[1] 95.125

$reverseacc
[1] 91.5

[1] -56.00181
[1] "Number of features selected in 9 iterations:"
[1] 5
[1] 0.88 0.95
[1] 0.88 0.95
[1] "accuracy: 89.6254934979778 num_feat:5 fitness:56.0018103493829"
$fitfunc
[1] -56.00181

$cverror
[1] 89.62549

$cvpermerror
[1] 49.4533

$testacc
[1] 95.125

$reverseacc
[1] 91.5

[1] -56.00181
[1] "Number of features selected in 10 iterations:"
[1] 1
[1] "accuracy: 1 num_feat:1 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8846  0.9327  0.9615  0.9462  0.9615  1.0000 
[1] "Number of features selected in 8 iterations:"
[1] 5
[1] "Modified train 10 fold accuracy using train data is "
[1] 93.07692
[1] "Modified train accuracy is "
[1] 0.9538462
[1] "train confusion matrix is "
          trainclass
pred_train  1  2
         1 47  3
         2  3 77
[1] "Train dimension is "
[1] 130   5
[1] "Test dimension is "
[1] 100   5
[1] "Test confusion matrix is "
    
pred  1  2
   1 32 10
   2  7 51
[1] "Test acc is "
[1] 0.83
[1] "train 10 fold"
[1] 92.30769
[1] "Test confusion matrix is "
    
pred  1  2
   1 32 10
   2  7 51
[1] "Test acc is "
[1] 0.83
[1] "Test AUC:"
[1] 0.8282892
[1] "Train acc is "
[1] 0.9538462
[1] "# of features after CMA:"
NULL
[1] "# of features after PSO:"
[1] 130   6
     user    system   elapsed 
  179.655    24.581 10163.096 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> 
> 
> feat_ind<-psores$bestfeatlist
> feat_names<-psores$bestfeatnames
> 
> scoringmatrix<-as.data.frame(psores$scoringmatrix)
> print(scoringmatrix)
   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
1   1  1  1  1  1  1  0  0  0   0
2   1  1  1  1  1  1  1  1  0   1
3   1  1  1  1  1  1  0  0  0   0
4   0  0  0  1  0  0  0  1  0   1
5   0  0  0  1  0  0  0  1  0   1
6   0  0  0  1  0  0  0  1  0   1
7   0  0  0  1  0  0  0  1  0   1
8   1  1  1  1  1  1  0  0  1   0
9   0  0  0  1  0  0  1  0  0   0
10  1  1  1  1  1  1  0  0  0   0
11  1  1  1  1  1  1  0  0  0   0
12  1  1  1  1  1  1  0  0  1   0
13  1  1  1  1  1  1  0  0  0   0
14  1  1  1  1  1  1  1  1  1   1
15  1  1  1  1  1  1  0  0  1   0
16  1  1  1  1  1  1  1  1  0   1
17  1  1  1  1  1  1  0  0  0   0
18  0  0  0  1  0  0  0  1  0   1
19  1  1  1  1  1  1  0  0  0   0
20  1  1  1  1  1  1  1  1  0   1
21  1  1  1  1  1  1  0  0  1   0
22  0  0  0  1  0  0  0  0  0   1
23  0  0  0  1  0  0  0  1  0   1
24  1  1  1  1  1  1  0  0  0   0
25  1  1  1  1  1  1  1  1  0   1
> print(feat_names[feat_ind])
[1] "1053_at"     "206754_s_at" "209173_at"   "212956_at"   "215867_x_at"
> 
> save(psores,file="psores.Rda")
> print("Complete")
[1] "Complete"
> 
