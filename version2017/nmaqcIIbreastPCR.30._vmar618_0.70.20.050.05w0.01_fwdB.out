
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/kuppal3/karan_libs/Rlibs")
> library(snow)
Warning message:
package ‘snow’ was built under R version 3.2.5 
> library(e1071)
Warning message:
package ‘e1071’ was built under R version 3.2.5 
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

Warning message:
package ‘pROC’ was built under R version 3.2.5 
> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
Warning message:
package ‘RankAggreg’ was built under R version 3.2.5 
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

Warning message:
package ‘CMA’ was built under R version 3.2.4 
> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

Warning messages:
1: package ‘expm’ was built under R version 3.2.5 
2: package ‘Matrix’ was built under R version 3.2.5 
> 
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> 
> dirloc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/"
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/versionnov2014/OCFS_",args[9],".R",sep="")
> 
> sname<-paste(dirloc,"version2017/OCFS_",args[9],".R",sep="")
> source(sname)
> 
> outloc<-paste(dirloc,"/Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCER",args[9],"/",sep="")
> 
> 
> sname<-paste(dirloc,"Datasets/MAQCII_BreastCancer/MaqcIIbr.Rda",sep="")
> load(sname)
> 
> trainm<-MaqcIIbr$trainx
> testm<-MaqcIIbr$testx
> trainclass<-MaqcIIbr$trainPCRvsRD
> testclass<-MaqcIIbr$testPCRvsRD
> 
> trainm<-trainm[,-c(22284)]
> testm<-testm[,-c(22284)]
> trainm<-apply(trainm,2,as.numeric)
> testm<-apply(testm,2,as.numeric)
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvmarch62018_v1' already exists
> setwd(outloc)
> 
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvmarch62018_v1' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> #if(FALSE)
> {
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 30
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.7586207 0.7500000
[1] 0.7586207 0.7500000
[1] "accuracy: 50.4953857392765 num_feat:3 fitness:18.7108606113901"
[1] 0.2580645 0.8953488
[1] 0.2580645 0.8953488
[1] "accuracy: 60.1632178991128 num_feat:3 fitness:25.7555345722934"
[1] 0.7000000 0.7701149
[1] 0.7000000 0.7701149
[1] "accuracy: 54.6314090247598 num_feat:3 fitness:17.5499470410199"
[1] 0.3571429 0.7078652
[1] 0.3571429 0.7078652
[1] "accuracy: 63.1009667894965 num_feat:3 fitness:25.9881105245457"
[1] 0.6666667 0.8275862
[1] 0.6666667 0.8275862
[1] "accuracy: 49.8479838700176 num_feat:3 fitness:13.2431355185195"
[1] 0.6071429 0.7528090
[1] 0.6071429 0.7528090
[1] "accuracy: 51.3112012364747 num_feat:3 fitness:18.8831459103412"
[1] 0.2187500 0.6470588
[1] 0.2187500 0.6470588
[1] "accuracy: 65.7601201958047 num_feat:3 fitness:23.984477573895"
[1] 0.1935484 0.9651163
[1] 0.1935484 0.9651163
[1] "accuracy: 62.6564189063962 num_feat:3 fitness:28.0706593952496"
[1] 0.5714286 0.7191011
[1] 0.5714286 0.7191011
[1] "accuracy: 56.7378879270946 num_feat:3 fitness:15.0123422706006"
[1] 0.1333333 0.9195402
[1] 0.1333333 0.9195402
[1] "accuracy: 61.3735081656487 num_feat:3 fitness:16.7282504533353"
[1] "limma:3:20.392646387119"
[1] "limma:3:20.392646387119"
[1] 0.8275862 0.7386364
[1] 0.8275862 0.7386364
[1] "accuracy: 53.0045386000848 num_feat:4 fitness:18.23668508193"
[1] 0.1935484 0.9302326
[1] 0.1935484 0.9302326
[1] "accuracy: 54.1398822307673 num_feat:4 fitness:22.0726150254838"
[1] 0.4000000 0.8390805
[1] 0.4000000 0.8390805
[1] "accuracy: 56.463241136061 num_feat:4 fitness:15.0128567070051"
[1] 0.2142857 0.8089888
[1] 0.2142857 0.8089888
[1] "accuracy: 58.9203916671204 num_feat:4 fitness:21.9983004371242"
[1] 0.5666667 0.8275862
[1] 0.5666667 0.8275862
[1] "accuracy: 54.6976532640206 num_feat:4 fitness:13.2970093534277"
[1] 0.5714286 0.7865169
[1] 0.5714286 0.7865169
[1] "accuracy: 54.4389602863366 num_feat:4 fitness:19.0248800725406"
[1] 0.2187500 0.6941176
[1] 0.2187500 0.6941176
[1] "accuracy: 59.9415649757155 num_feat:4 fitness:17.1842889618612"
[1] 0.2258065 0.9418605
[1] 0.2258065 0.9418605
[1] "accuracy: 62.5420043442692 num_feat:4 fitness:23.9164001318912"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 52.398086681593 num_feat:4 fitness:10.7395893163565"
[1] 0.4666667 0.8160920
[1] 0.4666667 0.8160920
[1] "accuracy: 61.7690190141756 num_feat:4 fitness:21.1380993298194"
[1] "limma:4:18.262072441744"
[1] "limma:3:20.392646387119"
[1] 0.8620690 0.7045455
[1] 0.8620690 0.7045455
[1] "accuracy: 53.5749691645187 num_feat:5 fitness:18.6654427518192"
[1] 0.1612903 0.9302326
[1] 0.1612903 0.9302326
[1] "accuracy: 51.3879772804918 num_feat:5 fitness:19.9318121891439"
[1] 0.4333333 0.8160920
[1] 0.4333333 0.8160920
[1] "accuracy: 57.9358415818196 num_feat:5 fitness:16.143124233029"
[1] 0.2142857 0.7752809
[1] 0.2142857 0.7752809
[1] "accuracy: 58.2495023336664 num_feat:5 fitness:24.6608188968517"
[1] 0.6666667 0.8390805
[1] 0.6666667 0.8390805
[1] "accuracy: 55.9098921618105 num_feat:5 fitness:14.4848792816933"
[1] 0.7142857 0.8089888
[1] 0.7142857 0.8089888
[1] "accuracy: 54.7207824835579 num_feat:5 fitness:21.8007247517188"
[1] 0.2500000 0.6823529
[1] 0.2500000 0.6823529
[1] "accuracy: 62.0491713012033 num_feat:5 fitness:18.8136620640105"
[1] 0.2258065 0.9418605
[1] 0.2258065 0.9418605
[1] "accuracy: 62.1826228888385 num_feat:5 fitness:23.6468191630575"
[1] 0.5357143 0.7303371
[1] 0.5357143 0.7303371
[1] "accuracy: 56.5048416572463 num_feat:5 fitness:14.0262719870477"
[1] 0.5000000 0.7931034
[1] 0.5000000 0.7931034
[1] "accuracy: 62.7044961163793 num_feat:5 fitness:21.865524348177"
[1] "limma:5:19.4039079666549"
[1] "limma:3:20.392646387119"
[1] 0.8965517 0.7045455
[1] 0.8965517 0.7045455
[1] "accuracy: 53.6280314310365 num_feat:6 fitness:18.7914014709986"
[1] 0.1612903 0.9186047
[1] 0.1612903 0.9186047
[1] "accuracy: 50.8770637653309 num_feat:6 fitness:19.5102398871852"
[1] 0.4000000 0.8505747
[1] 0.4000000 0.8505747
[1] "accuracy: 57.7075989661807 num_feat:6 fitness:15.9747709572574"
[1] 0.2500000 0.8202247
[1] 0.2500000 0.8202247
[1] "accuracy: 60.2975354190945 num_feat:6 fitness:26.3984440985095"
[1] 0.7000000 0.8390805
[1] 0.7000000 0.8390805
[1] "accuracy: 56.762159987266 num_feat:6 fitness:15.2073686068576"
[1] 0.7142857 0.7752809
[1] 0.7142857 0.7752809
[1] "accuracy: 55.3246236163215 num_feat:6 fitness:22.2171149815823"
[1] 0.2500000 0.6823529
[1] 0.2500000 0.6823529
[1] "accuracy: 61.1152173675561 num_feat:6 fitness:18.1131517365144"
[1] 0.2258065 0.9534884
[1] 0.2258065 0.9534884
[1] "accuracy: 61.3271691564304 num_feat:6 fitness:23.0342537539326"
[1] 0.5357143 0.7415730
[1] 0.5357143 0.7415730
[1] "accuracy: 55.8455089177465 num_feat:6 fitness:13.5598174428026"
[1] 0.3666667 0.8160920
[1] 0.3666667 0.8160920
[1] "accuracy: 59.4478146482881 num_feat:6 fitness:19.1471063008824"
[1] "limma:6:19.1953669236523"
[1] "limma:3:20.392646387119"
[1] 0.7931034 0.7045455
[1] 0.7931034 0.7045455
[1] "accuracy: 62.4057493746162 num_feat:7 fitness:25.1160243617675"
[1] 0.2903226 0.9302326
[1] 0.2903226 0.9302326
[1] "accuracy: 62.3462680370321 num_feat:7 fitness:27.5603955115212"
[1] 0.3666667 0.9195402
[1] 0.3666667 0.9195402
[1] "accuracy: 60.2446093309658 num_feat:7 fitness:17.9665643133557"
[1] 0.2500000 0.8539326
[1] 0.2500000 0.8539326
[1] "accuracy: 66.4326842629364 num_feat:7 fitness:29.8340305170516"
[1] 0.6333333 0.8735632
[1] 0.6333333 0.8735632
[1] "accuracy: 56.1236648016349 num_feat:7 fitness:17.981325903592"
[1] 0.7142857 0.7977528
[1] 0.7142857 0.7977528
[1] "accuracy: 57.0700292932485 num_feat:7 fitness:25.5823041372978"
[1] 0.1875000 0.7529412
[1] 0.1875000 0.7529412
[1] "accuracy: 70.2119777669061 num_feat:7 fitness:24.9558977470015"
[1] 0.2580645 0.9418605
[1] 0.2580645 0.9418605
[1] "accuracy: 69.3609533297854 num_feat:7 fitness:33.2020314914457"
[1] 0.4285714 0.7415730
[1] 0.4285714 0.7415730
[1] "accuracy: 58.032032660425 num_feat:7 fitness:17.6818082296937"
[1] 0.3333333 0.9195402
[1] 0.3333333 0.9195402
[1] "accuracy: 65.5654233132103 num_feat:7 fitness:24.9105552786352"
[1] "limma:7:24.4790937491362"
[1] "limma:7:24.4790937491362"
[1] 0.8275862 0.6931818
[1] 0.8275862 0.6931818
[1] "accuracy: 60.5611716105812 num_feat:8 fitness:23.7903439671232"
[1] 0.1935484 0.9418605
[1] 0.1935484 0.9418605
[1] "accuracy: 59.7706838581285 num_feat:8 fitness:26.3249893115295"
[1] 0.3333333 0.9080460
[1] 0.3333333 0.9080460
[1] "accuracy: 61.2097508026283 num_feat:8 fitness:18.5783065743247"
[1] 0.2500000 0.9438202
[1] 0.2500000 0.9438202
[1] "accuracy: 67.5781176278296 num_feat:8 fitness:32.1677797645844"
[1] 0.6333333 0.8275862
[1] 0.6333333 0.8275862
[1] "accuracy: 58.2395918317908 num_feat:8 fitness:19.4532837702126"
[1] 0.6428571 0.7752809
[1] 0.6428571 0.7752809
[1] "accuracy: 62.2624645376878 num_feat:8 fitness:29.2418344895142"
[1] 0.1562500 0.7529412
[1] 0.1562500 0.7529412
[1] "accuracy: 65.4467705068313 num_feat:8 fitness:20.7211283817411"
[1] 0.2258065 0.9186047
[1] 0.2258065 0.9186047
[1] "accuracy: 66.3036369373076 num_feat:8 fitness:23.9492715036111"
[1] 0.5357143 0.6853933
[1] 0.5357143 0.6853933
[1] "accuracy: 62.8897178072599 num_feat:8 fitness:20.702434917214"
[1] 0.4000000 0.9195402
[1] 0.4000000 0.9195402
[1] "accuracy: 61.5402389915119 num_feat:8 fitness:22.8530741864292"
[1] "limma:8:23.7782446866284"
[1] "limma:7:24.4790937491362"
[1] 0.6896552 0.7045455
[1] 0.6896552 0.7045455
[1] "accuracy: 60.8866218016062 num_feat:9 fitness:23.7179682378334"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 60.4348960571261 num_feat:9 fitness:26.8587374919941"
[1] 0.3333333 0.8965517
[1] 0.3333333 0.8965517
[1] "accuracy: 64.0756801044522 num_feat:9 fitness:20.698973041248"
[1] 0.2142857 0.9101124
[1] 0.2142857 0.9101124
[1] "accuracy: 64.5929525160829 num_feat:9 fitness:29.7553056763066"
[1] 0.6666667 0.8275862
[1] 0.6666667 0.8275862
[1] "accuracy: 58.2828045836752 num_feat:9 fitness:19.5689817901985"
[1] 0.6071429 0.7865169
[1] 0.6071429 0.7865169
[1] "accuracy: 62.8129599071362 num_feat:9 fitness:29.5934653126945"
[1] 0.1250000 0.8117647
[1] 0.1250000 0.8117647
[1] "accuracy: 65.7457040448292 num_feat:9 fitness:24.1132165924233"
[1] 0.1612903 0.9186047
[1] 0.1612903 0.9186047
[1] "accuracy: 66.5653275533191 num_feat:9 fitness:26.5682719795023"
[1] 0.5000000 0.6966292
[1] 0.5000000 0.6966292
[1] "accuracy: 62.8897178072599 num_feat:9 fitness:20.6411942133081"
[1] 0.3333333 0.9310345
[1] 0.3333333 0.9310345
[1] "accuracy: 62.2635832211833 num_feat:9 fitness:23.4628210872774"
[1] "limma:9:24.4978935422786"
[1] "limma:9:24.4978935422786"
[1] 0.7586207 0.6931818
[1] 0.7586207 0.6931818
[1] "accuracy: 61.7126047322386 num_feat:10 fitness:24.4814152607414"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 61.5388674237114 num_feat:10 fitness:27.6866711396723"
[1] 0.3333333 0.8965517
[1] 0.3333333 0.8965517
[1] "accuracy: 64.0756801044522 num_feat:10 fitness:20.6989281639873"
[1] 0.1428571 0.9213483
[1] 0.1428571 0.9213483
[1] "accuracy: 68.4387176344947 num_feat:10 fitness:32.4891030969238"
[1] 0.6333333 0.8160920
[1] 0.6333333 0.8160920
[1] "accuracy: 60.9047606032399 num_feat:10 fitness:21.4233349620941"
[1] 0.6071429 0.7752809
[1] 0.6071429 0.7752809
[1] "accuracy: 61.5116041903015 num_feat:10 fitness:28.5893137601673"
[1] 0.1250000 0.8117647
[1] 0.1250000 0.8117647
[1] "accuracy: 66.5931765104463 num_feat:10 fitness:22.9313645390719"
[1] 0.1612903 0.9186047
[1] 0.1612903 0.9186047
[1] "accuracy: 65.9364656420899 num_feat:10 fitness:26.0965806688197"
[1] 0.5357143 0.6966292
[1] 0.5357143 0.6966292
[1] "accuracy: 59.4223779930889 num_feat:10 fitness:20.1299301897049"
[1] 0.3333333 0.9310345
[1] 0.3333333 0.9310345
[1] "accuracy: 62.2635832211833 num_feat:10 fitness:23.4627762100168"
[1] "limma:10:24.79894179912"
[1] "limma:10:24.79894179912"
[1] 0.5517241 0.7272727
[1] 0.5517241 0.7272727
[1] "accuracy: 71.6132714700069 num_feat:11 fitness:28.9748563302239"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 62.1484237320871 num_feat:11 fitness:28.1147237262516"
[1] 0.3333333 0.9195402
[1] 0.3333333 0.9195402
[1] "accuracy: 62.8665918553537 num_feat:11 fitness:19.8495383642705"
[1] 0.3928571 0.8539326
[1] 0.3928571 0.8539326
[1] "accuracy: 71.6372877972452 num_feat:11 fitness:35.3444465158833"
[1] 0.6666667 0.8160920
[1] 0.6666667 0.8160920
[1] "accuracy: 64.0996039418434 num_feat:11 fitness:23.9027559221194"
[1] 0.7857143 0.7977528
[1] 0.7857143 0.7977528
[1] "accuracy: 61.5102893499482 num_feat:11 fitness:29.0908910993512"
[1] 0.0937500 0.8235294
[1] 0.0937500 0.8235294
[1] "accuracy: 65.7357062956965 num_feat:11 fitness:23.7015322708866"
[1] 0.1612903 0.9418605
[1] 0.1612903 0.9418605
[1] "accuracy: 70.4183609989648 num_feat:11 fitness:29.6142392390346"
[1] 0.5357143 0.6853933
[1] 0.5357143 0.6853933
[1] "accuracy: 63.2181086652399 num_feat:11 fitness:22.9485934289169"
[1] 0.3666667 0.9655172
[1] 0.3666667 0.9655172
[1] "accuracy: 66.0253012113296 num_feat:11 fitness:28.7868933885842"
[1] "limma:11:27.0328470285522"
[1] "limma:11:27.0328470285522"
[1] 0.6206897 0.7272727
[1] 0.6206897 0.7272727
[1] "accuracy: 69.0893710489203 num_feat:12 fitness:26.1431888191406"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 61.1189707325328 num_feat:12 fitness:27.2619439380348"
[1] 0.3333333 0.9080460
[1] 0.3333333 0.9080460
[1] "accuracy: 65.2530661808542 num_feat:12 fitness:21.6106135989513"
[1] 0.2142857 0.8876404
[1] 0.2142857 0.8876404
[1] "accuracy: 68.5571799468761 num_feat:12 fitness:32.6721618423386"
[1] 0.7333333 0.8160920
[1] 0.7333333 0.8160920
[1] "accuracy: 61.2987817668348 num_feat:12 fitness:22.307050951008"
[1] 0.7857143 0.7977528
[1] 0.7857143 0.7977528
[1] "accuracy: 60.6048137658395 num_feat:12 fitness:28.4117395340089"
[1] 0.0937500 0.8470588
[1] 0.0937500 0.8470588
[1] "accuracy: 69.0261010350732 num_feat:12 fitness:26.6266445709638"
[1] 0.1612903 0.9534884
[1] 0.1612903 0.9534884
[1] "accuracy: 69.8893395899934 num_feat:12 fitness:29.29432199296"
[1] 0.5357143 0.6516854
[1] 0.5357143 0.6516854
[1] "accuracy: 59.4099500808533 num_feat:12 fitness:20.008159950445"
[1] 0.3666667 0.9425287
[1] 0.3666667 0.9425287
[1] "accuracy: 65.9723918169448 num_feat:12 fitness:30.6896952011671"
[1] "limma:12:26.5025520399018"
[1] "limma:11:27.0328470285522"
[1] 0.6206897 0.7159091
[1] 0.6206897 0.7159091
[1] "accuracy: 66.7013039753998 num_feat:13 fitness:24.3236845458304"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 61.5069983502203 num_feat:13 fitness:27.6626347027719"
[1] 0.3000000 0.8965517
[1] 0.3000000 0.8965517
[1] "accuracy: 62.5644183626104 num_feat:13 fitness:19.4820138924906"
[1] 0.2857143 0.9325843
[1] 0.2857143 0.9325843
[1] "accuracy: 67.6229393544906 num_feat:13 fitness:32.262367499922"
[1] 0.7000000 0.8275862
[1] 0.7000000 0.8275862
[1] "accuracy: 60.9479505044294 num_feat:13 fitness:21.9892849257938"
[1] 0.8214286 0.7977528
[1] 0.8214286 0.7977528
[1] "accuracy: 59.3081958411999 num_feat:13 fitness:27.5285169275542"
[1] 0.0937500 0.8470588
[1] 0.0937500 0.8470588
[1] "accuracy: 71.3696019769258 num_feat:13 fitness:28.8386320224538"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 69.0132129321779 num_feat:13 fitness:28.6146764959311"
[1] 0.5714286 0.6292135
[1] 0.5714286 0.6292135
[1] "accuracy: 59.1185396979722 num_feat:13 fitness:19.8226632250283"
[1] 0.3333333 0.9425287
[1] 0.3333333 0.9425287
[1] "accuracy: 67.6678827339169 num_feat:13 fitness:31.672720537964"
[1] "limma:13:26.219719477574"
[1] "limma:11:27.0328470285522"
[1] 0.6206897 0.7045455
[1] 0.6206897 0.7045455
[1] "accuracy: 65.9126071580668 num_feat:14 fitness:23.7037079646609"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 60.1829866073917 num_feat:14 fitness:26.5082906958092"
[1] 0.3000000 0.8850575
[1] 0.3000000 0.8850575
[1] "accuracy: 62.5752104634046 num_feat:14 fitness:19.4613274586416"
[1] 0.2857143 0.9213483
[1] 0.2857143 0.9213483
[1] "accuracy: 68.7810407788426 num_feat:14 fitness:33.1028088032848"
[1] 0.7000000 0.8275862
[1] 0.7000000 0.8275862
[1] "accuracy: 60.6134998425779 num_feat:14 fitness:21.4001121814054"
[1] 0.7857143 0.7977528
[1] 0.7857143 0.7977528
[1] "accuracy: 58.6541053108114 num_feat:14 fitness:26.9486184382165"
[1] 0.0937500 0.8352941
[1] 0.0937500 0.8352941
[1] "accuracy: 69.7093888867191 num_feat:14 fitness:27.4870065105934"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 66.6358044598504 num_feat:14 fitness:26.8315752644248"
[1] 0.5714286 0.6404494
[1] 0.5714286 0.6404494
[1] "accuracy: 59.4099500808533 num_feat:14 fitness:20.0692660225689"
[1] 0.3666667 0.9425287
[1] 0.3666667 0.9425287
[1] "accuracy: 68.0099459367254 num_feat:14 fitness:32.2177710364812"
[1] "limma:14:25.7730484376087"
[1] "limma:11:27.0328470285522"
[1] 0.7586207 0.7045455
[1] 0.7586207 0.7045455
[1] "accuracy: 67.8564115126552 num_feat:15 fitness:28.0063439395484"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 64.4743614547419 num_feat:15 fitness:29.8074221153515"
[1] 0.3000000 0.8505747
[1] 0.3000000 0.8505747
[1] "accuracy: 65.1639333907542 num_feat:15 fitness:21.3166178803414"
[1] 0.3214286 0.8764045
[1] 0.3214286 0.8764045
[1] "accuracy: 67.9928554198246 num_feat:15 fitness:31.2385510704846"
[1] 0.7000000 0.8505747
[1] 0.7000000 0.8505747
[1] "accuracy: 62.1933483761728 num_feat:15 fitness:25.9757583020421"
[1] 0.8214286 0.7865169
[1] 0.8214286 0.7865169
[1] "accuracy: 58.3820682865102 num_feat:15 fitness:26.8057416193751"
[1] 0.1250000 0.8823529
[1] 0.1250000 0.8823529
[1] "accuracy: 65.1487537649724 num_feat:15 fitness:24.2622573508461"
[1] 0.09677419 0.97674419
[1] 0.09677419 0.97674419
[1] "accuracy: 68.32539610971 num_feat:15 fitness:25.3020310705569"
[1] 0.5000000 0.6179775
[1] 0.5000000 0.6179775
[1] "accuracy: 63.4837445065824 num_feat:15 fitness:20.8898157607527"
[1] 0.4000000 0.9425287
[1] 0.4000000 0.9425287
[1] "accuracy: 67.6845912540457 num_feat:15 fitness:30.057043480544"
[1] "limma:15:26.3661582589843"
[1] "limma:11:27.0328470285522"
[1] 0.7586207 0.7272727
[1] 0.7586207 0.7272727
[1] "accuracy: 70.2221972620824 num_feat:16 fitness:29.8374565561763"
[1] 0.2580645 0.9767442
[1] 0.2580645 0.9767442
[1] "accuracy: 62.5628455649308 num_feat:16 fitness:28.6672511984519"
[1] 0.3000000 0.8275862
[1] 0.3000000 0.8275862
[1] "accuracy: 65.0944276672404 num_feat:16 fitness:21.2069724460775"
[1] 0.2500000 0.8764045
[1] 0.2500000 0.8764045
[1] "accuracy: 68.9489160140324 num_feat:16 fitness:33.0269802103083"
[1] 0.7000000 0.8390805
[1] 0.7000000 0.8390805
[1] "accuracy: 61.2164661301252 num_feat:16 fitness:25.2143161080618"
[1] 0.8571429 0.7865169
[1] 0.8571429 0.7865169
[1] "accuracy: 62.5144832561858 num_feat:16 fitness:29.9942936836568"
[1] 0.0625000 0.8705882
[1] 0.0625000 0.8705882
[1] "accuracy: 71.162471057023 num_feat:16 fitness:28.6638477301564"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.3745193826814 num_feat:16 fitness:31.8163230216182"
[1] 0.5000000 0.6292135
[1] 0.5000000 0.6292135
[1] "accuracy: 64.5104867084976 num_feat:16 fitness:21.6879174225688"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 67.9295208858248 num_feat:16 fitness:27.9360981259682"
[1] "limma:16:27.8051456503044"
[1] "limma:16:27.8051456503044"
[1] 0.7586207 0.7272727
[1] 0.7586207 0.7272727
[1] "accuracy: 66.1547462779443 num_feat:17 fitness:26.786823440812"
[1] 0.2580645 0.9767442
[1] 0.2580645 0.9767442
[1] "accuracy: 66.2002870450659 num_feat:17 fitness:31.3952874312925"
[1] 0.3000000 0.8390805
[1] 0.3000000 0.8390805
[1] "accuracy: 67.5905298828374 num_feat:17 fitness:23.1077398626985"
[1] 0.2857143 0.8988764
[1] 0.2857143 0.8988764
[1] "accuracy: 67.5889936571833 num_feat:17 fitness:30.9024590549774"
[1] 0.7333333 0.8390805
[1] 0.7333333 0.8390805
[1] "accuracy: 63.551390711194 num_feat:17 fitness:27.048797999936"
[1] 0.7857143 0.7865169
[1] 0.7857143 0.7865169
[1] "accuracy: 61.3446448220661 num_feat:17 fitness:28.938298552235"
[1] 0.0625000 0.9529412
[1] 0.0625000 0.9529412
[1] "accuracy: 71.2784276453096 num_feat:17 fitness:28.879643594813"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 70.3911116082519 num_feat:17 fitness:34.515700438805"
[1] 0.4285714 0.7191011
[1] 0.4285714 0.7191011
[1] "accuracy: 64.111180630547 num_feat:17 fitness:21.4345406593973"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 67.3864463858974 num_feat:17 fitness:27.528747373762"
[1] "limma:17:28.0538038408729"
[1] "limma:17:28.0538038408729"
[1] 0.7931034 0.6931818
[1] 0.7931034 0.6931818
[1] "accuracy: 67.5007926906699 num_feat:18 fitness:25.2972929969199"
[1] 0.2580645 0.9767442
[1] 0.2580645 0.9767442
[1] "accuracy: 66.2997797949946 num_feat:18 fitness:31.4698621164784"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 63.5610132598646 num_feat:18 fitness:23.5022241848749"
[1] 0.2857143 0.8988764
[1] 0.2857143 0.8988764
[1] "accuracy: 69.8406913719328 num_feat:18 fitness:31.3411874637788"
[1] 0.7333333 0.8275862
[1] 0.7333333 0.8275862
[1] "accuracy: 64.2246736427301 num_feat:18 fitness:27.5249796891435"
[1] 0.8928571 0.7752809
[1] 0.8928571 0.7752809
[1] "accuracy: 63.2095731395223 num_feat:18 fitness:30.5767171682831"
[1] 0.0625 1.0000
[1] 0.0625 1.0000
[1] "accuracy: 72.7613319039969 num_feat:18 fitness:30.1094239703913"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.9705984158709 num_feat:18 fitness:34.9793404347005"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 66.4647406317225 num_feat:18 fitness:24.038951497304"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 65.8215439941618 num_feat:18 fitness:30.4831443956948"
[1] "limma:18:28.9323123917569"
[1] "limma:18:28.9323123917569"
[1] 0.7241379 0.7386364
[1] 0.7241379 0.7386364
[1] "accuracy: 66.387430527411 num_feat:19 fitness:24.403449067748"
[1] 0.1935484 0.9883721
[1] 0.1935484 0.9883721
[1] "accuracy: 66.8832017203089 num_feat:19 fitness:31.7751631280646"
[1] 0.3000000 0.8390805
[1] 0.3000000 0.8390805
[1] "accuracy: 63.6058625062089 num_feat:19 fitness:23.452482909039"
[1] 0.2857143 0.8876404
[1] 0.2857143 0.8876404
[1] "accuracy: 71.4749088300768 num_feat:19 fitness:32.5387157924857"
[1] 0.7666667 0.8275862
[1] 0.7666667 0.8275862
[1] "accuracy: 62.592516884484 num_feat:19 fitness:26.3841505765315"
[1] 0.8928571 0.7752809
[1] 0.8928571 0.7752809
[1] "accuracy: 61.9521954467537 num_feat:19 fitness:29.633639021446"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 73.9219301094817 num_feat:19 fitness:31.3078961056467"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.3709969000097 num_feat:19 fitness:34.5295944205438"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 66.2039814861636 num_feat:19 fitness:23.8433372608742"
[1] 0.3333333 0.9655172
[1] 0.3333333 0.9655172
[1] "accuracy: 65.0003255677883 num_feat:19 fitness:29.7292546641712"
[1] "limma:19:28.7597682946551"
[1] "limma:18:28.9323123917569"
[1] 0.7241379 0.7272727
[1] 0.7241379 0.7272727
[1] "accuracy: 70.0215551323358 num_feat:20 fitness:27.1005885532719"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 66.9359858870809 num_feat:20 fitness:31.6534160533023"
[1] 0.3333333 0.8505747
[1] 0.3333333 0.8505747
[1] "accuracy: 63.5254151690781 num_feat:20 fitness:26.8375048277808"
[1] 0.3214286 0.9325843
[1] 0.3214286 0.9325843
[1] "accuracy: 70.1809714796193 num_feat:20 fitness:31.7698631672294"
[1] 0.8000000 0.8390805
[1] 0.8000000 0.8390805
[1] "accuracy: 62.4836547069355 num_feat:20 fitness:26.4145280316267"
[1] 0.8928571 0.7865169
[1] 0.8928571 0.7865169
[1] "accuracy: 62.0100548491577 num_feat:20 fitness:31.657254663156"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 72.9270872563496 num_feat:20 fitness:30.4835940885369"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 71.5469785174786 num_feat:20 fitness:35.382465988943"
[1] 0.4642857 0.7078652
[1] 0.4642857 0.7078652
[1] "accuracy: 64.340717282097 num_feat:20 fitness:22.417754342923"
[1] 0.3666667 0.9540230
[1] 0.3666667 0.9540230
[1] "accuracy: 66.1864643049013 num_feat:20 fitness:30.8786261812328"
[1] "limma:20:29.4595595898003"
[1] "limma:20:29.4595595898003"
[1] 0.6551724 0.7613636
[1] 0.6551724 0.7613636
[1] "accuracy: 69.3057075661647 num_feat:21 fitness:26.4764714810067"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 66.1469633495084 num_feat:21 fitness:30.8487385564331"
[1] 0.2666667 0.8505747
[1] 0.2666667 0.8505747
[1] "accuracy: 62.7505620448363 num_feat:21 fitness:19.4229867740055"
[1] 0.2857143 0.9213483
[1] 0.2857143 0.9213483
[1] "accuracy: 67.2275562547257 num_feat:21 fitness:29.4373812693723"
[1] 0.800000 0.816092
[1] 0.800000 0.816092
[1] "accuracy: 60.189292129535 num_feat:21 fitness:24.6362399569478"
[1] 0.8928571 0.7977528
[1] 0.8928571 0.7977528
[1] "accuracy: 59.5082475268501 num_feat:21 fitness:29.808944181805"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 71.5766306406875 num_feat:21 fitness:29.2544483729931"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 71.4845992605395 num_feat:21 fitness:35.2549915076876"
[1] 0.5000000 0.7303371
[1] 0.5000000 0.7303371
[1] "accuracy: 63.7018950034129 num_feat:21 fitness:22.0840582462159"
[1] 0.2333333 0.9310345
[1] 0.2333333 0.9310345
[1] "accuracy: 63.9989445414163 num_feat:21 fitness:27.6419222433191"
[1] "limma:21:27.4866182589786"
[1] "limma:20:29.4595595898003"
[1] 0.6551724 0.7500000
[1] 0.6551724 0.7500000
[1] "accuracy: 69.8444764941076 num_feat:22 fitness:26.852094208794"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 63.2956186250938 num_feat:22 fitness:28.7101851358614"
[1] 0.3000000 0.8505747
[1] 0.3000000 0.8505747
[1] "accuracy: 64.2625194832221 num_feat:22 fitness:20.6402433088674"
[1] 0.2500000 0.9325843
[1] 0.2500000 0.9325843
[1] "accuracy: 64.6048428411561 num_feat:22 fitness:27.4091055052892"
[1] 0.800000 0.816092
[1] 0.800000 0.816092
[1] "accuracy: 60.1161047653948 num_feat:22 fitness:21.2479712232487"
[1] 0.8928571 0.7977528
[1] 0.8928571 0.7977528
[1] "accuracy: 59.0250797545971 num_feat:22 fitness:29.4465234753546"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 69.7136889219633 num_feat:22 fitness:27.8571972066893"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 67.5821808532681 num_feat:22 fitness:32.3281328249734"
[1] 0.500000 0.752809
[1] 0.500000 0.752809
[1] "accuracy: 63.9837631937421 num_feat:22 fitness:22.351594286983"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 65.056879662958 num_feat:22 fitness:28.6434169107712"
[1] "limma:22:26.5486464086832"
[1] "limma:20:29.4595595898003"
[1] 0.6551724 0.7613636
[1] 0.6551724 0.7613636
[1] "accuracy: 70.4077333179716 num_feat:23 fitness:27.3029010403404"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 64.8479250589101 num_feat:23 fitness:29.874370083963"
[1] 0.2666667 0.8620690
[1] 0.2666667 0.8620690
[1] "accuracy: 62.7994660523433 num_feat:23 fitness:19.4883106572982"
[1] 0.2857143 0.9662921
[1] 0.2857143 0.9662921
[1] "accuracy: 64.5408193338712 num_feat:23 fitness:27.5345983747719"
[1] 0.7666667 0.8045977
[1] 0.7666667 0.8045977
[1] "accuracy: 61.0901891003034 num_feat:23 fitness:21.8664206316521"
[1] 0.8928571 0.8089888
[1] 0.8928571 0.8089888
[1] "accuracy: 59.4998871622732 num_feat:23 fitness:29.8306740414914"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 69.9337184642239 num_feat:23 fitness:28.022174486124"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 67.1715378061174 num_feat:23 fitness:31.9394605010594"
[1] 0.5000000 0.7640449
[1] 0.5000000 0.7640449
[1] "accuracy: 58.6894515349969 num_feat:23 fitness:18.4089055533039"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 64.5672056563494 num_feat:23 fitness:24.7088329226987"
[1] "limma:23:25.8976648292703"
[1] "limma:20:29.4595595898003"
[1] 0.7241379 0.7613636
[1] 0.7241379 0.7613636
[1] "accuracy: 69.8567215902681 num_feat:24 fitness:27.0620111604056"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 65.4036120542872 num_feat:24 fitness:30.2910904532351"
[1] 0.3000000 0.8965517
[1] 0.3000000 0.8965517
[1] "accuracy: 61.7917742082534 num_feat:24 fitness:18.9020371268551"
[1] 0.2857143 0.9438202
[1] 0.2857143 0.9438202
[1] "accuracy: 65.1887036987205 num_feat:24 fitness:27.9642869958672"
[1] 0.7666667 0.8160920
[1] 0.7666667 0.8160920
[1] "accuracy: 61.0797609004577 num_feat:24 fitness:21.8872902366912"
[1] 0.8928571 0.8089888
[1] 0.8928571 0.8089888
[1] "accuracy: 59.2280524517406 num_feat:24 fitness:29.6267531313313"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 69.9337184642239 num_feat:24 fitness:27.9440046088633"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 67.5552069139593 num_feat:24 fitness:32.2271674546801"
[1] 0.5357143 0.7640449
[1] 0.5357143 0.7640449
[1] "accuracy: 62.1437309478626 num_feat:24 fitness:21.0888559499782"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 65.0865988579645 num_feat:24 fitness:25.0695973144654"
[1] "limma:24:26.2063094432372"
[1] "limma:20:29.4595595898003"
[1] 0.7241379 0.7500000
[1] 0.7241379 0.7500000
[1] "accuracy: 69.1693105592926 num_feat:25 fitness:26.5179989190041"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 65.8914468884674 num_feat:25 fitness:29.9091211150993"
[1] 0.2333333 0.9195402
[1] 0.2333333 0.9195402
[1] "accuracy: 60.7700362663986 num_feat:25 fitness:24.6931600575712"
[1] 0.2500000 0.9550562
[1] 0.2500000 0.9550562
[1] "accuracy: 63.88428588877 num_feat:25 fitness:26.9247329344984"
[1] 0.8000000 0.8045977
[1] 0.8000000 0.8045977
[1] "accuracy: 61.4168843342044 num_feat:25 fitness:22.1946856358898"
[1] 0.8571429 0.8089888
[1] 0.8571429 0.8089888
[1] "accuracy: 60.3388062685652 num_feat:25 fitness:30.3704879024034"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 70.160835342976 num_feat:25 fitness:28.1437091553726"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 69.6004131529535 num_feat:25 fitness:33.761027256665"
[1] 0.5000000 0.7865169
[1] 0.5000000 0.7865169
[1] "accuracy: 65.5748582220825 num_feat:25 fitness:24.8790505893776"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 62.1431610295763 num_feat:25 fitness:22.8619740659136"
[1] "limma:25:27.0255947631795"
[1] "limma:20:29.4595595898003"
[1] 0.7586207 0.7386364
[1] 0.7586207 0.7386364
[1] "accuracy: 66.6622668018186 num_feat:26 fitness:24.6954690292806"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 69.8119229979902 num_feat:26 fitness:32.930078481271"
[1] 0.2333333 0.9080460
[1] 0.2333333 0.9080460
[1] "accuracy: 64.1780767627639 num_feat:26 fitness:23.8870765870672"
[1] 0.2500000 0.9662921
[1] 0.2500000 0.9662921
[1] "accuracy: 68.3597973411321 num_feat:26 fitness:33.5594115341498"
[1] 0.8000000 0.7816092
[1] 0.8000000 0.7816092
[1] "accuracy: 66.0300479920367 num_feat:26 fitness:25.5970422376356"
[1] 0.8571429 0.8089888
[1] 0.8571429 0.8089888
[1] "accuracy: 62.7588256449506 num_feat:26 fitness:32.0948495839407"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 72.7660456706161 num_feat:26 fitness:30.1462852591361"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 71.5088215031422 num_feat:26 fitness:35.1922886420459"
[1] 0.5357143 0.8089888
[1] 0.5357143 0.8089888
[1] "accuracy: 62.3804920246468 num_feat:26 fitness:22.6286965536067"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 66.6353631082008 num_feat:26 fitness:29.6764830464718"
[1] "limma:26:29.0407680954605"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  1036  1083  3152  3155  3455  3490  4035  4349  4352  4752  5223  5927
[13]  8667  9093 10196 12339 13543 15240 15464 18415
     201508_at 201555_at 203625_x_at 203628_at 203928_x_at 203963_at
[1,]   10.8379    9.9323      8.9780   10.7755      9.6578   12.0638
[2,]    8.8812    9.5628      8.1801    9.8410      9.9980   11.3553
[3,]   12.8232   10.3905      7.7719    9.4169      6.2526   12.3832
     204508_s_at 204822_at 204825_at 205225_at 205696_s_at 206401_s_at
[1,]     10.1763    7.2891    8.9393   13.0759     11.6168      9.9796
[2,]      9.3275    6.4251    7.7652   13.7616      9.5737      9.9498
[3,]      9.9200    8.4023    9.9136   12.7360      7.2600      6.0807
     209173_at 209603_at 210735_s_at 212956_at 214164_x_at 215867_x_at
[1,]   12.9392   10.5793     11.5638   13.3600     12.6474     12.6194
[2,]   14.1501   10.5772     10.8918   13.2925     11.7852     11.5534
[3,]   14.5585   11.1181     11.6213   12.3582     12.7464     12.7285
     216092_s_at 219051_x_at
[1,]     10.4159      8.5236
[2,]      9.7648      8.9626
[3,]      8.3641     10.7458
     201508_at 201555_at 203625_x_at 203628_at 203928_x_at 203963_at
[1,]   10.2358    9.9499      8.6829    9.4326     10.9860   12.4052
[2,]   10.4887    9.6616      8.3696    9.8046      8.1054   10.4033
[3,]    9.3978    9.4638      8.5685    7.9079      8.3152    9.8307
     204508_s_at 204822_at 204825_at 205225_at 205696_s_at 206401_s_at
[1,]      9.8038    7.3928    7.9851   13.8754      9.0616     10.6463
[2,]      7.9689    6.1670    5.2744   11.7217      7.7288      8.2532
[3,]      7.6789    6.6156    5.9481   10.9960      7.1560      7.4477
     209173_at 209603_at 210735_s_at 212956_at 214164_x_at 215867_x_at
[1,]   13.2041   11.9790     11.3620   13.5201     12.7392     12.5744
[2,]   11.3631   10.8744      9.5434   12.5480     10.9092     11.0575
[3,]   11.1800    8.0211      9.2310   11.2917     10.6696     11.0769
     216092_s_at 219051_x_at
[1,]     10.6963      9.5138
[2,]      9.3780      5.3641
[3,]      9.3840      7.1097
[1] "numgenes selected:20"
[1] "test acc:0.74"
[1] "test AUC acc:0.709803921568627"
[1] "10 fold train82.3076923076923"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 25  7
         2  8 90
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 10 21
        2  5 64
[1] "train acc:0.884615384615385"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 25  7
         2  8 90
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 30
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
Loaded glmnet 2.0-10


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
 1083  3155  4352 15464  4208  4756  8166 18226  2667  8207 11253 20137 21064 
   10    10     9     9     8     8     8     8     7     7     7     7     7 
    1     2  5278 11968 18220     3  2211  4874  5223  5927 11729 18415 18802 
    6     6     6     6     6     5     5     5     5     5     5     5     5 
14806 21615     4     5     6  1326  1732 12226 12517 19283 19380 20616     7 
    4     4     3     3     3     3     3     3     3     3     3     3     2 
    8     9    10    11  4569  7691  8550 10291 10980 12814 13597 16398 16738 
    2     2     2     2     2     2     2     2     2     2     2     2     2 
18035 18313 19856 20350  1422  2475  2841  3152  3223  3455  4228  4349  4784 
    2     2     2     2     1     1     1     1     1     1     1     1     1 
 5357  6362  6528  7860  8080  8292  8845  8851  8870  9031  9093  9279  9586 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
 9853 10235 10271 10314 10830 11244 11850 11938 12074 12521 12908 13226 14725 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
15271 15303 15341 15535 15721 17601 17669 18171 18330 18456 18478 18968 19012 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
19398 19808 21518 
    1     1     1 
[1] "varselmethod"
[1] "forward"
[1] 0.3793103 0.5113636
[1] 0.3793103 0.5113636
[1] "accuracy: 68.7588840279326 num_feat:3 fitness:26.1413953345001"
[1] 0.2580645 0.9418605
[1] 0.2580645 0.9418605
[1] "accuracy: 66.9028518104034 num_feat:3 fitness:31.8337539911251"
[1] 0.3333333 0.9080460
[1] 0.3333333 0.9080460
[1] "accuracy: 68.6763919268321 num_feat:3 fitness:27.5118451371143"
[1] 0.4285714 0.9550562
[1] 0.4285714 0.9550562
[1] "accuracy: 73.070961945616 num_feat:3 fitness:38.7621558482967"
[1] 0.7666667 0.8505747
[1] 0.7666667 0.8505747
[1] "accuracy: 65.0031736753418 num_feat:3 fitness:25.7003424038495"
[1] 0.5714286 0.8539326
[1] 0.5714286 0.8539326
[1] "accuracy: 68.7368887627746 num_feat:3 fitness:34.1159348295444"
[1] 0.0000000 0.9529412
[1] 0.0000000 0.9529412
[1] "accuracy: 74.496448905779 num_feat:3 fitness:32.2752553399868"
[1] 0.2258065 0.8372093
[1] 0.2258065 0.8372093
[1] "accuracy: 72.096691623764 num_feat:3 fitness:36.7299234708871"
[1] 0.5357143 0.7865169
[1] 0.5357143 0.7865169
[1] "accuracy: 69.8932818778603 num_feat:3 fitness:26.4947502171963"
[1] 0.6000000 0.8850575
[1] 0.6000000 0.8850575
[1] "accuracy: 66.7923112563323 num_feat:3 fitness:31.5394792081296"
[1] "lasso:3:31.110483578063"
[1] "lasso:3:31.110483578063"
[1] 0.7586207 0.5795455
[1] 0.7586207 0.5795455
[1] "accuracy: 63.0830580326822 num_feat:4 fitness:25.2254335905473"
[1] 0.2258065 0.9651163
[1] 0.2258065 0.9651163
[1] "accuracy: 69.5755565012091 num_feat:4 fitness:33.8176079990567"
[1] 0.2666667 0.9080460
[1] 0.2666667 0.9080460
[1] "accuracy: 71.2354564607973 num_feat:4 fitness:29.2644319936608"
[1] 0.4642857 0.9213483
[1] 0.4642857 0.9213483
[1] "accuracy: 71.8698561995485 num_feat:4 fitness:36.6162977128498"
[1] 0.7666667 0.8160920
[1] 0.7666667 0.8160920
[1] "accuracy: 67.1952368685677 num_feat:4 fitness:29.8081280913208"
[1] 0.6785714 0.7977528
[1] 0.6785714 0.7977528
[1] "accuracy: 66.835502446105 num_feat:4 fitness:32.8172579194365"
[1] 0.0000000 0.9764706
[1] 0.0000000 0.9764706
[1] "accuracy: 73.6521613901889 num_feat:4 fitness:31.8135025726644"
[1] 0.3548387 0.8720930
[1] 0.3548387 0.8720930
[1] "accuracy: 71.3594087326113 num_feat:4 fitness:35.6244777742437"
[1] 0.2500000 0.6067416
[1] 0.2500000 0.6067416
[1] "accuracy: 71.1178043897082 num_feat:4 fitness:21.9627644353242"
[1] 0.500000 0.908046
[1] 0.500000 0.908046
[1] "accuracy: 65.1020322568028 num_feat:4 fitness:30.0791963455896"
[1] "lasso:4:30.7029098434694"
[1] "lasso:3:31.110483578063"
[1] 0.7931034 0.6136364
[1] 0.7931034 0.6136364
[1] "accuracy: 74.4270016461568 num_feat:5 fitness:33.9047964275307"
[1] 0.1935484 0.9883721
[1] 0.1935484 0.9883721
[1] "accuracy: 71.2525173128234 num_feat:5 fitness:35.0527939389593"
[1] 0.3666667 0.9080460
[1] 0.3666667 0.9080460
[1] "accuracy: 74.6333702307668 num_feat:5 fitness:35.3961557772106"
[1] 0.5000000 0.8089888
[1] 0.5000000 0.8089888
[1] "accuracy: 72.434584677308 num_feat:5 fitness:36.0981860317899"
[1] 0.700000 0.908046
[1] 0.700000 0.908046
[1] "accuracy: 71.1599058241091 num_feat:5 fitness:32.845238360514"
[1] 0.7500000 0.8426966
[1] 0.7500000 0.8426966
[1] "accuracy: 66.925611957292 num_feat:5 fitness:37.1757261546993"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 76.3400655850882 num_feat:5 fitness:32.1921309396174"
[1] 0.4193548 0.8953488
[1] 0.4193548 0.8953488
[1] "accuracy: 80.3061748369192 num_feat:5 fitness:43.4630282417692"
[1] 0.2500000 0.6404494
[1] 0.2500000 0.6404494
[1] "accuracy: 76.4629644835979 num_feat:5 fitness:28.0558592914021"
[1] 0.4333333 0.9770115
[1] 0.4333333 0.9770115
[1] "accuracy: 71.6398813951565 num_feat:5 fitness:33.92850554794"
[1] "lasso:5:34.8112420711433"
[1] "lasso:5:34.8112420711433"
[1] 0.8620690 0.4886364
[1] 0.8620690 0.4886364
[1] "accuracy: 72.8908561994925 num_feat:6 fitness:33.2485560774984"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 72.1956946519254 num_feat:6 fitness:35.5988259085853"
[1] 0.3000000 0.9310345
[1] 0.3000000 0.9310345
[1] "accuracy: 72.1735027748055 num_feat:6 fitness:33.4420149056801"
[1] 0.4642857 0.8089888
[1] 0.4642857 0.8089888
[1] "accuracy: 74.5782044694991 num_feat:6 fitness:38.3665702843868"
[1] 0.7000000 0.9195402
[1] 0.7000000 0.9195402
[1] "accuracy: 72.9286726077365 num_feat:6 fitness:34.2019666450273"
[1] 0.8214286 0.7865169
[1] 0.8214286 0.7865169
[1] "accuracy: 68.7518590283827 num_feat:6 fitness:36.5834885711258"
[1] 0.0000000 0.9764706
[1] 0.0000000 0.9764706
[1] "accuracy: 79.3523014726287 num_feat:6 fitness:34.6035877411976"
[1] 0.3548387 0.8953488
[1] 0.3548387 0.8953488
[1] "accuracy: 77.3634576141316 num_feat:6 fitness:41.0946551248372"
[1] 0.2857143 0.7191011
[1] 0.2857143 0.7191011
[1] "accuracy: 74.3198529678466 num_feat:6 fitness:24.7343957050968"
[1] 0.4333333 0.9885057
[1] 0.4333333 0.9885057
[1] "accuracy: 72.3559789853704 num_feat:6 fitness:33.840658268079"
[1] "lasso:6:34.5714719231514"
[1] "lasso:5:34.8112420711433"
[1] 0.6896552 0.6363636
[1] 0.6896552 0.6363636
[1] "accuracy: 67.1422058519018 num_feat:7 fitness:28.2392914846219"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 75.2487830370663 num_feat:7 fitness:37.9692424814706"
[1] 0.4333333 0.9310345
[1] 0.4333333 0.9310345
[1] "accuracy: 72.8493443256061 num_feat:7 fitness:29.9488511915198"
[1] 0.5357143 0.7415730
[1] 0.5357143 0.7415730
[1] "accuracy: 73.4615903750086 num_feat:7 fitness:38.7412730185142"
[1] 0.700000 0.908046
[1] 0.700000 0.908046
[1] "accuracy: 72.9646921551606 num_feat:7 fitness:34.2002007961508"
[1] 0.8571429 0.8089888
[1] 0.8571429 0.8089888
[1] "accuracy: 68.436334750988 num_feat:7 fitness:35.1342420290299"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 80.8082209856125 num_feat:7 fitness:36.0591709808217"
[1] 0.2903226 0.9069767
[1] 0.2903226 0.9069767
[1] "accuracy: 72.7743490841268 num_feat:7 fitness:37.5205582949341"
[1] 0.2142857 0.6966292
[1] 0.2142857 0.6966292
[1] "accuracy: 77.5624212711782 num_feat:7 fitness:26.9315258514825"
[1] 0.4000000 0.9885057
[1] 0.4000000 0.9885057
[1] "accuracy: 72.0665234309714 num_feat:7 fitness:34.2535795197213"
[1] "lasso:7:33.8997935648267"
[1] "lasso:5:34.8112420711433"
[1] 0.6896552 0.7386364
[1] 0.6896552 0.7386364
[1] "accuracy: 65.5977761282914 num_feat:8 fitness:26.2254950217242"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 68.1815655106895 num_feat:8 fitness:31.6790483890461"
[1] 0.4000000 0.9195402
[1] 0.4000000 0.9195402
[1] "accuracy: 70.8827534214723 num_feat:8 fitness:28.3617941706415"
[1] 0.5000000 0.7865169
[1] 0.5000000 0.7865169
[1] "accuracy: 70.3677171960647 num_feat:8 fitness:35.2417210137944"
[1] 0.6000000 0.8735632
[1] 0.6000000 0.8735632
[1] "accuracy: 71.9268246575682 num_feat:8 fitness:29.7507526239412"
[1] 0.8214286 0.7752809
[1] 0.8214286 0.7752809
[1] "accuracy: 67.5388897038882 num_feat:8 fitness:35.645581935593"
[1] 0 1
[1] 0 1
[1] "accuracy: 78.963165387003 num_feat:8 fitness:34.7047461693098"
[1] 0.2580645 0.9302326
[1] 0.2580645 0.9302326
[1] "accuracy: 75.1279474056213 num_feat:8 fitness:39.2632065323877"
[1] 0.2500000 0.7303371
[1] 0.2500000 0.7303371
[1] "accuracy: 72.2400766974993 num_feat:8 fitness:23.1132779211697"
[1] 0.4000000 0.9885057
[1] 0.4000000 0.9885057
[1] "accuracy: 71.417709743358 num_feat:8 fitness:32.7071444761596"
[1] "lasso:8:31.6692768253767"
[1] "lasso:5:34.8112420711433"
[1] 0.7931034 0.8409091
[1] 0.7931034 0.8409091
[1] "accuracy: 71.838172571859 num_feat:9 fitness:32.5311610960873"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 71.4727356646852 num_feat:9 fitness:36.0462081067543"
[1] 0.3333333 0.9655172
[1] 0.3333333 0.9655172
[1] "accuracy: 73.3716700846301 num_feat:9 fitness:30.1767126528182"
[1] 0.5357143 0.7977528
[1] 0.5357143 0.7977528
[1] "accuracy: 70.4764519004666 num_feat:9 fitness:36.6906027667613"
[1] 0.6000000 0.8735632
[1] 0.6000000 0.8735632
[1] "accuracy: 74.4852406320913 num_feat:9 fitness:31.6690846885796"
[1] 0.8214286 0.7640449
[1] 0.8214286 0.7640449
[1] "accuracy: 70.2854777309725 num_feat:9 fitness:35.6773881910052"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 77.8212605333393 num_feat:9 fitness:33.4876425879108"
[1] 0.2258065 0.9418605
[1] 0.2258065 0.9418605
[1] "accuracy: 69.6292824658735 num_feat:9 fitness:35.0875875564676"
[1] 0.1785714 0.8314607
[1] 0.1785714 0.8314607
[1] "accuracy: 74.5630139284197 num_feat:9 fitness:30.9296735272919"
[1] 0.3666667 0.9885057
[1] 0.3666667 0.9885057
[1] "accuracy: 71.8226596884023 num_feat:9 fitness:33.2738674969042"
[1] "lasso:9:33.556992867058"
[1] "lasso:5:34.8112420711433"
[1] 0.8275862 0.8409091
[1] 0.8275862 0.8409091
[1] "accuracy: 72.7645842258239 num_feat:10 fitness:33.312131855852"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 71.8907248534445 num_feat:10 fitness:34.4092527477425"
[1] 0.300000 0.954023
[1] 0.300000 0.954023
[1] "accuracy: 73.3883432723868 num_feat:10 fitness:33.4104370341911"
[1] 0.5000000 0.8426966
[1] 0.5000000 0.8426966
[1] "accuracy: 75.9824995134545 num_feat:10 fitness:40.8431674355176"
[1] 0.5666667 0.9195402
[1] 0.5666667 0.9195402
[1] "accuracy: 75.0872470240899 num_feat:10 fitness:35.4854871340535"
[1] 0.8571429 0.8089888
[1] 0.8571429 0.8089888
[1] "accuracy: 73.1463435869719 num_feat:10 fitness:39.9715002811773"
[1] 0.0000000 0.9764706
[1] 0.0000000 0.9764706
[1] "accuracy: 77.9445358907655 num_feat:10 fitness:34.5406598054986"
[1] 0.1612903 0.9651163
[1] 0.1612903 0.9651163
[1] "accuracy: 71.9798349013624 num_feat:10 fitness:36.7473062181267"
[1] 0.2857143 0.8651685
[1] 0.2857143 0.8651685
[1] "accuracy: 76.986302714892 num_feat:10 fitness:33.0992220456639"
[1] 0.4000000 0.9885057
[1] 0.4000000 0.9885057
[1] "accuracy: 73.4625720032795 num_feat:10 fitness:34.3004813171703"
[1] "lasso:10:35.6119645874994"
[1] "lasso:10:35.6119645874994"
[1] 0.7241379 0.8522727
[1] 0.7241379 0.8522727
[1] "accuracy: 76.4290157930902 num_feat:11 fitness:35.830199055295"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 73.7092808705764 num_feat:11 fitness:36.7337911862701"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 74.0033988960575 num_feat:11 fitness:33.6504195068674"
[1] 0.5714286 0.8314607
[1] 0.5714286 0.8314607
[1] "accuracy: 74.8695826029098 num_feat:11 fitness:41.302641037451"
[1] 0.4666667 0.9770115
[1] 0.4666667 0.9770115
[1] "accuracy: 73.7844681735332 num_feat:11 fitness:34.4020362797948"
[1] 0.8571429 0.8202247
[1] 0.8571429 0.8202247
[1] "accuracy: 75.9894492329715 num_feat:11 fitness:42.1318745260567"
[1] 0.0000000 0.9647059
[1] 0.0000000 0.9647059
[1] "accuracy: 77.7701207434205 num_feat:11 fitness:33.794564365854"
[1] 0.09677419 0.96511628
[1] 0.09677419 0.96511628
[1] "accuracy: 75.7518645719792 num_feat:11 fitness:39.414993271248"
[1] 0.2857143 0.8764045
[1] 0.2857143 0.8764045
[1] "accuracy: 77.9523732140388 num_feat:11 fitness:33.8518199304038"
[1] 0.3000000 0.9885057
[1] 0.3000000 0.9885057
[1] "accuracy: 75.793241959724 num_feat:11 fitness:34.798438907243"
[1] "lasso:11:36.5910778066484"
[1] "lasso:11:36.5910778066484"
[1] 0.6206897 0.8750000
[1] 0.6206897 0.8750000
[1] "accuracy: 76.851042057449 num_feat:12 fitness:38.4448713684663"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 80.7694530007437 num_feat:12 fitness:42.0288754066349"
[1] 0.1666667 0.9655172
[1] 0.1666667 0.9655172
[1] "accuracy: 80.7047803021169 num_feat:12 fitness:39.592975732033"
[1] 0.6071429 0.8202247
[1] 0.6071429 0.8202247
[1] "accuracy: 76.0119302726932 num_feat:12 fitness:40.634578945059"
[1] 0.4333333 0.9655172
[1] 0.4333333 0.9655172
[1] "accuracy: 76.3684229173083 num_feat:12 fitness:36.2278884948482"
[1] 0.6785714 0.7977528
[1] 0.6785714 0.7977528
[1] "accuracy: 80.9112267635382 num_feat:12 fitness:45.2277258240173"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 85.4044263295777 num_feat:12 fitness:40.3127167621368"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 78.0986966155193 num_feat:12 fitness:41.0137821040617"
[1] 0.3928571 0.8876404
[1] 0.3928571 0.8876404
[1] "accuracy: 72.7299332911359 num_feat:12 fitness:32.2308921414635"
[1] 0.2666667 0.9885057
[1] 0.2666667 0.9885057
[1] "accuracy: 84.8370146333747 num_feat:12 fitness:42.497890201887"
[1] "lasso:12:39.8212196980608"
[1] "lasso:12:39.8212196980608"
[1] 0.5517241 0.9204545
[1] 0.5517241 0.9204545
[1] "accuracy: 81.5926886607199 num_feat:13 fitness:41.9422840141918"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 84.1259374522447 num_feat:13 fitness:44.517124100558"
[1] 0.2000000 0.9885057
[1] 0.2000000 0.9885057
[1] "accuracy: 83.5610070676846 num_feat:13 fitness:45.2092388599826"
[1] 0.7857143 0.8876404
[1] 0.7857143 0.8876404
[1] "accuracy: 75.8401707419463 num_feat:13 fitness:43.1206823170094"
[1] 0.4666667 0.9655172
[1] 0.4666667 0.9655172
[1] "accuracy: 82.2369676961513 num_feat:13 fitness:40.7125855350531"
[1] 0.8214286 0.8202247
[1] 0.8214286 0.8202247
[1] "accuracy: 83.8657123251601 num_feat:13 fitness:47.8568677503968"
[1] 0 1
[1] 0 1
[1] "accuracy: 86.8151775082222 num_feat:13 fitness:41.6909023238705"
[1] 0.06451613 0.96511628
[1] 0.06451613 0.96511628
[1] "accuracy: 79.7623658269397 num_feat:13 fitness:42.3952719860709"
[1] 0.5714286 0.8764045
[1] 0.5714286 0.8764045
[1] "accuracy: 74.5938353071804 num_feat:13 fitness:35.2971124600243"
[1] 0.2666667 0.9885057
[1] 0.2666667 0.9885057
[1] "accuracy: 87.9553599360879 num_feat:13 fitness:45.0897613504076"
[1] "lasso:13:42.7831830697565"
[1] "lasso:13:42.7831830697565"
[1] 0.5172414 0.9204545
[1] 0.5172414 0.9204545
[1] "accuracy: 84.0018666454281 num_feat:14 fitness:43.6629157289105"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 85.677333702815 num_feat:14 fitness:46.6703624816063"
[1] 0.2000000 0.9770115
[1] 0.2000000 0.9770115
[1] "accuracy: 79.8621490549305 num_feat:14 fitness:39.072981507639"
[1] 0.7857143 0.8764045
[1] 0.7857143 0.8764045
[1] "accuracy: 75.7476859119424 num_feat:14 fitness:43.6725734333601"
[1] 0.4666667 0.9655172
[1] 0.4666667 0.9655172
[1] "accuracy: 82.2135793434852 num_feat:14 fitness:40.6949993932928"
[1] 0.6785714 0.8426966
[1] 0.6785714 0.8426966
[1] "accuracy: 83.2618910114758 num_feat:14 fitness:49.2011362009467"
[1] 0 1
[1] 0 1
[1] "accuracy: 87.2289595786793 num_feat:14 fitness:42.7123790899456"
[1] 0.0000000 0.9651163
[1] 0.0000000 0.9651163
[1] "accuracy: 83.0343333277271 num_feat:14 fitness:44.6347747224059"
[1] 0.6071429 0.8651685
[1] 0.6071429 0.8651685
[1] "accuracy: 76.460185987943 num_feat:14 fitness:36.7580264199808"
[1] 0.2 1.0
[1] 0.2 1.0
[1] "accuracy: 88.0400158984361 num_feat:14 fitness:45.0152774104253"
[1] "lasso:14:43.2095426388513"
[1] "lasso:14:43.2095426388513"
[1] 0.5172414 0.9204545
[1] 0.5172414 0.9204545
[1] "accuracy: 77.2336616599691 num_feat:15 fitness:38.5867171125555"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 83.3057322645667 num_feat:15 fitness:44.0115953840104"
[1] 0.2000000 0.9770115
[1] 0.2000000 0.9770115
[1] "accuracy: 78.3095861552196 num_feat:15 fitness:41.2418477889285"
[1] 0.6785714 0.8764045
[1] 0.6785714 0.8764045
[1] "accuracy: 74.1716247371148 num_feat:15 fitness:43.2123475118951"
[1] 0.4666667 0.9655172
[1] 0.4666667 0.9655172
[1] "accuracy: 81.7668078073187 num_feat:15 fitness:40.3598758639072"
[1] 0.6071429 0.8426966
[1] 0.6071429 0.8426966
[1] "accuracy: 83.1103656071692 num_feat:15 fitness:48.9088758418846"
[1] 0 1
[1] 0 1
[1] "accuracy: 87.2289595786793 num_feat:15 fitness:41.7686055888554"
[1] 0.0000000 0.9767442
[1] 0.0000000 0.9767442
[1] "accuracy: 79.6345495706773 num_feat:15 fitness:42.1139617947997"
[1] 0.6071429 0.8651685
[1] 0.6071429 0.8651685
[1] "accuracy: 76.5002118471459 num_feat:15 fitness:36.7282210365314"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 86.6739316422357 num_feat:15 fitness:43.657336007681"
[1] "lasso:15:42.0589383931049"
[1] "lasso:14:43.2095426388513"
[1] 0.5172414 0.9318182
[1] 0.5172414 0.9318182
[1] "accuracy: 79.0322189986795 num_feat:16 fitness:39.9639993302368"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 82.9779187760911 num_feat:16 fitness:44.6229245189969"
[1] 0.2000000 0.9770115
[1] 0.2000000 0.9770115
[1] "accuracy: 79.4677804670162 num_feat:16 fitness:38.7771153121819"
[1] 0.7142857 0.9213483
[1] 0.7142857 0.9213483
[1] "accuracy: 74.3704977884166 num_feat:16 fitness:43.5631026879584"
[1] 0.4666667 0.9655172
[1] 0.4666667 0.9655172
[1] "accuracy: 80.0317060652458 num_feat:16 fitness:39.0585046800918"
[1] 0.8214286 0.8876404
[1] 0.8214286 0.8876404
[1] "accuracy: 82.4993456096519 num_feat:16 fitness:49.098639802762"
[1] 0 1
[1] 0 1
[1] "accuracy: 87.2971717443338 num_feat:16 fitness:42.9243368516065"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 78.8318513786783 num_feat:16 fitness:41.5634686673882"
[1] 0.6071429 0.8651685
[1] 0.6071429 0.8651685
[1] "accuracy: 75.3537253690875 num_feat:16 fitness:35.9280912013178"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 86.9916929196541 num_feat:16 fitness:44.3335494248641"
[1] "lasso:16:41.9833732477404"
[1] "lasso:14:43.2095426388513"
[1] 0.5172414 0.9318182
[1] 0.5172414 0.9318182
[1] "accuracy: 81.1179784081897 num_feat:17 fitness:39.0282740101087"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 82.3130687884782 num_feat:17 fitness:43.9629518284459"
[1] 0.1000000 0.9770115
[1] 0.1000000 0.9770115
[1] "accuracy: 79.6726785868646 num_feat:17 fitness:38.6808456435924"
[1] 0.6785714 0.9438202
[1] 0.6785714 0.9438202
[1] "accuracy: 75.7493990251897 num_feat:17 fitness:44.5641277992726"
[1] 0.5333333 0.9770115
[1] 0.5333333 0.9770115
[1] "accuracy: 79.6436009093046 num_feat:17 fitness:38.9627832347259"
[1] 0.8214286 0.9101124
[1] 0.8214286 0.9101124
[1] "accuracy: 82.4061990922144 num_feat:17 fitness:49.0849148127041"
[1] 0 1
[1] 0 1
[1] "accuracy: 82.5720438976103 num_feat:17 fitness:37.6085814994891"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 79.6743940585285 num_feat:17 fitness:42.2484684894294"
[1] 0.6428571 0.8764045
[1] 0.6428571 0.8764045
[1] "accuracy: 74.8599006344585 num_feat:17 fitness:35.6750533750116"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 88.5493117984152 num_feat:17 fitness:38.3137813702942"
[1] "lasso:17:40.8129782063074"
[1] "lasso:14:43.2095426388513"
[1] 0.4827586 0.9545455
[1] 0.4827586 0.9545455
[1] "accuracy: 79.5141546715637 num_feat:18 fitness:37.795972615645"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 82.1197567045634 num_feat:18 fitness:43.8179228882491"
[1] 0.1333333 0.9885057
[1] 0.1333333 0.9885057
[1] "accuracy: 77.3561628218112 num_feat:18 fitness:37.0554829080589"
[1] 0.6785714 1.0000000
[1] 0.6785714 1.0000000
[1] "accuracy: 76.9544817475374 num_feat:18 fitness:45.507668875874"
[1] 0.6000000 0.9655172
[1] 0.6000000 0.9655172
[1] "accuracy: 81.7469952870873 num_feat:18 fitness:40.678215175285"
[1] 0.7500000 0.8876404
[1] 0.7500000 0.8876404
[1] "accuracy: 83.1476193298343 num_feat:18 fitness:47.406183909806"
[1] 0 1
[1] 0 1
[1] "accuracy: 82.5956181039183 num_feat:18 fitness:39.3502579463008"
[1] 0.03225806 0.97674419
[1] 0.03225806 0.97674419
[1] "accuracy: 81.1387277669988 num_feat:18 fitness:43.3757436609632"
[1] 0.6785714 0.8651685
[1] 0.6785714 0.8651685
[1] "accuracy: 73.2674280652973 num_feat:18 fitness:34.5418498975252"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 89.2450660556536 num_feat:18 fitness:39.582395137216"
[1] "lasso:18:40.9111693014923"
[1] "lasso:14:43.2095426388513"
[1] 0.4827586 0.9431818
[1] 0.4827586 0.9431818
[1] "accuracy: 79.3083734019627 num_feat:19 fitness:40.1131826952745"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 81.1633596409221 num_feat:19 fitness:43.1005802132575"
[1] 0.1666667 0.9770115
[1] 0.1666667 0.9770115
[1] "accuracy: 76.4288357459671 num_feat:19 fitness:36.4144388062797"
[1] 0.6071429 1.0000000
[1] 0.6071429 1.0000000
[1] "accuracy: 77.9825867561004 num_feat:19 fitness:44.9508068525651"
[1] 0.5666667 0.9770115
[1] 0.5666667 0.9770115
[1] "accuracy: 81.9208986049039 num_feat:19 fitness:40.7540000852372"
[1] 0.7500000 0.8876404
[1] 0.7500000 0.8876404
[1] "accuracy: 83.0574733399439 num_feat:19 fitness:47.3385295401275"
[1] 0 1
[1] 0 1
[1] "accuracy: 83.0053217230523 num_feat:19 fitness:39.7497198391939"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 79.2499651700971 num_feat:19 fitness:41.9881966034681"
[1] 0.6428571 0.9101124
[1] 0.6428571 0.9101124
[1] "accuracy: 78.3436864413912 num_feat:19 fitness:38.3720726386111"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 89.9336698521823 num_feat:19 fitness:40.3519601560982"
[1] "lasso:19:41.3133487430113"
[1] "lasso:14:43.2095426388513"
[1] 0.4137931 0.9886364
[1] 0.4137931 0.9886364
[1] "accuracy: 83.1417375810147 num_feat:20 fitness:45.4293835228357"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 87.5076590121238 num_feat:20 fitness:47.8590412510365"
[1] 0.1666667 0.9885057
[1] 0.1666667 0.9885057
[1] "accuracy: 79.8527504047942 num_feat:20 fitness:42.3445005074414"
[1] 0.5 1.0
[1] 0.5 1.0
[1] "accuracy: 87.8834771048684 num_feat:20 fitness:53.3585725940233"
[1] 0.5666667 0.9770115
[1] 0.5666667 0.9770115
[1] "accuracy: 89.3677458472932 num_feat:20 fitness:46.3390906397686"
[1] 0.8928571 0.9213483
[1] 0.8928571 0.9213483
[1] "accuracy: 85.2720529254533 num_feat:20 fitness:51.4408318720631"
[1] 0 1
[1] 0 1
[1] "accuracy: 88.9774268551964 num_feat:20 fitness:53.395420477708"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 86.9675981334389 num_feat:20 fitness:47.7763764487138"
[1] 0.6428571 0.9325843
[1] 0.6428571 0.9325843
[1] "accuracy: 87.7284436217812 num_feat:20 fitness:45.4667754219237"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 93.5412619572504 num_feat:20 fitness:46.3909426909719"
[1] "lasso:20:47.9800935426486"
[1] "lasso:20:47.9800935426486"
[1] 0.3103448 0.9886364
[1] 0.3103448 0.9886364
[1] "accuracy: 80.7649331594359 num_feat:21 fitness:43.3881146397357"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 85.7291983064508 num_feat:21 fitness:46.4445056832308"
[1] 0.1666667 0.9770115
[1] 0.1666667 0.9770115
[1] "accuracy: 77.4079700737785 num_feat:21 fitness:40.4821347497351"
[1] 0.5 1.0
[1] 0.5 1.0
[1] "accuracy: 82.2501643941301 num_feat:21 fitness:47.8835431837089"
[1] 0.5666667 0.9655172
[1] 0.5666667 0.9655172
[1] "accuracy: 86.9144801739083 num_feat:21 fitness:44.4703608752853"
[1] 0.8928571 0.9213483
[1] 0.8928571 0.9213483
[1] "accuracy: 83.6872753177084 num_feat:21 fitness:50.3020203728195"
[1] 0 1
[1] 0 1
[1] "accuracy: 86.9692698231721 num_feat:21 fitness:52.630362103959"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 87.0571646214373 num_feat:21 fitness:47.8435064374519"
[1] 0.6428571 0.9101124
[1] 0.6428571 0.9101124
[1] "accuracy: 86.7810247130905 num_feat:21 fitness:44.6999865878641"
[1] 0 1
[1] 0 1
[1] "accuracy: 92.6290735973337 num_feat:21 fitness:45.6234232104403"
[1] "lasso:21:46.3767957844231"
[1] "lasso:20:47.9800935426486"
[1] 0.2758621 0.9886364
[1] 0.2758621 0.9886364
[1] "accuracy: 78.7454401911307 num_feat:22 fitness:41.7872431396944"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 83.7115068234647 num_feat:22 fitness:44.9311921937305"
[1] 0.2000000 0.9885057
[1] 0.2000000 0.9885057
[1] "accuracy: 78.5261956459844 num_feat:22 fitness:41.432828017146"
[1] 0.5357143 1.0000000
[1] 0.5357143 1.0000000
[1] "accuracy: 82.2501643941301 num_feat:22 fitness:45.9727840207339"
[1] 0.5666667 0.9655172
[1] 0.5666667 0.9655172
[1] "accuracy: 82.4130521765456 num_feat:22 fitness:41.0942450000026"
[1] 0.7857143 0.9213483
[1] 0.7857143 0.9213483
[1] "accuracy: 82.4212003270708 num_feat:22 fitness:49.0845621097235"
[1] 0 1
[1] 0 1
[1] "accuracy: 83.7227361041841 num_feat:22 fitness:50.1954169374573"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 85.2648949973039 num_feat:22 fitness:46.4992593420911"
[1] 0.6785714 0.8764045
[1] 0.6785714 0.8764045
[1] "accuracy: 84.7804403370534 num_feat:22 fitness:43.20451947994"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 91.6389248556526 num_feat:22 fitness:44.9641001102521"
[1] "lasso:22:44.9166150350772"
[1] "lasso:20:47.9800935426486"
[1] 0.3103448 0.9886364
[1] 0.3103448 0.9886364
[1] "accuracy: 78.850555877756 num_feat:23 fitness:41.9522419239544"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 82.6511570817436 num_feat:23 fitness:44.135885010179"
[1] 0.2000000 0.9885057
[1] 0.2000000 0.9885057
[1] "accuracy: 77.164211512455 num_feat:23 fitness:40.4112950397383"
[1] 0.5 1.0
[1] 0.5 1.0
[1] "accuracy: 79.8153094992726 num_feat:23 fitness:45.3073122580443"
[1] 0.5333333 0.9655172
[1] 0.5333333 0.9655172
[1] "accuracy: 83.2065691334397 num_feat:23 fitness:41.6060045070791"
[1] 0.7500000 0.9325843
[1] 0.7500000 0.9325843
[1] "accuracy: 82.5139897096481 num_feat:23 fitness:49.0430968589247"
[1] 0 1
[1] 0 1
[1] "accuracy: 83.5482866323125 num_feat:23 fitness:50.0645349562929"
[1] 0.03225806 0.97674419
[1] 0.03225806 0.97674419
[1] "accuracy: 86.0241122450645 num_feat:23 fitness:47.0395576332091"
[1] 0.6071429 0.8988764
[1] 0.6071429 0.8988764
[1] "accuracy: 84.2120343300633 num_feat:23 fitness:42.6557784441462"
[1] 0 1
[1] 0 1
[1] "accuracy: 90.144202986568 num_feat:23 fitness:47.093013831178"
[1] "lasso:23:44.9308720462746"
[1] "lasso:20:47.9800935426486"
[1] 0.3103448 0.9772727
[1] 0.3103448 0.9772727
[1] "accuracy: 77.6957326684227 num_feat:24 fitness:38.5576705487846"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 83.5315697915205 num_feat:24 fitness:44.796149665251"
[1] 0.2 1.0
[1] 0.2 1.0
[1] "accuracy: 77.6558162173711 num_feat:24 fitness:40.8086893233486"
[1] 0.5714286 1.0000000
[1] 0.5714286 1.0000000
[1] "accuracy: 81.0966924434515 num_feat:24 fitness:46.0000137069034"
[1] 0.5333333 0.9655172
[1] 0.5333333 0.9655172
[1] "accuracy: 82.5776324532552 num_feat:24 fitness:41.13425711968"
[1] 0.7857143 0.9325843
[1] 0.7857143 0.9325843
[1] "accuracy: 82.2446892134091 num_feat:24 fitness:48.9303623237705"
[1] 0 1
[1] 0 1
[1] "accuracy: 83.7227361041841 num_feat:24 fitness:40.1953271829359"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 87.0520547048344 num_feat:24 fitness:47.7588942069274"
[1] 0.6785714 0.9101124
[1] 0.6785714 0.9101124
[1] "accuracy: 83.8529413393924 num_feat:24 fitness:42.5930751400942"
[1] 0 1
[1] 0 1
[1] "accuracy: 89.1970387006093 num_feat:24 fitness:46.3825957394483"
[1] "lasso:24:43.7157034957144"
[1] "lasso:20:47.9800935426486"
[1] 0.3103448 0.9772727
[1] 0.3103448 0.9772727
[1] "accuracy: 79.4772499970705 num_feat:25 fitness:39.8937636680098"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 82.4814443777939 num_feat:25 fitness:44.0085107276954"
[1] 0.1333333 1.0000000
[1] 0.1333333 1.0000000
[1] "accuracy: 78.1416217194779 num_feat:25 fitness:41.0063319060013"
[1] 0.5714286 1.0000000
[1] 0.5714286 1.0000000
[1] "accuracy: 79.6786170980145 num_feat:25 fitness:42.936412320565"
[1] 0.5333333 0.9655172
[1] 0.5333333 0.9655172
[1] "accuracy: 83.3972595368222 num_feat:25 fitness:41.7489325550946"
[1] 0.9285714 0.9213483
[1] 0.9285714 0.9213483
[1] "accuracy: 82.2446892134091 num_feat:25 fitness:49.2593704160122"
[1] 0 1
[1] 0 1
[1] "accuracy: 83.8049370728492 num_feat:25 fitness:40.256933032174"
[1] 0 1
[1] 0 1
[1] "accuracy: 84.3578918920079 num_feat:25 fitness:45.7672969874886"
[1] 0.6785714 0.9213483
[1] 0.6785714 0.9213483
[1] "accuracy: 84.0556589603706 num_feat:25 fitness:42.9998420300543"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 88.6620481106088 num_feat:25 fitness:46.0646412530206"
[1] "lasso:25:43.3942034896116"
[1] "lasso:20:47.9800935426486"
[1] 0.3448276 0.9886364
[1] 0.3448276 0.9886364
[1] "accuracy: 78.5422685219888 num_feat:26 fitness:39.3070986718986"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 83.8119857339423 num_feat:26 fitness:45.006371867546"
[1] 0.1333333 1.0000000
[1] 0.1333333 1.0000000
[1] "accuracy: 77.7177141379084 num_feat:26 fitness:40.6883563425635"
[1] 0.6071429 0.9775281
[1] 0.6071429 0.9775281
[1] "accuracy: 79.7242273689991 num_feat:26 fitness:45.5036810855476"
[1] 0.5000000 0.9655172
[1] 0.5000000 0.9655172
[1] "accuracy: 82.3595842819847 num_feat:26 fitness:40.8872979033725"
[1] 0.7857143 0.9213483
[1] 0.7857143 0.9213483
[1] "accuracy: 82.4212003270708 num_feat:26 fitness:49.0345660168549"
[1] 0 1
[1] 0 1
[1] "accuracy: 83.8049370728492 num_feat:26 fitness:40.2568881549133"
[1] 0 1
[1] 0 1
[1] "accuracy: 84.1092758909736 num_feat:26 fitness:45.5807901094522"
[1] 0.6071429 0.9213483
[1] 0.6071429 0.9213483
[1] "accuracy: 79.1284214950793 num_feat:26 fitness:39.1257976252538"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 88.6620481106088 num_feat:26 fitness:46.0645963757599"
[1] "lasso:26:43.1455444153162"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]     1     2     3  1083  2211  2667  3155  4208  4352  4756  5278  8166
[13]  8207 11253 11968 15464 18220 18226 20137 21064
     1007_s_at 1053_at 117_at 201555_at 202683_s_at 203139_at 203628_at
[1,]   12.4440  8.3774 6.7866    9.9323      8.8393    9.7965   10.7755
[2,]   12.2005  7.8592 8.0963    9.5628      8.4030    8.3696    9.8410
[3,]   12.6709  8.6762 7.4812   10.3905      8.3998    9.0933    9.4169
     204681_s_at 204825_at 205229_s_at 205751_at 208670_s_at 208712_at
[1,]      7.5046    8.9393      6.8695    5.3569      8.6539   10.9476
[2,]      8.7229    7.7652      5.4533    3.7733      9.5953   11.4622
[3,]      6.9584    9.9136      6.2767    2.5009      9.8134   10.4996
     211864_s_at 212583_at 216092_s_at 218856_at 218862_at 220773_s_at
[1,]     10.7931    6.8476     10.4159    6.2115    9.8843      8.2917
[2,]      9.0349    6.8369      9.7648    8.8050   10.0105      7.4700
[3,]     10.4934    7.3452      8.3641    9.9478    9.0597      7.3719
     221704_s_at
[1,]      8.2502
[2,]      8.0569
[3,]      8.5453
     1007_s_at 1053_at 117_at 201555_at 202683_s_at 203139_at 203628_at
[1,]   12.3446  7.0781 7.5017    9.9499      8.8732    8.8140    9.4326
[2,]   12.0376  7.6011 7.3458    9.6616      8.5511    8.7652    9.8046
[3,]   10.9684  7.4696 8.3759    9.4638      8.5826    9.4426    7.9079
     204681_s_at 204825_at 205229_s_at 205751_at 208670_s_at 208712_at
[1,]      8.7098    7.9851      5.2668    5.4450      8.8319   10.8225
[2,]      8.1223    5.2744      7.1769    6.3482      9.8519    9.8721
[3,]      7.5006    5.9481      6.9284    6.0619      9.3521   10.2362
     211864_s_at 212583_at 216092_s_at 218856_at 218862_at 220773_s_at
[1,]      9.2348    7.5912     10.6963    6.8392   10.4625      8.3954
[2,]     10.1938    7.5112      9.3780   10.2503    9.8143      8.2496
[3,]      8.4931    4.6920      9.3840   10.6432    9.3484      8.0706
     221704_s_at
[1,]      7.8720
[2,]      7.9795
[3,]      7.5452
[1] "numgenes selected:20"
[1] "test acc:0.75"
[1] "test AUC acc:0.633333333333333"
[1] "10 fold train93.8461538461538"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 32  0
         2  1 97
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1  7 17
        2  8 68
[1] "train acc:0.992307692307692"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 32  0
         2  1 97
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 30
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.4137931 0.8863636
[1] 0.4137931 0.8863636
[1] "accuracy: 64.1715742598686 num_feat:3 fitness:24.0189692198063"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 64.9818881981668 num_feat:3 fitness:30.5650685746087"
[1] 0.6000000 0.8275862
[1] 0.6000000 0.8275862
[1] "accuracy: 62.7363089275222 num_feat:3 fitness:23.5221985102263"
[1] 0.3928571 0.6741573
[1] 0.3928571 0.6741573
[1] "accuracy: 67.2631744353045 num_feat:3 fitness:32.8647823102661"
[1] 0.4666667 0.9310345
[1] 0.4666667 0.9310345
[1] "accuracy: 61.6585402863358 num_feat:3 fitness:21.8596735204133"
[1] 0.8571429 0.6516854
[1] 0.8571429 0.6516854
[1] "accuracy: 64.4020585307644 num_feat:3 fitness:31.0734798922944"
[1] 0.0000000 0.9529412
[1] 0.0000000 0.9529412
[1] "accuracy: 70.2213664038749 num_feat:3 fitness:20.9474101897552"
[1] 0.03225806 0.93023256
[1] 0.03225806 0.93023256
[1] "accuracy: 67.806658105195 num_feat:3 fitness:32.3519945946624"
[1] 0.2142857 0.7303371
[1] 0.2142857 0.7303371
[1] "accuracy: 69.0793904618821 num_feat:3 fitness:21.9037019164746"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 62.9627511110358 num_feat:3 fitness:27.1723087757193"
[1] "rfe:3:26.6279587504227"
[1] "rfe:3:26.6279587504227"
[1] 0.4482759 0.9204545
[1] 0.4482759 0.9204545
[1] "accuracy: 68.5995944332185 num_feat:4 fitness:32.2866396563752"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 63.8677430415296 num_feat:4 fitness:30.6800431586588"
[1] 0.4333333 0.9195402
[1] 0.4333333 0.9195402
[1] "accuracy: 63.3280154244361 num_feat:4 fitness:27.3985596695484"
[1] 0.5000000 0.8089888
[1] 0.5000000 0.8089888
[1] "accuracy: 71.5708721393193 num_feat:4 fitness:35.450446505559"
[1] 0.5666667 0.8620690
[1] 0.5666667 0.8620690
[1] "accuracy: 70.0530239112931 num_feat:4 fitness:24.8997442354338"
[1] 0.8928571 0.6853933
[1] 0.8928571 0.6853933
[1] "accuracy: 66.4155012253559 num_feat:4 fitness:32.7092484927117"
[1] 0.2187500 0.8705882
[1] 0.2187500 0.8705882
[1] "accuracy: 70.0789473104792 num_feat:4 fitness:24.6129605771813"
[1] 0.03225806 0.94186047
[1] 0.03225806 0.94186047
[1] "accuracy: 70.934731473223 num_feat:4 fitness:34.5720785650957"
[1] 0.3928571 0.7865169
[1] 0.3928571 0.7865169
[1] "accuracy: 68.7093325046311 num_feat:4 fitness:24.5938719785426"
[1] 0.3000000 0.9195402
[1] 0.3000000 0.9195402
[1] "accuracy: 64.4426602794403 num_feat:4 fitness:24.7800696614183"
[1] "rfe:4:29.1983662500525"
[1] "rfe:4:29.1983662500525"
[1] 0.3793103 0.8522727
[1] 0.3793103 0.8522727
[1] "accuracy: 69.8939434961676 num_feat:5 fitness:32.9144882377683"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 67.6721142615666 num_feat:5 fitness:32.5496709213347"
[1] 0.4333333 0.9310345
[1] 0.4333333 0.9310345
[1] "accuracy: 67.8437736567959 num_feat:5 fitness:30.8162831691337"
[1] 0.5000000 0.9213483
[1] 0.5000000 0.9213483
[1] "accuracy: 71.1877075329315 num_feat:5 fitness:35.443927049912"
[1] 0.5000000 0.8850575
[1] 0.5000000 0.8850575
[1] "accuracy: 70.8940906686452 num_feat:5 fitness:28.755072396215"
[1] 0.8571429 0.7752809
[1] 0.8571429 0.7752809
[1] "accuracy: 65.4254418842882 num_feat:5 fitness:36.1499164169608"
[1] 0.1875000 0.8823529
[1] 0.1875000 0.8823529
[1] "accuracy: 70.9605239591622 num_feat:5 fitness:26.6091259103848"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 72.6330755122952 num_feat:5 fitness:40.1433129244822"
[1] 0.4285714 0.8314607
[1] 0.4285714 0.8314607
[1] "accuracy: 69.8878338632628 num_feat:5 fitness:26.8077609713517"
[1] 0.1666667 0.9425287
[1] 0.1666667 0.9425287
[1] "accuracy: 73.5970376940326 num_feat:5 fitness:31.3699457761363"
[1] "rfe:5:32.155950377368"
[1] "rfe:5:32.155950377368"
[1] 0.3793103 0.9204545
[1] 0.3793103 0.9204545
[1] "accuracy: 69.3165031904855 num_feat:6 fitness:29.7774302895871"
[1] 0.1612903 1.0000000
[1] 0.1612903 1.0000000
[1] "accuracy: 66.3072044735448 num_feat:6 fitness:31.6390905983237"
[1] 0.3000000 0.9655172
[1] 0.3000000 0.9655172
[1] "accuracy: 68.5953682190993 num_feat:6 fitness:31.130425998243"
[1] 0.4285714 0.9213483
[1] 0.4285714 0.9213483
[1] "accuracy: 67.833751169809 num_feat:6 fitness:32.7498434717381"
[1] 0.4333333 0.9425287
[1] 0.4333333 0.9425287
[1] "accuracy: 67.4391712832806 num_feat:6 fitness:26.1408494741837"
[1] 0.7500000 0.7977528
[1] 0.7500000 0.7977528
[1] "accuracy: 64.2589271746015 num_feat:6 fitness:33.0154842193861"
[1] 0.1250000 0.9176471
[1] 0.1250000 0.9176471
[1] "accuracy: 73.7511822959899 num_feat:6 fitness:28.6378935501845"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 68.978136558967 num_feat:6 fitness:33.5699292038169"
[1] 0.3928571 0.8539326
[1] 0.3928571 0.8539326
[1] "accuracy: 70.9481011680614 num_feat:6 fitness:26.2468235442402"
[1] 0.1666667 0.9655172
[1] 0.1666667 0.9655172
[1] "accuracy: 69.6106402210459 num_feat:6 fitness:28.3897501380307"
[1] "rfe:6:30.1297520487734"
[1] "rfe:5:32.155950377368"
[1] 0.3793103 0.8863636
[1] 0.3793103 0.8863636
[1] "accuracy: 70.6148364334131 num_feat:7 fitness:29.8677640616533"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 68.3291574062791 num_feat:7 fitness:33.540307133036"
[1] 0.1666667 0.9080460
[1] 0.1666667 0.9080460
[1] "accuracy: 72.8987810933977 num_feat:7 fitness:27.2142626157866"
[1] 0.6071429 0.8651685
[1] 0.6071429 0.8651685
[1] "accuracy: 64.9326123615411 num_feat:7 fitness:30.1299236215028"
[1] 0.2666667 0.9195402
[1] 0.2666667 0.9195402
[1] "accuracy: 66.4048515718698 num_feat:7 fitness:21.5575935489971"
[1] 0.6428571 0.7640449
[1] 0.6428571 0.7640449
[1] "accuracy: 65.187157728698 num_feat:7 fitness:31.4073093723921"
[1] 0.0937500 0.9529412
[1] 0.0937500 0.9529412
[1] "accuracy: 70.920104433343 num_feat:7 fitness:27.095464654053"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 70.0454912275356 num_feat:7 fitness:39.3891544810135"
[1] 0.3571429 0.8876404
[1] 0.3571429 0.8876404
[1] "accuracy: 69.454241746518 num_feat:7 fitness:27.6850621550178"
[1] 0.1666667 0.9770115
[1] 0.1666667 0.9770115
[1] "accuracy: 73.2772867995748 num_feat:7 fitness:27.7633566128081"
[1] "rfe:7:29.565019825626"
[1] "rfe:5:32.155950377368"
[1] 0.3793103 0.9204545
[1] 0.3793103 0.9204545
[1] "accuracy: 70.1838389217857 num_feat:8 fitness:32.1013805547082"
[1] 0.1612903 1.0000000
[1] 0.1612903 1.0000000
[1] "accuracy: 67.475417725859 num_feat:8 fitness:32.15215690895"
[1] 0.1000000 0.9195402
[1] 0.1000000 0.9195402
[1] "accuracy: 73.3173935645632 num_feat:8 fitness:28.5693619178122"
[1] 0.5000000 0.8651685
[1] 0.5000000 0.8651685
[1] "accuracy: 65.5289051440754 num_feat:8 fitness:29.0592411882856"
[1] 0.4333333 0.9080460
[1] 0.4333333 0.9080460
[1] "accuracy: 70.7582873768882 num_feat:8 fitness:25.2101215209896"
[1] 0.7142857 0.8202247
[1] 0.7142857 0.8202247
[1] "accuracy: 66.2748865309191 num_feat:8 fitness:32.4889442741567"
[1] 0.1250000 0.9294118
[1] 0.1250000 0.9294118
[1] "accuracy: 72.8527500572475 num_feat:8 fitness:25.650164974524"
[1] 0.03225806 0.97674419
[1] 0.03225806 0.97674419
[1] "accuracy: 72.5682162105567 num_feat:8 fitness:41.0409735641778"
[1] 0.5000000 0.8314607
[1] 0.5000000 0.8314607
[1] "accuracy: 62.1421107133682 num_feat:8 fitness:23.8550677610075"
[1] 0.2333333 0.9655172
[1] 0.2333333 0.9655172
[1] "accuracy: 72.0116378221876 num_feat:8 fitness:30.345119270914"
[1] "rfe:8:30.0472531935526"
[1] "rfe:5:32.155950377368"
[1] 0.3103448 0.9318182
[1] 0.3103448 0.9318182
[1] "accuracy: 70.5728855260113 num_feat:9 fitness:32.6274765301213"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 64.6915477248424 num_feat:9 fitness:30.8863187088881"
[1] 0.1000000 0.9310345
[1] 0.1000000 0.9310345
[1] "accuracy: 66.6831122147211 num_feat:9 fitness:20.2890083270205"
[1] 0.4285714 0.8764045
[1] 0.4285714 0.8764045
[1] "accuracy: 69.6010197546788 num_feat:9 fitness:30.8763815709619"
[1] 0.4000000 0.9310345
[1] 0.4000000 0.9310345
[1] "accuracy: 69.2731897838742 num_feat:9 fitness:24.9231760926213"
[1] 0.6785714 0.8651685
[1] 0.6785714 0.8651685
[1] "accuracy: 70.3466204318053 num_feat:9 fitness:35.5657736588367"
[1] 0.1250000 0.9294118
[1] 0.1250000 0.9294118
[1] "accuracy: 70.868649391569 num_feat:9 fitness:25.866400932598"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 71.5571641125089 num_feat:9 fitness:31.0786195210026"
[1] 0.3928571 0.8764045
[1] 0.3928571 0.8764045
[1] "accuracy: 61.0822350591303 num_feat:9 fitness:22.7171632116009"
[1] 0.2666667 0.9540230
[1] 0.2666667 0.9540230
[1] "accuracy: 70.4712158683394 num_feat:9 fitness:29.2443556294166"
[1] "rfe:9:28.4074674183068"
[1] "rfe:5:32.155950377368"
[1] 0.3448276 0.9431818
[1] 0.3448276 0.9431818
[1] "accuracy: 68.4172739363306 num_feat:10 fitness:28.5746525598965"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 64.6318403025968 num_feat:10 fitness:29.8580937644013"
[1] 0.1000000 0.9195402
[1] 0.1000000 0.9195402
[1] "accuracy: 69.7396993121417 num_feat:10 fitness:22.6142812462102"
[1] 0.6071429 0.8876404
[1] 0.6071429 0.8876404
[1] "accuracy: 68.2894939016436 num_feat:10 fitness:33.9230686496189"
[1] 0.4666667 0.9195402
[1] 0.4666667 0.9195402
[1] "accuracy: 66.7663992370794 num_feat:10 fitness:22.3281846271289"
[1] 0.6428571 0.8651685
[1] 0.6428571 0.8651685
[1] "accuracy: 68.5800185966937 num_feat:10 fitness:34.2046293803708"
[1] 0.0937500 0.9411765
[1] 0.0937500 0.9411765
[1] "accuracy: 69.8602747028478 num_feat:10 fitness:24.6086682555742"
[1] 0.0000000 0.9651163
[1] 0.0000000 0.9651163
[1] "accuracy: 70.2743413461948 num_feat:10 fitness:29.211497854814"
[1] 0.6071429 0.7977528
[1] 0.6071429 0.7977528
[1] "accuracy: 69.0169725588236 num_feat:10 fitness:27.0072565313413"
[1] 0.2666667 0.9655172
[1] 0.2666667 0.9655172
[1] "accuracy: 72.2356603949829 num_feat:10 fitness:30.6561596799134"
[1] "rfe:10:28.298649254927"
[1] "rfe:5:32.155950377368"
[1] 0.3448276 0.9318182
[1] 0.3448276 0.9318182
[1] "accuracy: 65.3306699042733 num_feat:11 fitness:26.564783240286"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 66.1981464710696 num_feat:11 fitness:26.0090117425542"
[1] 0.1000000 0.9425287
[1] 0.1000000 0.9425287
[1] "accuracy: 70.0865046449093 num_feat:11 fitness:25.0217801267711"
[1] 0.5357143 0.9213483
[1] 0.5357143 0.9213483
[1] "accuracy: 67.388812036745 num_feat:11 fitness:33.8806341890795"
[1] 0.4333333 0.9540230
[1] 0.4333333 0.9540230
[1] "accuracy: 63.1070744528905 num_feat:11 fitness:19.586519724945"
[1] 0.6428571 0.8764045
[1] 0.6428571 0.8764045
[1] "accuracy: 65.3098434464146 num_feat:11 fitness:31.7800430280413"
[1] 0.0937500 0.9647059
[1] 0.0937500 0.9647059
[1] "accuracy: 67.9589974147028 num_feat:11 fitness:23.6875939211991"
[1] 0.03225806 0.97674419
[1] 0.03225806 0.97674419
[1] "accuracy: 67.6445105136966 num_feat:11 fitness:33.2578856910027"
[1] 0.5714286 0.8202247
[1] 0.5714286 0.8202247
[1] "accuracy: 66.0321084519365 num_feat:11 fitness:22.6823199454964"
[1] 0.2666667 0.9770115
[1] 0.2666667 0.9770115
[1] "accuracy: 72.4812677080287 num_feat:11 fitness:31.1556647915853"
[1] "rfe:11:27.3626236400961"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1] 4756 5223 5240 5278 8388
     205229_s_at 205696_s_at 205713_s_at 205751_at 208893_s_at
[1,]      6.8695     11.6168     10.0607    5.3569      4.0949
[2,]      5.4533      9.5737      5.6228    3.7733      9.2703
[3,]      6.2767      7.2600      6.8404    2.5009      3.9487
     205229_s_at 205696_s_at 205713_s_at 205751_at 208893_s_at
[1,]      5.2668      9.0616      5.2933    5.4450      7.6049
[2,]      7.1769      7.7288      4.3142    6.3482      8.9154
[3,]      6.9284      7.1560      4.5240    6.0619      9.1121
[1] "numgenes selected:5"
[1] "test acc:0.85"
[1] "test AUC acc:0.637254901960784"
[1] "10 fold train83.0769230769231"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 24  4
         2  9 93
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1  5  5
        2 10 80
[1] "train acc:0.9"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 24  4
         2  9 93
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 30
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.5862069 0.6931818
[1] 0.5862069 0.6931818
[1] "accuracy: 50 num_feat:3 fitness:10.2662413696287"
[1] 0.1935484 0.8953488
[1] 0.1935484 0.8953488
[1] "accuracy: 50 num_feat:3 fitness:11.2844488366399"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 50 num_feat:3 fitness:10.284776886528"
[1] 0.07142857 0.92134831
[1] 0.07142857 0.92134831
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:14.4694084353837"
[1] 0.2000000 0.7931034
[1] 0.2000000 0.7931034
[1] "accuracy: 50 num_feat:3 fitness:5.77589725686025"
[1] 0.2142857 0.7303371
[1] 0.2142857 0.7303371
[1] "accuracy: 50.028466619329 num_feat:3 fitness:14.8392960237193"
[1] 0.0312500 0.9529412
[1] 0.0312500 0.9529412
[1] "accuracy: 47.3510945916462 num_feat:3 fitness:12.973664253129"
[1] 0.06451613 0.94186047
[1] 0.06451613 0.94186047
[1] "accuracy: 48.7388169917419 num_feat:3 fitness:13.0571399182948"
[1] 0.3571429 0.6629213
[1] 0.3571429 0.6629213
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:7.27036345344063"
[1] 0.03333333 0.93103448
[1] 0.03333333 0.93103448
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:7.38427952877327"
[1] "elasticnet:3:10.7605515962398"
[1] "elasticnet:3:10.7605515962398"
[1] 0.3103448 0.7613636
[1] 0.3103448 0.7613636
[1] "accuracy: 48.6050070027093 num_feat:4 fitness:8.70075111744067"
[1] 0.1290323 0.9418605
[1] 0.1290323 0.9418605
[1] "accuracy: 50 num_feat:4 fitness:10.2573922268332"
[1] 0.2333333 0.8275862
[1] 0.2333333 0.8275862
[1] "accuracy: 49.1660627495078 num_feat:4 fitness:9.09446899945481"
[1] 0.1071429 0.9325843
[1] 0.1071429 0.9325843
[1] "accuracy: 49.3168011361034 num_feat:4 fitness:14.5867391600492"
[1] 0.2666667 0.7586207
[1] 0.2666667 0.7586207
[1] "accuracy: 47.9800314067994 num_feat:4 fitness:4.34133570481402"
[1] 0.4285714 0.6629213
[1] 0.4285714 0.6629213
[1] "accuracy: 50.028466619329 num_feat:4 fitness:15.2499023976691"
[1] 0.0312500 0.9647059
[1] 0.0312500 0.9647059
[1] "accuracy: 48.5800334135401 num_feat:4 fitness:13.8051754558128"
[1] 0.06451613 0.95348837
[1] 0.06451613 0.95348837
[1] "accuracy: 48.6687967863937 num_feat:4 fitness:12.0078341609056"
[1] 0.4285714 0.6067416
[1] 0.4285714 0.6067416
[1] "accuracy: 49.3168011361034 num_feat:4 fitness:7.30844056654912"
[1] 0.0000000 0.9310345
[1] 0.0000000 0.9310345
[1] "accuracy: 48.1791869466693 num_feat:4 fitness:6.44769067610368"
[1] "elasticnet:4:10.1799730465632"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2758621 0.7840909
[1] 0.2758621 0.7840909
[1] "accuracy: 50 num_feat:5 fitness:9.7175622734145"
[1] 0.06451613 0.96511628
[1] 0.06451613 0.96511628
[1] "accuracy: 50 num_feat:5 fitness:10.1541965618755"
[1] 0.2333333 0.7931034
[1] 0.2333333 0.7931034
[1] "accuracy: 50 num_feat:5 fitness:10.7025822704592"
[1] 0.1071429 0.9101124
[1] 0.1071429 0.9101124
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:14.5305145075076"
[1] 0.0000000 0.9195402
[1] 0.0000000 0.9195402
[1] "accuracy: 49.2945330148801 num_feat:5 fitness:5.06248353911387"
[1] 0.1428571 0.6629213
[1] 0.1428571 0.6629213
[1] "accuracy: 49.3229996342091 num_feat:5 fitness:13.95864764681"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:5 fitness:14.3320486339253"
[1] 0.06451613 0.90697674
[1] 0.06451613 0.90697674
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:6.88294054074305"
[1] 0.4285714 0.7191011
[1] 0.4285714 0.7191011
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:7.58929456569293"
[1] 0.0000000 0.9655172
[1] 0.0000000 0.9655172
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:7.08076859930968"
[1] "elasticnet:5:10.0011039138852"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2758621 0.6590909
[1] 0.2758621 0.6590909
[1] "accuracy: 49.2239863163681 num_feat:6 fitness:9.17040024054832"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 50 num_feat:6 fitness:10.2122912194986"
[1] 0.2333333 0.8390805
[1] 0.2333333 0.8390805
[1] "accuracy: 50 num_feat:6 fitness:9.50399362871429"
[1] 0.2857143 0.8426966
[1] 0.2857143 0.8426966
[1] "accuracy: 49.4914547142425 num_feat:6 fitness:14.8862113700229"
[1] 0.03333333 0.95402299
[1] 0.03333333 0.95402299
[1] "accuracy: 50 num_feat:6 fitness:5.42286979787284"
[1] 0.3571429 0.6966292
[1] 0.3571429 0.6966292
[1] "accuracy: 49.3229996342091 num_feat:6 fitness:14.6264106386577"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:6 fitness:14.6687110124924"
[1] 0.03225806 0.95348837
[1] 0.03225806 0.95348837
[1] "accuracy: 49.3168011361034 num_feat:6 fitness:6.3544698271838"
[1] 0.3928571 0.7078652
[1] 0.3928571 0.7078652
[1] "accuracy: 49.3168011361034 num_feat:6 fitness:7.47187408650607"
[1] 0.0000000 0.9655172
[1] 0.0000000 0.9655172
[1] "accuracy: 49.4306676134195 num_feat:6 fitness:7.41949779351555"
[1] "elasticnet:6:9.97367296150124"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2413793 0.7272727
[1] 0.2413793 0.7272727
[1] "accuracy: 49.2239863163681 num_feat:7 fitness:9.25460301219044"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 50 num_feat:7 fitness:10.2122463422379"
[1] 0.3333333 0.7126437
[1] 0.3333333 0.7126437
[1] "accuracy: 50 num_feat:7 fitness:8.5704565188801"
[1] 0.250000 0.752809
[1] 0.250000 0.752809
[1] "accuracy: 49.4914547142425 num_feat:7 fitness:14.5721616773529"
[1] 0.1000000 0.8965517
[1] 0.1000000 0.8965517
[1] "accuracy: 49.0299828954602 num_feat:7 fitness:4.71853573832875"
[1] 0.2500000 0.6629213
[1] 0.2500000 0.6629213
[1] "accuracy: 50.028466619329 num_feat:7 fitness:14.7555152739857"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:7 fitness:14.5410412096783"
[1] 0.0000000 0.9186047
[1] 0.0000000 0.9186047
[1] "accuracy: 49.3168011361034 num_feat:7 fitness:6.18627831607062"
[1] 0.3928571 0.6292135
[1] 0.3928571 0.6292135
[1] "accuracy: 49.3168011361034 num_feat:7 fitness:7.27519999576223"
[1] 0.000000 0.954023
[1] 0.000000 0.954023
[1] "accuracy: 49.4306676134195 num_feat:7 fitness:7.19048076000565"
[1] "elasticnet:7:9.72765188444926"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2068966 0.8295455
[1] 0.2068966 0.8295455
[1] "accuracy: 49.2239863163681 num_feat:8 fitness:9.42403305655985"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 49.2239863163681 num_feat:8 fitness:9.1468252563481"
[1] 0.2666667 0.8275862
[1] 0.2666667 0.8275862
[1] "accuracy: 50 num_feat:8 fitness:8.03869057412909"
[1] 0.1785714 0.7640449
[1] 0.1785714 0.7640449
[1] "accuracy: 49.4914547142425 num_feat:8 fitness:14.4216352591612"
[1] 0.06666667 0.93103448
[1] 0.06666667 0.93103448
[1] "accuracy: 49.2945330148801 num_feat:8 fitness:4.91977701385142"
[1] 0.1785714 0.7303371
[1] 0.1785714 0.7303371
[1] "accuracy: 50.028466619329 num_feat:8 fitness:14.7454382939963"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:8 fitness:14.5409963324177"
[1] 0.0000000 0.9418605
[1] 0.0000000 0.9418605
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:8.24271650249028"
[1] 0.4285714 0.6067416
[1] 0.4285714 0.6067416
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:7.30826105750636"
[1] 0.0000000 0.9770115
[1] 0.0000000 0.9770115
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:7.1625072891257"
[1] "elasticnet:8:9.79508806355859"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2758621 0.8863636
[1] 0.2758621 0.8863636
[1] "accuracy: 50.6056071278097 num_feat:9 fitness:10.7746630355292"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 48.2202010073769 num_feat:9 fitness:13.3648716299021"
[1] 0.3333333 0.9195402
[1] 0.3333333 0.9195402
[1] "accuracy: 47.4841210064442 num_feat:9 fitness:11.057079539486"
[1] 0.1071429 0.8539326
[1] 0.1071429 0.8539326
[1] "accuracy: 55.4720988770022 num_feat:9 fitness:18.4532211765225"
[1] 0.2666667 0.9425287
[1] 0.2666667 0.9425287
[1] "accuracy: 49.6295462868683 num_feat:9 fitness:5.69972772276574"
[1] 0.2857143 0.7865169
[1] 0.2857143 0.7865169
[1] "accuracy: 52.8913866359719 num_feat:9 fitness:17.2530660898043"
[1] 0.0000000 0.9764706
[1] 0.0000000 0.9764706
[1] "accuracy: 51.2036913048454 num_feat:9 fitness:15.7957171334033"
[1] 0 1
[1] 0 1
[1] "accuracy: 49.9723255153161 num_feat:9 fitness:7.97057283775756"
[1] 0.4642857 0.6629213
[1] 0.4642857 0.6629213
[1] "accuracy: 48.1482781756417 num_feat:9 fitness:9.41155911238736"
[1] 0.000000 0.954023
[1] 0.000000 0.954023
[1] "accuracy: 54.1516749693214 num_feat:9 fitness:10.6780088329965"
[1] "elasticnet:9:12.0458487110555"
[1] "elasticnet:9:12.0458487110555"
[1] 0.1724138 0.8977273
[1] 0.1724138 0.8977273
[1] "accuracy: 55.1221491198582 num_feat:10 fitness:11.3621977242182"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 51.0154474360906 num_feat:10 fitness:18.6430797559949"
[1] 0.4666667 0.8965517
[1] 0.4666667 0.8965517
[1] "accuracy: 50.800050095679 num_feat:10 fitness:13.244921807169"
[1] 0.2500000 0.8876404
[1] 0.2500000 0.8876404
[1] "accuracy: 53.5229553943427 num_feat:10 fitness:20.6827312073315"
[1] 0.3666667 0.9080460
[1] 0.3666667 0.9080460
[1] "accuracy: 56.4819635486555 num_feat:10 fitness:11.0027888952937"
[1] 0.5000000 0.7977528
[1] 0.5000000 0.7977528
[1] "accuracy: 56.3459723558865 num_feat:10 fitness:20.4077646758343"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 56.4671054346257 num_feat:10 fitness:19.8204685386564"
[1] 0 1
[1] 0 1
[1] "accuracy: 59.1711909035094 num_feat:10 fitness:18.489201811066"
[1] 0.5357143 0.6179775
[1] 0.5357143 0.6179775
[1] "accuracy: 51.1027178400781 num_feat:10 fitness:12.4435558614637"
[1] 0.03333333 0.98850575
[1] 0.03333333 0.98850575
[1] "accuracy: 61.0801183035102 num_feat:10 fitness:16.0438366862625"
[1] "elasticnet:10:16.214054696329"
[1] "elasticnet:10:16.214054696329"
[1] 0.2758621 0.8636364
[1] 0.2758621 0.8636364
[1] "accuracy: 57.9417533058047 num_feat:11 fitness:13.6502494033453"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 50.5821336194285 num_feat:11 fitness:19.2559288061318"
[1] 0.3000000 0.8965517
[1] 0.3000000 0.8965517
[1] "accuracy: 54.288817734142 num_feat:11 fitness:15.4447859920889"
[1] 0.2500000 0.9325843
[1] 0.2500000 0.9325843
[1] "accuracy: 60.8694944959136 num_feat:11 fitness:18.5663775933752"
[1] 0.4000000 0.9310345
[1] 0.4000000 0.9310345
[1] "accuracy: 57.4695709980516 num_feat:11 fitness:15.2180225751078"
[1] 0.5357143 0.7865169
[1] 0.5357143 0.7865169
[1] "accuracy: 57.2939927297163 num_feat:11 fitness:19.9299309055912"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 57.3769829827492 num_feat:11 fitness:20.5028318224884"
[1] 0 1
[1] 0 1
[1] "accuracy: 57.3999768501661 num_feat:11 fitness:18.539350985954"
[1] 0.5714286 0.6404494
[1] 0.5714286 0.6404494
[1] "accuracy: 50.6945390671773 num_feat:11 fitness:13.5328423940939"
[1] 0 1
[1] 0 1
[1] "accuracy: 62.6482466582314 num_feat:11 fitness:17.4186645873728"
[1] "elasticnet:11:17.2058985065549"
[1] "elasticnet:11:17.2058985065549"
[1] 0.4137931 0.8750000
[1] 0.4137931 0.8750000
[1] "accuracy: 61.4101636434436 num_feat:12 fitness:19.359406891999"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 56.3705976595914 num_feat:12 fitness:22.688422436541"
[1] 0.200000 0.908046
[1] 0.200000 0.908046
[1] "accuracy: 58.2079136241106 num_feat:12 fitness:19.3510262069719"
[1] 0.2500000 0.9438202
[1] 0.2500000 0.9438202
[1] "accuracy: 61.0721686671985 num_feat:12 fitness:20.7464282322186"
[1] 0.3333333 0.9425287
[1] 0.3333333 0.9425287
[1] "accuracy: 53.6598083490863 num_feat:12 fitness:15.5556229709805"
[1] 0.6071429 0.7865169
[1] 0.6071429 0.7865169
[1] "accuracy: 59.5251967322709 num_feat:12 fitness:23.031860458818"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 61.0931746518152 num_feat:12 fitness:22.6434189551519"
[1] 0 1
[1] 0 1
[1] "accuracy: 63.7284366718622 num_feat:12 fitness:28.0259069018962"
[1] 0.3571429 0.6966292
[1] 0.3571429 0.6966292
[1] "accuracy: 59.9705486118313 num_feat:12 fitness:16.8445398278117"
[1] 0 1
[1] 0 1
[1] "accuracy: 62.7969968636555 num_feat:12 fitness:16.5301823641801"
[1] "elasticnet:12:20.4776815246569"
[1] "elasticnet:12:20.4776815246569"
[1] 0.3448276 0.8863636
[1] 0.3448276 0.8863636
[1] "accuracy: 57.5099576078299 num_feat:13 fitness:17.5922802695928"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 60.6265819733779 num_feat:13 fitness:25.8803657946202"
[1] 0.1666667 0.9080460
[1] 0.1666667 0.9080460
[1] "accuracy: 58.6572980485859 num_feat:13 fitness:20.2164249431383"
[1] 0.2857143 0.9550562
[1] 0.2857143 0.9550562
[1] "accuracy: 60.2659919054827 num_feat:13 fitness:19.1080152744861"
[1] 0.3666667 0.9425287
[1] 0.3666667 0.9425287
[1] "accuracy: 54.3052304990874 num_feat:13 fitness:16.122978039554"
[1] 0.6071429 0.7977528
[1] 0.6071429 0.7977528
[1] "accuracy: 58.9879220213146 num_feat:13 fitness:22.6569494359804"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 61.0865158363377 num_feat:13 fitness:22.9485254541603"
[1] 0 1
[1] 0 1
[1] "accuracy: 64.4373912647421 num_feat:13 fitness:28.5480942443469"
[1] 0.3571429 0.6966292
[1] 0.3571429 0.6966292
[1] "accuracy: 61.2645541892423 num_feat:13 fitness:17.8149991336092"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 62.8603214872206 num_feat:13 fitness:16.74429762126"
[1] "elasticnet:13:20.7632930210748"
[1] "elasticnet:13:20.7632930210748"
[1] 0.3103448 0.9204545
[1] 0.3103448 0.9204545
[1] "accuracy: 59.7081715950977 num_feat:14 fitness:19.9254030618523"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 57.1175167701825 num_feat:14 fitness:24.1576129240538"
[1] 0.2666667 0.9195402
[1] 0.2666667 0.9195402
[1] "accuracy: 60.2038823055717 num_feat:14 fitness:21.3050110577932"
[1] 0.3214286 0.9325843
[1] 0.3214286 0.9325843
[1] "accuracy: 61.5285894644321 num_feat:14 fitness:18.0880245054424"
[1] 0.3000000 0.9425287
[1] 0.3000000 0.9425287
[1] "accuracy: 58.4430021565205 num_feat:14 fitness:19.0595952387015"
[1] 0.5357143 0.8202247
[1] 0.5357143 0.8202247
[1] "accuracy: 57.4313099478692 num_feat:14 fitness:21.3670538503452"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 60.4971258876146 num_feat:14 fitness:22.5064381153573"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 60.0562728923915 num_feat:14 fitness:25.3428557491136"
[1] 0.3928571 0.8202247
[1] 0.3928571 0.8202247
[1] "accuracy: 53.6149979650893 num_feat:14 fitness:13.7260615665645"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 64.6104493205975 num_feat:14 fitness:19.109769143713"
[1] "elasticnet:14:20.4587825212937"
[1] "elasticnet:13:20.7632930210748"
[1] 0.3103448 0.9090909
[1] 0.3103448 0.9090909
[1] "accuracy: 64.8376321759584 num_feat:15 fitness:23.145369131564"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 64.0268835363271 num_feat:15 fitness:29.3395931214016"
[1] 0.2333333 0.9425287
[1] 0.2333333 0.9425287
[1] "accuracy: 61.3467228941281 num_feat:15 fitness:22.1362345529843"
[1] 0.3214286 0.9213483
[1] 0.3214286 0.9213483
[1] "accuracy: 63.4322495164115 num_feat:15 fitness:17.4876347795257"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 59.2089946338987 num_feat:15 fitness:19.9127803516583"
[1] 0.5714286 0.8202247
[1] 0.5714286 0.8202247
[1] "accuracy: 57.580597608753 num_feat:15 fitness:21.5682604330331"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 64.5491577245389 num_feat:15 fitness:25.6173714408504"
[1] 0 1
[1] 0 1
[1] "accuracy: 65.4814593101601 num_feat:15 fitness:29.3405392488376"
[1] 0.3928571 0.8314607
[1] 0.3928571 0.8314607
[1] "accuracy: 56.5554541225322 num_feat:15 fitness:14.7094486950264"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 66.336626669811 num_feat:15 fitness:23.3012321995723"
[1] "elasticnet:15:22.6558463954454"
[1] "elasticnet:15:22.6558463954454"
[1] 0.2413793 0.9204545
[1] 0.2413793 0.9204545
[1] "accuracy: 66.2922098774208 num_feat:16 fitness:26.0798171148587"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 65.7072951607559 num_feat:16 fitness:30.5998569624625"
[1] 0.2333333 0.9310345
[1] 0.2333333 0.9310345
[1] "accuracy: 63.2420882929254 num_feat:16 fitness:27.2123542589787"
[1] 0.3214286 0.9213483
[1] 0.3214286 0.9213483
[1] "accuracy: 70.0016731878235 num_feat:16 fitness:28.1414311770733"
[1] 0.300000 0.954023
[1] 0.300000 0.954023
[1] "accuracy: 64.4052149471475 num_feat:16 fitness:23.5599007093342"
[1] 0.5714286 0.8314607
[1] 0.5714286 0.8314607
[1] "accuracy: 58.5840961715372 num_feat:16 fitness:22.348929365501"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 69.735455036481 num_feat:16 fitness:28.8685013165171"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 69.8486403069182 num_feat:16 fitness:33.9616686052715"
[1] 0.4285714 0.8539326
[1] 0.4285714 0.8539326
[1] "accuracy: 61.3258332526531 num_feat:16 fitness:20.432653654923"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 68.165330276245 num_feat:16 fitness:24.4121289112912"
[1] "elasticnet:16:26.5617242076211"
[1] "elasticnet:16:26.5617242076211"
[1] 0.3103448 0.9318182
[1] 0.3103448 0.9318182
[1] "accuracy: 63.9147206624867 num_feat:17 fitness:26.1210250348682"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 62.4204426125473 num_feat:17 fitness:27.1965119975126"
[1] 0.2000000 0.9310345
[1] 0.2000000 0.9310345
[1] "accuracy: 62.3197258604128 num_feat:17 fitness:26.4372042240003"
[1] 0.4285714 0.9101124
[1] 0.4285714 0.9101124
[1] "accuracy: 70.3052394309349 num_feat:17 fitness:28.6088282373628"
[1] 0.3666667 0.9540230
[1] 0.3666667 0.9540230
[1] "accuracy: 66.5432191412929 num_feat:17 fitness:25.3304606833425"
[1] 0.6071429 0.8426966
[1] 0.6071429 0.8426966
[1] "accuracy: 63.7533650087691 num_feat:17 fitness:26.4191909961915"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 68.9417040083534 num_feat:17 fitness:26.8415832771827"
[1] 0 1
[1] 0 1
[1] "accuracy: 67.4810050244594 num_feat:17 fitness:32.045904000053"
[1] 0.2857143 0.9101124
[1] 0.2857143 0.9101124
[1] "accuracy: 64.2485443189289 num_feat:17 fitness:22.4079486584285"
[1] 0.06666667 0.98850575
[1] 0.06666667 0.98850575
[1] "accuracy: 65.2167942596951 num_feat:17 fitness:22.4325325052801"
[1] "elasticnet:17:26.3841189614222"
[1] "elasticnet:16:26.5617242076211"
[1] 0.3448276 0.9204545
[1] 0.3448276 0.9204545
[1] "accuracy: 66.7478837943587 num_feat:18 fitness:30.8036503121541"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 67.8756916512806 num_feat:18 fitness:32.1454194145443"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 63.1903241565251 num_feat:18 fitness:26.7975365001839"
[1] 0.5000000 0.9213483
[1] 0.5000000 0.9213483
[1] "accuracy: 70.1289346170882 num_feat:18 fitness:34.6492639586405"
[1] 0.3666667 0.9770115
[1] 0.3666667 0.9770115
[1] "accuracy: 64.0691743149598 num_feat:18 fitness:23.5323534506998"
[1] 0.6071429 0.8426966
[1] 0.6071429 0.8426966
[1] "accuracy: 68.6193510023955 num_feat:18 fitness:34.1899300079996"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 75.2131222359325 num_feat:18 fitness:31.5451020706063"
[1] 0 1
[1] 0 1
[1] "accuracy: 71.1132780750673 num_feat:18 fitness:34.7700639107482"
[1] 0.3928571 0.9101124
[1] 0.3928571 0.9101124
[1] "accuracy: 65.9679486592746 num_feat:18 fitness:25.2153141792843"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 70.4835653192066 num_feat:18 fitness:30.1808394670055"
[1] "elasticnet:18:30.3829473271867"
[1] "elasticnet:18:30.3829473271867"
[1] 0.2758621 0.9204545
[1] 0.2758621 0.9204545
[1] "accuracy: 72.4419638002054 num_feat:19 fitness:34.901751646175"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 67.6694101293332 num_feat:19 fitness:31.990663395823"
[1] 0.2333333 0.9310345
[1] 0.2333333 0.9310345
[1] "accuracy: 69.3156118336567 num_feat:19 fitness:31.4173194497374"
[1] 0.3571429 0.9662921
[1] 0.3571429 0.9662921
[1] "accuracy: 72.0267238790713 num_feat:19 fitness:33.1117298285746"
[1] 0.3333333 0.9885057
[1] 0.3333333 0.9885057
[1] "accuracy: 66.4117842579876 num_feat:19 fitness:25.2346683295606"
[1] 0.5714286 0.8539326
[1] 0.5714286 0.8539326
[1] "accuracy: 67.9888627661725 num_feat:19 fitness:33.5561899592748"
[1] 0.0000000 0.9764706
[1] 0.0000000 0.9764706
[1] "accuracy: 74.9491568083218 num_feat:19 fitness:31.3176713579317"
[1] 0 1
[1] 0 1
[1] "accuracy: 71.1271530988652 num_feat:19 fitness:35.6895162104269"
[1] 0.2142857 0.9213483
[1] 0.2142857 0.9213483
[1] "accuracy: 68.6136267475775 num_feat:19 fitness:26.7811891844626"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 70.857907882393 num_feat:19 fitness:30.2051489982619"
[1] "elasticnet:19:31.4205848360229"
[1] "elasticnet:19:31.4205848360229"
[1] 0.2413793 0.9318182
[1] 0.2413793 0.9318182
[1] "accuracy: 71.8317932384951 num_feat:20 fitness:33.8738453286419"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 72.7012895341942 num_feat:20 fitness:35.7645280722081"
[1] 0.3333333 0.9195402
[1] 0.3333333 0.9195402
[1] "accuracy: 67.9284708788218 num_feat:20 fitness:30.5981832241666"
[1] 0.3571429 0.9887640
[1] 0.3571429 0.9887640
[1] "accuracy: 71.7643240171304 num_feat:20 fitness:34.9710648301391"
[1] 0.3000000 0.9885057
[1] 0.3000000 0.9885057
[1] "accuracy: 68.9372392328378 num_feat:20 fitness:27.0453813501042"
[1] 0.5714286 0.8539326
[1] 0.5714286 0.8539326
[1] "accuracy: 67.4479703241568 num_feat:20 fitness:33.1504757505024"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 78.2507761698673 num_feat:20 fitness:34.6565860998693"
[1] 0 1
[1] 0 1
[1] "accuracy: 72.3627777142121 num_feat:20 fitness:36.6161897946764"
[1] 0.3214286 0.8988764
[1] 0.3214286 0.8988764
[1] "accuracy: 72.4571469410638 num_feat:20 fitness:29.8754618198929"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 73.1352128722327 num_feat:20 fitness:31.913082863381"
[1] "elasticnet:20:32.8464799133582"
[1] "elasticnet:20:32.8464799133582"
[1] 0.2413793 0.9545455
[1] 0.2413793 0.9545455
[1] "accuracy: 72.0395402600249 num_feat:21 fitness:31.5864288993467"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 74.9601931486356 num_feat:21 fitness:37.4586609057785"
[1] 0.3000000 0.9425287
[1] 0.3000000 0.9425287
[1] "accuracy: 68.9966891558741 num_feat:21 fitness:31.3734399857296"
[1] 0.3928571 0.9887640
[1] 0.3928571 0.9887640
[1] "accuracy: 72.3983231021835 num_feat:21 fitness:33.5358049809539"
[1] 0.3000000 0.9770115
[1] 0.3000000 0.9770115
[1] "accuracy: 72.5901281096259 num_feat:21 fitness:29.7562674982507"
[1] 0.5714286 0.8539326
[1] 0.5714286 0.8539326
[1] "accuracy: 70.0667179181798 num_feat:21 fitness:35.1144915687589"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 76.3641885859049 num_feat:21 fitness:33.3280571237622"
[1] 0 1
[1] 0 1
[1] "accuracy: 73.4886948729902 num_feat:21 fitness:37.4605827864992"
[1] 0.3928571 0.8988764
[1] 0.3928571 0.8988764
[1] "accuracy: 68.8339747604623 num_feat:21 fitness:27.3366092357525"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 72.3909842977692 num_feat:21 fitness:31.3548665552727"
[1] "elasticnet:21:32.8305209540105"
[1] "elasticnet:21:32.8464799133582"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 72.3856875398271 num_feat:22 fitness:29.3744035728468"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 75.6059692218481 num_feat:22 fitness:38.8520389925181"
[1] 0.300000 0.954023
[1] 0.300000 0.954023
[1] "accuracy: 72.9913110847983 num_feat:22 fitness:34.398097187346"
[1] 0.3928571 0.9775281
[1] 0.3928571 0.9775281
[1] "accuracy: 72.2301753466005 num_feat:22 fitness:34.6315593993656"
[1] 0.2666667 0.9885057
[1] 0.2666667 0.9885057
[1] "accuracy: 69.3799926822155 num_feat:22 fitness:30.627356682616"
[1] 0.5714286 0.8539326
[1] 0.5714286 0.8539326
[1] "accuracy: 72.1909032236101 num_feat:22 fitness:38.707585670571"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 79.3772029939915 num_feat:22 fitness:35.5877730525665"
[1] 0 1
[1] 0 1
[1] "accuracy: 75.1222296072242 num_feat:22 fitness:38.6856889599141"
[1] 0.3928571 0.9101124
[1] 0.3928571 0.9101124
[1] "accuracy: 73.0797273676016 num_feat:22 fitness:30.5489687014868"
[1] 0.06666667 1.00000000
[1] 0.06666667 1.00000000
[1] "accuracy: 73.2353535679263 num_feat:22 fitness:31.9880986306298"
[1] "elasticnet:22:34.3401570849861"
[1] "elasticnet:22:34.3401570849861"
[1] 0.2758621 0.9431818
[1] 0.2758621 0.9431818
[1] "accuracy: 72.4461267924631 num_feat:23 fitness:26.9490768497967"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 75.0538022985065 num_feat:23 fitness:38.5185140840415"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 71.3632754274659 num_feat:23 fitness:29.5649566015687"
[1] 0.4642857 1.0000000
[1] 0.4642857 1.0000000
[1] "accuracy: 72.2420649470326 num_feat:23 fitness:36.8751829262813"
[1] 0.2666667 0.9885057
[1] 0.2666667 0.9885057
[1] "accuracy: 67.837660484014 num_feat:23 fitness:29.4705626567042"
[1] 0.6071429 0.8651685
[1] 0.6071429 0.8651685
[1] "accuracy: 67.5092914018231 num_feat:23 fitness:35.3137075288962"
[1] 0.0000000 0.9764706
[1] 0.0000000 0.9764706
[1] "accuracy: 80.6784486971477 num_feat:23 fitness:36.7980807401879"
[1] 0 1
[1] 0 1
[1] "accuracy: 72.676369362515 num_feat:23 fitness:36.8512488991214"
[1] 0.3928571 0.8988764
[1] 0.3928571 0.8988764
[1] "accuracy: 66.2305381259687 num_feat:23 fitness:25.3839420053609"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 76.4694474919121 num_feat:23 fitness:33.8899026822167"
[1] "elasticnet:23:32.9615174974175"
[1] "elasticnet:22:34.3401570849861"
[1] 0.2068966 0.9431818
[1] 0.2068966 0.9431818
[1] "accuracy: 72.5250036033487 num_feat:24 fitness:26.8357757875967"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 74.4517867790847 num_feat:24 fitness:37.9863124059241"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 70.480480367945 num_feat:24 fitness:28.9028154296674"
[1] 0.4642857 1.0000000
[1] 0.4642857 1.0000000
[1] "accuracy: 70.0911013581201 num_feat:24 fitness:35.2619153573362"
[1] 0.3333333 0.9885057
[1] 0.3333333 0.9885057
[1] "accuracy: 67.1423444435968 num_feat:24 fitness:25.782364082464"
[1] 0.6071429 0.8988764
[1] 0.6071429 0.8988764
[1] "accuracy: 67.0141279279181 num_feat:24 fitness:35.0265597091281"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 79.3406296974538 num_feat:24 fitness:36.6362088989459"
[1] 0 1
[1] 0 1
[1] "accuracy: 72.676369362515 num_feat:24 fitness:36.8512040218607"
[1] 0.3571429 0.9101124
[1] 0.3571429 0.9101124
[1] "accuracy: 66.2005410285347 num_feat:24 fitness:25.3002034783795"
[1] 0 1
[1] 0 1
[1] "accuracy: 74.9007896007508 num_feat:24 fitness:32.3270755812211"
[1] "elasticnet:24:32.0910434752524"
[1] "elasticnet:22:34.3401570849861"
[1] 0.2413793 0.9545455
[1] 0.2413793 0.9545455
[1] "accuracy: 71.4312620133548 num_feat:25 fitness:28.6300407053014"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 72.452193318113 num_feat:25 fitness:36.4865724329347"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 71.0071050533649 num_feat:25 fitness:29.2977390664716"
[1] 0.5 1.0
[1] 0.5 1.0
[1] "accuracy: 70.9756180555587 num_feat:25 fitness:36.0145437174402"
[1] 0.3000000 0.9655172
[1] 0.3000000 0.9655172
[1] "accuracy: 64.0984427491107 num_feat:25 fitness:26.6919216699709"
[1] 0.6071429 0.8988764
[1] 0.6071429 0.8988764
[1] "accuracy: 66.0037088473453 num_feat:25 fitness:34.2687005214378"
[1] 0.0000000 0.9764706
[1] 0.0000000 0.9764706
[1] "accuracy: 77.419770845521 num_feat:25 fitness:34.4628370274641"
[1] 0 1
[1] 0 1
[1] "accuracy: 73.9299059761681 num_feat:25 fitness:37.7913116048399"
[1] 0.3571429 0.9213483
[1] 0.3571429 0.9213483
[1] "accuracy: 64.1298372106502 num_feat:25 fitness:23.7752206253459"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 76.2092165470366 num_feat:25 fitness:34.6946397190387"
[1] "elasticnet:25:32.2113527090245"
[1] "elasticnet:22:34.3401570849861"
[1] 0.2068966 0.9431818
[1] 0.2068966 0.9431818
[1] "accuracy: 69.721666329039 num_feat:26 fitness:27.233183077343"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 72.9979841006638 num_feat:26 fitness:36.895870642587"
[1] 0.1666667 0.9310345
[1] 0.1666667 0.9310345
[1] "accuracy: 68.9050484365612 num_feat:26 fitness:27.6090827610909"
[1] 0.4642857 1.0000000
[1] 0.4642857 1.0000000
[1] "accuracy: 72.2166898563743 num_feat:26 fitness:39.572064869217"
[1] 0.3000000 0.9655172
[1] 0.3000000 0.9655172
[1] "accuracy: 64.4125134295917 num_feat:26 fitness:26.927429803071"
[1] 0.5714286 0.8988764
[1] 0.5714286 0.8988764
[1] "accuracy: 66.7546053918651 num_feat:26 fitness:34.7425423382812"
[1] 0 1
[1] 0 1
[1] "accuracy: 79.0151199468272 num_feat:26 fitness:35.7064415140029"
[1] 0 1
[1] 0 1
[1] "accuracy: 73.6664185816869 num_feat:26 fitness:37.5936511817183"
[1] 0.3571429 0.9213483
[1] 0.3571429 0.9213483
[1] "accuracy: 66.5441914777803 num_feat:26 fitness:25.5859414484328"
[1] 0 1
[1] 0 1
[1] "accuracy: 77.6157708570112 num_feat:26 fitness:34.6661772409256"
[1] "elasticnet:26:32.653238487667"
[1] "elasticnet:22:34.3401570849861"
[1] 0.2413793 0.9431818
[1] 0.2413793 0.9431818
[1] "accuracy: 73.067808142616 num_feat:27 fitness:29.8289514568168"
[1] 0 1
[1] 0 1
[1] "accuracy: 73.9836367567812 num_feat:27 fitness:37.5544200961241"
[1] 0.1666667 0.9540230
[1] 0.1666667 0.9540230
[1] "accuracy: 72.3978579959154 num_feat:27 fitness:33.619449651047"
[1] 0.4642857 1.0000000
[1] 0.4642857 1.0000000
[1] "accuracy: 73.112100048672 num_feat:27 fitness:38.9935776361796"
[1] 0.3333333 0.9655172
[1] 0.3333333 0.9655172
[1] "accuracy: 68.2509101549457 num_feat:27 fitness:26.5561824698258"
[1] 0.6428571 0.9101124
[1] 0.6428571 0.9101124
[1] "accuracy: 67.1714034161161 num_feat:27 fitness:35.2617572954207"
[1] 0 1
[1] 0 1
[1] "accuracy: 80.0371402858316 num_feat:27 fitness:36.5383142492328"
[1] 0 1
[1] 0 1
[1] "accuracy: 74.6716314513887 num_feat:27 fitness:38.3475159567339"
[1] 0.4285714 0.9101124
[1] 0.4285714 0.9101124
[1] "accuracy: 67.1743672942025 num_feat:27 fitness:26.2090099744197"
[1] 0 1
[1] 0 1
[1] "accuracy: 77.5068623518113 num_feat:27 fitness:34.2814955127344"
[1] "elasticnet:27:33.7190674298535"
[1] "elasticnet:22:34.3401570849861"
[1] 0.2413793 0.9545455
[1] 0.2413793 0.9545455
[1] "accuracy: 72.7199749865567 num_feat:28 fitness:32.0964408034207"
[1] 0 1
[1] 0 1
[1] "accuracy: 75.3656549079136 num_feat:28 fitness:37.6817979231218"
[1] 0.1666667 0.9655172
[1] 0.1666667 0.9655172
[1] "accuracy: 71.8485622128341 num_feat:28 fitness:36.5695019019926"
[1] 0.4285714 1.0000000
[1] 0.4285714 1.0000000
[1] "accuracy: 76.0759444942436 num_feat:28 fitness:41.1271303788119"
[1] 0.3333333 0.9655172
[1] 0.3333333 0.9655172
[1] "accuracy: 69.9393515148764 num_feat:28 fitness:27.8224686125131"
[1] 0.6428571 0.8988764
[1] 0.6428571 0.8988764
[1] "accuracy: 68.7629018771529 num_feat:28 fitness:36.4272463762972"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.4218004275763 num_feat:28 fitness:38.4100978116139"
[1] 0 1
[1] 0 1
[1] "accuracy: 76.3052799036449 num_feat:28 fitness:39.6798794439615"
[1] 0.4642857 0.9213483
[1] 0.4642857 0.9213483
[1] "accuracy: 65.5885395244317 num_feat:28 fitness:25.1369698717571"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 76.9171030645801 num_feat:28 fitness:33.9224645033836"
[1] "elasticnet:28:34.8873997626873"
[1] "elasticnet:28:34.8873997626873"
[1] 0.2068966 0.9431818
[1] 0.2068966 0.9431818
[1] "accuracy: 72.687859801114 num_feat:29 fitness:31.9576935496172"
[1] 0 1
[1] 0 1
[1] "accuracy: 76.0815788943645 num_feat:29 fitness:38.2186960356993"
[1] 0.1666667 0.9655172
[1] 0.1666667 0.9655172
[1] "accuracy: 71.6600119404965 num_feat:29 fitness:36.4280443204787"
[1] 0.4285714 1.0000000
[1] 0.4285714 1.0000000
[1] "accuracy: 75.8697800847639 num_feat:29 fitness:39.7224621944414"
[1] 0.4000000 0.9655172
[1] 0.4000000 0.9655172
[1] "accuracy: 68.0215284597193 num_feat:29 fitness:29.8840564438846"
[1] 0.6785714 0.8876404
[1] 0.6785714 0.8876404
[1] "accuracy: 68.1275377145149 num_feat:29 fitness:35.9620576198774"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.0655725813892 num_feat:29 fitness:37.3688968212029"
[1] 0 1
[1] 0 1
[1] "accuracy: 76.3164506241656 num_feat:29 fitness:39.6882126070913"
[1] 0.5000000 0.9213483
[1] 0.5000000 0.9213483
[1] "accuracy: 66.5277628759911 num_feat:29 fitness:25.9306282224516"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 77.5483641809097 num_feat:29 fitness:34.1427084146237"
[1] "elasticnet:29:34.9303456229368"
[1] "elasticnet:29:34.9303456229368"
[1] 0.2068966 0.9431818
[1] 0.2068966 0.9431818
[1] "accuracy: 69.7063107153221 num_feat:30 fitness:29.7214868580126"
[1] 0 1
[1] 0 1
[1] "accuracy: 73.8787780367287 num_feat:30 fitness:36.5665505152117"
[1] 0.1666667 0.9655172
[1] 0.1666667 0.9655172
[1] "accuracy: 70.2804568633321 num_feat:30 fitness:32.0599998020114"
[1] 0.5714286 1.0000000
[1] 0.5714286 1.0000000
[1] "accuracy: 76.2775010388182 num_feat:30 fitness:40.3853508898643"
[1] 0.3666667 0.9770115
[1] 0.3666667 0.9770115
[1] "accuracy: 66.5046702117907 num_feat:30 fitness:28.691770179528"
[1] 0.6785714 0.8876404
[1] 0.6785714 0.8876404
[1] "accuracy: 68.1691079887949 num_feat:30 fitness:36.0213458059551"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.383277867199 num_feat:30 fitness:37.6071309082996"
[1] 0 1
[1] 0 1
[1] "accuracy: 74.4537531498544 num_feat:30 fitness:38.2911446240972"
[1] 0.5357143 0.9213483
[1] 0.5357143 0.9213483
[1] "accuracy: 65.4014316537468 num_feat:30 fitness:25.1751206427934"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 77.7957527531143 num_feat:30 fitness:37.6615382998499"
[1] "elasticnet:30:34.2181438525623"
[1] "elasticnet:29:34.9303456229368"
[1] 0.2413793 0.9431818
[1] 0.2413793 0.9431818
[1] "accuracy: 70.3690683849595 num_feat:31 fitness:32.8047171295317"
[1] 0 1
[1] 0 1
[1] "accuracy: 77.6043223158443 num_feat:31 fitness:39.3606638472877"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 68.024316752013 num_feat:31 fitness:30.4224475424107"
[1] 0.5714286 0.9887640
[1] 0.5714286 0.9887640
[1] "accuracy: 76.6337604888077 num_feat:31 fitness:41.8744107124553"
[1] 0.4000000 0.9770115
[1] 0.4000000 0.9770115
[1] "accuracy: 66.0474829745291 num_feat:31 fitness:28.4317331686612"
[1] 0.6785714 0.8876404
[1] 0.6785714 0.8876404
[1] "accuracy: 70.1023990196996 num_feat:31 fitness:37.4712692018729"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 81.066420833588 num_feat:31 fitness:37.3400314911248"
[1] 0 1
[1] 0 1
[1] "accuracy: 73.5652142185996 num_feat:31 fitness:37.6246955483955"
[1] 0.5357143 0.9101124
[1] 0.5357143 0.9101124
[1] "accuracy: 68.8279777695175 num_feat:31 fitness:27.7168954647203"
[1] 0.03333333 0.98850575
[1] 0.03333333 0.98850575
[1] "accuracy: 78.6725786185633 num_feat:31 fitness:38.2903771894919"
[1] "elasticnet:31:35.1337241295952"
[1] "elasticnet:31:35.1337241295952"
[1] 0.2758621 0.9431818
[1] 0.2758621 0.9431818
[1] "accuracy: 69.2073602173925 num_feat:32 fitness:32.0195980231475"
[1] 0 1
[1] 0 1
[1] "accuracy: 77.6151889372058 num_feat:32 fitness:39.3687689360482"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 68.1682621767459 num_feat:32 fitness:30.5303617336997"
[1] 0.5714286 0.9887640
[1] 0.5714286 0.9887640
[1] "accuracy: 74.6980335221637 num_feat:32 fitness:40.4225706102116"
[1] 0.3666667 0.9770115
[1] 0.3666667 0.9770115
[1] "accuracy: 66.0150549244318 num_feat:32 fitness:28.3240339204942"
[1] 0.6428571 0.8988764
[1] 0.6428571 0.8988764
[1] "accuracy: 70.1313216283412 num_feat:32 fitness:37.4533816806456"
[1] 0 1
[1] 0 1
[1] "accuracy: 79.7603887010575 num_feat:32 fitness:34.6658336098308"
[1] 0 1
[1] 0 1
[1] "accuracy: 71.6220766865247 num_feat:32 fitness:36.1672975220786"
[1] 0.4642857 0.9213483
[1] 0.4642857 0.9213483
[1] "accuracy: 68.0053563667323 num_feat:32 fitness:26.9494029944398"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 78.5844452746992 num_feat:32 fitness:38.2529679365171"
[1] "elasticnet:32:34.4154216967113"
[1] "elasticnet:31:35.1337241295952"
[1] 0.2413793 0.9431818
[1] 0.2413793 0.9431818
[1] "accuracy: 70.0881952814666 num_feat:33 fitness:32.5939725473906"
[1] 0 1
[1] 0 1
[1] "accuracy: 77.0579680054588 num_feat:33 fitness:38.9508083599773"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 68.6292777458807 num_feat:33 fitness:30.9048141654741"
[1] 0.5714286 0.9887640
[1] 0.5714286 0.9887640
[1] "accuracy: 75.8288434966538 num_feat:33 fitness:41.2706332138185"
[1] 0.3666667 0.9770115
[1] 0.3666667 0.9770115
[1] "accuracy: 66.0150549244318 num_feat:33 fitness:28.3239890432335"
[1] 0.6071429 0.8876404
[1] 0.6071429 0.8876404
[1] "accuracy: 68.6222127779337 num_feat:33 fitness:36.2041295636531"
[1] 0 1
[1] 0 1
[1] "accuracy: 79.2592396993714 num_feat:33 fitness:34.2899269813055"
[1] 0 1
[1] 0 1
[1] "accuracy: 71.3084253297904 num_feat:33 fitness:35.9320141272672"
[1] 0.4642857 0.9325843
[1] 0.4642857 0.9325843
[1] "accuracy: 68.9374429302312 num_feat:33 fitness:27.6765129274436"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 78.2403013982233 num_feat:33 fitness:37.9948151518995"
[1] "elasticnet:33:34.4141616081463"
[1] "elasticnet:31:35.1337241295952"
[1] 0.2413793 0.9431818
[1] 0.2413793 0.9431818
[1] "accuracy: 73.6446095316346 num_feat:34 fitness:32.761238357756"
[1] 0 1
[1] 0 1
[1] "accuracy: 75.5230023546497 num_feat:34 fitness:37.7995392446097"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 71.0846524370828 num_feat:34 fitness:32.717564674431"
[1] 0.6071429 0.9775281
[1] 0.6071429 0.9775281
[1] "accuracy: 73.5017727651068 num_feat:34 fitness:39.5430048232039"
[1] 0.3333333 0.9770115
[1] 0.3333333 0.9770115
[1] "accuracy: 66.4093654566358 num_feat:34 fitness:28.5363437317925"
[1] 0.6785714 0.8988764
[1] 0.6785714 0.8988764
[1] "accuracy: 68.594917138154 num_feat:34 fitness:38.3902742727695"
[1] 0 1
[1] 0 1
[1] "accuracy: 78.542306083899 num_feat:34 fitness:33.7521818924405"
[1] 0 1
[1] 0 1
[1] "accuracy: 72.8944093348598 num_feat:34 fitness:37.1214572538086"
[1] 0.5000000 0.9325843
[1] 0.5000000 0.9325843
[1] "accuracy: 68.4341496202743 num_feat:34 fitness:27.388283782001"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 79.6322800420328 num_feat:34 fitness:35.7054209241626"
[1] "elasticnet:34:34.3715308956975"
[1] "elasticnet:31:35.1337241295952"
[1] 0.2413793 0.9545455
[1] 0.2413793 0.9545455
[1] "accuracy: 76.6514249208277 num_feat:35 fitness:37.5447141132992"
[1] 0 1
[1] 0 1
[1] "accuracy: 82.2726738068083 num_feat:35 fitness:43.7708388655589"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 73.7538664362469 num_feat:35 fitness:38.0527636298768"
[1] 0.6071429 0.9775281
[1] 0.6071429 0.9775281
[1] "accuracy: 81.4472580936893 num_feat:35 fitness:44.7520739423802"
[1] 0.3333333 0.9770115
[1] 0.3333333 0.9770115
[1] "accuracy: 76.0715307188498 num_feat:35 fitness:35.7829228011923"
[1] 0.7142857 0.9213483
[1] 0.7142857 0.9213483
[1] "accuracy: 72.8459678542073 num_feat:35 fitness:41.7239829221154"
[1] 0 1
[1] 0 1
[1] "accuracy: 82.6482895586545 num_feat:35 fitness:39.3889986239212"
[1] 0 1
[1] 0 1
[1] "accuracy: 78.6634893069085 num_feat:35 fitness:41.4482223555844"
[1] 0.5000000 0.9325843
[1] 0.5000000 0.9325843
[1] "accuracy: 77.4804462940092 num_feat:35 fitness:36.1729614100415"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 81.3104479649112 num_feat:35 fitness:36.9640019890607"
[1] "elasticnet:35:39.5601480653031"
[1] "elasticnet:35:39.5601480653031"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 80.7781764874394 num_feat:36 fitness:40.6681420019063"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 80.2770441899481 num_feat:36 fitness:42.7021100440618"
[1] 0.2333333 0.9655172
[1] 0.2333333 0.9655172
[1] "accuracy: 73.8989891814097 num_feat:36 fitness:38.2736297770054"
[1] 0.5357143 1.0000000
[1] 0.5357143 1.0000000
[1] "accuracy: 79.663653605199 num_feat:36 fitness:42.0419340454612"
[1] 0.3333333 0.9770115
[1] 0.3333333 0.9770115
[1] "accuracy: 77.2668940142681 num_feat:36 fitness:33.346067062162"
[1] 0.7500000 0.9213483
[1] 0.7500000 0.9213483
[1] "accuracy: 71.3347177616685 num_feat:36 fitness:40.6797861897363"
[1] 0 1
[1] 0 1
[1] "accuracy: 83.4614613115217 num_feat:36 fitness:39.9988325613108"
[1] 0 1
[1] 0 1
[1] "accuracy: 80.1076173841051 num_feat:36 fitness:42.5312735362211"
[1] 0.5357143 0.9325843
[1] 0.5357143 0.9325843
[1] "accuracy: 76.4974429831266 num_feat:36 fitness:35.5249497639046"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 80.414394068908 num_feat:36 fitness:39.625250023131"
[1] "elasticnet:36:39.5391975004901"
[1] "elasticnet:36:39.5601480653031"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 80.7781764874394 num_feat:37 fitness:40.6680971246456"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 82.0453040885165 num_feat:37 fitness:44.0282600907274"
[1] 0.2333333 0.9770115
[1] 0.2333333 0.9770115
[1] "accuracy: 75.8248423236076 num_feat:37 fitness:39.7467103885771"
[1] 0.6428571 1.0000000
[1] 0.6428571 1.0000000
[1] "accuracy: 79.1026494367442 num_feat:37 fitness:41.8889931847165"
[1] 0.4000000 0.9770115
[1] 0.4000000 0.9770115
[1] "accuracy: 76.8116957678664 num_feat:37 fitness:33.1712901667667"
[1] 0.7500000 0.9213483
[1] 0.7500000 0.9213483
[1] "accuracy: 72.5137922199565 num_feat:37 fitness:41.5640471561917"
[1] 0 1
[1] 0 1
[1] "accuracy: 84.475665672591 num_feat:37 fitness:40.7594409548522"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.8075259778856 num_feat:37 fitness:43.8539840247686"
[1] 0.5000000 0.9325843
[1] 0.5000000 0.9325843
[1] "accuracy: 82.0557633764454 num_feat:37 fitness:37.6043594673473"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 80.9297200888918 num_feat:37 fitness:40.0116996608581"
[1] "elasticnet:37:40.3296882219451"
[1] "elasticnet:37:40.3296882219451"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 80.6819628529774 num_feat:38 fitness:40.5958920215384"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.9022196043291 num_feat:38 fitness:43.8402566890359"
[1] 0.2333333 0.9655172
[1] 0.2333333 0.9655172
[1] "accuracy: 75.5715744268937 num_feat:38 fitness:39.527978956597"
[1] 0.6428571 1.0000000
[1] 0.6428571 1.0000000
[1] "accuracy: 78.8173520447957 num_feat:38 fitness:41.6749752634944"
[1] 0.4000000 0.9770115
[1] 0.4000000 0.9770115
[1] "accuracy: 76.5192673705662 num_feat:38 fitness:32.9519239915308"
[1] 0.7500000 0.9325843
[1] 0.7500000 0.9325843
[1] "accuracy: 72.5137922199565 num_feat:38 fitness:41.5920921665714"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.3324071592507 num_feat:38 fitness:38.2888877211175"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.9447075735289 num_feat:38 fitness:43.9568253442404"
[1] 0.5357143 0.9213483
[1] 0.5357143 0.9213483
[1] "accuracy: 82.0557633764454 num_feat:38 fitness:37.6655104167318"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 79.9954205124301 num_feat:38 fitness:39.3109301012512"
[1] "elasticnet:38:39.9405272672109"
[1] "elasticnet:37:40.3296882219451"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 80.0442028544652 num_feat:39 fitness:39.0064160342825"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.8745331239592 num_feat:39 fitness:43.8194469514977"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 74.7587904947064 num_feat:39 fitness:38.889610498012"
[1] 0.6428571 1.0000000
[1] 0.6428571 1.0000000
[1] "accuracy: 78.7857190254779 num_feat:39 fitness:42.9012056217454"
[1] 0.3666667 0.9770115
[1] 0.3666667 0.9770115
[1] "accuracy: 76.5192673705662 num_feat:39 fitness:32.8685457809368"
[1] 0.7500000 0.9325843
[1] 0.7500000 0.9325843
[1] "accuracy: 72.3730955736186 num_feat:39 fitness:41.4865248045573"
[1] 0 1
[1] 0 1
[1] "accuracy: 82.6921546849819 num_feat:39 fitness:39.1997990576376"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.1693577754998 num_feat:39 fitness:43.3752681184578"
[1] 0.5357143 0.9213483
[1] 0.5357143 0.9213483
[1] "accuracy: 81.9368491270694 num_feat:39 fitness:37.5762798524391"
[1] 0.03333333 1.00000000
[1] 0.03333333 1.00000000
[1] "accuracy: 78.3895209431926 num_feat:39 fitness:38.1064605470623"
[1] "elasticnet:39:39.7229557266629"
[1] "elasticnet:37:40.3296882219451"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 81.9644078716994 num_feat:40 fitness:40.4465249199475"
[1] 0 1
[1] 0 1
[1] "accuracy: 82.2754878128282 num_feat:40 fitness:44.1201180908888"
[1] 0.2333333 0.9655172
[1] 0.2333333 0.9655172
[1] "accuracy: 76.8050665145424 num_feat:40 fitness:40.4530082678122"
[1] 0.5714286 1.0000000
[1] 0.5714286 1.0000000
[1] "accuracy: 78.3551781331535 num_feat:40 fitness:42.39968364667"
[1] 0.3333333 0.9885057
[1] 0.3333333 0.9885057
[1] "accuracy: 76.8389562130233 num_feat:40 fitness:33.0536698343696"
[1] 0.7142857 0.9325843
[1] 0.7142857 0.9325843
[1] "accuracy: 71.7239189524872 num_feat:40 fitness:40.9103117471623"
[1] 0 1
[1] 0 1
[1] "accuracy: 82.4316570620221 num_feat:40 fitness:39.1132353936747"
[1] 0 1
[1] 0 1
[1] "accuracy: 79.3428760587225 num_feat:40 fitness:42.0053619536142"
[1] 0.5000000 0.9213483
[1] 0.5000000 0.9213483
[1] "accuracy: 79.8789968187592 num_feat:40 fitness:35.9435600296601"
[1] 0 1
[1] 0 1
[1] "accuracy: 77.4628329602874 num_feat:40 fitness:37.3280663492894"
[1] "elasticnet:40:39.5773540233089"
[1] "elasticnet:37:40.3296882219451"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 81.691130465372 num_feat:41 fitness:37.7415219879412"
[1] 0 1
[1] 0 1
[1] "accuracy: 78.2316576182438 num_feat:41 fitness:41.0872005676898"
[1] 0.2333333 0.9655172
[1] 0.2333333 0.9655172
[1] "accuracy: 78.6706996503528 num_feat:41 fitness:41.8521882424093"
[1] 0.5 1.0
[1] 0.5 1.0
[1] "accuracy: 78.1407045223453 num_feat:41 fitness:42.0602121327318"
[1] 0.2666667 0.9885057
[1] 0.2666667 0.9885057
[1] "accuracy: 72.5657823336358 num_feat:41 fitness:29.6820778809015"
[1] 0.6785714 0.9213483
[1] 0.6785714 0.9213483
[1] "accuracy: 71.871001833692 num_feat:41 fitness:40.9032034288791"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.9734405316654 num_feat:41 fitness:37.9361947853132"
[1] 0 1
[1] 0 1
[1] "accuracy: 80.0617406504478 num_feat:41 fitness:42.5444655201475"
[1] 0.5000000 0.9213483
[1] 0.5000000 0.9213483
[1] "accuracy: 75.8148848100193 num_feat:41 fitness:32.8954311458445"
[1] 0 1
[1] 0 1
[1] "accuracy: 77.7194135009432 num_feat:41 fitness:37.5204568775205"
[1] "elasticnet:41:38.4222952569378"
[1] "elasticnet:37:40.3296882219451"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 81.3831145705994 num_feat:42 fitness:38.6215763007122"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 77.6290132532348 num_feat:42 fitness:40.7158175779627"
[1] 0.2666667 0.9655172
[1] 0.2666667 0.9655172
[1] "accuracy: 76.3786010286494 num_feat:42 fitness:39.9304299112298"
[1] 0.4642857 1.0000000
[1] 0.4642857 1.0000000
[1] "accuracy: 77.3379784648507 num_feat:42 fitness:40.1188369980644"
[1] 0.3333333 0.9885057
[1] 0.3333333 0.9885057
[1] "accuracy: 72.5657823336358 num_feat:42 fitness:29.8486996703075"
[1] 0.6785714 0.9325843
[1] 0.6785714 0.9325843
[1] "accuracy: 70.833313879386 num_feat:42 fitness:40.1529824735293"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.9734405316654 num_feat:42 fitness:37.9361499080525"
[1] 0 1
[1] 0 1
[1] "accuracy: 79.702423588234 num_feat:42 fitness:42.2749328462264"
[1] 0.5000000 0.9213483
[1] 0.5000000 0.9213483
[1] "accuracy: 75.8535590052218 num_feat:42 fitness:32.9243919149856"
[1] 0 1
[1] 0 1
[1] "accuracy: 76.8516300717371 num_feat:42 fitness:36.8695744283553"
[1] "elasticnet:42:37.9393392029426"
[1] "elasticnet:37:40.3296882219451"
[1] 0.2413793 0.9659091
[1] 0.2413793 0.9659091
[1] "accuracy: 75.7848226779792 num_feat:43 fitness:33.3117013928752"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 78.6902492543419 num_feat:43 fitness:41.1643065944139"
[1] 0.2666667 0.9540230
[1] 0.2666667 0.9540230
[1] "accuracy: 75.4531446379446 num_feat:43 fitness:39.2075571087566"
[1] 0.4285714 1.0000000
[1] 0.4285714 1.0000000
[1] "accuracy: 78.8376688548062 num_feat:43 fitness:42.4042741989846"
[1] 0.3000000 0.9770115
[1] 0.3000000 0.9770115
[1] "accuracy: 72.1193052028858 num_feat:43 fitness:29.4017279794671"
[1] 0.7142857 0.9325843
[1] 0.7142857 0.9325843
[1] "accuracy: 71.2254385760154 num_feat:43 fitness:40.5363168330264"
[1] 0 1
[1] 0 1
[1] "accuracy: 81.8082244071972 num_feat:43 fitness:37.8749389344463"
[1] 0 1
[1] 0 1
[1] "accuracy: 79.0811174583731 num_feat:43 fitness:41.80890837157"
[1] 0.5000000 0.9213483
[1] 0.5000000 0.9213483
[1] "accuracy: 77.3089771353547 num_feat:43 fitness:34.0159106353246"
[1] 0 1
[1] 0 1
[1] "accuracy: 76.9469036319106 num_feat:43 fitness:36.9409847212247"
[1] "elasticnet:43:37.6666626770089"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]     1     2     3     4     5     6     7     8     9    10    11    12
[13]    13  1083  1326  2211  2667  3155  4208  4352  4756  4874  5223  5278
[25]  5927  8166  8207 11253 11729 11968 15464 18171 18226 18415 18802 19380
[37] 20616
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
     1405_i_at 1431_at 1438_at 1487_at 1494_f_at 201555_at 201798_s_at
[1,]    6.2325  6.8450  7.5774  9.3080    8.5992    9.9323     11.6423
[2,]    6.9047  5.8878  9.8562  8.8356    8.3173    9.5628     10.3129
[3,]    6.5940  5.6843  7.4038  9.5398    8.7748   10.3905     11.6751
     202683_s_at 203139_at 203628_at 204681_s_at 204825_at 205229_s_at
[1,]      8.8393    9.7965   10.7755      7.5046    8.9393      6.8695
[2,]      8.4030    8.3696    9.8410      8.7229    7.7652      5.4533
[3,]      8.3998    9.0933    9.4169      6.9584    9.9136      6.2767
     205347_s_at 205696_s_at 205751_at 206401_s_at 208670_s_at 208712_at
[1,]      7.7184     11.6168    5.3569      9.9796      8.6539   10.9476
[2,]      7.0526      9.5737    3.7733      9.9498      9.5953   11.4622
[3,]      7.7606      7.2600    2.5009      6.0807      9.8134   10.4996
     211864_s_at 212344_at 212583_at 216092_s_at 218807_at 218862_at
[1,]     10.7931    9.2335    6.8476     10.4159   11.7120    9.8843
[2,]      9.0349    7.4051    6.8369      9.7648   11.2932   10.0105
[3,]     10.4934    8.4941    7.3452      8.3641   10.2407    9.0597
     219051_x_at 219438_at 220016_at 221253_s_at
[1,]      8.5236    8.4788    3.4755     11.5740
[2,]      8.9626    7.7381    6.8893     11.6896
[3,]     10.7458    7.3137    7.4639     11.6025
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327  9.2305  8.1481  6.1196
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568  9.1180  8.3105  7.1575
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579  9.3514  8.1214  7.7247
     1405_i_at 1431_at 1438_at 1487_at 1494_f_at 201555_at 201798_s_at
[1,]    4.2718  7.1375  8.5984  8.9272    9.0705    9.9499     10.8345
[2,]    8.4540  6.6935  8.5378  8.8336    8.7718    9.6616     11.4169
[3,]    9.9479  7.7319  8.2890  9.4868    9.9207    9.4638     10.0144
     202683_s_at 203139_at 203628_at 204681_s_at 204825_at 205229_s_at
[1,]      8.8732    8.8140    9.4326      8.7098    7.9851      5.2668
[2,]      8.5511    8.7652    9.8046      8.1223    5.2744      7.1769
[3,]      8.5826    9.4426    7.9079      7.5006    5.9481      6.9284
     205347_s_at 205696_s_at 205751_at 206401_s_at 208670_s_at 208712_at
[1,]      8.3232      9.0616    5.4450     10.6463      8.8319   10.8225
[2,]      7.4873      7.7288    6.3482      8.2532      9.8519    9.8721
[3,]      8.2573      7.1560    6.0619      7.4477      9.3521   10.2362
     211864_s_at 212344_at 212583_at 216092_s_at 218807_at 218862_at
[1,]      9.2348   11.6005    7.5912     10.6963   12.5435   10.4625
[2,]     10.1938    8.1512    7.5112      9.3780   10.8753    9.8143
[3,]      8.4931    8.0329    4.6920      9.3840   10.1820    9.3484
     219051_x_at 219438_at 220016_at 221253_s_at
[1,]      9.5138    8.4629    3.5858     11.2380
[2,]      5.3641    6.6613    8.0826     11.0556
[3,]      7.1097    6.9982    8.3940     10.9418
[1] "numgenes selected:37"
[1] "test acc:0.79"
[1] "test AUC acc:0.684313725490196"
[1] "10 fold train90.7692307692308"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 32  1
         2  1 96
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1  8 14
        2  7 71
[1] "train acc:0.984615384615385"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 32  1
         2  1 96
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 30
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.6896552 0.7840909
[1] 0.6896552 0.7840909
[1] "accuracy: 50.4107517392399 num_feat:3 fitness:16.0601985909865"
[1] 0.3548387 0.9186047
[1] 0.3548387 0.9186047
[1] "accuracy: 48.138716468708 num_feat:3 fitness:17.9459416202098"
[1] 0.2666667 0.8505747
[1] 0.2666667 0.8505747
[1] "accuracy: 55.6783846051355 num_feat:3 fitness:14.1196614849223"
[1] 0.1428571 0.8089888
[1] 0.1428571 0.8089888
[1] "accuracy: 58.4666899003338 num_feat:3 fitness:20.7294975607235"
[1] 0.4666667 0.8735632
[1] 0.4666667 0.8735632
[1] "accuracy: 55.3442844395815 num_feat:3 fitness:13.6469701410947"
[1] 0.7142857 0.7640449
[1] 0.7142857 0.7640449
[1] "accuracy: 54.3641519251602 num_feat:3 fitness:21.470798620706"
[1] 0.1875000 0.8235294
[1] 0.1875000 0.8235294
[1] "accuracy: 59.1850867644429 num_feat:3 fitness:17.3229498818782"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 59.0922877959585 num_feat:3 fitness:21.1266074959007"
[1] 0.3214286 0.9213483
[1] 0.3214286 0.9213483
[1] "accuracy: 53.5386083254281 num_feat:3 fitness:11.7435005468788"
[1] 0.5333333 0.8390805
[1] 0.5333333 0.8390805
[1] "accuracy: 55.4079921213664 num_feat:3 fitness:15.0529639948362"
[1] "f.test:3:16.9219089938137"
[1] "f.test:3:16.9219089938137"
[1] 0.7241379 0.7272727
[1] 0.7241379 0.7272727
[1] "accuracy: 50.5393977952105 num_feat:4 fitness:16.1007996977101"
[1] 0.3225806 0.9186047
[1] 0.3225806 0.9186047
[1] "accuracy: 50.887888153788 num_feat:4 fitness:19.9271303454688"
[1] 0.2666667 0.8850575
[1] 0.2666667 0.8850575
[1] "accuracy: 57.9776272425641 num_feat:4 fitness:15.9302554822848"
[1] 0.2142857 0.7640449
[1] 0.2142857 0.7640449
[1] "accuracy: 59.004415631939 num_feat:4 fitness:25.1989588601763"
[1] 0.4333333 0.8965517
[1] 0.4333333 0.8965517
[1] "accuracy: 56.6992671043649 num_feat:4 fitness:14.637300193456"
[1] 0.6785714 0.7865169
[1] 0.6785714 0.7865169
[1] "accuracy: 58.0625801587344 num_feat:4 fitness:24.2094763162681"
[1] 0.1875000 0.7647059
[1] 0.1875000 0.7647059
[1] "accuracy: 63.0609915756314 num_feat:4 fitness:20.0827747894795"
[1] 0.09677419 0.94186047
[1] 0.09677419 0.94186047
[1] "accuracy: 59.9960267647496 num_feat:4 fitness:21.6365123816174"
[1] 0.3214286 0.8876404
[1] 0.3214286 0.8876404
[1] "accuracy: 56.1618138760445 num_feat:4 fitness:13.6265901696591"
[1] 0.6333333 0.7931034
[1] 0.6333333 0.7931034
[1] "accuracy: 56.2706828056441 num_feat:4 fitness:19.1683279353815"
[1] "f.test:4:19.0518126171502"
[1] "f.test:4:19.0518126171502"
[1] 0.8620690 0.6818182
[1] 0.8620690 0.6818182
[1] "accuracy: 49.6137610858214 num_feat:5 fitness:15.637718510978"
[1] 0.3548387 0.9186047
[1] 0.3548387 0.9186047
[1] "accuracy: 50.887888153788 num_feat:5 fitness:20.0022740235306"
[1] 0.2666667 0.8735632
[1] 0.2666667 0.8735632
[1] "accuracy: 57.9776272425641 num_feat:5 fitness:15.9014749728402"
[1] 0.2857143 0.7752809
[1] 0.2857143 0.7752809
[1] "accuracy: 59.6637081263505 num_feat:5 fitness:25.9000446699361"
[1] 0.4333333 0.9080460
[1] 0.4333333 0.9080460
[1] "accuracy: 56.4999334462162 num_feat:5 fitness:14.5164907047677"
[1] 0.6785714 0.7977528
[1] 0.6785714 0.7977528
[1] "accuracy: 55.2243962736366 num_feat:5 fitness:22.0610594923517"
[1] 0.1875000 0.7764706
[1] 0.1875000 0.7764706
[1] "accuracy: 62.3912392505963 num_feat:5 fitness:19.6098274331483"
[1] 0.06451613 0.97674419
[1] 0.06451613 0.97674419
[1] "accuracy: 60.2976798870565 num_feat:5 fitness:21.8692714871222"
[1] 0.2142857 0.9101124
[1] 0.2142857 0.9101124
[1] "accuracy: 56.2912202214447 num_feat:5 fitness:13.5119226838723"
[1] 0.5000000 0.8045977
[1] 0.5000000 0.8045977
[1] "accuracy: 56.8795600475186 num_feat:5 fitness:15.9870099550439"
[1] "f.test:5:18.4997093933591"
[1] "f.test:4:19.0518126171502"
[1] 0.6896552 0.7159091
[1] 0.6896552 0.7159091
[1] "accuracy: 59.2138252781632 num_feat:6 fitness:22.4919145679423"
[1] 0.1612903 0.9302326
[1] 0.1612903 0.9302326
[1] "accuracy: 56.8674513876174 num_feat:6 fitness:24.0321003713419"
[1] 0.300000 0.908046
[1] 0.300000 0.908046
[1] "accuracy: 61.6945307559671 num_feat:6 fitness:18.8586479605168"
[1] 0.2500000 0.8089888
[1] 0.2500000 0.8089888
[1] "accuracy: 62.6270462630606 num_feat:6 fitness:28.1174873438437"
[1] 0.6000000 0.8965517
[1] 0.6000000 0.8965517
[1] "accuracy: 56.7397097793651 num_feat:6 fitness:15.0842091118515"
[1] 0.6785714 0.7977528
[1] 0.6785714 0.7977528
[1] "accuracy: 54.3726066636892 num_feat:6 fitness:23.4699963281032"
[1] 0.0625000 0.9294118
[1] 0.0625000 0.9294118
[1] "accuracy: 66.9369621453493 num_feat:6 fitness:23.0865477354277"
[1] 0.1935484 0.9302326
[1] 0.1935484 0.9302326
[1] "accuracy: 63.4332552262537 num_feat:6 fitness:28.5181187805624"
[1] 0.3214286 0.7865169
[1] 0.3214286 0.7865169
[1] "accuracy: 59.1035458769591 num_feat:6 fitness:17.5799904270596"
[1] 0.3333333 0.9540230
[1] 0.3333333 0.9540230
[1] "accuracy: 59.5451616668084 num_feat:6 fitness:21.2763961773081"
[1] "f.test:6:22.2515408803957"
[1] "f.test:6:22.2515408803957"
[1] 0.7586207 0.7159091
[1] 0.7586207 0.7159091
[1] "accuracy: 57.1846269544992 num_feat:7 fitness:21.1423847410371"
[1] 0.2258065 0.9302326
[1] 0.2258065 0.9302326
[1] "accuracy: 56.1732009124021 num_feat:7 fitness:23.6784973733438"
[1] 0.2666667 0.8850575
[1] 0.2666667 0.8850575
[1] "accuracy: 60.6022384935128 num_feat:7 fitness:17.8985792887142"
[1] 0.2142857 0.8988764
[1] 0.2142857 0.8988764
[1] "accuracy: 60.9693600484503 num_feat:7 fitness:27.0096111924631"
[1] 0.6000000 0.8390805
[1] 0.6000000 0.8390805
[1] "accuracy: 53.5494755297093 num_feat:7 fitness:12.5478103864294"
[1] 0.4642857 0.7528090
[1] 0.4642857 0.7528090
[1] "accuracy: 60.7476751155669 num_feat:7 fitness:27.6031789534748"
[1] 0.0625000 0.9411765
[1] 0.0625000 0.9411765
[1] "accuracy: 62.7385970770512 num_feat:7 fitness:17.6551095407593"
[1] 0.1612903 0.9186047
[1] 0.1612903 0.9186047
[1] "accuracy: 64.0438493331728 num_feat:7 fitness:17.2693828727952"
[1] 0.3571429 0.5393258
[1] 0.3571429 0.5393258
[1] "accuracy: 59.9310065916206 num_feat:7 fitness:15.6718492719908"
[1] 0.3333333 0.9310345
[1] 0.3333333 0.9310345
[1] "accuracy: 58.1608589646112 num_feat:7 fitness:20.1806530090317"
[1] "f.test:7:20.065705663004"
[1] "f.test:6:22.2515408803957"
[1] 0.7241379 0.5454545
[1] 0.7241379 0.5454545
[1] "accuracy: 65.4064843756718 num_feat:8 fitness:24.2963896694678"
[1] 0.2258065 0.9418605
[1] 0.2258065 0.9418605
[1] "accuracy: 64.2494308564034 num_feat:8 fitness:28.8556038124351"
[1] 0.3333333 0.9195402
[1] 0.3333333 0.9195402
[1] "accuracy: 60.4708134657936 num_feat:8 fitness:18.0528392038826"
[1] 0.5000000 0.8988764
[1] 0.5000000 0.8988764
[1] "accuracy: 69.0624993482005 num_feat:8 fitness:32.5437065043008"
[1] 0.6666667 0.8505747
[1] 0.6666667 0.8505747
[1] "accuracy: 58.220411912959 num_feat:8 fitness:19.5797034287899"
[1] 0.7142857 0.7640449
[1] 0.7142857 0.7640449
[1] "accuracy: 56.8383939939257 num_feat:8 fitness:23.2764392021508"
[1] 0.0625000 0.9529412
[1] 0.0625000 0.9529412
[1] "accuracy: 70.9170638424732 num_feat:8 fitness:23.1071086678831"
[1] 0.1612903 0.9418605
[1] 0.1612903 0.9418605
[1] "accuracy: 67.0499376582598 num_feat:8 fitness:22.051177607456"
[1] 0.3214286 0.6404494
[1] 0.3214286 0.6404494
[1] "accuracy: 57.5138248781483 num_feat:8 fitness:14.7724413841043"
[1] 0.3333333 0.9770115
[1] 0.3333333 0.9770115
[1] "accuracy: 58.5905514001113 num_feat:8 fitness:20.6178199871317"
[1] "f.test:8:22.7153229467602"
[1] "f.test:8:22.7153229467602"
[1] 0.7241379 0.6590909
[1] 0.7241379 0.6590909
[1] "accuracy: 64.3905134344801 num_feat:9 fitness:23.8184574954043"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 60.7496541191066 num_feat:9 fitness:26.1050699680983"
[1] 0.3333333 0.8505747
[1] 0.3333333 0.8505747
[1] "accuracy: 60.2801384390633 num_feat:9 fitness:17.7373742634707"
[1] 0.5000000 0.9101124
[1] 0.5000000 0.9101124
[1] "accuracy: 70.385622284448 num_feat:9 fitness:33.5640937168662"
[1] 0.7000000 0.8275862
[1] 0.7000000 0.8275862
[1] "accuracy: 57.0918643108 num_feat:9 fitness:18.7591099188754"
[1] 0.6785714 0.8089888
[1] 0.6785714 0.8089888
[1] "accuracy: 59.0337009313549 num_feat:9 fitness:26.9937722847109"
[1] 0.0937500 0.9294118
[1] 0.0937500 0.9294118
[1] "accuracy: 68.9964049424248 num_feat:9 fitness:22.3769893649019"
[1] 0.1290323 0.9302326
[1] 0.1290323 0.9302326
[1] "accuracy: 69.2801585673576 num_feat:9 fitness:23.6140834832865"
[1] 0.4642857 0.7303371
[1] 0.4642857 0.7303371
[1] "accuracy: 59.5412670207684 num_feat:9 fitness:20.1248400720751"
[1] 0.3000000 0.9770115
[1] 0.3000000 0.9770115
[1] "accuracy: 58.4746860770148 num_feat:9 fitness:20.4475427842152"
[1] "f.test:9:23.3541333351904"
[1] "f.test:9:23.3541333351904"
[1] 0.7586207 0.6136364
[1] 0.7586207 0.6136364
[1] "accuracy: 64.8686589733693 num_feat:10 fitness:24.1495923052258"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 62.5987819607045 num_feat:10 fitness:27.4918709720359"
[1] 0.3000000 0.8505747
[1] 0.3000000 0.8505747
[1] "accuracy: 60.9876970802091 num_feat:10 fitness:18.184665033736"
[1] 0.4642857 0.9101124
[1] 0.4642857 0.9101124
[1] "accuracy: 70.0813996476013 num_feat:10 fitness:33.2465961476847"
[1] 0.7000000 0.8275862
[1] 0.7000000 0.8275862
[1] "accuracy: 58.4119724229395 num_feat:10 fitness:19.7491461257194"
[1] 0.6785714 0.7865169
[1] 0.6785714 0.7865169
[1] "accuracy: 60.2313357505757 num_feat:10 fitness:27.8357737465849"
[1] 0.0937500 0.9176471
[1] 0.0937500 0.9176471
[1] "accuracy: 69.6983457626612 num_feat:10 fitness:23.707321671446"
[1] 0.06451613 0.91860465
[1] 0.06451613 0.91860465
[1] "accuracy: 70.4203641842034 num_feat:10 fitness:29.3103977175282"
[1] 0.4642857 0.7415730
[1] 0.4642857 0.7415730
[1] "accuracy: 57.4404304861006 num_feat:10 fitness:17.327257681454"
[1] 0.3000000 0.9770115
[1] 0.3000000 0.9770115
[1] "accuracy: 59.0934758335529 num_feat:10 fitness:24.2449235576914"
[1] "f.test:10:24.5247544959106"
[1] "f.test:10:24.5247544959106"
[1] 0.7241379 0.6363636
[1] 0.7241379 0.6363636
[1] "accuracy: 64.1256921494195 num_feat:11 fitness:22.4518224841581"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 59.3323278400673 num_feat:11 fitness:25.9801461808301"
[1] 0.300000 0.862069
[1] 0.300000 0.862069
[1] "accuracy: 60.0590167886856 num_feat:11 fitness:17.5168455700166"
[1] 0.3214286 0.9550562
[1] 0.3214286 0.9550562
[1] "accuracy: 71.8562731561899 num_feat:11 fitness:34.3329230952844"
[1] 0.7000000 0.8505747
[1] 0.7000000 0.8505747
[1] "accuracy: 59.5122846459593 num_feat:11 fitness:23.9651400134247"
[1] 0.7500000 0.7977528
[1] 0.7500000 0.7977528
[1] "accuracy: 57.6692568103425 num_feat:11 fitness:26.1208309803612"
[1] 0.0937500 0.9411765
[1] 0.0937500 0.9411765
[1] "accuracy: 71.8725578014905 num_feat:11 fitness:27.2740224371329"
[1] 0.09677419 0.94186047
[1] 0.09677419 0.94186047
[1] "accuracy: 69.1892229401599 num_feat:11 fitness:28.5257816034089"
[1] 0.3928571 0.7528090
[1] 0.3928571 0.7528090
[1] "accuracy: 60.8550289898166 num_feat:11 fitness:19.7376801410494"
[1] 0.3666667 0.9540230
[1] 0.3666667 0.9540230
[1] "accuracy: 63.1556735414821 num_feat:11 fitness:27.4007223636765"
[1] "f.test:11:25.3305914869343"
[1] "f.test:11:25.3305914869343"
[1] 0.7586207 0.6477273
[1] 0.7586207 0.6477273
[1] "accuracy: 63.4129490925079 num_feat:12 fitness:22.0318363016745"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 61.0012531050844 num_feat:12 fitness:26.3742797370898"
[1] 0.3000000 0.8505747
[1] 0.3000000 0.8505747
[1] "accuracy: 62.6328963788942 num_feat:12 fitness:19.4184747532284"
[1] 0.2857143 0.9550562
[1] 0.2857143 0.9550562
[1] "accuracy: 71.569717194258 num_feat:12 fitness:32.7786755322891"
[1] 0.7000000 0.8390805
[1] 0.7000000 0.8390805
[1] "accuracy: 61.6000282663824 num_feat:12 fitness:25.5021672192975"
[1] 0.7500000 0.7977528
[1] 0.7500000 0.7977528
[1] "accuracy: 57.8896877090465 num_feat:12 fitness:26.2861092771285"
[1] 0.0937500 0.9294118
[1] 0.0937500 0.9294118
[1] "accuracy: 72.1493013496742 num_feat:12 fitness:28.8017081189331"
[1] 0.09677419 0.95348837
[1] 0.09677419 0.95348837
[1] "accuracy: 69.1380704384953 num_feat:12 fitness:28.5164421173416"
[1] 0.5714286 0.6966292
[1] 0.5714286 0.6966292
[1] "accuracy: 62.2922726907965 num_feat:12 fitness:22.3715471727499"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 64.8893486806658 num_feat:12 fitness:28.9894818144751"
[1] "f.test:12:26.1070722044207"
[1] "f.test:12:26.1070722044207"
[1] 0.7586207 0.6477273
[1] 0.7586207 0.6477273
[1] "accuracy: 63.6878905464698 num_feat:13 fitness:22.2379975148852"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 60.5128207739662 num_feat:13 fitness:25.8466202889099"
[1] 0.3000000 0.8390805
[1] 0.3000000 0.8390805
[1] "accuracy: 62.230103698226 num_feat:13 fitness:19.0875997332827"
[1] 0.3214286 0.9550562
[1] 0.3214286 0.9550562
[1] "accuracy: 71.6440895831468 num_feat:13 fitness:32.9236956609807"
[1] 0.7000000 0.8505747
[1] 0.7000000 0.8505747
[1] "accuracy: 61.6834560581662 num_feat:13 fitness:25.5934288180585"
[1] 0.8214286 0.8089888
[1] 0.8214286 0.8089888
[1] "accuracy: 57.892739107766 num_feat:13 fitness:26.4950142651193"
[1] 0.0937500 0.9176471
[1] 0.0937500 0.9176471
[1] "accuracy: 72.1493013496742 num_feat:13 fitness:29.7647368880141"
[1] 0.09677419 0.96511628
[1] 0.09677419 0.96511628
[1] "accuracy: 68.8941817763774 num_feat:13 fitness:28.3625505109343"
[1] 0.5714286 0.6853933
[1] 0.5714286 0.6853933
[1] "accuracy: 58.5506789127368 num_feat:13 fitness:18.287217074304"
[1] 0.4333333 0.9540230
[1] 0.4333333 0.9540230
[1] "accuracy: 64.5923755568325 num_feat:13 fitness:28.6448257873346"
[1] "f.test:13:25.7243686541823"
[1] "f.test:12:26.1070722044207"
[1] 0.7931034 0.6363636
[1] 0.7931034 0.6363636
[1] "accuracy: 61.3467499620844 num_feat:14 fitness:23.0398950049782"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 65.3663028672718 num_feat:14 fitness:29.5157567490702"
[1] 0.3000000 0.8390805
[1] 0.3000000 0.8390805
[1] "accuracy: 63.0724651321646 num_feat:14 fitness:19.719325931476"
[1] 0.3214286 0.9438202
[1] 0.3214286 0.9438202
[1] "accuracy: 70.9789811711351 num_feat:14 fitness:33.6467295870708"
[1] 0.6666667 0.8620690
[1] 0.6666667 0.8620690
[1] "accuracy: 60.2198620925386 num_feat:14 fitness:24.4410907654277"
[1] 0.8571429 0.8089888
[1] 0.8571429 0.8089888
[1] "accuracy: 59.7334956604711 num_feat:14 fitness:27.9648225166731"
[1] 0.0625000 0.9647059
[1] 0.0625000 0.9647059
[1] "accuracy: 72.1804494663131 num_feat:14 fitness:29.8275751570561"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 73.0326704651796 num_feat:14 fitness:31.524511685159"
[1] 0.3928571 0.6629213
[1] 0.3928571 0.6629213
[1] "accuracy: 64.8200036195432 num_feat:14 fitness:22.4865573804386"
[1] 0.4333333 0.9540230
[1] 0.4333333 0.9540230
[1] "accuracy: 65.2750049117991 num_feat:14 fitness:29.1567529262988"
[1] "f.test:14:27.1323017703649"
[1] "f.test:14:27.1323017703649"
[1] 0.7931034 0.6590909
[1] 0.7931034 0.6590909
[1] "accuracy: 68.7140611195001 num_feat:15 fitness:26.1221516775974"
[1] 0.2258065 0.9883721
[1] 0.2258065 0.9883721
[1] "accuracy: 65.1454231700479 num_feat:15 fitness:29.643562976611"
[1] 0.3000000 0.8275862
[1] 0.3000000 0.8275862
[1] "accuracy: 61.7092242565755 num_feat:15 fitness:22.0014480986728"
[1] 0.2857143 0.9101124
[1] 0.2857143 0.9101124
[1] "accuracy: 71.3831830882709 num_feat:15 fitness:32.5262807704549"
[1] 0.7333333 0.8505747
[1] 0.7333333 0.8505747
[1] "accuracy: 62.9461625122006 num_feat:15 fitness:26.6237022373962"
[1] 0.8928571 0.7977528
[1] 0.8928571 0.7977528
[1] "accuracy: 62.386352797991 num_feat:15 fitness:31.9677923987249"
[1] 0.0312500 0.9647059
[1] 0.0312500 0.9647059
[1] "accuracy: 72.8360708693285 num_feat:15 fitness:30.241121332057"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 71.7919172397088 num_feat:15 fitness:35.6470395782094"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 63.4781943774021 num_feat:15 fitness:21.7991764383458"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 63.54373634638 num_feat:15 fitness:27.7749232916405"
[1] "f.test:15:28.434719879971"
[1] "f.test:15:28.434719879971"
[1] 0.7931034 0.6818182
[1] 0.7931034 0.6818182
[1] "accuracy: 69.2176512952059 num_feat:16 fitness:26.5566176139342"
[1] 0.1935484 0.9883721
[1] 0.1935484 0.9883721
[1] "accuracy: 64.6072814484246 num_feat:16 fitness:30.0683575559334"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 62.5389242847999 num_feat:16 fitness:22.7357472080977"
[1] 0.2857143 0.9101124
[1] 0.2857143 0.9101124
[1] "accuracy: 69.9779680774718 num_feat:16 fitness:31.4723246350949"
[1] 0.7333333 0.8505747
[1] 0.7333333 0.8505747
[1] "accuracy: 64.0097847567318 num_feat:16 fitness:27.759663914273"
[1] 0.8928571 0.7977528
[1] 0.8928571 0.7977528
[1] "accuracy: 62.7730559122064 num_feat:16 fitness:32.2577748571257"
[1] 0.0625000 0.9647059
[1] 0.0625000 0.9647059
[1] "accuracy: 72.9385866739633 num_feat:16 fitness:30.1542195082698"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 72.2002229943571 num_feat:16 fitness:35.8725788556446"
[1] 0.5000000 0.6292135
[1] 0.5000000 0.6292135
[1] "accuracy: 64.0370077216624 num_feat:16 fitness:22.0828081824424"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 66.5908871665254 num_feat:16 fitness:30.0602415294889"
[1] "f.test:16:28.9020333860305"
[1] "f.test:16:28.9020333860305"
[1] 0.7931034 0.6704545
[1] 0.7931034 0.6704545
[1] "accuracy: 72.1242820855687 num_feat:17 fitness:28.7081367385366"
[1] 0.2258065 0.9767442
[1] 0.2258065 0.9767442
[1] "accuracy: 64.119023829861 num_feat:17 fitness:29.7536948585985"
[1] 0.3666667 0.8390805
[1] 0.3666667 0.8390805
[1] "accuracy: 62.0269102970539 num_feat:17 fitness:22.4350251733608"
[1] 0.2857143 0.8988764
[1] 0.2857143 0.8988764
[1] "accuracy: 69.9779680774718 num_feat:17 fitness:31.4441898701938"
[1] 0.7333333 0.8390805
[1] 0.7333333 0.8390805
[1] "accuracy: 62.9019242362836 num_feat:17 fitness:26.5616981437532"
[1] 0.8571429 0.7865169
[1] 0.8571429 0.7865169
[1] "accuracy: 62.3604318414798 num_feat:17 fitness:29.8787102453667"
[1] 0.0625000 0.9529412
[1] 0.0625000 0.9529412
[1] "accuracy: 72.9978109791932 num_feat:17 fitness:30.1691810952257"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.4249146767814 num_feat:17 fitness:34.5701225076441"
[1] 0.4285714 0.6292135
[1] 0.4285714 0.6292135
[1] "accuracy: 65.2248894656052 num_feat:17 fitness:22.7951031845674"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 66.5908871665254 num_feat:17 fitness:30.2654112925663"
[1] "f.test:17:28.6581273109813"
[1] "f.test:16:28.9020333860305"
[1] 0.7931034 0.6931818
[1] 0.7931034 0.6931818
[1] "accuracy: 67.5007926906699 num_feat:18 fitness:25.2972929969199"
[1] 0.2580645 0.9767442
[1] 0.2580645 0.9767442
[1] "accuracy: 66.2997797949946 num_feat:18 fitness:31.4698621164784"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 63.5610132598646 num_feat:18 fitness:23.5022241848749"
[1] 0.2857143 0.8988764
[1] 0.2857143 0.8988764
[1] "accuracy: 69.8406913719328 num_feat:18 fitness:31.3411874637788"
[1] 0.7333333 0.8275862
[1] 0.7333333 0.8275862
[1] "accuracy: 64.2246736427301 num_feat:18 fitness:27.5249796891435"
[1] 0.8928571 0.7752809
[1] 0.8928571 0.7752809
[1] "accuracy: 63.2095731395223 num_feat:18 fitness:30.5767171682831"
[1] 0.0625 1.0000
[1] 0.0625 1.0000
[1] "accuracy: 72.7613319039969 num_feat:18 fitness:30.1094239703913"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.9705984158709 num_feat:18 fitness:34.9793404347005"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 66.4647406317225 num_feat:18 fitness:24.038951497304"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 65.8215439941618 num_feat:18 fitness:30.4831443956948"
[1] "f.test:18:28.9323123917569"
[1] "f.test:18:28.9323123917569"
[1] 0.7241379 0.7386364
[1] 0.7241379 0.7386364
[1] "accuracy: 66.387430527411 num_feat:19 fitness:24.403449067748"
[1] 0.1935484 0.9883721
[1] 0.1935484 0.9883721
[1] "accuracy: 66.8832017203089 num_feat:19 fitness:31.7751631280646"
[1] 0.3000000 0.8390805
[1] 0.3000000 0.8390805
[1] "accuracy: 63.6058625062089 num_feat:19 fitness:23.452482909039"
[1] 0.2857143 0.8876404
[1] 0.2857143 0.8876404
[1] "accuracy: 71.4749088300768 num_feat:19 fitness:32.5387157924857"
[1] 0.7666667 0.8275862
[1] 0.7666667 0.8275862
[1] "accuracy: 62.592516884484 num_feat:19 fitness:26.3841505765315"
[1] 0.8928571 0.7752809
[1] 0.8928571 0.7752809
[1] "accuracy: 61.9521954467537 num_feat:19 fitness:29.633639021446"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 73.9219301094817 num_feat:19 fitness:31.3078961056467"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.3709969000097 num_feat:19 fitness:34.5295944205438"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 66.2039814861636 num_feat:19 fitness:23.8433372608742"
[1] 0.3333333 0.9655172
[1] 0.3333333 0.9655172
[1] "accuracy: 65.0003255677883 num_feat:19 fitness:29.7292546641712"
[1] "f.test:19:28.7597682946551"
[1] "f.test:18:28.9323123917569"
[1] 0.7586207 0.7500000
[1] 0.7586207 0.7500000
[1] "accuracy: 69.9261387293654 num_feat:20 fitness:28.2831624405251"
[1] 0.2258065 0.9767442
[1] 0.2258065 0.9767442
[1] "accuracy: 63.8803899203678 num_feat:20 fitness:28.6654938856056"
[1] 0.2666667 0.8735632
[1] 0.2666667 0.8735632
[1] "accuracy: 60.4873316419684 num_feat:20 fitness:21.1164134468164"
[1] 0.3571429 0.8876404
[1] 0.3571429 0.8876404
[1] "accuracy: 69.6708005601898 num_feat:20 fitness:33.8641611413811"
[1] 0.7666667 0.8275862
[1] 0.7666667 0.8275862
[1] "accuracy: 63.8558348428698 num_feat:20 fitness:27.3315941680602"
[1] 0.8571429 0.7865169
[1] 0.8571429 0.7865169
[1] "accuracy: 64.2752516261227 num_feat:20 fitness:33.2668665315941"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 70.8982361305054 num_feat:20 fitness:29.0517397124998"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 73.2859113854834 num_feat:20 fitness:31.7157354073884"
[1] 0.4642857 0.7640449
[1] 0.4642857 0.7640449
[1] "accuracy: 63.9921485885698 num_feat:20 fitness:23.5467772609799"
[1] 0.3333333 0.9655172
[1] 0.3333333 0.9655172
[1] "accuracy: 63.8146628478035 num_feat:20 fitness:28.839962746922"
[1] "f.test:20:28.5681906741772"
[1] "f.test:18:28.9323123917569"
[1] 0.7586207 0.7386364
[1] 0.7586207 0.7386364
[1] "accuracy: 70.9378971828791 num_feat:21 fitness:27.9024162013794"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 64.2436221988639 num_feat:21 fitness:29.6050286424369"
[1] 0.3333333 0.8735632
[1] 0.3333333 0.8735632
[1] "accuracy: 62.0730795714406 num_feat:21 fitness:25.8056795166598"
[1] 0.3214286 0.9325843
[1] 0.3214286 0.9325843
[1] "accuracy: 71.2679141878655 num_feat:21 fitness:35.8350253211533"
[1] 0.800000 0.816092
[1] 0.800000 0.816092
[1] "accuracy: 65.4574045240035 num_feat:21 fitness:28.5873242527992"
[1] 0.8571429 0.7977528
[1] 0.8571429 0.7977528
[1] "accuracy: 62.9276169121329 num_feat:21 fitness:32.2841855064814"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 74.4774313948484 num_feat:21 fitness:31.7244323151504"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 72.5623490063085 num_feat:21 fitness:36.1439489783047"
[1] 0.4642857 0.7528090
[1] 0.4642857 0.7528090
[1] "accuracy: 64.0895928776651 num_feat:21 fitness:22.3417257129002"
[1] 0.3666667 0.9540230
[1] 0.3666667 0.9540230
[1] "accuracy: 65.2588869711931 num_feat:21 fitness:29.9776836633529"
[1] "f.test:21:30.0207450110618"
[1] "f.test:21:30.0207450110618"
[1] 0.7241379 0.7500000
[1] 0.7241379 0.7500000
[1] "accuracy: 70.5136040806017 num_feat:22 fitness:27.5263536917681"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 64.3783718758783 num_feat:22 fitness:29.6835403965304"
[1] 0.3000000 0.8850575
[1] 0.3000000 0.8850575
[1] "accuracy: 61.9892357325015 num_feat:22 fitness:22.354820725712"
[1] 0.2500000 0.9325843
[1] 0.2500000 0.9325843
[1] "accuracy: 64.411265112577 num_feat:22 fitness:28.5139222088548"
[1] 0.8000000 0.8045977
[1] 0.8000000 0.8045977
[1] "accuracy: 60.4330731432157 num_feat:22 fitness:21.4569618744304"
[1] 0.8928571 0.8089888
[1] 0.8928571 0.8089888
[1] "accuracy: 60.4324445816163 num_feat:22 fitness:30.5301369832594"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 72.8761830388024 num_feat:22 fitness:30.0258641290447"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 73.724321980107 num_feat:22 fitness:36.9347386701026"
[1] 0.5000000 0.7752809
[1] 0.5000000 0.7752809
[1] "accuracy: 64.6654152640004 num_feat:22 fitness:24.1690131149576"
[1] 0.2333333 0.9310345
[1] 0.2333333 0.9310345
[1] "accuracy: 65.9149882571255 num_feat:22 fitness:26.745576819507"
[1] "f.test:22:27.7940928614167"
[1] "f.test:21:30.0207450110618"
[1] 0.6896552 0.7500000
[1] 0.6896552 0.7500000
[1] "accuracy: 68.8350148832164 num_feat:23 fitness:26.1811600199166"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 63.8376944097505 num_feat:23 fitness:28.3398267431411"
[1] 0.2333333 0.8965517
[1] 0.2333333 0.8965517
[1] "accuracy: 61.3093273579671 num_feat:23 fitness:25.0402468664011"
[1] 0.2857143 0.9325843
[1] 0.2857143 0.9325843
[1] "accuracy: 64.8329716985695 num_feat:23 fitness:28.9194429853742"
[1] 0.8000000 0.7931034
[1] 0.8000000 0.7931034
[1] "accuracy: 65.0469514831427 num_feat:23 fitness:28.2219234532644"
[1] 0.8928571 0.8089888
[1] 0.8928571 0.8089888
[1] "accuracy: 60.459640986318 num_feat:23 fitness:30.5504894095251"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 72.9017982906779 num_feat:23 fitness:30.1701093559646"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 72.5657325791819 num_feat:23 fitness:35.9851065808577"
[1] 0.5714286 0.7865169
[1] 0.5714286 0.7865169
[1] "accuracy: 64.390362223903 num_feat:23 fitness:22.9193397738357"
[1] 0.2333333 0.9425287
[1] 0.2333333 0.9425287
[1] "accuracy: 67.1344091857408 num_feat:23 fitness:25.6888332708917"
[1] "f.test:23:28.2016478459172"
[1] "f.test:21:30.0207450110618"
[1] 0.7241379 0.7500000
[1] 0.7241379 0.7500000
[1] "accuracy: 69.4290923283654 num_feat:24 fitness:26.7128801230694"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 64.068455400229 num_feat:24 fitness:28.5419223761812"
[1] 0.2333333 0.9195402
[1] 0.2333333 0.9195402
[1] "accuracy: 60.7972829079349 num_feat:24 fitness:24.7136399159841"
[1] 0.2857143 0.9325843
[1] 0.2857143 0.9325843
[1] "accuracy: 67.001788785819 num_feat:24 fitness:29.2960109235507"
[1] 0.8000000 0.8045977
[1] 0.8000000 0.8045977
[1] "accuracy: 63.121786497934 num_feat:24 fitness:26.8067404692811"
[1] 0.8928571 0.8089888
[1] 0.8928571 0.8089888
[1] "accuracy: 62.0586853207961 num_feat:24 fitness:31.7497277831229"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 72.0547038657111 num_feat:24 fitness:29.5641554246846"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 72.1619026567075 num_feat:24 fitness:30.6821892617413"
[1] 0.5000000 0.8089888
[1] 0.5000000 0.8089888
[1] "accuracy: 62.6369099296276 num_feat:24 fitness:21.481814022578"
[1] 0.2333333 0.9425287
[1] 0.2333333 0.9425287
[1] "accuracy: 67.0049703627129 num_feat:24 fitness:25.59170927636"
[1] "f.test:24:27.5140789576553"
[1] "f.test:21:30.0207450110618"
[1] 0.6896552 0.7500000
[1] 0.6896552 0.7500000
[1] "accuracy: 68.4298720126998 num_feat:25 fitness:25.8772131125078"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 64.4887013414753 num_feat:25 fitness:28.7764167935649"
[1] 0.2000000 0.9310345
[1] 0.2000000 0.9310345
[1] "accuracy: 58.9998100759472 num_feat:25 fitness:19.9775593802499"
[1] 0.2500000 0.9438202
[1] 0.2500000 0.9438202
[1] "accuracy: 62.5512999224907 num_feat:25 fitness:25.8969035721485"
[1] 0.8000000 0.8045977
[1] 0.8000000 0.8045977
[1] "accuracy: 61.7437596210068 num_feat:25 fitness:25.773175434325"
[1] 0.8928571 0.7977528
[1] 0.8928571 0.7977528
[1] "accuracy: 61.9548739758358 num_feat:25 fitness:31.6437345095016"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 70.8916962313892 num_feat:25 fitness:28.6918548216826"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 70.1761001616006 num_feat:25 fitness:29.1396548237362"
[1] 0.5000000 0.7865169
[1] 0.5000000 0.7865169
[1] "accuracy: 58.164150805828 num_feat:25 fitness:18.0710200271867"
[1] 0.2666667 0.9425287
[1] 0.2666667 0.9425287
[1] "accuracy: 66.0688428659668 num_feat:25 fitness:24.9729021098731"
[1] "f.test:25:25.8820434584776"
[1] "f.test:21:30.0207450110618"
[1] 0.6551724 0.7500000
[1] 0.6551724 0.7500000
[1] "accuracy: 68.1277332391058 num_feat:26 fitness:25.5643572584999"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 64.1226367495282 num_feat:26 fitness:28.4211783110535"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 58.2612080423173 num_feat:26 fitness:19.4522986099507"
[1] 0.2500000 0.9325843
[1] 0.2500000 0.9325843
[1] "accuracy: 70.8187872778539 num_feat:26 fitness:32.0693843237697"
[1] 0.8000000 0.8045977
[1] 0.8000000 0.8045977
[1] "accuracy: 62.2751608133866 num_feat:26 fitness:26.1716814513492"
[1] 0.8928571 0.7865169
[1] 0.8928571 0.7865169
[1] "accuracy: 60.7843131047367 num_feat:26 fitness:30.7376790912761"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 68.2220818191953 num_feat:26 fitness:26.8778286923799"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 70.8676893050573 num_feat:26 fitness:29.7114394934822"
[1] 0.6071429 0.7865169
[1] 0.6071429 0.7865169
[1] "accuracy: 57.1771432772458 num_feat:26 fitness:17.5985766463465"
[1] 0.3000000 0.9425287
[1] 0.3000000 0.9425287
[1] "accuracy: 65.2607439381704 num_feat:26 fitness:24.4501163700985"
[1] "f.test:26:26.1054540248206"
[1] "f.test:21:30.0207450110618"
[1] 0.6896552 0.7500000
[1] 0.6896552 0.7500000
[1] "accuracy: 67.4523770446459 num_feat:27 fitness:25.144002131946"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 65.5325252836545 num_feat:27 fitness:29.5591949956779"
[1] 0.2000000 0.9310345
[1] 0.2000000 0.9310345
[1] "accuracy: 58.0400725170767 num_feat:27 fitness:19.2576664565756"
[1] 0.2857143 0.9438202
[1] 0.2857143 0.9438202
[1] "accuracy: 63.0849489653554 num_feat:27 fitness:26.3863363140613"
[1] 0.8000000 0.8045977
[1] 0.8000000 0.8045977
[1] "accuracy: 60.9207466869723 num_feat:27 fitness:21.8224926459444"
[1] 0.8571429 0.7865169
[1] 0.8571429 0.7865169
[1] "accuracy: 61.0058652848712 num_feat:27 fitness:30.8145126348305"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 71.5573865773729 num_feat:27 fitness:29.3792623837524"
[1] 0.0000000 0.9767442
[1] 0.0000000 0.9767442
[1] "accuracy: 69.7850207831112 num_feat:27 fitness:33.87032345732"
[1] 0.6071429 0.7752809
[1] 0.6071429 0.7752809
[1] "accuracy: 64.5535532336719 num_feat:27 fitness:24.3527493487649"
[1] 0.2666667 0.9425287
[1] 0.2666667 0.9425287
[1] "accuracy: 63.5276530312804 num_feat:27 fitness:24.0669199793369"
[1] "f.test:27:26.465346034821"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  1036  1083  2667  3152  3155  3455  3490  4035  4349  4352  4752  5223
[13]  5927  8667  9093 10196 12339 13543 15240 15464 18415
     201508_at 201555_at 203139_at 203625_x_at 203628_at 203928_x_at 203963_at
[1,]   10.8379    9.9323    9.7965      8.9780   10.7755      9.6578   12.0638
[2,]    8.8812    9.5628    8.3696      8.1801    9.8410      9.9980   11.3553
[3,]   12.8232   10.3905    9.0933      7.7719    9.4169      6.2526   12.3832
     204508_s_at 204822_at 204825_at 205225_at 205696_s_at 206401_s_at
[1,]     10.1763    7.2891    8.9393   13.0759     11.6168      9.9796
[2,]      9.3275    6.4251    7.7652   13.7616      9.5737      9.9498
[3,]      9.9200    8.4023    9.9136   12.7360      7.2600      6.0807
     209173_at 209603_at 210735_s_at 212956_at 214164_x_at 215867_x_at
[1,]   12.9392   10.5793     11.5638   13.3600     12.6474     12.6194
[2,]   14.1501   10.5772     10.8918   13.2925     11.7852     11.5534
[3,]   14.5585   11.1181     11.6213   12.3582     12.7464     12.7285
     216092_s_at 219051_x_at
[1,]     10.4159      8.5236
[2,]      9.7648      8.9626
[3,]      8.3641     10.7458
     201508_at 201555_at 203139_at 203625_x_at 203628_at 203928_x_at 203963_at
[1,]   10.2358    9.9499    8.8140      8.6829    9.4326     10.9860   12.4052
[2,]   10.4887    9.6616    8.7652      8.3696    9.8046      8.1054   10.4033
[3,]    9.3978    9.4638    9.4426      8.5685    7.9079      8.3152    9.8307
     204508_s_at 204822_at 204825_at 205225_at 205696_s_at 206401_s_at
[1,]      9.8038    7.3928    7.9851   13.8754      9.0616     10.6463
[2,]      7.9689    6.1670    5.2744   11.7217      7.7288      8.2532
[3,]      7.6789    6.6156    5.9481   10.9960      7.1560      7.4477
     209173_at 209603_at 210735_s_at 212956_at 214164_x_at 215867_x_at
[1,]   13.2041   11.9790     11.3620   13.5201     12.7392     12.5744
[2,]   11.3631   10.8744      9.5434   12.5480     10.9092     11.0575
[3,]   11.1800    8.0211      9.2310   11.2917     10.6696     11.0769
     216092_s_at 219051_x_at
[1,]     10.6963      9.5138
[2,]      9.3780      5.3641
[3,]      9.3840      7.1097
[1] "numgenes selected:21"
[1] "test acc:0.73"
[1] "test AUC acc:0.703921568627451"
[1] "10 fold train83.0769230769231"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 24  5
         2  9 92
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 10 22
        2  5 63
[1] "train acc:0.892307692307692"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 24  5
         2  9 92
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
There were 32 warnings (use warnings() to see them)
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 30
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.7586207 0.7500000
[1] 0.7586207 0.7500000
[1] "accuracy: 50.4953857392765 num_feat:3 fitness:18.7108606113901"
[1] 0.2580645 0.8953488
[1] 0.2580645 0.8953488
[1] "accuracy: 60.1632178991128 num_feat:3 fitness:25.7555345722934"
[1] 0.7000000 0.7701149
[1] 0.7000000 0.7701149
[1] "accuracy: 54.6314090247598 num_feat:3 fitness:17.5499470410199"
[1] 0.3571429 0.7078652
[1] 0.3571429 0.7078652
[1] "accuracy: 63.1009667894965 num_feat:3 fitness:25.9881105245457"
[1] 0.6666667 0.8275862
[1] 0.6666667 0.8275862
[1] "accuracy: 49.8479838700176 num_feat:3 fitness:13.2431355185195"
[1] 0.6071429 0.7528090
[1] 0.6071429 0.7528090
[1] "accuracy: 51.3112012364747 num_feat:3 fitness:18.8831459103412"
[1] 0.2187500 0.6470588
[1] 0.2187500 0.6470588
[1] "accuracy: 65.7601201958047 num_feat:3 fitness:23.984477573895"
[1] 0.1935484 0.9651163
[1] 0.1935484 0.9651163
[1] "accuracy: 62.6564189063962 num_feat:3 fitness:28.0706593952496"
[1] 0.5714286 0.7191011
[1] 0.5714286 0.7191011
[1] "accuracy: 56.7378879270946 num_feat:3 fitness:15.0123422706006"
[1] 0.1333333 0.9195402
[1] 0.1333333 0.9195402
[1] "accuracy: 61.3735081656487 num_feat:3 fitness:16.7282504533353"
[1] "limma:3:20.392646387119"
[1] "limma:3:20.392646387119"
[1] 0.8275862 0.7386364
[1] 0.8275862 0.7386364
[1] "accuracy: 53.0045386000848 num_feat:4 fitness:18.23668508193"
[1] 0.1935484 0.9302326
[1] 0.1935484 0.9302326
[1] "accuracy: 54.1398822307673 num_feat:4 fitness:22.0726150254838"
[1] 0.4000000 0.8390805
[1] 0.4000000 0.8390805
[1] "accuracy: 56.463241136061 num_feat:4 fitness:15.0128567070051"
[1] 0.2142857 0.8089888
[1] 0.2142857 0.8089888
[1] "accuracy: 58.9203916671204 num_feat:4 fitness:21.9983004371242"
[1] 0.5666667 0.8275862
[1] 0.5666667 0.8275862
[1] "accuracy: 54.6976532640206 num_feat:4 fitness:13.2970093534277"
[1] 0.5714286 0.7865169
[1] 0.5714286 0.7865169
[1] "accuracy: 54.4389602863366 num_feat:4 fitness:19.0248800725406"
[1] 0.2187500 0.6941176
[1] 0.2187500 0.6941176
[1] "accuracy: 59.9415649757155 num_feat:4 fitness:17.1842889618612"
[1] 0.2258065 0.9418605
[1] 0.2258065 0.9418605
[1] "accuracy: 62.5420043442692 num_feat:4 fitness:23.9164001318912"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 52.398086681593 num_feat:4 fitness:10.7395893163565"
[1] 0.4666667 0.8160920
[1] 0.4666667 0.8160920
[1] "accuracy: 61.7690190141756 num_feat:4 fitness:21.1380993298194"
[1] "limma:4:18.262072441744"
[1] "limma:3:20.392646387119"
[1] 0.8620690 0.7045455
[1] 0.8620690 0.7045455
[1] "accuracy: 53.5749691645187 num_feat:5 fitness:18.6654427518192"
[1] 0.1612903 0.9302326
[1] 0.1612903 0.9302326
[1] "accuracy: 51.3879772804918 num_feat:5 fitness:19.9318121891439"
[1] 0.4333333 0.8160920
[1] 0.4333333 0.8160920
[1] "accuracy: 57.9358415818196 num_feat:5 fitness:16.143124233029"
[1] 0.2142857 0.7752809
[1] 0.2142857 0.7752809
[1] "accuracy: 58.2495023336664 num_feat:5 fitness:24.6608188968517"
[1] 0.6666667 0.8390805
[1] 0.6666667 0.8390805
[1] "accuracy: 55.9098921618105 num_feat:5 fitness:14.4848792816933"
[1] 0.7142857 0.8089888
[1] 0.7142857 0.8089888
[1] "accuracy: 54.7207824835579 num_feat:5 fitness:21.8007247517188"
[1] 0.2500000 0.6823529
[1] 0.2500000 0.6823529
[1] "accuracy: 62.0491713012033 num_feat:5 fitness:18.8136620640105"
[1] 0.2258065 0.9418605
[1] 0.2258065 0.9418605
[1] "accuracy: 62.1826228888385 num_feat:5 fitness:23.6468191630575"
[1] 0.5357143 0.7303371
[1] 0.5357143 0.7303371
[1] "accuracy: 56.5048416572463 num_feat:5 fitness:14.0262719870477"
[1] 0.5000000 0.7931034
[1] 0.5000000 0.7931034
[1] "accuracy: 62.7044961163793 num_feat:5 fitness:21.865524348177"
[1] "limma:5:19.4039079666549"
[1] "limma:3:20.392646387119"
[1] 0.8965517 0.7045455
[1] 0.8965517 0.7045455
[1] "accuracy: 53.6280314310365 num_feat:6 fitness:18.7914014709986"
[1] 0.1612903 0.9186047
[1] 0.1612903 0.9186047
[1] "accuracy: 50.8770637653309 num_feat:6 fitness:19.5102398871852"
[1] 0.4000000 0.8505747
[1] 0.4000000 0.8505747
[1] "accuracy: 57.7075989661807 num_feat:6 fitness:15.9747709572574"
[1] 0.2500000 0.8202247
[1] 0.2500000 0.8202247
[1] "accuracy: 60.2975354190945 num_feat:6 fitness:26.3984440985095"
[1] 0.7000000 0.8390805
[1] 0.7000000 0.8390805
[1] "accuracy: 56.762159987266 num_feat:6 fitness:15.2073686068576"
[1] 0.7142857 0.7752809
[1] 0.7142857 0.7752809
[1] "accuracy: 55.3246236163215 num_feat:6 fitness:22.2171149815823"
[1] 0.2500000 0.6823529
[1] 0.2500000 0.6823529
[1] "accuracy: 61.1152173675561 num_feat:6 fitness:18.1131517365144"
[1] 0.2258065 0.9534884
[1] 0.2258065 0.9534884
[1] "accuracy: 61.3271691564304 num_feat:6 fitness:23.0342537539326"
[1] 0.5357143 0.7415730
[1] 0.5357143 0.7415730
[1] "accuracy: 55.8455089177465 num_feat:6 fitness:13.5598174428026"
[1] 0.3666667 0.8160920
[1] 0.3666667 0.8160920
[1] "accuracy: 59.4478146482881 num_feat:6 fitness:19.1471063008824"
[1] "limma:6:19.1953669236523"
[1] "limma:3:20.392646387119"
[1] 0.7931034 0.7045455
[1] 0.7931034 0.7045455
[1] "accuracy: 62.4057493746162 num_feat:7 fitness:25.1160243617675"
[1] 0.2903226 0.9302326
[1] 0.2903226 0.9302326
[1] "accuracy: 62.3462680370321 num_feat:7 fitness:27.5603955115212"
[1] 0.3666667 0.9195402
[1] 0.3666667 0.9195402
[1] "accuracy: 60.2446093309658 num_feat:7 fitness:17.9665643133557"
[1] 0.2500000 0.8539326
[1] 0.2500000 0.8539326
[1] "accuracy: 66.4326842629364 num_feat:7 fitness:29.8340305170516"
[1] 0.6333333 0.8735632
[1] 0.6333333 0.8735632
[1] "accuracy: 56.1236648016349 num_feat:7 fitness:17.981325903592"
[1] 0.7142857 0.7977528
[1] 0.7142857 0.7977528
[1] "accuracy: 57.0700292932485 num_feat:7 fitness:25.5823041372978"
[1] 0.1875000 0.7529412
[1] 0.1875000 0.7529412
[1] "accuracy: 70.2119777669061 num_feat:7 fitness:24.9558977470015"
[1] 0.2580645 0.9418605
[1] 0.2580645 0.9418605
[1] "accuracy: 69.3609533297854 num_feat:7 fitness:33.2020314914457"
[1] 0.4285714 0.7415730
[1] 0.4285714 0.7415730
[1] "accuracy: 58.032032660425 num_feat:7 fitness:17.6818082296937"
[1] 0.3333333 0.9195402
[1] 0.3333333 0.9195402
[1] "accuracy: 65.5654233132103 num_feat:7 fitness:24.9105552786352"
[1] "limma:7:24.4790937491362"
[1] "limma:7:24.4790937491362"
[1] 0.8275862 0.6931818
[1] 0.8275862 0.6931818
[1] "accuracy: 60.5611716105812 num_feat:8 fitness:23.7903439671232"
[1] 0.1935484 0.9418605
[1] 0.1935484 0.9418605
[1] "accuracy: 59.7706838581285 num_feat:8 fitness:26.3249893115295"
[1] 0.3333333 0.9080460
[1] 0.3333333 0.9080460
[1] "accuracy: 61.2097508026283 num_feat:8 fitness:18.5783065743247"
[1] 0.2500000 0.9438202
[1] 0.2500000 0.9438202
[1] "accuracy: 67.5781176278296 num_feat:8 fitness:32.1677797645844"
[1] 0.6333333 0.8275862
[1] 0.6333333 0.8275862
[1] "accuracy: 58.2395918317908 num_feat:8 fitness:19.4532837702126"
[1] 0.6428571 0.7752809
[1] 0.6428571 0.7752809
[1] "accuracy: 62.2624645376878 num_feat:8 fitness:29.2418344895142"
[1] 0.1562500 0.7529412
[1] 0.1562500 0.7529412
[1] "accuracy: 65.4467705068313 num_feat:8 fitness:20.7211283817411"
[1] 0.2258065 0.9186047
[1] 0.2258065 0.9186047
[1] "accuracy: 66.3036369373076 num_feat:8 fitness:23.9492715036111"
[1] 0.5357143 0.6853933
[1] 0.5357143 0.6853933
[1] "accuracy: 62.8897178072599 num_feat:8 fitness:20.702434917214"
[1] 0.4000000 0.9195402
[1] 0.4000000 0.9195402
[1] "accuracy: 61.5402389915119 num_feat:8 fitness:22.8530741864292"
[1] "limma:8:23.7782446866284"
[1] "limma:7:24.4790937491362"
[1] 0.6896552 0.7045455
[1] 0.6896552 0.7045455
[1] "accuracy: 60.8866218016062 num_feat:9 fitness:23.7179682378334"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 60.4348960571261 num_feat:9 fitness:26.8587374919941"
[1] 0.3333333 0.8965517
[1] 0.3333333 0.8965517
[1] "accuracy: 64.0756801044522 num_feat:9 fitness:20.698973041248"
[1] 0.2142857 0.9101124
[1] 0.2142857 0.9101124
[1] "accuracy: 64.5929525160829 num_feat:9 fitness:29.7553056763066"
[1] 0.6666667 0.8275862
[1] 0.6666667 0.8275862
[1] "accuracy: 58.2828045836752 num_feat:9 fitness:19.5689817901985"
[1] 0.6071429 0.7865169
[1] 0.6071429 0.7865169
[1] "accuracy: 62.8129599071362 num_feat:9 fitness:29.5934653126945"
[1] 0.1250000 0.8117647
[1] 0.1250000 0.8117647
[1] "accuracy: 65.7457040448292 num_feat:9 fitness:24.1132165924233"
[1] 0.1612903 0.9186047
[1] 0.1612903 0.9186047
[1] "accuracy: 66.5653275533191 num_feat:9 fitness:26.5682719795023"
[1] 0.5000000 0.6966292
[1] 0.5000000 0.6966292
[1] "accuracy: 62.8897178072599 num_feat:9 fitness:20.6411942133081"
[1] 0.3333333 0.9310345
[1] 0.3333333 0.9310345
[1] "accuracy: 62.2635832211833 num_feat:9 fitness:23.4628210872774"
[1] "limma:9:24.4978935422786"
[1] "limma:9:24.4978935422786"
[1] 0.7586207 0.6931818
[1] 0.7586207 0.6931818
[1] "accuracy: 61.7126047322386 num_feat:10 fitness:24.4814152607414"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 61.5388674237114 num_feat:10 fitness:27.6866711396723"
[1] 0.3333333 0.8965517
[1] 0.3333333 0.8965517
[1] "accuracy: 64.0756801044522 num_feat:10 fitness:20.6989281639873"
[1] 0.1428571 0.9213483
[1] 0.1428571 0.9213483
[1] "accuracy: 68.4387176344947 num_feat:10 fitness:32.4891030969238"
[1] 0.6333333 0.8160920
[1] 0.6333333 0.8160920
[1] "accuracy: 60.9047606032399 num_feat:10 fitness:21.4233349620941"
[1] 0.6071429 0.7752809
[1] 0.6071429 0.7752809
[1] "accuracy: 61.5116041903015 num_feat:10 fitness:28.5893137601673"
[1] 0.1250000 0.8117647
[1] 0.1250000 0.8117647
[1] "accuracy: 66.5931765104463 num_feat:10 fitness:22.9313645390719"
[1] 0.1612903 0.9186047
[1] 0.1612903 0.9186047
[1] "accuracy: 65.9364656420899 num_feat:10 fitness:26.0965806688197"
[1] 0.5357143 0.6966292
[1] 0.5357143 0.6966292
[1] "accuracy: 59.4223779930889 num_feat:10 fitness:20.1299301897049"
[1] 0.3333333 0.9310345
[1] 0.3333333 0.9310345
[1] "accuracy: 62.2635832211833 num_feat:10 fitness:23.4627762100168"
[1] "limma:10:24.79894179912"
[1] "limma:10:24.79894179912"
[1] 0.5517241 0.7272727
[1] 0.5517241 0.7272727
[1] "accuracy: 71.6132714700069 num_feat:11 fitness:28.9748563302239"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 62.1484237320871 num_feat:11 fitness:28.1147237262516"
[1] 0.3333333 0.9195402
[1] 0.3333333 0.9195402
[1] "accuracy: 62.8665918553537 num_feat:11 fitness:19.8495383642705"
[1] 0.3928571 0.8539326
[1] 0.3928571 0.8539326
[1] "accuracy: 71.6372877972452 num_feat:11 fitness:35.3444465158833"
[1] 0.6666667 0.8160920
[1] 0.6666667 0.8160920
[1] "accuracy: 64.0996039418434 num_feat:11 fitness:23.9027559221194"
[1] 0.7857143 0.7977528
[1] 0.7857143 0.7977528
[1] "accuracy: 61.5102893499482 num_feat:11 fitness:29.0908910993512"
[1] 0.0937500 0.8235294
[1] 0.0937500 0.8235294
[1] "accuracy: 65.7357062956965 num_feat:11 fitness:23.7015322708866"
[1] 0.1612903 0.9418605
[1] 0.1612903 0.9418605
[1] "accuracy: 70.4183609989648 num_feat:11 fitness:29.6142392390346"
[1] 0.5357143 0.6853933
[1] 0.5357143 0.6853933
[1] "accuracy: 63.2181086652399 num_feat:11 fitness:22.9485934289169"
[1] 0.3666667 0.9655172
[1] 0.3666667 0.9655172
[1] "accuracy: 66.0253012113296 num_feat:11 fitness:28.7868933885842"
[1] "limma:11:27.0328470285522"
[1] "limma:11:27.0328470285522"
[1] 0.6206897 0.7272727
[1] 0.6206897 0.7272727
[1] "accuracy: 69.0893710489203 num_feat:12 fitness:26.1431888191406"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 61.1189707325328 num_feat:12 fitness:27.2619439380348"
[1] 0.3333333 0.9080460
[1] 0.3333333 0.9080460
[1] "accuracy: 65.2530661808542 num_feat:12 fitness:21.6106135989513"
[1] 0.2142857 0.8876404
[1] 0.2142857 0.8876404
[1] "accuracy: 68.5571799468761 num_feat:12 fitness:32.6721618423386"
[1] 0.7333333 0.8160920
[1] 0.7333333 0.8160920
[1] "accuracy: 61.2987817668348 num_feat:12 fitness:22.307050951008"
[1] 0.7857143 0.7977528
[1] 0.7857143 0.7977528
[1] "accuracy: 60.6048137658395 num_feat:12 fitness:28.4117395340089"
[1] 0.0937500 0.8470588
[1] 0.0937500 0.8470588
[1] "accuracy: 69.0261010350732 num_feat:12 fitness:26.6266445709638"
[1] 0.1612903 0.9534884
[1] 0.1612903 0.9534884
[1] "accuracy: 69.8893395899934 num_feat:12 fitness:29.29432199296"
[1] 0.5357143 0.6516854
[1] 0.5357143 0.6516854
[1] "accuracy: 59.4099500808533 num_feat:12 fitness:20.008159950445"
[1] 0.3666667 0.9425287
[1] 0.3666667 0.9425287
[1] "accuracy: 65.9723918169448 num_feat:12 fitness:30.6896952011671"
[1] "limma:12:26.5025520399018"
[1] "limma:11:27.0328470285522"
[1] 0.6206897 0.7159091
[1] 0.6206897 0.7159091
[1] "accuracy: 66.7013039753998 num_feat:13 fitness:24.3236845458304"
[1] 0.1612903 0.9883721
[1] 0.1612903 0.9883721
[1] "accuracy: 61.5069983502203 num_feat:13 fitness:27.6626347027719"
[1] 0.3000000 0.8965517
[1] 0.3000000 0.8965517
[1] "accuracy: 62.5644183626104 num_feat:13 fitness:19.4820138924906"
[1] 0.2857143 0.9325843
[1] 0.2857143 0.9325843
[1] "accuracy: 67.6229393544906 num_feat:13 fitness:32.262367499922"
[1] 0.7000000 0.8275862
[1] 0.7000000 0.8275862
[1] "accuracy: 60.9479505044294 num_feat:13 fitness:21.9892849257938"
[1] 0.8214286 0.7977528
[1] 0.8214286 0.7977528
[1] "accuracy: 59.3081958411999 num_feat:13 fitness:27.5285169275542"
[1] 0.0937500 0.8470588
[1] 0.0937500 0.8470588
[1] "accuracy: 71.3696019769258 num_feat:13 fitness:28.8386320224538"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 69.0132129321779 num_feat:13 fitness:28.6146764959311"
[1] 0.5714286 0.6292135
[1] 0.5714286 0.6292135
[1] "accuracy: 59.1185396979722 num_feat:13 fitness:19.8226632250283"
[1] 0.3333333 0.9425287
[1] 0.3333333 0.9425287
[1] "accuracy: 67.6678827339169 num_feat:13 fitness:31.672720537964"
[1] "limma:13:26.219719477574"
[1] "limma:11:27.0328470285522"
[1] 0.6206897 0.7045455
[1] 0.6206897 0.7045455
[1] "accuracy: 65.9126071580668 num_feat:14 fitness:23.7037079646609"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 60.1829866073917 num_feat:14 fitness:26.5082906958092"
[1] 0.3000000 0.8850575
[1] 0.3000000 0.8850575
[1] "accuracy: 62.5752104634046 num_feat:14 fitness:19.4613274586416"
[1] 0.2857143 0.9213483
[1] 0.2857143 0.9213483
[1] "accuracy: 68.7810407788426 num_feat:14 fitness:33.1028088032848"
[1] 0.7000000 0.8275862
[1] 0.7000000 0.8275862
[1] "accuracy: 60.6134998425779 num_feat:14 fitness:21.4001121814054"
[1] 0.7857143 0.7977528
[1] 0.7857143 0.7977528
[1] "accuracy: 58.6541053108114 num_feat:14 fitness:26.9486184382165"
[1] 0.0937500 0.8352941
[1] 0.0937500 0.8352941
[1] "accuracy: 69.7093888867191 num_feat:14 fitness:27.4870065105934"
[1] 0.1290323 0.9767442
[1] 0.1290323 0.9767442
[1] "accuracy: 66.6358044598504 num_feat:14 fitness:26.8315752644248"
[1] 0.5714286 0.6404494
[1] 0.5714286 0.6404494
[1] "accuracy: 59.4099500808533 num_feat:14 fitness:20.0692660225689"
[1] 0.3666667 0.9425287
[1] 0.3666667 0.9425287
[1] "accuracy: 68.0099459367254 num_feat:14 fitness:32.2177710364812"
[1] "limma:14:25.7730484376087"
[1] "limma:11:27.0328470285522"
[1] 0.7586207 0.7045455
[1] 0.7586207 0.7045455
[1] "accuracy: 67.8564115126552 num_feat:15 fitness:28.0063439395484"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 64.4743614547419 num_feat:15 fitness:29.8074221153515"
[1] 0.3000000 0.8505747
[1] 0.3000000 0.8505747
[1] "accuracy: 65.1639333907542 num_feat:15 fitness:21.3166178803414"
[1] 0.3214286 0.8764045
[1] 0.3214286 0.8764045
[1] "accuracy: 67.9928554198246 num_feat:15 fitness:31.2385510704846"
[1] 0.7000000 0.8505747
[1] 0.7000000 0.8505747
[1] "accuracy: 62.1933483761728 num_feat:15 fitness:25.9757583020421"
[1] 0.8214286 0.7865169
[1] 0.8214286 0.7865169
[1] "accuracy: 58.3820682865102 num_feat:15 fitness:26.8057416193751"
[1] 0.1250000 0.8823529
[1] 0.1250000 0.8823529
[1] "accuracy: 65.1487537649724 num_feat:15 fitness:24.2622573508461"
[1] 0.09677419 0.97674419
[1] 0.09677419 0.97674419
[1] "accuracy: 68.32539610971 num_feat:15 fitness:25.3020310705569"
[1] 0.5000000 0.6179775
[1] 0.5000000 0.6179775
[1] "accuracy: 63.4837445065824 num_feat:15 fitness:20.8898157607527"
[1] 0.4000000 0.9425287
[1] 0.4000000 0.9425287
[1] "accuracy: 67.6845912540457 num_feat:15 fitness:30.057043480544"
[1] "limma:15:26.3661582589843"
[1] "limma:11:27.0328470285522"
[1] 0.7586207 0.7272727
[1] 0.7586207 0.7272727
[1] "accuracy: 70.2221972620824 num_feat:16 fitness:29.8374565561763"
[1] 0.2580645 0.9767442
[1] 0.2580645 0.9767442
[1] "accuracy: 62.5628455649308 num_feat:16 fitness:28.6672511984519"
[1] 0.3000000 0.8275862
[1] 0.3000000 0.8275862
[1] "accuracy: 65.0944276672404 num_feat:16 fitness:21.2069724460775"
[1] 0.2500000 0.8764045
[1] 0.2500000 0.8764045
[1] "accuracy: 68.9489160140324 num_feat:16 fitness:33.0269802103083"
[1] 0.7000000 0.8390805
[1] 0.7000000 0.8390805
[1] "accuracy: 61.2164661301252 num_feat:16 fitness:25.2143161080618"
[1] 0.8571429 0.7865169
[1] 0.8571429 0.7865169
[1] "accuracy: 62.5144832561858 num_feat:16 fitness:29.9942936836568"
[1] 0.0625000 0.8705882
[1] 0.0625000 0.8705882
[1] "accuracy: 71.162471057023 num_feat:16 fitness:28.6638477301564"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.3745193826814 num_feat:16 fitness:31.8163230216182"
[1] 0.5000000 0.6292135
[1] 0.5000000 0.6292135
[1] "accuracy: 64.5104867084976 num_feat:16 fitness:21.6879174225688"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 67.9295208858248 num_feat:16 fitness:27.9360981259682"
[1] "limma:16:27.8051456503044"
[1] "limma:16:27.8051456503044"
[1] 0.7586207 0.7272727
[1] 0.7586207 0.7272727
[1] "accuracy: 66.1547462779443 num_feat:17 fitness:26.786823440812"
[1] 0.2580645 0.9767442
[1] 0.2580645 0.9767442
[1] "accuracy: 66.2002870450659 num_feat:17 fitness:31.3952874312925"
[1] 0.3000000 0.8390805
[1] 0.3000000 0.8390805
[1] "accuracy: 67.5905298828374 num_feat:17 fitness:23.1077398626985"
[1] 0.2857143 0.8988764
[1] 0.2857143 0.8988764
[1] "accuracy: 67.5889936571833 num_feat:17 fitness:30.9024590549774"
[1] 0.7333333 0.8390805
[1] 0.7333333 0.8390805
[1] "accuracy: 63.551390711194 num_feat:17 fitness:27.048797999936"
[1] 0.7857143 0.7865169
[1] 0.7857143 0.7865169
[1] "accuracy: 61.3446448220661 num_feat:17 fitness:28.938298552235"
[1] 0.0625000 0.9529412
[1] 0.0625000 0.9529412
[1] "accuracy: 71.2784276453096 num_feat:17 fitness:28.879643594813"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 70.3911116082519 num_feat:17 fitness:34.515700438805"
[1] 0.4285714 0.7191011
[1] 0.4285714 0.7191011
[1] "accuracy: 64.111180630547 num_feat:17 fitness:21.4345406593973"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 67.3864463858974 num_feat:17 fitness:27.528747373762"
[1] "limma:17:28.0538038408729"
[1] "limma:17:28.0538038408729"
[1] 0.7931034 0.6931818
[1] 0.7931034 0.6931818
[1] "accuracy: 67.5007926906699 num_feat:18 fitness:25.2972929969199"
[1] 0.2580645 0.9767442
[1] 0.2580645 0.9767442
[1] "accuracy: 66.2997797949946 num_feat:18 fitness:31.4698621164784"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 63.5610132598646 num_feat:18 fitness:23.5022241848749"
[1] 0.2857143 0.8988764
[1] 0.2857143 0.8988764
[1] "accuracy: 69.8406913719328 num_feat:18 fitness:31.3411874637788"
[1] 0.7333333 0.8275862
[1] 0.7333333 0.8275862
[1] "accuracy: 64.2246736427301 num_feat:18 fitness:27.5249796891435"
[1] 0.8928571 0.7752809
[1] 0.8928571 0.7752809
[1] "accuracy: 63.2095731395223 num_feat:18 fitness:30.5767171682831"
[1] 0.0625 1.0000
[1] 0.0625 1.0000
[1] "accuracy: 72.7613319039969 num_feat:18 fitness:30.1094239703913"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.9705984158709 num_feat:18 fitness:34.9793404347005"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 66.4647406317225 num_feat:18 fitness:24.038951497304"
[1] 0.400000 0.954023
[1] 0.400000 0.954023
[1] "accuracy: 65.8215439941618 num_feat:18 fitness:30.4831443956948"
[1] "limma:18:28.9323123917569"
[1] "limma:18:28.9323123917569"
[1] 0.7241379 0.7386364
[1] 0.7241379 0.7386364
[1] "accuracy: 66.387430527411 num_feat:19 fitness:24.403449067748"
[1] 0.1935484 0.9883721
[1] 0.1935484 0.9883721
[1] "accuracy: 66.8832017203089 num_feat:19 fitness:31.7751631280646"
[1] 0.3000000 0.8390805
[1] 0.3000000 0.8390805
[1] "accuracy: 63.6058625062089 num_feat:19 fitness:23.452482909039"
[1] 0.2857143 0.8876404
[1] 0.2857143 0.8876404
[1] "accuracy: 71.4749088300768 num_feat:19 fitness:32.5387157924857"
[1] 0.7666667 0.8275862
[1] 0.7666667 0.8275862
[1] "accuracy: 62.592516884484 num_feat:19 fitness:26.3841505765315"
[1] 0.8928571 0.7752809
[1] 0.8928571 0.7752809
[1] "accuracy: 61.9521954467537 num_feat:19 fitness:29.633639021446"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 73.9219301094817 num_feat:19 fitness:31.3078961056467"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 70.3709969000097 num_feat:19 fitness:34.5295944205438"
[1] 0.4642857 0.7191011
[1] 0.4642857 0.7191011
[1] "accuracy: 66.2039814861636 num_feat:19 fitness:23.8433372608742"
[1] 0.3333333 0.9655172
[1] 0.3333333 0.9655172
[1] "accuracy: 65.0003255677883 num_feat:19 fitness:29.7292546641712"
[1] "limma:19:28.7597682946551"
[1] "limma:18:28.9323123917569"
[1] 0.7241379 0.7272727
[1] 0.7241379 0.7272727
[1] "accuracy: 70.0215551323358 num_feat:20 fitness:27.1005885532719"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 66.9359858870809 num_feat:20 fitness:31.6534160533023"
[1] 0.3333333 0.8505747
[1] 0.3333333 0.8505747
[1] "accuracy: 63.5254151690781 num_feat:20 fitness:26.8375048277808"
[1] 0.3214286 0.9325843
[1] 0.3214286 0.9325843
[1] "accuracy: 70.1809714796193 num_feat:20 fitness:31.7698631672294"
[1] 0.8000000 0.8390805
[1] 0.8000000 0.8390805
[1] "accuracy: 62.4836547069355 num_feat:20 fitness:26.4145280316267"
[1] 0.8928571 0.7865169
[1] 0.8928571 0.7865169
[1] "accuracy: 62.0100548491577 num_feat:20 fitness:31.657254663156"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 72.9270872563496 num_feat:20 fitness:30.4835940885369"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 71.5469785174786 num_feat:20 fitness:35.382465988943"
[1] 0.4642857 0.7078652
[1] 0.4642857 0.7078652
[1] "accuracy: 64.340717282097 num_feat:20 fitness:22.417754342923"
[1] 0.3666667 0.9540230
[1] 0.3666667 0.9540230
[1] "accuracy: 66.1864643049013 num_feat:20 fitness:30.8786261812328"
[1] "limma:20:29.4595595898003"
[1] "limma:20:29.4595595898003"
[1] 0.6551724 0.7613636
[1] 0.6551724 0.7613636
[1] "accuracy: 69.3057075661647 num_feat:21 fitness:26.4764714810067"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 66.1469633495084 num_feat:21 fitness:30.8487385564331"
[1] 0.2666667 0.8505747
[1] 0.2666667 0.8505747
[1] "accuracy: 62.7505620448363 num_feat:21 fitness:19.4229867740055"
[1] 0.2857143 0.9213483
[1] 0.2857143 0.9213483
[1] "accuracy: 67.2275562547257 num_feat:21 fitness:29.4373812693723"
[1] 0.800000 0.816092
[1] 0.800000 0.816092
[1] "accuracy: 60.189292129535 num_feat:21 fitness:24.6362399569478"
[1] 0.8928571 0.7977528
[1] 0.8928571 0.7977528
[1] "accuracy: 59.5082475268501 num_feat:21 fitness:29.808944181805"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 71.5766306406875 num_feat:21 fitness:29.2544483729931"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 71.4845992605395 num_feat:21 fitness:35.2549915076876"
[1] 0.5000000 0.7303371
[1] 0.5000000 0.7303371
[1] "accuracy: 63.7018950034129 num_feat:21 fitness:22.0840582462159"
[1] 0.2333333 0.9310345
[1] 0.2333333 0.9310345
[1] "accuracy: 63.9989445414163 num_feat:21 fitness:27.6419222433191"
[1] "limma:21:27.4866182589786"
[1] "limma:20:29.4595595898003"
[1] 0.6551724 0.7500000
[1] 0.6551724 0.7500000
[1] "accuracy: 69.8444764941076 num_feat:22 fitness:26.852094208794"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 63.2956186250938 num_feat:22 fitness:28.7101851358614"
[1] 0.3000000 0.8505747
[1] 0.3000000 0.8505747
[1] "accuracy: 64.2625194832221 num_feat:22 fitness:20.6402433088674"
[1] 0.2500000 0.9325843
[1] 0.2500000 0.9325843
[1] "accuracy: 64.6048428411561 num_feat:22 fitness:27.4091055052892"
[1] 0.800000 0.816092
[1] 0.800000 0.816092
[1] "accuracy: 60.1161047653948 num_feat:22 fitness:21.2479712232487"
[1] 0.8928571 0.7977528
[1] 0.8928571 0.7977528
[1] "accuracy: 59.0250797545971 num_feat:22 fitness:29.4465234753546"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 69.7136889219633 num_feat:22 fitness:27.8571972066893"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 67.5821808532681 num_feat:22 fitness:32.3281328249734"
[1] 0.500000 0.752809
[1] 0.500000 0.752809
[1] "accuracy: 63.9837631937421 num_feat:22 fitness:22.351594286983"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 65.056879662958 num_feat:22 fitness:28.6434169107712"
[1] "limma:22:26.5486464086832"
[1] "limma:20:29.4595595898003"
[1] 0.6551724 0.7613636
[1] 0.6551724 0.7613636
[1] "accuracy: 70.4077333179716 num_feat:23 fitness:27.3029010403404"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 64.8479250589101 num_feat:23 fitness:29.874370083963"
[1] 0.2666667 0.8620690
[1] 0.2666667 0.8620690
[1] "accuracy: 62.7994660523433 num_feat:23 fitness:19.4883106572982"
[1] 0.2857143 0.9662921
[1] 0.2857143 0.9662921
[1] "accuracy: 64.5408193338712 num_feat:23 fitness:27.5345983747719"
[1] 0.7666667 0.8045977
[1] 0.7666667 0.8045977
[1] "accuracy: 61.0901891003034 num_feat:23 fitness:21.8664206316521"
[1] 0.8928571 0.8089888
[1] 0.8928571 0.8089888
[1] "accuracy: 59.4998871622732 num_feat:23 fitness:29.8306740414914"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 69.9337184642239 num_feat:23 fitness:28.022174486124"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 67.1715378061174 num_feat:23 fitness:31.9394605010594"
[1] 0.5000000 0.7640449
[1] 0.5000000 0.7640449
[1] "accuracy: 58.6894515349969 num_feat:23 fitness:18.4089055533039"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 64.5672056563494 num_feat:23 fitness:24.7088329226987"
[1] "limma:23:25.8976648292703"
[1] "limma:20:29.4595595898003"
[1] 0.7241379 0.7613636
[1] 0.7241379 0.7613636
[1] "accuracy: 69.8567215902681 num_feat:24 fitness:27.0620111604056"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 65.4036120542872 num_feat:24 fitness:30.2910904532351"
[1] 0.3000000 0.8965517
[1] 0.3000000 0.8965517
[1] "accuracy: 61.7917742082534 num_feat:24 fitness:18.9020371268551"
[1] 0.2857143 0.9438202
[1] 0.2857143 0.9438202
[1] "accuracy: 65.1887036987205 num_feat:24 fitness:27.9642869958672"
[1] 0.7666667 0.8160920
[1] 0.7666667 0.8160920
[1] "accuracy: 61.0797609004577 num_feat:24 fitness:21.8872902366912"
[1] 0.8928571 0.8089888
[1] 0.8928571 0.8089888
[1] "accuracy: 59.2280524517406 num_feat:24 fitness:29.6267531313313"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 69.9337184642239 num_feat:24 fitness:27.9440046088633"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 67.5552069139593 num_feat:24 fitness:32.2271674546801"
[1] 0.5357143 0.7640449
[1] 0.5357143 0.7640449
[1] "accuracy: 62.1437309478626 num_feat:24 fitness:21.0888559499782"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 65.0865988579645 num_feat:24 fitness:25.0695973144654"
[1] "limma:24:26.2063094432372"
[1] "limma:20:29.4595595898003"
[1] 0.7241379 0.7500000
[1] 0.7241379 0.7500000
[1] "accuracy: 69.1693105592926 num_feat:25 fitness:26.5179989190041"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 65.8914468884674 num_feat:25 fitness:29.9091211150993"
[1] 0.2333333 0.9195402
[1] 0.2333333 0.9195402
[1] "accuracy: 60.7700362663986 num_feat:25 fitness:24.6931600575712"
[1] 0.2500000 0.9550562
[1] 0.2500000 0.9550562
[1] "accuracy: 63.88428588877 num_feat:25 fitness:26.9247329344984"
[1] 0.8000000 0.8045977
[1] 0.8000000 0.8045977
[1] "accuracy: 61.4168843342044 num_feat:25 fitness:22.1946856358898"
[1] 0.8571429 0.8089888
[1] 0.8571429 0.8089888
[1] "accuracy: 60.3388062685652 num_feat:25 fitness:30.3704879024034"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 70.160835342976 num_feat:25 fitness:28.1437091553726"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 69.6004131529535 num_feat:25 fitness:33.761027256665"
[1] 0.5000000 0.7865169
[1] 0.5000000 0.7865169
[1] "accuracy: 65.5748582220825 num_feat:25 fitness:24.8790505893776"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 62.1431610295763 num_feat:25 fitness:22.8619740659136"
[1] "limma:25:27.0255947631795"
[1] "limma:20:29.4595595898003"
[1] 0.7586207 0.7386364
[1] 0.7586207 0.7386364
[1] "accuracy: 66.6622668018186 num_feat:26 fitness:24.6954690292806"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 69.8119229979902 num_feat:26 fitness:32.930078481271"
[1] 0.2333333 0.9080460
[1] 0.2333333 0.9080460
[1] "accuracy: 64.1780767627639 num_feat:26 fitness:23.8870765870672"
[1] 0.2500000 0.9662921
[1] 0.2500000 0.9662921
[1] "accuracy: 68.3597973411321 num_feat:26 fitness:33.5594115341498"
[1] 0.8000000 0.7816092
[1] 0.8000000 0.7816092
[1] "accuracy: 66.0300479920367 num_feat:26 fitness:25.5970422376356"
[1] 0.8571429 0.8089888
[1] 0.8571429 0.8089888
[1] "accuracy: 62.7588256449506 num_feat:26 fitness:32.0948495839407"
[1] 0.0625000 0.9882353
[1] 0.0625000 0.9882353
[1] "accuracy: 72.7660456706161 num_feat:26 fitness:30.1462852591361"
[1] 0.0000000 0.9883721
[1] 0.0000000 0.9883721
[1] "accuracy: 71.5088215031422 num_feat:26 fitness:35.1922886420459"
[1] 0.5357143 0.8089888
[1] 0.5357143 0.8089888
[1] "accuracy: 62.3804920246468 num_feat:26 fitness:22.6286965536067"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 66.6353631082008 num_feat:26 fitness:29.6764830464718"
[1] "limma:26:29.0407680954605"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
    1     2     3     4     5     6     7     8     9    10    11    12    13 
   10    10    10    10    10    10    10    10    10    10    10    10    10 
   14    15    16    17    18    19    20    21    22    23    24    25    26 
   10    10    10    10    10    10    10    10    10    10    10    10    10 
   27    28    29    30    31    32    33    34    35  1083  3155    36    37 
   10    10    10    10    10    10    10    10    10    10    10     9     9 
   38    39    40  4352 15464    41  4208  4756  8166 18226  2667  5278  8207 
    9     9     9     9     9     8     8     8     8     8     7     7     7 
11253 18220 20137 21064    42    43  5223 11968    44  2211  4874  5927 11729 
    7     7     7     7     6     6     6     6     5     5     5     5     5 
18415 18802 12226 14806 21615    45    46    47  1326  1732 10291 12517 19283 
    5     5     4     4     4     3     3     3     3     3     3     3     3 
19380 20616    48    49    50    51    52  4569  7691  8550 10980 11938 12814 
    3     3     2     2     2     2     2     2     2     2     2     2     2 
13597 16398 16738 18035 18313 19856 20350  1422  2475  2841  3152  3223  3455 
    2     2     2     2     2     2     2     1     1     1     1     1     1 
 4228  4349  4784  5357  6362  6528  7860  8080  8292  8845  8851  8870  9031 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
 9093  9279  9586  9853 10235 10271 10314 10830 11244 11850 12074 12521 12908 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
13226 14725 15271 15303 15341 15535 15721 17601 17669 18171 18330 18456 18478 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
18968 19012 19275 19398 19808 21518 
    1     1     1     1     1     1 
[1] "varselmethod"
[1] "forward"
[1] 0.5862069 0.6931818
[1] 0.5862069 0.6931818
[1] "accuracy: 50 num_feat:3 fitness:10.2662413696287"
[1] 0.1935484 0.8953488
[1] 0.1935484 0.8953488
[1] "accuracy: 50 num_feat:3 fitness:11.2844488366399"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 50 num_feat:3 fitness:10.284776886528"
[1] 0.07142857 0.92134831
[1] 0.07142857 0.92134831
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:14.4694084353837"
[1] 0.2000000 0.7931034
[1] 0.2000000 0.7931034
[1] "accuracy: 50 num_feat:3 fitness:5.77589725686025"
[1] 0.2142857 0.7303371
[1] 0.2142857 0.7303371
[1] "accuracy: 50.028466619329 num_feat:3 fitness:14.8392960237193"
[1] 0.0312500 0.9529412
[1] 0.0312500 0.9529412
[1] "accuracy: 47.3510945916462 num_feat:3 fitness:12.973664253129"
[1] 0.06451613 0.94186047
[1] 0.06451613 0.94186047
[1] "accuracy: 48.7388169917419 num_feat:3 fitness:13.0571399182948"
[1] 0.3571429 0.6629213
[1] 0.3571429 0.6629213
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:7.27036345344063"
[1] 0.03333333 0.93103448
[1] 0.03333333 0.93103448
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:7.38427952877327"
[1] "lasso:3:10.7605515962398"
[1] "lasso:3:10.7605515962398"
[1] 0.3103448 0.7613636
[1] 0.3103448 0.7613636
[1] "accuracy: 48.6050070027093 num_feat:4 fitness:8.70075111744067"
[1] 0.1290323 0.9418605
[1] 0.1290323 0.9418605
[1] "accuracy: 50 num_feat:4 fitness:10.2573922268332"
[1] 0.2333333 0.8275862
[1] 0.2333333 0.8275862
[1] "accuracy: 49.1660627495078 num_feat:4 fitness:9.09446899945481"
[1] 0.1071429 0.9325843
[1] 0.1071429 0.9325843
[1] "accuracy: 49.3168011361034 num_feat:4 fitness:14.5867391600492"
[1] 0.2666667 0.7586207
[1] 0.2666667 0.7586207
[1] "accuracy: 47.9800314067994 num_feat:4 fitness:4.34133570481402"
[1] 0.4285714 0.6629213
[1] 0.4285714 0.6629213
[1] "accuracy: 50.028466619329 num_feat:4 fitness:15.2499023976691"
[1] 0.0312500 0.9647059
[1] 0.0312500 0.9647059
[1] "accuracy: 48.5800334135401 num_feat:4 fitness:13.8051754558128"
[1] 0.06451613 0.95348837
[1] 0.06451613 0.95348837
[1] "accuracy: 48.6687967863937 num_feat:4 fitness:12.0078341609056"
[1] 0.4285714 0.6067416
[1] 0.4285714 0.6067416
[1] "accuracy: 49.3168011361034 num_feat:4 fitness:7.30844056654912"
[1] 0.0000000 0.9310345
[1] 0.0000000 0.9310345
[1] "accuracy: 48.1791869466693 num_feat:4 fitness:6.44769067610368"
[1] "lasso:4:10.1799730465632"
[1] "lasso:3:10.7605515962398"
[1] 0.2758621 0.7840909
[1] 0.2758621 0.7840909
[1] "accuracy: 50 num_feat:5 fitness:9.7175622734145"
[1] 0.06451613 0.96511628
[1] 0.06451613 0.96511628
[1] "accuracy: 50 num_feat:5 fitness:10.1541965618755"
[1] 0.2333333 0.7931034
[1] 0.2333333 0.7931034
[1] "accuracy: 50 num_feat:5 fitness:10.7025822704592"
[1] 0.1071429 0.9101124
[1] 0.1071429 0.9101124
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:14.5305145075076"
[1] 0.0000000 0.9195402
[1] 0.0000000 0.9195402
[1] "accuracy: 49.2945330148801 num_feat:5 fitness:5.06248353911387"
[1] 0.1428571 0.6629213
[1] 0.1428571 0.6629213
[1] "accuracy: 49.3229996342091 num_feat:5 fitness:13.95864764681"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:5 fitness:14.3320486339253"
[1] 0.06451613 0.90697674
[1] 0.06451613 0.90697674
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:6.88294054074305"
[1] 0.4285714 0.7191011
[1] 0.4285714 0.7191011
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:7.58929456569293"
[1] 0.0000000 0.9655172
[1] 0.0000000 0.9655172
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:7.08076859930968"
[1] "lasso:5:10.0011039138852"
[1] "lasso:3:10.7605515962398"
[1] 0.2758621 0.6590909
[1] 0.2758621 0.6590909
[1] "accuracy: 49.2239863163681 num_feat:6 fitness:9.17040024054832"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 50 num_feat:6 fitness:10.2122912194986"
[1] 0.2333333 0.8390805
[1] 0.2333333 0.8390805
[1] "accuracy: 50 num_feat:6 fitness:9.50399362871429"
[1] 0.2857143 0.8426966
[1] 0.2857143 0.8426966
[1] "accuracy: 49.4914547142425 num_feat:6 fitness:14.8862113700229"
[1] 0.03333333 0.95402299
[1] 0.03333333 0.95402299
[1] "accuracy: 50 num_feat:6 fitness:5.42286979787284"
[1] 0.3571429 0.6966292
[1] 0.3571429 0.6966292
[1] "accuracy: 49.3229996342091 num_feat:6 fitness:14.6264106386577"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:6 fitness:14.6687110124924"
[1] 0.03225806 0.95348837
[1] 0.03225806 0.95348837
[1] "accuracy: 49.3168011361034 num_feat:6 fitness:6.3544698271838"
[1] 0.3928571 0.7078652
[1] 0.3928571 0.7078652
[1] "accuracy: 49.3168011361034 num_feat:6 fitness:7.47187408650607"
[1] 0.0000000 0.9655172
[1] 0.0000000 0.9655172
[1] "accuracy: 49.4306676134195 num_feat:6 fitness:7.41949779351555"
[1] "lasso:6:9.97367296150124"
[1] "lasso:3:10.7605515962398"
[1] 0.2413793 0.7272727
[1] 0.2413793 0.7272727
[1] "accuracy: 49.2239863163681 num_feat:7 fitness:9.25460301219044"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 50 num_feat:7 fitness:10.2122463422379"
[1] 0.3333333 0.7126437
[1] 0.3333333 0.7126437
[1] "accuracy: 50 num_feat:7 fitness:8.5704565188801"
[1] 0.250000 0.752809
[1] 0.250000 0.752809
[1] "accuracy: 49.4914547142425 num_feat:7 fitness:14.5721616773529"
[1] 0.1000000 0.8965517
[1] 0.1000000 0.8965517
[1] "accuracy: 49.0299828954602 num_feat:7 fitness:4.71853573832875"
[1] 0.2500000 0.6629213
[1] 0.2500000 0.6629213
[1] "accuracy: 50.028466619329 num_feat:7 fitness:14.7555152739857"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:7 fitness:14.5410412096783"
[1] 0.0000000 0.9186047
[1] 0.0000000 0.9186047
[1] "accuracy: 49.3168011361034 num_feat:7 fitness:6.18627831607062"
[1] 0.3928571 0.6292135
[1] 0.3928571 0.6292135
[1] "accuracy: 49.3168011361034 num_feat:7 fitness:7.27519999576223"
[1] 0.000000 0.954023
[1] 0.000000 0.954023
[1] "accuracy: 49.4306676134195 num_feat:7 fitness:7.19048076000565"
[1] "lasso:7:9.72765188444926"
[1] "lasso:3:10.7605515962398"
[1] 0.2068966 0.8295455
[1] 0.2068966 0.8295455
[1] "accuracy: 49.2239863163681 num_feat:8 fitness:9.42403305655985"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 49.2239863163681 num_feat:8 fitness:9.1468252563481"
[1] 0.2666667 0.8275862
[1] 0.2666667 0.8275862
[1] "accuracy: 50 num_feat:8 fitness:8.03869057412909"
[1] 0.1785714 0.7640449
[1] 0.1785714 0.7640449
[1] "accuracy: 49.4914547142425 num_feat:8 fitness:14.4216352591612"
[1] 0.06666667 0.93103448
[1] 0.06666667 0.93103448
[1] "accuracy: 49.2945330148801 num_feat:8 fitness:4.91977701385142"
[1] 0.1785714 0.7303371
[1] 0.1785714 0.7303371
[1] "accuracy: 50.028466619329 num_feat:8 fitness:14.7454382939963"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:8 fitness:14.5409963324177"
[1] 0.0000000 0.9418605
[1] 0.0000000 0.9418605
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:8.24271650249028"
[1] 0.4285714 0.6067416
[1] 0.4285714 0.6067416
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:7.30826105750636"
[1] 0.0000000 0.9770115
[1] 0.0000000 0.9770115
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:7.1625072891257"
[1] "lasso:8:9.79508806355859"
[1] "lasso:3:10.7605515962398"
[1] 0.2413793 0.8750000
[1] 0.2413793 0.8750000
[1] "accuracy: 47.5184402799024 num_feat:9 fitness:7.99717718623466"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 48.8214391565884 num_feat:9 fitness:8.81580024181075"
[1] 0.3000000 0.8850575
[1] 0.3000000 0.8850575
[1] "accuracy: 48.9618195313574 num_feat:9 fitness:9.00683284085253"
[1] 0.4285714 0.7078652
[1] 0.4285714 0.7078652
[1] "accuracy: 48.9567647954719 num_feat:9 fitness:10.8818937184098"
[1] 0.2333333 0.9195402
[1] 0.2333333 0.9195402
[1] "accuracy: 48.6202806523543 num_feat:9 fitness:4.80197389917911"
[1] 0.1785714 0.7415730
[1] 0.1785714 0.7415730
[1] "accuracy: 50.0260019266528 num_feat:9 fitness:13.5714513686947"
[1] 0 1
[1] 0 1
[1] "accuracy: 47.850663798018 num_feat:9 fitness:13.3875939531673"
[1] 0 1
[1] 0 1
[1] "accuracy: 48.9658988214125 num_feat:9 fitness:8.12484372642076"
[1] 0.6428571 0.3932584
[1] 0.6428571 0.3932584
[1] "accuracy: 49.3168011361034 num_feat:9 fitness:7.31022260079141"
[1] 0 1
[1] 0 1
[1] "accuracy: 49.6263453520374 num_feat:9 fitness:7.45209183818334"
[1] "lasso:9:9.13498813737442"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.5862069 0.6818182
[1] 0.5862069 0.6818182
[1] "accuracy: 69.3185420276309 num_feat:3 fitness:29.7267387994427"
[1] 0.1935484 1.0000000
[1] 0.1935484 1.0000000
[1] "accuracy: 65.2990364100454 num_feat:3 fitness:31.8119406049282"
[1] 0.3333333 0.9080460
[1] 0.3333333 0.9080460
[1] "accuracy: 61.9208673300313 num_feat:3 fitness:25.7800112181714"
[1] 0.7142857 0.4382022
[1] 0.7142857 0.4382022
[1] "accuracy: 70.0266290619407 num_feat:3 fitness:29.799309309364"
[1] 0.6000000 0.8390805
[1] 0.6000000 0.8390805
[1] "accuracy: 64.8656931755406 num_feat:3 fitness:24.3689011412069"
[1] 0.6785714 0.4269663
[1] 0.6785714 0.4269663
[1] "accuracy: 72.0404941431122 num_feat:3 fitness:35.7923606921084"
[1] 0.1250000 0.9176471
[1] 0.1250000 0.9176471
[1] "accuracy: 70.6273870359414 num_feat:3 fitness:30.4517141660222"
[1] 0.4516129 0.8255814
[1] 0.4516129 0.8255814
[1] "accuracy: 68.4927056880844 num_feat:3 fitness:33.6498726984779"
[1] 0.2857143 0.7865169
[1] 0.2857143 0.7865169
[1] "accuracy: 62.3581132254452 num_feat:3 fitness:17.9317648559206"
[1] 0.1000000 0.9195402
[1] 0.1000000 0.9195402
[1] "accuracy: 67.8178137097897 num_feat:3 fitness:27.7333119983766"
[1] "rfe:3:28.7045925484019"
[1] "rfe:3:28.7045925484019"
[1] 0.4137931 0.9090909
[1] 0.4137931 0.9090909
[1] "accuracy: 66.1433465465692 num_feat:4 fitness:27.482444646809"
[1] 0.1935484 0.9883721
[1] 0.1935484 0.9883721
[1] "accuracy: 67.8526782309116 num_feat:4 fitness:32.7889164909015"
[1] 0.3333333 0.9080460
[1] 0.3333333 0.9080460
[1] "accuracy: 66.5239910912331 num_feat:4 fitness:29.228285467239"
[1] 0.7142857 0.4831461
[1] 0.7142857 0.4831461
[1] "accuracy: 69.0760587017344 num_feat:4 fitness:33.162012077548"
[1] 0.6333333 0.8735632
[1] 0.6333333 0.8735632
[1] "accuracy: 66.8510287737705 num_feat:4 fitness:26.027418553469"
[1] 0.7142857 0.5617978
[1] 0.7142857 0.5617978
[1] "accuracy: 72.5480060580762 num_feat:4 fitness:36.6010337022512"
[1] 0.0625000 0.8941176
[1] 0.0625000 0.8941176
[1] "accuracy: 71.6255075707183 num_feat:4 fitness:30.5461087056263"
[1] 0.4838710 0.8488372
[1] 0.4838710 0.8488372
[1] "accuracy: 69.0726591173243 num_feat:4 fitness:35.1363113347087"
[1] 0.2857143 0.8089888
[1] 0.2857143 0.8089888
[1] "accuracy: 65.8468717403833 num_feat:4 fitness:20.6044686401443"
[1] 0.2666667 0.9195402
[1] 0.2666667 0.9195402
[1] "accuracy: 73.0043626420904 num_feat:4 fitness:30.7641685321678"
[1] "rfe:4:30.2341168150865"
[1] "rfe:4:30.2341168150865"
[1] 0.4482759 0.8863636
[1] 0.4482759 0.8863636
[1] "accuracy: 67.5496498875455 num_feat:5 fitness:28.7272893820768"
[1] 0.3225806 1.0000000
[1] 0.3225806 1.0000000
[1] "accuracy: 66.4376668959488 num_feat:5 fitness:32.9883544341128"
[1] 0.4333333 0.9195402
[1] 0.4333333 0.9195402
[1] "accuracy: 66.624155234234 num_feat:5 fitness:29.582099329413"
[1] 0.6428571 0.5617978
[1] 0.6428571 0.5617978
[1] "accuracy: 71.0194688593855 num_feat:5 fitness:34.776014497401"
[1] 0.5333333 0.8965517
[1] 0.5333333 0.8965517
[1] "accuracy: 69.2517200798405 num_feat:5 fitness:27.6349283811354"
[1] 0.7500000 0.6404494
[1] 0.7500000 0.6404494
[1] "accuracy: 71.2164942364324 num_feat:5 fitness:37.6899996836005"
[1] 0.0312500 0.8588235
[1] 0.0312500 0.8588235
[1] "accuracy: 69.3736287425703 num_feat:5 fitness:25.1101727234517"
[1] 0.2258065 0.9069767
[1] 0.2258065 0.9069767
[1] "accuracy: 71.4013990838449 num_feat:5 fitness:36.3827829160776"
[1] 0.2857143 0.8426966
[1] 0.2857143 0.8426966
[1] "accuracy: 69.0916493639564 num_feat:5 fitness:26.2090683306037"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 70.4342939452232 num_feat:5 fitness:30.1411013251667"
[1] "rfe:5:30.9241811003039"
[1] "rfe:5:30.9241811003039"
[1] 0.4137931 0.8863636
[1] 0.4137931 0.8863636
[1] "accuracy: 69.9746096883059 num_feat:6 fitness:30.4597574588347"
[1] 0.2580645 1.0000000
[1] 0.2580645 1.0000000
[1] "accuracy: 69.6375105394595 num_feat:6 fitness:35.9279693291441"
[1] 0.3666667 0.9540230
[1] 0.3666667 0.9540230
[1] "accuracy: 72.4764655146843 num_feat:6 fitness:37.5098774642564"
[1] 0.5714286 0.6404494
[1] 0.5714286 0.6404494
[1] "accuracy: 76.4096872331291 num_feat:6 fitness:39.7363623438763"
[1] 0.600000 0.908046
[1] 0.600000 0.908046
[1] "accuracy: 73.9320267371649 num_feat:6 fitness:31.3409508347118"
[1] 0.8214286 0.7415730
[1] 0.8214286 0.7415730
[1] "accuracy: 76.1415681174323 num_feat:6 fitness:42.0045100204663"
[1] 0.0625000 0.9764706
[1] 0.0625000 0.9764706
[1] "accuracy: 77.0077825547886 num_feat:6 fitness:31.5957051281049"
[1] 0.1935484 0.9534884
[1] 0.1935484 0.9534884
[1] "accuracy: 75.4354466700003 num_feat:6 fitness:39.3907699474963"
[1] 0.3214286 0.8876404
[1] 0.3214286 0.8876404
[1] "accuracy: 68.7541785618264 num_feat:6 fitness:27.0707739294741"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 79.0527691523475 num_feat:6 fitness:35.679100894031"
[1] "rfe:6:35.0715777350396"
[1] "rfe:6:35.0715777350396"
[1] 0.4482759 0.9318182
[1] 0.4482759 0.9318182
[1] "accuracy: 68.2397994025935 num_feat:7 fitness:29.3584481274777"
[1] 0.1612903 1.0000000
[1] 0.1612903 1.0000000
[1] "accuracy: 70.3036540484682 num_feat:7 fitness:36.5302565043034"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 73.9512905164867 num_feat:7 fitness:34.6111036092581"
[1] 0.5714286 0.8089888
[1] 0.5714286 0.8089888
[1] "accuracy: 76.5339284540176 num_feat:7 fitness:39.2980378489579"
[1] 0.5666667 0.9195402
[1] 0.5666667 0.9195402
[1] "accuracy: 71.4624545256439 num_feat:7 fitness:32.7674624309943"
[1] 0.8571429 0.7078652
[1] 0.8571429 0.7078652
[1] "accuracy: 77.6913034712733 num_feat:7 fitness:41.1253117227513"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 72.8272568473271 num_feat:7 fitness:29.0740450555644"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 71.1770993953786 num_feat:7 fitness:41.0953761221382"
[1] 0.2500000 0.9101124
[1] 0.2500000 0.9101124
[1] "accuracy: 68.6233230393732 num_feat:7 fitness:26.850195757083"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 78.1582252414554 num_feat:7 fitness:35.1847083286295"
[1] "rfe:7:34.5894945507158"
[1] "rfe:6:35.0715777350396"
[1] 0.3793103 0.9090909
[1] 0.3793103 0.9090909
[1] "accuracy: 68.0363279728392 num_feat:8 fitness:28.9765677029797"
[1] 0.1612903 1.0000000
[1] 0.1612903 1.0000000
[1] "accuracy: 67.7088446516837 num_feat:8 fitness:33.2521231050672"
[1] 0.200000 0.954023
[1] 0.200000 0.954023
[1] "accuracy: 72.8939016418157 num_feat:8 fitness:37.3715344663353"
[1] 0.5000000 0.8314607
[1] 0.5000000 0.8314607
[1] "accuracy: 74.5567426589895 num_feat:8 fitness:37.5431068588112"
[1] 0.6000000 0.9310345
[1] 0.6000000 0.9310345
[1] "accuracy: 68.5017014084922 num_feat:8 fitness:27.3251533090605"
[1] 0.8928571 0.6741573
[1] 0.8928571 0.6741573
[1] "accuracy: 76.1108874325629 num_feat:8 fitness:39.9568663805676"
[1] 0.0312500 0.9764706
[1] 0.0312500 0.9764706
[1] "accuracy: 73.9638721830851 num_feat:8 fitness:32.0739418502624"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 71.5220352192948 num_feat:8 fitness:41.3008954234005"
[1] 0.3214286 0.8876404
[1] 0.3214286 0.8876404
[1] "accuracy: 65.6916657431176 num_feat:8 fitness:25.0604084328855"
[1] 0.1333333 0.9540230
[1] 0.1333333 0.9540230
[1] "accuracy: 77.7435271634724 num_feat:8 fitness:34.4250805452847"
[1] "rfe:8:33.7285678074654"
[1] "rfe:6:35.0715777350396"
[1] 0.2758621 0.9204545
[1] 0.2758621 0.9204545
[1] "accuracy: 72.3606140470337 num_feat:9 fitness:31.9895257826188"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 69.1055271171569 num_feat:9 fitness:34.2192263022596"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 72.4124802070577 num_feat:9 fitness:33.7977230585792"
[1] 0.6071429 0.8539326
[1] 0.6071429 0.8539326
[1] "accuracy: 74.2828150853942 num_feat:9 fitness:37.7581206434024"
[1] 0.5333333 0.9310345
[1] 0.5333333 0.9310345
[1] "accuracy: 75.2649992209904 num_feat:9 fitness:25.5640133174658"
[1] 0.8928571 0.7303371
[1] 0.8928571 0.7303371
[1] "accuracy: 71.8592894164731 num_feat:9 fitness:36.9520487207806"
[1] 0.0312500 0.9764706
[1] 0.0312500 0.9764706
[1] "accuracy: 73.2682293216515 num_feat:9 fitness:29.0960904563106"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 74.0084741772747 num_feat:9 fitness:43.2188174540389"
[1] 0.3928571 0.8764045
[1] 0.3928571 0.8764045
[1] "accuracy: 71.0447917758748 num_feat:9 fitness:32.1890807491593"
[1] 0.1333333 0.9655172
[1] 0.1333333 0.9655172
[1] "accuracy: 76.4610164253519 num_feat:9 fitness:33.4918882466175"
[1] "rfe:9:33.8276534731233"
[1] "rfe:6:35.0715777350396"
[1] 0.2758621 0.9204545
[1] 0.2758621 0.9204545
[1] "accuracy: 73.6154027742849 num_feat:10 fitness:32.6463417267906"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 68.1070226274236 num_feat:10 fitness:32.4770544175551"
[1] 0.1666667 0.9425287
[1] 0.1666667 0.9425287
[1] "accuracy: 72.9783927779246 num_feat:10 fitness:34.029092089194"
[1] 0.5000000 0.8764045
[1] 0.5000000 0.8764045
[1] "accuracy: 72.2035097992329 num_feat:10 fitness:36.0400571233586"
[1] 0.500000 0.908046
[1] 0.500000 0.908046
[1] "accuracy: 73.1678873931041 num_feat:10 fitness:30.5172317786302"
[1] 0.9285714 0.7415730
[1] 0.9285714 0.7415730
[1] "accuracy: 73.8795951848468 num_feat:10 fitness:38.5314710823123"
[1] 0.0312500 0.9764706
[1] 0.0312500 0.9764706
[1] "accuracy: 74.0796550204273 num_feat:10 fitness:30.6657774268402"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 71.8707819950824 num_feat:10 fitness:41.4817205894295"
[1] 0.4642857 0.8988764
[1] 0.4642857 0.8988764
[1] "accuracy: 68.2033228862408 num_feat:10 fitness:30.2926854085254"
[1] 0.1333333 0.9770115
[1] 0.1333333 0.9770115
[1] "accuracy: 77.0576797116557 num_feat:10 fitness:34.2212335150149"
[1] "rfe:10:34.0902665157651"
[1] "rfe:6:35.0715777350396"
[1] 0.4137931 0.9090909
[1] 0.4137931 0.9090909
[1] "accuracy: 69.7344968251442 num_feat:11 fitness:30.0510383682799"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 69.8635250880653 num_feat:11 fitness:33.7943863857757"
[1] 0.1333333 0.9655172
[1] 0.1333333 0.9655172
[1] "accuracy: 69.2512864737328 num_feat:11 fitness:30.9196685234572"
[1] 0.4285714 0.8651685
[1] 0.4285714 0.8651685
[1] "accuracy: 72.1698824753715 num_feat:11 fitness:33.80813043699"
[1] 0.5666667 0.8965517
[1] 0.5666667 0.8965517
[1] "accuracy: 70.5244350909047 num_feat:11 fitness:28.672963748196"
[1] 0.7857143 0.8089888
[1] 0.7857143 0.8089888
[1] "accuracy: 72.273550566225 num_feat:11 fitness:37.138289209785"
[1] 0.0312500 0.9764706
[1] 0.0312500 0.9764706
[1] "accuracy: 72.2464502018612 num_feat:11 fitness:27.5468048763248"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 69.1869500623019 num_feat:11 fitness:39.4172263687349"
[1] 0.4642857 0.8988764
[1] 0.4642857 0.8988764
[1] "accuracy: 66.969011219553 num_feat:11 fitness:27.3669067812489"
[1] 0.1666667 0.9770115
[1] 0.1666667 0.9770115
[1] "accuracy: 78.4352131418891 num_feat:11 fitness:35.0845149950162"
[1] "rfe:11:32.3799929693809"
[1] "rfe:6:35.0715777350396"
[1] 0.4482759 0.9204545
[1] 0.4482759 0.9204545
[1] "accuracy: 77.2038389372827 num_feat:12 fitness:33.5463913550539"
[1] 0.09677419 1.00000000
[1] 0.09677419 1.00000000
[1] "accuracy: 69.5547889834996 num_feat:12 fitness:33.5537321899128"
[1] 0.1333333 0.9540230
[1] 0.1333333 0.9540230
[1] "accuracy: 70.9328089200909 num_feat:12 fitness:35.4852615633296"
[1] 0.6071429 0.8651685
[1] 0.6071429 0.8651685
[1] "accuracy: 70.7523114772778 num_feat:12 fitness:36.4413358825876"
[1] 0.5333333 0.9195402
[1] 0.5333333 0.9195402
[1] "accuracy: 71.2325027154051 num_feat:12 fitness:29.1776724813518"
[1] 0.8214286 0.7977528
[1] 0.8214286 0.7977528
[1] "accuracy: 74.6633481487524 num_feat:12 fitness:39.0449260354793"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 73.5838041281733 num_feat:12 fitness:28.5875070525836"
[1] 0.03225806 1.00000000
[1] 0.03225806 1.00000000
[1] "accuracy: 71.365191943945 num_feat:12 fitness:41.0508629027066"
[1] 0.5000000 0.8764045
[1] 0.5000000 0.8764045
[1] "accuracy: 70.1715427112689 num_feat:12 fitness:28.0070811021181"
[1] 0.2000000 0.9770115
[1] 0.2000000 0.9770115
[1] "accuracy: 70.584997982381 num_feat:12 fitness:30.2801420814578"
[1] "rfe:12:33.5174912646581"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.5862069 0.6931818
[1] 0.5862069 0.6931818
[1] "accuracy: 50 num_feat:3 fitness:10.2662413696287"
[1] 0.1935484 0.8953488
[1] 0.1935484 0.8953488
[1] "accuracy: 50 num_feat:3 fitness:11.2844488366399"
[1] 0.3333333 0.8390805
[1] 0.3333333 0.8390805
[1] "accuracy: 50 num_feat:3 fitness:10.284776886528"
[1] 0.07142857 0.92134831
[1] 0.07142857 0.92134831
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:14.4694084353837"
[1] 0.2000000 0.7931034
[1] 0.2000000 0.7931034
[1] "accuracy: 50 num_feat:3 fitness:5.77589725686025"
[1] 0.2142857 0.7303371
[1] 0.2142857 0.7303371
[1] "accuracy: 50.028466619329 num_feat:3 fitness:14.8392960237193"
[1] 0.0312500 0.9529412
[1] 0.0312500 0.9529412
[1] "accuracy: 47.3510945916462 num_feat:3 fitness:12.973664253129"
[1] 0.06451613 0.94186047
[1] 0.06451613 0.94186047
[1] "accuracy: 48.7388169917419 num_feat:3 fitness:13.0571399182948"
[1] 0.3571429 0.6629213
[1] 0.3571429 0.6629213
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:7.27036345344063"
[1] 0.03333333 0.93103448
[1] 0.03333333 0.93103448
[1] "accuracy: 49.3168011361034 num_feat:3 fitness:7.38427952877327"
[1] "elasticnet:3:10.7605515962398"
[1] "elasticnet:3:10.7605515962398"
[1] 0.3103448 0.7613636
[1] 0.3103448 0.7613636
[1] "accuracy: 48.6050070027093 num_feat:4 fitness:8.70075111744067"
[1] 0.1290323 0.9418605
[1] 0.1290323 0.9418605
[1] "accuracy: 50 num_feat:4 fitness:10.2573922268332"
[1] 0.2333333 0.8275862
[1] 0.2333333 0.8275862
[1] "accuracy: 49.1660627495078 num_feat:4 fitness:9.09446899945481"
[1] 0.1071429 0.9325843
[1] 0.1071429 0.9325843
[1] "accuracy: 49.3168011361034 num_feat:4 fitness:14.5867391600492"
[1] 0.2666667 0.7586207
[1] 0.2666667 0.7586207
[1] "accuracy: 47.9800314067994 num_feat:4 fitness:4.34133570481402"
[1] 0.4285714 0.6629213
[1] 0.4285714 0.6629213
[1] "accuracy: 50.028466619329 num_feat:4 fitness:15.2499023976691"
[1] 0.0312500 0.9647059
[1] 0.0312500 0.9647059
[1] "accuracy: 48.5800334135401 num_feat:4 fitness:13.8051754558128"
[1] 0.06451613 0.95348837
[1] 0.06451613 0.95348837
[1] "accuracy: 48.6687967863937 num_feat:4 fitness:12.0078341609056"
[1] 0.4285714 0.6067416
[1] 0.4285714 0.6067416
[1] "accuracy: 49.3168011361034 num_feat:4 fitness:7.30844056654912"
[1] 0.0000000 0.9310345
[1] 0.0000000 0.9310345
[1] "accuracy: 48.1791869466693 num_feat:4 fitness:6.44769067610368"
[1] "elasticnet:4:10.1799730465632"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2758621 0.7840909
[1] 0.2758621 0.7840909
[1] "accuracy: 50 num_feat:5 fitness:9.7175622734145"
[1] 0.06451613 0.96511628
[1] 0.06451613 0.96511628
[1] "accuracy: 50 num_feat:5 fitness:10.1541965618755"
[1] 0.2333333 0.7931034
[1] 0.2333333 0.7931034
[1] "accuracy: 50 num_feat:5 fitness:10.7025822704592"
[1] 0.1071429 0.9101124
[1] 0.1071429 0.9101124
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:14.5305145075076"
[1] 0.0000000 0.9195402
[1] 0.0000000 0.9195402
[1] "accuracy: 49.2945330148801 num_feat:5 fitness:5.06248353911387"
[1] 0.1428571 0.6629213
[1] 0.1428571 0.6629213
[1] "accuracy: 49.3229996342091 num_feat:5 fitness:13.95864764681"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:5 fitness:14.3320486339253"
[1] 0.06451613 0.90697674
[1] 0.06451613 0.90697674
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:6.88294054074305"
[1] 0.4285714 0.7191011
[1] 0.4285714 0.7191011
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:7.58929456569293"
[1] 0.0000000 0.9655172
[1] 0.0000000 0.9655172
[1] "accuracy: 49.3168011361034 num_feat:5 fitness:7.08076859930968"
[1] "elasticnet:5:10.0011039138852"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2758621 0.6590909
[1] 0.2758621 0.6590909
[1] "accuracy: 49.2239863163681 num_feat:6 fitness:9.17040024054832"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 50 num_feat:6 fitness:10.2122912194986"
[1] 0.2333333 0.8390805
[1] 0.2333333 0.8390805
[1] "accuracy: 50 num_feat:6 fitness:9.50399362871429"
[1] 0.2857143 0.8426966
[1] 0.2857143 0.8426966
[1] "accuracy: 49.4914547142425 num_feat:6 fitness:14.8862113700229"
[1] 0.03333333 0.95402299
[1] 0.03333333 0.95402299
[1] "accuracy: 50 num_feat:6 fitness:5.42286979787284"
[1] 0.3571429 0.6966292
[1] 0.3571429 0.6966292
[1] "accuracy: 49.3229996342091 num_feat:6 fitness:14.6264106386577"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:6 fitness:14.6687110124924"
[1] 0.03225806 0.95348837
[1] 0.03225806 0.95348837
[1] "accuracy: 49.3168011361034 num_feat:6 fitness:6.3544698271838"
[1] 0.3928571 0.7078652
[1] 0.3928571 0.7078652
[1] "accuracy: 49.3168011361034 num_feat:6 fitness:7.47187408650607"
[1] 0.0000000 0.9655172
[1] 0.0000000 0.9655172
[1] "accuracy: 49.4306676134195 num_feat:6 fitness:7.41949779351555"
[1] "elasticnet:6:9.97367296150124"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2413793 0.7272727
[1] 0.2413793 0.7272727
[1] "accuracy: 49.2239863163681 num_feat:7 fitness:9.25460301219044"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 50 num_feat:7 fitness:10.2122463422379"
[1] 0.3333333 0.7126437
[1] 0.3333333 0.7126437
[1] "accuracy: 50 num_feat:7 fitness:8.5704565188801"
[1] 0.250000 0.752809
[1] 0.250000 0.752809
[1] "accuracy: 49.4914547142425 num_feat:7 fitness:14.5721616773529"
[1] 0.1000000 0.8965517
[1] 0.1000000 0.8965517
[1] "accuracy: 49.0299828954602 num_feat:7 fitness:4.71853573832875"
[1] 0.2500000 0.6629213
[1] 0.2500000 0.6629213
[1] "accuracy: 50.028466619329 num_feat:7 fitness:14.7555152739857"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:7 fitness:14.5410412096783"
[1] 0.0000000 0.9186047
[1] 0.0000000 0.9186047
[1] "accuracy: 49.3168011361034 num_feat:7 fitness:6.18627831607062"
[1] 0.3928571 0.6292135
[1] 0.3928571 0.6292135
[1] "accuracy: 49.3168011361034 num_feat:7 fitness:7.27519999576223"
[1] 0.000000 0.954023
[1] 0.000000 0.954023
[1] "accuracy: 49.4306676134195 num_feat:7 fitness:7.19048076000565"
[1] "elasticnet:7:9.72765188444926"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2068966 0.8295455
[1] 0.2068966 0.8295455
[1] "accuracy: 49.2239863163681 num_feat:8 fitness:9.42403305655985"
[1] 0.06451613 1.00000000
[1] 0.06451613 1.00000000
[1] "accuracy: 49.2239863163681 num_feat:8 fitness:9.1468252563481"
[1] 0.2666667 0.8275862
[1] 0.2666667 0.8275862
[1] "accuracy: 50 num_feat:8 fitness:8.03869057412909"
[1] 0.1785714 0.7640449
[1] 0.1785714 0.7640449
[1] "accuracy: 49.4914547142425 num_feat:8 fitness:14.4216352591612"
[1] 0.06666667 0.93103448
[1] 0.06666667 0.93103448
[1] "accuracy: 49.2945330148801 num_feat:8 fitness:4.91977701385142"
[1] 0.1785714 0.7303371
[1] 0.1785714 0.7303371
[1] "accuracy: 50.028466619329 num_feat:8 fitness:14.7454382939963"
[1] 0.0000000 0.9882353
[1] 0.0000000 0.9882353
[1] "accuracy: 49.4914547142425 num_feat:8 fitness:14.5409963324177"
[1] 0.0000000 0.9418605
[1] 0.0000000 0.9418605
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:8.24271650249028"
[1] 0.4285714 0.6067416
[1] 0.4285714 0.6067416
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:7.30826105750636"
[1] 0.0000000 0.9770115
[1] 0.0000000 0.9770115
[1] "accuracy: 49.3168011361034 num_feat:8 fitness:7.1625072891257"
[1] "elasticnet:8:9.79508806355859"
[1] "elasticnet:3:10.7605515962398"
[1] 0.2413793 0.8750000
[1] 0.2413793 0.8750000
[1] "accuracy: 47.5184402799024 num_feat:9 fitness:7.99717718623466"
[1] 0.06451613 0.98837209
[1] 0.06451613 0.98837209
[1] "accuracy: 48.8214391565884 num_feat:9 fitness:8.81580024181075"
[1] 0.3000000 0.8850575
[1] 0.3000000 0.8850575
[1] "accuracy: 48.9618195313574 num_feat:9 fitness:9.00683284085253"
[1] 0.4285714 0.7078652
[1] 0.4285714 0.7078652
[1] "accuracy: 48.9567647954719 num_feat:9 fitness:10.8818937184098"
[1] 0.2333333 0.9195402
[1] 0.2333333 0.9195402
[1] "accuracy: 48.6202806523543 num_feat:9 fitness:4.80197389917911"
[1] 0.1785714 0.7415730
[1] 0.1785714 0.7415730
[1] "accuracy: 50.0260019266528 num_feat:9 fitness:13.5714513686947"
[1] 0 1
[1] 0 1
[1] "accuracy: 47.850663798018 num_feat:9 fitness:13.3875939531673"
[1] 0 1
[1] 0 1
[1] "accuracy: 48.9658988214125 num_feat:9 fitness:8.12484372642076"
[1] 0.6428571 0.3932584
[1] 0.6428571 0.3932584
[1] "accuracy: 49.3168011361034 num_feat:9 fitness:7.31022260079141"
[1] 0 1
[1] 0 1
[1] "accuracy: 49.6263453520374 num_feat:9 fitness:7.45209183818334"
[1] "elasticnet:9:9.13498813737442"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.5172414 0.7840909
[1] 0.5172414 0.7840909
[1] "accuracy: 46.3743179300691 num_feat:3 fitness:10.1018387513498"
[1] 0.1612903 0.9418605
[1] 0.1612903 0.9418605
[1] "accuracy: 53.7376417322644 num_feat:3 fitness:21.7197869421445"
[1] 0.4333333 0.8045977
[1] 0.4333333 0.8045977
[1] "accuracy: 52.5349397283843 num_feat:3 fitness:12.0612544660413"
[1] 0.3928571 0.8539326
[1] 0.3928571 0.8539326
[1] "accuracy: 55.1383680942539 num_feat:3 fitness:22.9706157567254"
[1] 0.5000000 0.8735632
[1] 0.5000000 0.8735632
[1] "accuracy: 50.47270238196 num_feat:3 fitness:10.0766169312119"
[1] 0.4285714 0.6629213
[1] 0.4285714 0.6629213
[1] "accuracy: 57.6433897528868 num_feat:3 fitness:21.7111396250981"
[1] 0 1
[1] 0 1
[1] "accuracy: 58.3433157168809 num_feat:3 fitness:19.5965409823262"
[1] 0.06451613 0.93023256
[1] 0.06451613 0.93023256
[1] "accuracy: 57.9504440387194 num_feat:3 fitness:20.949570115187"
[1] 0.2500000 0.7078652
[1] 0.2500000 0.7078652
[1] "accuracy: 59.3967707718984 num_feat:3 fitness:13.4248430879916"
[1] 0.4333333 0.7816092
[1] 0.4333333 0.7816092
[1] "accuracy: 54.4198450289483 num_feat:3 fitness:14.0197367542104"
[1] "f.test:3:16.6631943412286"
[1] "f.test:3:16.6631943412286"
[1] 0.6206897 0.7500000
[1] 0.6206897 0.7500000
[1] "accuracy: 45.6646393476731 num_feat:4 fitness:9.74292835422002"
[1] 0.2580645 0.9534884
[1] 0.2580645 0.9534884
[1] "accuracy: 50.6801968506094 num_feat:4 fitness:19.6976636549554"
[1] 0.300000 0.862069
[1] 0.300000 0.862069
[1] "accuracy: 45.6582639223833 num_feat:4 fitness:6.70996094414709"
[1] 0.2500000 0.9101124
[1] 0.2500000 0.9101124
[1] "accuracy: 52.5802883862664 num_feat:4 fitness:19.5853176795334"
[1] 0.6333333 0.8045977
[1] 0.6333333 0.8045977
[1] "accuracy: 50.1788258012614 num_feat:4 fitness:10.0170841586572"
[1] 0.5357143 0.6516854
[1] 0.5357143 0.6516854
[1] "accuracy: 52.0446445081479 num_feat:4 fitness:15.7039791490272"
[1] 0.0625000 0.9411765
[1] 0.0625000 0.9411765
[1] "accuracy: 57.8294566697228 num_feat:4 fitness:19.1531520814089"
[1] 0.09677419 0.94186047
[1] 0.09677419 0.94186047
[1] "accuracy: 50.000690339403 num_feat:4 fitness:15.0969248921712"
[1] 0.3214286 0.7078652
[1] 0.3214286 0.7078652
[1] "accuracy: 56.8402889075777 num_feat:4 fitness:11.6860082410618"
[1] 0.300000 0.862069
[1] 0.300000 0.862069
[1] "accuracy: 47.6685944130169 num_feat:4 fitness:5.49073667362186"
[1] "f.test:4:13.2883755828804"
[1] "f.test:3:16.6631943412286"
[1] 0.6206897 0.7500000
[1] 0.6206897 0.7500000
[1] "accuracy: 46.9663588816096 num_feat:5 fitness:8.21917312741168"
[1] 0.2258065 0.9767442
[1] 0.2258065 0.9767442
[1] "accuracy: 49.8540520180165 num_feat:5 fitness:19.0555045268434"
[1] 0.2666667 0.8390805
[1] 0.2666667 0.8390805
[1] "accuracy: 45.5352222745209 num_feat:5 fitness:6.48336273147121"
[1] 0.2857143 0.8876404
[1] 0.2857143 0.8876404
[1] "accuracy: 50.8195778697939 num_feat:5 fitness:19.5478458539232"
[1] 0.6333333 0.8045977
[1] 0.6333333 0.8045977
[1] "accuracy: 48.9712164174149 num_feat:5 fitness:9.1113322435116"
[1] 0.5714286 0.5842697
[1] 0.5714286 0.5842697
[1] "accuracy: 50.0306548026758 num_feat:5 fitness:14.1620123015782"
[1] 0.0312500 0.9411765
[1] 0.0312500 0.9411765
[1] "accuracy: 54.4642599142532 num_feat:5 fitness:16.5510846375461"
[1] 0.09677419 0.94186047
[1] 0.09677419 0.94186047
[1] "accuracy: 50.9093045240757 num_feat:5 fitness:15.778340653415"
[1] 0.4285714 0.6741573
[1] 0.4285714 0.6741573
[1] "accuracy: 57.1552789464039 num_feat:5 fitness:12.1057933728565"
[1] 0.1666667 0.9195402
[1] 0.1666667 0.9195402
[1] "accuracy: 49.1436285028194 num_feat:5 fitness:7.25792703121917"
[1] "f.test:5:12.8272376479776"
[1] "f.test:3:16.6631943412286"
[1] 0.5862069 0.7272727
[1] 0.5862069 0.7272727
[1] "accuracy: 54.1627357612725 num_feat:6 fitness:13.4733858315282"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 48.5212056417958 num_feat:6 fitness:17.8429591509881"
[1] 0.2666667 0.8505747
[1] 0.2666667 0.8505747
[1] "accuracy: 53.1543464179362 num_feat:6 fitness:12.2262168261022"
[1] 0.3571429 0.8651685
[1] 0.3571429 0.8651685
[1] "accuracy: 54.7029416109049 num_feat:6 fitness:19.3327154357862"
[1] 0.5666667 0.8275862
[1] 0.5666667 0.8275862
[1] "accuracy: 51.9058430201234 num_feat:6 fitness:11.9860198763194"
[1] 0.5357143 0.5955056
[1] 0.5357143 0.5955056
[1] "accuracy: 54.0239190070512 num_feat:6 fitness:17.8457197509538"
[1] 0.0625000 0.9647059
[1] 0.0625000 0.9647059
[1] "accuracy: 57.1736117539072 num_feat:6 fitness:18.6618526681006"
[1] 0.09677419 0.93023256
[1] 0.09677419 0.93023256
[1] "accuracy: 52.4407350389595 num_feat:6 fitness:15.9887079857844"
[1] 0.4285714 0.6966292
[1] 0.4285714 0.6966292
[1] "accuracy: 57.4390724657046 num_feat:6 fitness:12.3747734103522"
[1] 0.1666667 0.9195402
[1] 0.1666667 0.9195402
[1] "accuracy: 52.3452806174721 num_feat:6 fitness:13.46235837699"
[1] "f.test:6:15.3194709312905"
[1] "f.test:3:16.6631943412286"
[1] 0.5862069 0.7386364
[1] 0.5862069 0.7386364
[1] "accuracy: 53.6950282609397 num_feat:7 fitness:13.150969419927"
[1] 0.1612903 1.0000000
[1] 0.1612903 1.0000000
[1] "accuracy: 49.7114253646112 num_feat:7 fitness:18.8452939945711"
[1] 0.2666667 0.8390805
[1] 0.2666667 0.8390805
[1] "accuracy: 52.6805710538039 num_feat:7 fitness:11.834739148705"
[1] 0.3928571 0.7415730
[1] 0.3928571 0.7415730
[1] "accuracy: 53.8196004832029 num_feat:7 fitness:20.4504616629898"
[1] 0.5666667 0.8275862
[1] 0.5666667 0.8275862
[1] "accuracy: 51.5063514209368 num_feat:7 fitness:11.6863562996688"
[1] 0.5357143 0.6292135
[1] 0.5357143 0.6292135
[1] "accuracy: 55.2513771468629 num_feat:7 fitness:18.8505381414732"
[1] 0.0625000 0.9647059
[1] 0.0625000 0.9647059
[1] "accuracy: 56.1073296706287 num_feat:7 fitness:17.9835238147154"
[1] 0.06451613 0.96511628
[1] 0.06451613 0.96511628
[1] "accuracy: 52.7367325402898 num_feat:7 fitness:16.2172253755566"
[1] 0.3571429 0.7752809
[1] 0.3571429 0.7752809
[1] "accuracy: 56.0534165546903 num_feat:7 fitness:11.3535443847426"
[1] 0.1666667 0.9310345
[1] 0.1666667 0.9310345
[1] "accuracy: 52.3816809340692 num_feat:7 fitness:9.75308015185951"
[1] "f.test:7:15.0125732394209"
[1] "f.test:3:16.6631943412286"
[1] 0.5517241 0.8181818
[1] 0.5517241 0.8181818
[1] "accuracy: 52.8396772170721 num_feat:8 fitness:12.6220679995776"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 56.0723375979178 num_feat:8 fitness:23.5352881310001"
[1] 0.3000000 0.8735632
[1] 0.3000000 0.8735632
[1] "accuracy: 52.1718747355878 num_feat:8 fitness:11.6300779075207"
[1] 0.3571429 0.8314607
[1] 0.3571429 0.8314607
[1] "accuracy: 56.682834704924 num_feat:8 fitness:22.7332758388578"
[1] 0.6666667 0.8505747
[1] 0.6666667 0.8505747
[1] "accuracy: 51.9731920557761 num_feat:8 fitness:12.3439131629053"
[1] 0.4285714 0.5955056
[1] 0.4285714 0.5955056
[1] "accuracy: 54.3170827867152 num_feat:8 fitness:15.7498217678505"
[1] 0.0312500 0.9764706
[1] 0.0312500 0.9764706
[1] "accuracy: 57.178996299777 num_feat:8 fitness:17.9051823406884"
[1] 0.06451613 0.97674419
[1] 0.06451613 0.97674419
[1] "accuracy: 53.9838719398309 num_feat:8 fitness:17.1816048153936"
[1] 0.3571429 0.7415730
[1] 0.3571429 0.7415730
[1] "accuracy: 54.9276250883418 num_feat:8 fitness:10.4248862447992"
[1] 0.2333333 0.9195402
[1] 0.2333333 0.9195402
[1] "accuracy: 51.8124273145236 num_feat:8 fitness:11.807215428688"
[1] "f.test:8:15.5933333637281"
[1] "f.test:3:16.6631943412286"
[1] 0.6206897 0.7727273
[1] 0.6206897 0.7727273
[1] "accuracy: 50.7850606982974 num_feat:9 fitness:13.639838162703"
[1] 0.1290323 1.0000000
[1] 0.1290323 1.0000000
[1] "accuracy: 50.3619884993933 num_feat:9 fitness:18.3433905207551"
[1] 0.3333333 0.8735632
[1] 0.3333333 0.8735632
[1] "accuracy: 52.829528633585 num_feat:9 fitness:15.5402215070631"
[1] 0.3571429 0.9325843
[1] 0.3571429 0.9325843
[1] "accuracy: 58.4253153364984 num_feat:9 fitness:24.292900424042"
[1] 0.7333333 0.8390805
[1] 0.7333333 0.8390805
[1] "accuracy: 54.2365337023626 num_feat:9 fitness:17.5126388884006"
[1] 0.4285714 0.7528090
[1] 0.4285714 0.7528090
[1] "accuracy: 56.9046257612922 num_feat:9 fitness:20.0836925484889"
[1] 0.0312500 0.9764706
[1] 0.0312500 0.9764706
[1] "accuracy: 58.8709688612636 num_feat:9 fitness:20.0074502178761"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 56.725357223161 num_feat:9 fitness:20.0370498809893"
[1] 0.2142857 0.7303371
[1] 0.2142857 0.7303371
[1] "accuracy: 56.3512962231155 num_feat:9 fitness:11.1073619738354"
[1] 0.1666667 0.9310345
[1] 0.1666667 0.9310345
[1] "accuracy: 55.9908644885986 num_feat:9 fitness:18.1364007308341"
[1] "f.test:9:17.8700944854988"
[1] "f.test:9:17.8700944854988"
[1] 0.6206897 0.7840909
[1] 0.6206897 0.7840909
[1] "accuracy: 48.4027015643921 num_feat:10 fitness:11.8814330259224"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 50.9893241740459 num_feat:10 fitness:18.7041324707517"
[1] 0.3333333 0.8965517
[1] 0.3333333 0.8965517
[1] "accuracy: 51.1385014015705 num_feat:10 fitness:14.3293774701594"
[1] 0.3571429 0.9438202
[1] 0.3571429 0.9438202
[1] "accuracy: 56.1287505006427 num_feat:10 fitness:23.84852180753"
[1] 0.7000000 0.8275862
[1] 0.7000000 0.8275862
[1] "accuracy: 54.8656079321853 num_feat:10 fitness:17.8723307179897"
[1] 0.4642857 0.6966292
[1] 0.4642857 0.6966292
[1] "accuracy: 58.6414697074545 num_feat:10 fitness:19.3351169069333"
[1] 0.0312500 0.9764706
[1] 0.0312500 0.9764706
[1] "accuracy: 59.6984568516224 num_feat:10 fitness:18.7285706371252"
[1] 0.03225806 0.98837209
[1] 0.03225806 0.98837209
[1] "accuracy: 56.8876744357496 num_feat:10 fitness:20.1571025474628"
[1] 0.2857143 0.7415730
[1] 0.2857143 0.7415730
[1] "accuracy: 54.6519212108939 num_feat:10 fitness:10.0394471536204"
[1] 0.1333333 0.9655172
[1] 0.1333333 0.9655172
[1] "accuracy: 56.2875437382977 num_feat:10 fitness:11.6950721873995"
[1] "f.test:10:16.6591104924894"
[1] "f.test:9:17.8700944854988"
[1] 0.4482759 0.7954545
[1] 0.4482759 0.7954545
[1] "accuracy: 49.9937573214754 num_feat:11 fitness:12.6720545746246"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 48.500386483249 num_feat:11 fitness:16.8374001602525"
[1] 0.2000000 0.9425287
[1] 0.2000000 0.9425287
[1] "accuracy: 53.710177645584 num_feat:11 fitness:16.039698971311"
[1] 0.3571429 0.9438202
[1] 0.3571429 0.9438202
[1] "accuracy: 56.3713414114018 num_feat:11 fitness:24.0304201133387"
[1] 0.6666667 0.8505747
[1] 0.6666667 0.8505747
[1] "accuracy: 55.145357878102 num_feat:11 fitness:14.7229028978677"
[1] 0.4285714 0.7303371
[1] 0.4285714 0.7303371
[1] "accuracy: 59.3072606967424 num_feat:11 fitness:21.0793992202742"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 58.397311499763 num_feat:11 fitness:18.1933264851133"
[1] 0.03225806 0.97674419
[1] 0.03225806 0.97674419
[1] "accuracy: 55.0479919223099 num_feat:11 fitness:18.8080059182714"
[1] 0.1785714 0.7977528
[1] 0.1785714 0.7977528
[1] "accuracy: 54.9103915017476 num_feat:11 fitness:10.1058472898451"
[1] 0.1333333 0.9770115
[1] 0.1333333 0.9770115
[1] "accuracy: 56.821649880914 num_feat:11 fitness:15.8470199058239"
[1] "f.test:11:16.8336075536722"
[1] "f.test:9:17.8700944854988"
[1] 0.3793103 0.8068182
[1] 0.3793103 0.8068182
[1] "accuracy: 49.4434008601074 num_feat:12 fitness:12.1152376491435"
[1] 0.09677419 0.98837209
[1] 0.09677419 0.98837209
[1] "accuracy: 50.1320333195701 num_feat:12 fitness:18.0610745753735"
[1] 0.3000000 0.9310345
[1] 0.3000000 0.9310345
[1] "accuracy: 51.0553857394133 num_feat:12 fitness:14.2695431455999"
[1] 0.3214286 0.9325843
[1] 0.3214286 0.9325843
[1] "accuracy: 56.0860216607644 num_feat:12 fitness:22.4490098211737"
[1] 0.6666667 0.8505747
[1] 0.6666667 0.8505747
[1] "accuracy: 54.0162401381302 num_feat:12 fitness:13.8760197156282"
[1] 0.3571429 0.7528090
[1] 0.3571429 0.7528090
[1] "accuracy: 60.0890963077514 num_feat:12 fitness:21.5433393979798"
[1] 0.0312500 0.9882353
[1] 0.0312500 0.9882353
[1] "accuracy: 58.6667527508932 num_feat:12 fitness:18.8275429014443"
[1] 0.03225806 0.97674419
[1] 0.03225806 0.97674419
[1] "accuracy: 57.9373854551809 num_feat:12 fitness:20.975006190664"
[1] 0.1428571 0.7752809
[1] 0.1428571 0.7752809
[1] "accuracy: 55.2396766731103 num_feat:12 fitness:10.2073008015398"
[1] 0.1666667 0.9770115
[1] 0.1666667 0.9770115
[1] "accuracy: 56.8301754724294 num_feat:12 fitness:13.6033692221997"
[1] "f.test:12:16.5927443420746"
[1] "f.test:9:17.8700944854988"
[1] 0.4827586 0.8068182
[1] 0.4827586 0.8068182
[1] "accuracy: 55.7415948184146 num_feat:13 fitness:17.0974589302685"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 49.3346362236325 num_feat:13 fitness:17.5436270374499"
[1] 0.2666667 0.9310345
[1] 0.2666667 0.9310345
[1] "accuracy: 52.4024593480277 num_feat:13 fitness:15.1967515281052"
[1] 0.2857143 0.9438202
[1] 0.2857143 0.9438202
[1] "accuracy: 56.5800708024182 num_feat:13 fitness:21.5083059735081"
[1] 0.6333333 0.8620690
[1] 0.6333333 0.8620690
[1] "accuracy: 56.1435304051441 num_feat:13 fitness:18.7501781708118"
[1] 0.4642857 0.7528090
[1] 0.4642857 0.7528090
[1] "accuracy: 58.9396650735493 num_feat:13 fitness:22.9969021583974"
[1] 0.03125 1.00000
[1] 0.03125 1.00000
[1] "accuracy: 60.060646629053 num_feat:13 fitness:19.6868630486808"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 59.2386792706227 num_feat:13 fitness:21.9218619075427"
[1] 0.2142857 0.7977528
[1] 0.2142857 0.7977528
[1] "accuracy: 56.4315176826998 num_feat:13 fitness:11.3358878853236"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 57.3178901230372 num_feat:13 fitness:14.0783057351937"
[1] "f.test:13:18.0116142375282"
[1] "f.test:13:18.0116142375282"
[1] 0.5172414 0.8181818
[1] 0.5172414 0.8181818
[1] "accuracy: 54.5946804302827 num_feat:14 fitness:16.3518442493696"
[1] 0.1290323 0.9883721
[1] 0.1290323 0.9883721
[1] "accuracy: 52.696489180758 num_feat:14 fitness:20.0649718780333"
[1] 0.2333333 0.9310345
[1] 0.2333333 0.9310345
[1] "accuracy: 52.8556313147936 num_feat:14 fitness:15.4532522925857"
[1] 0.3214286 0.9438202
[1] 0.3214286 0.9438202
[1] "accuracy: 58.7997857784251 num_feat:14 fitness:23.2623330425383"
[1] 0.6000000 0.8735632
[1] 0.6000000 0.8735632
[1] "accuracy: 55.1432464369154 num_feat:14 fitness:17.9456153193397"
[1] 0.4285714 0.7528090
[1] 0.4285714 0.7528090
[1] "accuracy: 55.977270293498 num_feat:14 fitness:20.6857754818125"
[1] 0 1
[1] 0 1
[1] "accuracy: 59.8964222873462 num_feat:14 fitness:19.4855249151399"
[1] 0.03225806 0.97674419
[1] 0.03225806 0.97674419
[1] "accuracy: 58.1121601958479 num_feat:14 fitness:21.1059974916429"
[1] 0.2500000 0.8089888
[1] 0.2500000 0.8089888
[1] "accuracy: 56.71399708741 num_feat:14 fitness:11.6650781635217"
[1] 0.3000000 0.9425287
[1] 0.3000000 0.9425287
[1] "accuracy: 58.4893416864578 num_feat:14 fitness:15.0947805649813"
[1] "f.test:14:18.1115173398965"
[1] "f.test:14:18.1115173398965"
[1] 0.3448276 0.8181818
[1] 0.3448276 0.8181818
[1] "accuracy: 55.3584934739909 num_feat:15 fitness:16.4936246721315"
[1] 0.2258065 0.9767442
[1] 0.2258065 0.9767442
[1] "accuracy: 51.8731070255282 num_feat:15 fitness:19.6602561007794"
[1] 0.2666667 0.9310345
[1] 0.2666667 0.9310345
[1] "accuracy: 55.8036257782401 num_feat:15 fitness:17.7475365962432"
[1] 0.3928571 0.9438202
[1] 0.3928571 0.9438202
[1] "accuracy: 56.8875029822705 num_feat:15 fitness:22.0066474967331"
[1] 0.5666667 0.8620690
[1] 0.5666667 0.8620690
[1] "accuracy: 54.751892238871 num_feat:15 fitness:17.5399858280285"
[1] 0.3928571 0.7528090
[1] 0.3928571 0.7528090
[1] "accuracy: 58.0472945645164 num_feat:15 fitness:23.3989630935299"
[1] 0 1
[1] 0 1
[1] "accuracy: 59.4314050630941 num_feat:15 fitness:19.9458512339267"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 58.0542695272828 num_feat:15 fitness:21.0334648455164"
[1] 0.2500000 0.7977528
[1] 0.2500000 0.7977528
[1] "accuracy: 58.6919695970371 num_feat:15 fitness:13.3078781200129"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 57.1373247576469 num_feat:15 fitness:17.0919959070955"
[1] "f.test:15:18.8226203893997"
[1] "f.test:15:18.8226203893997"
[1] 0.4482759 0.8181818
[1] 0.4482759 0.8181818
[1] "accuracy: 55.311431466686 num_feat:16 fitness:16.7169039790473"
[1] 0.2258065 0.9767442
[1] 0.2258065 0.9767442
[1] "accuracy: 51.2175171040228 num_feat:16 fitness:19.1685187823897"
[1] 0.1666667 0.9310345
[1] 0.1666667 0.9310345
[1] "accuracy: 53.5238275375991 num_feat:16 fitness:15.7876430385017"
[1] 0.3214286 0.9438202
[1] 0.3214286 0.9438202
[1] "accuracy: 58.7139633757552 num_feat:16 fitness:24.4478764860145"
[1] 0.5666667 0.8505747
[1] 0.5666667 0.8505747
[1] "accuracy: 55.8132412215751 num_feat:16 fitness:18.3072170556119"
[1] 0.3928571 0.7865169
[1] 0.3928571 0.7865169
[1] "accuracy: 56.7822350862643 num_feat:16 fitness:21.2843932705015"
[1] 0 1
[1] 0 1
[1] "accuracy: 60.119886573617 num_feat:16 fitness:19.8417451018653"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 57.0039143169436 num_feat:16 fitness:20.2456535605013"
[1] 0.4285714 0.7977528
[1] 0.4285714 0.7977528
[1] "accuracy: 58.3600974099945 num_feat:16 fitness:13.5053576738988"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 55.634234430105 num_feat:16 fitness:15.910035583029"
[1] "f.test:16:18.5215344531361"
[1] "f.test:15:18.8226203893997"
[1] 0.4137931 0.8295455
[1] 0.4137931 0.8295455
[1] "accuracy: 54.9897031912378 num_feat:17 fitness:16.4177650895578"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 52.494009339649 num_feat:17 fitness:19.9645527592679"
[1] 0.1666667 0.9425287
[1] 0.1666667 0.9425287
[1] "accuracy: 52.4958859785028 num_feat:17 fitness:15.0453776241027"
[1] 0.3571429 0.9438202
[1] 0.3571429 0.9438202
[1] "accuracy: 55.9500920217975 num_feat:17 fitness:22.4642138075713"
[1] 0.5666667 0.8505747
[1] 0.5666667 0.8505747
[1] "accuracy: 55.9246081440602 num_feat:17 fitness:17.6078168004048"
[1] 0.3214286 0.7415730
[1] 0.3214286 0.7415730
[1] "accuracy: 56.1826965551885 num_feat:17 fitness:21.745939595328"
[1] 0 1
[1] 0 1
[1] "accuracy: 58.591904837272 num_feat:17 fitness:19.2863902429237"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 56.756923269545 num_feat:17 fitness:20.0603653976917"
[1] 0.4285714 0.7865169
[1] 0.4285714 0.7865169
[1] "accuracy: 58.2204675389313 num_feat:17 fitness:13.3725005057003"
[1] 0.2666667 0.9540230
[1] 0.2666667 0.9540230
[1] "accuracy: 56.4739215387596 num_feat:17 fitness:16.677687071742"
[1] "f.test:17:18.264260889429"
[1] "f.test:15:18.8226203893997"
[1] 0.4482759 0.8636364
[1] 0.4482759 0.8636364
[1] "accuracy: 54.8083336987728 num_feat:18 fitness:15.3420161511163"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 52.2115785772563 num_feat:18 fitness:19.7526848102127"
[1] 0.1666667 0.9425287
[1] 0.1666667 0.9425287
[1] "accuracy: 53.5258370420422 num_feat:18 fitness:15.8177960444966"
[1] 0.3571429 0.9438202
[1] 0.3571429 0.9438202
[1] "accuracy: 55.5419850575901 num_feat:18 fitness:22.1146124158161"
[1] 0.6000000 0.8505747
[1] 0.6000000 0.8505747
[1] "accuracy: 54.4084988967083 num_feat:18 fitness:16.5536532273283"
[1] 0.3928571 0.7752809
[1] 0.3928571 0.7752809
[1] "accuracy: 56.6984808790311 num_feat:18 fitness:21.145574052442"
[1] 0 1
[1] 0 1
[1] "accuracy: 59.3941166534002 num_feat:18 fitness:19.8880042277592"
[1] 0.03225806 0.96511628
[1] 0.03225806 0.96511628
[1] "accuracy: 57.7776345595886 num_feat:18 fitness:19.8484431924832"
[1] 0.3928571 0.8314607
[1] 0.3928571 0.8314607
[1] "accuracy: 58.2204675389313 num_feat:18 fitness:13.3955294647157"
[1] 0.2666667 0.9425287
[1] 0.2666667 0.9425287
[1] "accuracy: 55.2789725667017 num_feat:18 fitness:15.752694833254"
[1] "f.test:18:17.9611008419624"
[1] "f.test:15:18.8226203893997"
[1] 0.4137931 0.8636364
[1] 0.4137931 0.8636364
[1] "accuracy: 54.6792722634349 num_feat:19 fitness:15.1589683008004"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 52.1752761659784 num_feat:19 fitness:19.7254131244936"
[1] 0.1666667 0.9425287
[1] 0.1666667 0.9425287
[1] "accuracy: 51.7238304229176 num_feat:19 fitness:14.4662462028924"
[1] 0.3571429 0.9438202
[1] 0.3571429 0.9438202
[1] "accuracy: 57.3483447491952 num_feat:19 fitness:23.5128135985981"
[1] 0.6000000 0.8505747
[1] 0.6000000 0.8505747
[1] "accuracy: 55.1201110450573 num_feat:19 fitness:17.0873174613293"
[1] 0.4642857 0.7752809
[1] 0.4642857 0.7752809
[1] "accuracy: 56.4943394328785 num_feat:19 fitness:21.1709945191383"
[1] 0 1
[1] 0 1
[1] "accuracy: 59.4117287350683 num_feat:19 fitness:18.4771587578384"
[1] 0.0000000 0.9651163
[1] 0.0000000 0.9651163
[1] "accuracy: 56.4293738564623 num_feat:19 fitness:18.7565576265875"
[1] 0.3214286 0.7752809
[1] 0.3214286 0.7752809
[1] "accuracy: 58.0845739195985 num_feat:19 fitness:12.9745435061818"
[1] 0.2333333 0.9540230
[1] 0.2333333 0.9540230
[1] "accuracy: 57.1257903848989 num_feat:19 fitness:20.4164989518251"
[1] "f.test:19:18.1746512049685"
[1] "f.test:15:18.8226203893997"
[1] 0.4137931 0.8636364
[1] 0.4137931 0.8636364
[1] "accuracy: 54.8733260864432 num_feat:20 fitness:16.415574901907"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 52.3631727400883 num_feat:20 fitness:19.8662906778154"
[1] 0.2000000 0.9310345
[1] 0.2000000 0.9310345
[1] "accuracy: 52.1418460788146 num_feat:20 fitness:14.8343107687039"
[1] 0.3214286 0.9325843
[1] 0.3214286 0.9325843
[1] "accuracy: 58.5520082393262 num_feat:20 fitness:24.2981407370096"
[1] 0.600000 0.816092
[1] 0.600000 0.816092
[1] "accuracy: 55.6595301903661 num_feat:20 fitness:17.4056300464985"
[1] 0.4642857 0.7640449
[1] 0.4642857 0.7640449
[1] "accuracy: 57.2414982660838 num_feat:20 fitness:21.7032288791411"
[1] 0 1
[1] 0 1
[1] "accuracy: 59.4382473260292 num_feat:20 fitness:18.4970028237984"
[1] 0.0000000 0.9767442
[1] 0.0000000 0.9767442
[1] "accuracy: 56.4293738564623 num_feat:20 fitness:18.7855825167686"
[1] 0.2857143 0.7865169
[1] 0.2857143 0.7865169
[1] "accuracy: 57.8704201058794 num_feat:20 fitness:12.7526874419865"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 57.196292615054 num_feat:20 fitness:20.4147330460313"
[1] "f.test:20:18.497318183966"
[1] "f.test:15:18.8226203893997"
[1] 0.3448276 0.8522727
[1] 0.3448276 0.8522727
[1] "accuracy: 54.8588406476101 num_feat:21 fitness:15.0927319503979"
[1] 0.1612903 0.9767442
[1] 0.1612903 0.9767442
[1] "accuracy: 53.2380061114396 num_feat:21 fitness:20.5223708290681"
[1] 0.200000 0.908046
[1] 0.200000 0.908046
[1] "accuracy: 52.4132105770004 num_feat:21 fitness:14.9803180007147"
[1] 0.3214286 0.9325843
[1] 0.3214286 0.9325843
[1] "accuracy: 57.9674185223488 num_feat:21 fitness:23.8596535720158"
[1] 0.600000 0.816092
[1] 0.600000 0.816092
[1] "accuracy: 54.565597408822 num_feat:21 fitness:16.5851355830797"
[1] 0.4285714 0.7977528
[1] 0.4285714 0.7977528
[1] "accuracy: 56.8301141282615 num_feat:21 fitness:22.6396298471493"
[1] 0 1
[1] 0 1
[1] "accuracy: 59.4382473260292 num_feat:21 fitness:19.9209676004489"
[1] 0.0000000 0.9767442
[1] 0.0000000 0.9767442
[1] "accuracy: 55.7776756616543 num_feat:21 fitness:18.3650838797916"
[1] 0.3214286 0.7865169
[1] 0.3214286 0.7865169
[1] "accuracy: 57.7862831056879 num_feat:21 fitness:12.5913701896958"
[1] 0.2000000 0.9655172
[1] 0.2000000 0.9655172
[1] "accuracy: 58.2628104456473 num_feat:21 fitness:21.2145765417155"
[1] "f.test:21:18.5771837994077"
[1] "dim of scoring matrix is "
[1] 22283     5
[1] 22283
[1] "DS index stage 1"
[1] 0.1268132
[1] "bestgenelist"
 [1]     1     2     3   239   247   332   338   339   462   558  1036  1083
[13]  1209  1225  1238  1283  1323  1326  3152  3155  3455  3490  4035  4349
[25]  4352  4752  4756  5005  5223  5240  5278  5927  8667  9093 10196 12339
[37] 13543 15240 15464 18415
     1007_s_at 1053_at 117_at 200711_s_at 200719_at 200804_at 200810_s_at
[1,]   12.4440  8.3774 6.7866     11.7183    9.2735   13.3450     11.3835
[2,]   12.2005  7.8592 8.0963     11.5833    9.7808   13.4263     11.6389
[3,]   12.6709  8.6762 7.4812     12.0750   10.0493   13.6292     10.4619
     200811_at 200934_at 201030_x_at 201508_at 201555_at 201681_s_at
[1,]   11.2643   10.3457     10.1271   10.8379    9.9323     11.7340
[2,]   11.4352   10.3656     11.1338    8.8812    9.5628     11.8892
[3,]   10.2966   10.1336      9.6161   12.8232   10.3905     10.9745
     201697_s_at 201710_at 201755_at 201795_at 201798_s_at 203625_x_at
[1,]      9.8854    8.8408    7.4028    9.0945     11.6423      8.9780
[2,]      9.0466    5.8249    7.4471    9.8185     10.3129      8.1801
[3,]      9.5427    8.9400    4.1318    9.9005     11.6751      7.7719
     203628_at 203928_x_at 203963_at 204508_s_at 204822_at 204825_at 205225_at
[1,]   10.7755      9.6578   12.0638     10.1763    7.2891    8.9393   13.0759
[2,]    9.8410      9.9980   11.3553      9.3275    6.4251    7.7652   13.7616
[3,]    9.4169      6.2526   12.3832      9.9200    8.4023    9.9136   12.7360
     205229_s_at 205478_at 205696_s_at 205713_s_at 205751_at 206401_s_at
[1,]      6.8695    7.9799     11.6168     10.0607    5.3569      9.9796
[2,]      5.4533    6.0596      9.5737      5.6228    3.7733      9.9498
[3,]      6.2767    5.5057      7.2600      6.8404    2.5009      6.0807
     209173_at 209603_at 210735_s_at 212956_at 214164_x_at 215867_x_at
[1,]   12.9392   10.5793     11.5638   13.3600     12.6474     12.6194
[2,]   14.1501   10.5772     10.8918   13.2925     11.7852     11.5534
[3,]   14.5585   11.1181     11.6213   12.3582     12.7464     12.7285
     216092_s_at 219051_x_at
[1,]     10.4159      8.5236
[2,]      9.7648      8.9626
[3,]      8.3641     10.7458
     1007_s_at 1053_at 117_at 200711_s_at 200719_at 200804_at 200810_s_at
[1,]   12.3446  7.0781 7.5017     11.6623    9.3727   13.3177     12.0629
[2,]   12.0376  7.6011 7.3458     11.5301    9.6370   13.5641     12.2673
[3,]   10.9684  7.4696 8.3759     11.4169    9.3538   12.3580     11.2106
     200811_at 200934_at 201030_x_at 201508_at 201555_at 201681_s_at
[1,]   11.5715   10.8724     11.0348   10.2358    9.9499     11.6013
[2,]   12.2390   10.7471     13.3466   10.4887    9.6616     10.0901
[3,]   11.3558   10.1967     13.0118    9.3978    9.4638      8.0386
     201697_s_at 201710_at 201755_at 201795_at 201798_s_at 203625_x_at
[1,]     10.1331    5.9070    4.0773    7.7125     10.8345      8.6829
[2,]      8.5666    5.5538    5.1763    9.6134     11.4169      8.3696
[3,]      7.9505    5.8474    5.8587    9.0350     10.0144      8.5685
     203628_at 203928_x_at 203963_at 204508_s_at 204822_at 204825_at 205225_at
[1,]    9.4326     10.9860   12.4052      9.8038    7.3928    7.9851   13.8754
[2,]    9.8046      8.1054   10.4033      7.9689    6.1670    5.2744   11.7217
[3,]    7.9079      8.3152    9.8307      7.6789    6.6156    5.9481   10.9960
     205229_s_at 205478_at 205696_s_at 205713_s_at 205751_at 206401_s_at
[1,]      5.2668    4.8386      9.0616      5.2933    5.4450     10.6463
[2,]      7.1769   11.9784      7.7288      4.3142    6.3482      8.2532
[3,]      6.9284   12.5884      7.1560      4.5240    6.0619      7.4477
     209173_at 209603_at 210735_s_at 212956_at 214164_x_at 215867_x_at
[1,]   13.2041   11.9790     11.3620   13.5201     12.7392     12.5744
[2,]   11.3631   10.8744      9.5434   12.5480     10.9092     11.0575
[3,]   11.1800    8.0211      9.2310   11.2917     10.6696     11.0769
     216092_s_at 219051_x_at
[1,]     10.6963      9.5138
[2,]      9.3780      5.3641
[3,]      9.3840      7.1097
[1] "numgenes selected:40"
[1] "test acc:0.77"
[1] "test AUC acc:0.617647058823529"
[1] "10 fold train80"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 28  3
         2  5 94
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1  6 14
        2  9 71
[1] "train acc:0.938461538461538"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 28  3
         2  5 94
[1] "DS index stage 1"
[1] 0.1268132
[1] "KI index stage 1"
[1] -0.04680198
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 130  40
> 
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=5,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.01,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=0.8))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 5"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.7"
[1] "weightB: 0.2"
[1] "weightC: 0.05"
[1] "weightD: 0.05"
[1] "featweight.max: 0.01"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.45"
[1] "confusionprob: 0.2"
[1] "leaderprob: 0.25"
[1] "wmax: 1"
[1] "wmin: 1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 30"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 1"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 76.92308
[1] "here"
[1] "s"
[1] 104
[1] 130  40
[1] 10
[1] "learning sets: 1"
  [1] 110 106  24 109  32  30  33 120 103  74  41  93  54   8  91  14  31  22
 [19]  15  29  89  66  78  43  17  46  67  49 125  58 112  36 130  92 101 123
 [37] 115  65  52  25  40  85  42 126  63 116  48 118  69   1  20   2  50  96
 [55]  73  60  68  87 102  59  82  75 114 113  16   5  34  13 111  39  28  86
 [73]  44  95  51 105  10 121  21 100  72  11  47  38  53 108  61   4 104  18
 [91]  55  64  70 124  79 122   7  77  84 127  81 107   6  71
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -26.41795
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -33.81901
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -35.23011
[1] "Best solution:"
 [1] 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0
[39] 1 0
[1] 13
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "Best fitness updated to:"
[1] -36.20543
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0
[39] 1 0
[1] 21
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "Best fitness updated to:"
[1] -40.03096
[1] "Best solution:"
 [1] 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1
[39] 1 1
[1] 16
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "Best fitness updated to:"
[1] -40.05801
[1] "Best solution:"
 [1] 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1
[39] 1 0
[1] 20
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "Best fitness updated to:"
[1] -41.33416
[1] "Best solution:"
 [1] 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1
[39] 1 0
[1] 21
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 37
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 34
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 32
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "Best fitness updated to:"
[1] -41.59912
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1
[39] 1 0
[1] 20
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 31
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 31
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 30
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 30
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 30
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 30
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 28
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 28
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "No change for 8 iterations. Exiting PSO."
 [1]  4  5 12 18 19 20 21 22 25 28 31 32 38 39
[1] 1
[1] "##################################"
[1] "Results summary for itr:1"
[1] "number of features selected using population mean"
[1] 16
[1] "number of features selected using current global best"
[1] 14
[1] "feat ind length"
[1] 14
[1] "best accuracy"
[1] 41.59912
[1] "test acc:0.807692307692308"
[1] "##################################"
[1] "learning sets: 2"
  [1] 120  41  14  56  22  74  66  93  54  31  91   8  43  90  46  15  24 110
 [19]  33 106   9  99  12  78  98  32  51   5  37  62  58  34 129 104  23  48
 [37]  75  39   2  18  52  27 119 117  82  36  77 116  79   3 111  38  95  70
 [55]  20  13 112  87  49  21  28  57 114  40 101 122 100  84  86  10 123  67
 [73]   6 113  44  61  68  85 118  97   7  71  45  16  47  19   4  76  53 128
 [91]  88  11  35  59  25 130  60  96  65  42  64  94 124  69
[1] "Starting global iteration number : 2"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -16.35243
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -31.02099
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -31.58257
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 1 1
[1] 9
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -35.76682
[1] "Best solution:"
 [1] 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0
[39] 0 1
[1] 17
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -36.09136
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0
[39] 0 1
[1] 14
[1] "iteration number: "
[1] 15
[1] "Best fitness updated to:"
[1] -38.8086
[1] "Best solution:"
 [1] 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0
[39] 0 1
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 31
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 31
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 29
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 22
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 21
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "Best fitness updated to:"
[1] -38.91171
[1] "Best solution:"
 [1] 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0
[39] 1 1
[1] 12
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "Best fitness updated to:"
[1] -38.99782
[1] "Best solution:"
 [1] 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0
[39] 1 1
[1] 12
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "Best fitness updated to:"
[1] -39.09789
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0
[39] 0 1
[1] 8
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 18
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 21
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 20
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 18
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 21
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 20
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "No change for 8 iterations. Exiting PSO."
 [1]  3  4 10 11 12 18 30 31 34 40
[1] 2
[1] "##################################"
[1] "Results summary for itr:2"
[1] "number of features selected using population mean"
[1] 12
[1] "number of features selected using current global best"
[1] 10
[1] "feat ind length"
[1] 10
[1] "best accuracy"
[1] 39.09789
[1] "test acc:0.846153846153846"
[1] "##################################"
[1] "learning sets: 3"
  [1]   8  14  78 109 110  24  29  56   9  91  46  12  89  90  54  66  99  74
 [19]  98  17 120  32  31  93 103  30  40  45  88 102  36   6   7 105 129 111
 [37] 112 119  58  73 108  50  81  76 127  82  92 101  35 117  57 113  69  13
 [55]  20 125  10  96  47  18 130   1 115  68  75  71  87  60  72  86  42 104
 [73]  63   4  64  95  26  94  77  85  23  70  21  37  49 128   3 126  65  61
 [91] 118  39 121  38 124 107  80 114 122  79  19  28  34  11
[1] "Starting global iteration number : 3"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -20.93403
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -33.96342
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -34.2087
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1
[39] 1 1
[1] 12
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -37.1022
[1] "Best solution:"
 [1] 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0
[39] 0 1
[1] 16
[1] "iteration number: "
[1] 8
[1] "Best fitness updated to:"
[1] -38.60735
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0
[39] 0 1
[1] 9
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 37
 [1] 2 2 1 1 1 2 4 1 2 4 3 2 2 1 1 2 4 1 3 1
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "Best fitness updated to:"
[1] -38.68725
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0
[39] 0 1
[1] 11
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 25
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "Best fitness updated to:"
[1] -39.23294
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0
[39] 0 0
[1] 6
[1] "iteration number: "
[1] 54
[1] "Best fitness updated to:"
[1] -39.53448
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0
[39] 0 1
[1] 8
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "Best fitness updated to:"
[1] -39.64299
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1
[39] 0 0
[1] 12
[1] "iteration number: "
[1] 57
[1] "Best fitness updated to:"
[1] -45.85898
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0
[39] 0 1
[1] 10
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 26
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 25
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 22
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 19
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 19
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "No change for 8 iterations. Exiting PSO."
[1]  2  9 10 12 18 29 30 31 34
[1] 3
[1] "##################################"
[1] "Results summary for itr:3"
[1] "number of features selected using population mean"
[1] 9
[1] "number of features selected using current global best"
[1] 9
[1] "feat ind length"
[1] 9
[1] "best accuracy"
[1] 45.85898
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 4"
  [1]  54  22   9  14  46  99 120  29  43  74  66  91  41 106  32  56  83  93
 [19]  78  33  12  17 109   8  31  24  42  81  20  36 113   6  73 130  94  18
 [37]  26  75   7  28  71  72 121 107 129  59  27 127  92 112  39  67  97  79
 [55] 101  50 115 102  38  10  37  64  47  96 124  86  11  61  52  95 104  35
 [73]  23   4  70   3   1 118  16  49  88 119  58  68  45 100 117  77 116  63
 [91]  69  87  34 128 108 114 122   2  48  21  85  53  80  60
[1] "Starting global iteration number : 4"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -16.52391
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -24.96061
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -29.23724
[1] "Best solution:"
 [1] 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0
[39] 0 0
[1] 14
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "Best fitness updated to:"
[1] -29.54799
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1
[39] 0 0
[1] 14
[1] "iteration number: "
[1] 10
[1] "Best fitness updated to:"
[1] -30.77955
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1
[39] 0 0
[1] 11
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -30.93835
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0
[39] 0 1
[1] 8
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "Best fitness updated to:"
[1] -34.32214
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0
[39] 0 1
[1] 8
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "Best fitness updated to:"
[1] -39.77686
[1] "Best solution:"
 [1] 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0
[39] 0 0
[1] 12
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 32
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 36
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 31
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 28
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 66
[1] "Best fitness updated to:"
[1] -40.20907
[1] "Best solution:"
 [1] 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 31
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 78
[1] "Best fitness updated to:"
[1] -40.58839
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "Best fitness updated to:"
[1] -40.82101
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0
[39] 0 0
[1] 10
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "Best fitness updated to:"
[1] -40.95978
[1] "Best solution:"
 [1] 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "Best fitness updated to:"
[1] -41.15263
[1] "Best solution:"
 [1] 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0
[39] 0 0
[1] 11
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 24
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 25
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 23
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 24
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 26
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 23
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 23
[1] "No change for 7 iterations. Exiting PSO."
[1]  2 10 12 18 22 25 28 30 31
[1] 4
[1] "##################################"
[1] "Results summary for itr:4"
[1] "number of features selected using population mean"
[1] 9
[1] "number of features selected using current global best"
[1] 9
[1] "feat ind length"
[1] 9
[1] "best accuracy"
[1] 41.15263
[1] "test acc:0.884615384615385"
[1] "##################################"
[1] "learning sets: 5"
  [1]  41 109  74  78  24  32  15  22  46  33  43  54 106  17  99   8  91  12
 [19] 103  29  66  93   9 110  89  98  25  23  86 108 114  77 112   4  26   6
 [37]  11 122  21  38 101  50 124  84 130  80 115  62   1  69  75  82  58  19
 [55]  18  61   2  60   3 100 113 121  28  65 117 116  57 129  63  27 125  51
 [73]  55  47  72  16  70  13 127  92  79  10  96  94  34   7   5  88  20  68
 [91]  45  48  49  81 118 107 105  39 111  42  40  35 102  59
[1] "Starting global iteration number : 5"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -20.22986
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -34.30118
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -35.97227
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1
[39] 1 1
[1] 20
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 39
 [1] 2 2 1 1 1 2 4 1 2 4 3 2 2 1 1 2 4 1 3 1
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "Best fitness updated to:"
[1] -37.60832
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 1 1
[1] 10
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 35
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "Best fitness updated to:"
[1] -38.73827
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0
[39] 1 1
[1] 6
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "Best fitness updated to:"
[1] -39.1623
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0
[39] 1 1
[1] 9
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 21
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 58
[1] "Best fitness updated to:"
[1] -39.43993
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0
[39] 1 1
[1] 11
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "Best fitness updated to:"
[1] -39.77554
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0
[39] 0 1
[1] 6
[1] "iteration number: "
[1] 62
[1] "Best fitness updated to:"
[1] -41.71752
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0
[39] 1 1
[1] 8
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 18
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 15
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 17
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 14
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 14
[1] "No change for 6 iterations. Exiting PSO."
[1]  2 10 25 30 31 32 40
[1] 5
[1] "##################################"
[1] "Results summary for itr:5"
[1] "number of features selected using population mean"
[1] 7
[1] "number of features selected using current global best"
[1] 7
[1] "feat ind length"
[1] 7
[1] "best accuracy"
[1] 41.71752
[1] "test acc:0.846153846153846"
[1] "##################################"
[1] "learning sets: 6"
  [1]   8  24  31  78  33  93 106  14  99  17  91  15 110 109  29  43  74  83
 [19]  54  12  90  66  98 103  32   9  49  72  23  77 118  96  70 111  35  28
 [37]  47  76 130  45  10  61  68  20  87  58 129   6 119  42  75  95 114  53
 [55]  82  73  63  34  80 121   1 123  51  40  26   3  60  69  84 102  44   4
 [73]  52 116  88 100 127 108 128  36  19  71 104  85  92 105  59  64 126   7
 [91]  11 117  67  27  65 124  39  21  97  86  94  79   5  55
[1] "Starting global iteration number : 6"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -19.45293
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -30.40104
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -31.85705
[1] "Best solution:"
 [1] 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0
[39] 1 1
[1] 13
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "Best fitness updated to:"
[1] -35.41949
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0
[39] 1 0
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "Best fitness updated to:"
[1] -36.20574
[1] "Best solution:"
 [1] 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1
[39] 1 0
[1] 11
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 33
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 30
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "Best fitness updated to:"
[1] -37.20935
[1] "Best solution:"
 [1] 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1
[39] 1 0
[1] 18
[1] "iteration number: "
[1] 47
[1] "Best fitness updated to:"
[1] -39.76903
[1] "Best solution:"
 [1] 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0
[39] 1 0
[1] 16
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "Best fitness updated to:"
[1] -39.91536
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1
[39] 1 0
[1] 11
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 30
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "Best fitness updated to:"
[1] -40.50551
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1
[39] 1 0
[1] 11
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "Best fitness updated to:"
[1] -41.06936
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1
[39] 0 0
[1] 10
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 30
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 29
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 26
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 26
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 27
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 25
[1] "No change for 6 iterations. Exiting PSO."
 [1]  2  8 10 12 18 25 28 30 31 38
[1] 6
[1] "##################################"
[1] "Results summary for itr:6"
[1] "number of features selected using population mean"
[1] 10
[1] "number of features selected using current global best"
[1] 10
[1] "feat ind length"
[1] 10
[1] "best accuracy"
[1] 41.06936
[1] "test acc:0.884615384615385"
[1] "##################################"
[1] "learning sets: 7"
  [1]  90  83  54  17  22 110  56  91  41  98 106  14  74  30  12  78   8  93
 [19]  99 120 103  29  89  15 109  66  59  75 128   1  84 123   6  87 113 129
 [37] 125 118  62  19  69  20   5 100 111  85  68  92  81  51  23 112 115  10
 [55]  13  67  82  16  71  73  47  18  70  61  28 124  27  25   7  63 114  48
 [73]  57 117  58 119   4  52  21  88  64  53  49  95  55  94 116 102  37 121
 [91]   3  40  39 122 105 104  60  80  97  42 101  76  44  35
[1] "Starting global iteration number : 7"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -15.32564
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -26.78326
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -29.67245
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 1 1
[1] 10
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "Best fitness updated to:"
[1] -35.35921
[1] "Best solution:"
 [1] 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 0 1
[1] 15
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -37.37669
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0
[39] 0 1
[1] 14
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "Best fitness updated to:"
[1] -37.98713
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 0 1
[1] 10
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "Best fitness updated to:"
[1] -38.0935
[1] "Best solution:"
 [1] 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 0 1
[1] 9
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 22
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "Best fitness updated to:"
[1] -38.19995
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0
[39] 0 1
[1] 7
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "Best fitness updated to:"
[1] -39.59149
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 0 1
[1] 9
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "Best fitness updated to:"
[1] -40.58986
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 0 1
[1] 9
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 19
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 19
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 18
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 18
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 18
[1] "No change for 8 iterations. Exiting PSO."
[1]  2 10 25 30 31 32 34 40
[1] 7
[1] "##################################"
[1] "Results summary for itr:7"
[1] "number of features selected using population mean"
[1] 8
[1] "number of features selected using current global best"
[1] 8
[1] "feat ind length"
[1] 8
[1] "best accuracy"
[1] 40.58986
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 8"
  [1]  41  66  90  46  12  31  22  33  91  98  54 110 106 109  30  83  14  43
 [19]   9   8 103  74  56  99  24  93  13  57  26 113  39  68  36  80  82 112
 [37]  69 127 116  51  92  48  16 104  49  75 100 126 107  85  44  64  88  84
 [55] 119 117 105  96   7 111 121 125  28  47  70  95  71  61  76 128  11  63
 [73]  79  94 114  53 108  73  34 129  55 124  60  45 123 130  19  50   3  65
 [91]  23  20  62  10  58 122  25  67   2  81 118 102  97   4
[1] "Starting global iteration number : 8"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -23.7847
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -37.5251
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -37.91637
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 1 1
[1] 9
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "Best fitness updated to:"
[1] -38.81321
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0
[39] 0 1
[1] 13
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "Best fitness updated to:"
[1] -40.83278
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0
[39] 0 1
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "Best fitness updated to:"
[1] -41.45115
[1] "Best solution:"
 [1] 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0
[39] 1 1
[1] 12
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "Best fitness updated to:"
[1] -42.11184
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0
[39] 0 1
[1] 11
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 31
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 30
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 23
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 23
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 18
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 15
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 15
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "No change for 8 iterations. Exiting PSO."
 [1]  2 10 19 21 27 28 31 32 36 40
[1] 8
[1] "##################################"
[1] "Results summary for itr:8"
[1] "number of features selected using population mean"
[1] 9
[1] "number of features selected using current global best"
[1] 10
[1] "feat ind length"
[1] 10
[1] "best accuracy"
[1] 42.11184
[1] "test acc:0.769230769230769"
[1] "##################################"
[1] "learning sets: 9"
  [1]  14  66  43  91 106 109  78  22  31  93  29  30   9 120  41 110 103  74
 [19]  83  99  33  32  90  54  46  24  27  40 126  59  87   2 107 118 130  49
 [37] 122  52 114 102  55  73  82 104  39 123  69  25  67  63  13 127  38  64
 [55]  18  72 129 115  21 119  61  62  58   6  48 121   7  37 113  88 124  84
 [73] 117  76  97  45  47   5  79  42  60 100 128  35  70  81  92  36 108 116
 [91] 105  71  77  11  51  20  96  65 112  28  34  57  23   4
[1] "Starting global iteration number : 9"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -21.68219
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -34.77634
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "Best fitness updated to:"
[1] -35.52077
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1
[39] 0 1
[1] 13
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "Best fitness updated to:"
[1] -36.00405
[1] "Best solution:"
 [1] 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0
[39] 1 1
[1] 14
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -40.39792
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1
[39] 0 1
[1] 10
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "Best fitness updated to:"
[1] -41.36291
[1] "Best solution:"
 [1] 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0
[39] 1 1
[1] 8
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "Best fitness updated to:"
[1] -42.70783
[1] "Best solution:"
 [1] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0
[39] 1 1
[1] 8
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "Best fitness updated to:"
[1] -44.06844
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0
[39] 0 1
[1] 7
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 29
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 24
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 21
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 16
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 16
[1] "No change for 7 iterations. Exiting PSO."
[1]  3 10 25 30 31 32 40
[1] 9
[1] "##################################"
[1] "Results summary for itr:9"
[1] "number of features selected using population mean"
[1] 7
[1] "number of features selected using current global best"
[1] 7
[1] "feat ind length"
[1] 7
[1] "best accuracy"
[1] 44.06844
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 10"
  [1]  66  99  15  32 106  98  89  31  17  43  91  56  14  12  41  74 120  93
 [19]  29 110 103  78  22  30  83  90 121  11  53  92  40  20  39 112  49  97
 [37]   5  35  96 123  52   7  70  68  51  79  57 102 129   3  77 126 114 130
 [55] 101  45  36   4 104 117  72  61  21  18  81  60 127  88   6 107  67  58
 [73]  85  80  65 116  34 108  84  64  55  59  71  62 119  13   1  47  87 122
 [91]  76 118  38 128  27  25 105 125   2  23 100 113  63  86
[1] "Starting global iteration number : 10"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -22.9454
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -32.3812
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1
[39] 0 0
[1] 13
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -33.42645
[1] "Best solution:"
 [1] 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0
[39] 0 1
[1] 17
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -33.93727
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0
[39] 0 1
[1] 12
[1] "iteration number: "
[1] 8
[1] "Best fitness updated to:"
[1] -33.98921
[1] "Best solution:"
 [1] 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1
[39] 0 1
[1] 12
[1] "iteration number: "
[1] 9
[1] "Best fitness updated to:"
[1] -35.59131
[1] "Best solution:"
 [1] 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0
[39] 0 1
[1] 16
[1] "iteration number: "
[1] 10
[1] "Best fitness updated to:"
[1] -36.69327
[1] "Best solution:"
 [1] 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1
[39] 1 1
[1] 20
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "Best fitness updated to:"
[1] -37.06371
[1] "Best solution:"
 [1] 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0
[39] 0 1
[1] 11
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -38.43857
[1] "Best solution:"
 [1] 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0
[39] 1 1
[1] 18
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "Best fitness updated to:"
[1] -38.92885
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1
[39] 0 1
[1] 10
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 33
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "Best fitness updated to:"
[1] -39.48786
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0
[39] 0 1
[1] 10
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "Best fitness updated to:"
[1] -39.94147
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0
[39] 0 1
[1] 12
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "Best fitness updated to:"
[1] -40.3924
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0
[39] 0 1
[1] 13
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "Best fitness updated to:"
[1] -41.81542
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0
[39] 0 1
[1] 10
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 27
 [1] 2 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 3 1 4 3
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 22
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 20
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 17
 [1] 2 2 2 2 2 1 2 1 2 2 4 2 1 2 2 2 3 2 2 1
[1] "No change for 8 iterations. Exiting PSO."
 [1]  3 10 18 25 27 30 31 32 34 40
[1] 10
[1] "##################################"
[1] "Results summary for itr:10"
[1] "number of features selected using population mean"
[1] 11
[1] "number of features selected using current global best"
[1] 10
[1] "feat ind length"
[1] 10
[1] "best accuracy"
[1] 41.81542
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "testacc"
 [1] 0.8076923 0.8461538 0.9230769 0.8846154 0.8461538 0.8846154 0.9615385
 [8] 0.7692308 0.9230769 0.9230769
[1] 0.8769231
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.7692  0.8462  0.8846  0.8769  0.9231  0.9615 
[1] 0.05958436
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    0    0    0    0    0    0    0    0     0
 [2,]    0    0    1    1    1    1    1    1    0     0
 [3,]    0    1    0    0    0    0    0    0    1     1
 [4,]    1    1    0    0    0    0    0    0    0     0
 [5,]    1    0    0    0    0    0    0    0    0     0
 [6,]    0    0    0    0    0    0    0    0    0     0
 [7,]    0    0    0    0    0    0    0    0    0     0
 [8,]    0    0    0    0    0    1    0    0    0     0
 [9,]    0    0    1    0    0    0    0    0    0     0
[10,]    0    1    1    1    1    1    1    1    1     1
[11,]    0    1    0    0    0    0    0    0    0     0
[12,]    1    1    1    1    0    1    0    0    0     0
[13,]    0    0    0    0    0    0    0    0    0     0
[14,]    0    0    0    0    0    0    0    0    0     0
[15,]    0    0    0    0    0    0    0    0    0     0
[16,]    0    0    0    0    0    0    0    0    0     0
[17,]    0    0    0    0    0    0    0    0    0     0
[18,]    1    1    1    1    0    1    0    0    0     1
[19,]    1    0    0    0    0    0    0    1    0     0
[20,]    1    0    0    0    0    0    0    0    0     0
[21,]    1    0    0    0    0    0    0    1    0     0
[22,]    1    0    0    1    0    0    0    0    0     0
[23,]    0    0    0    0    0    0    0    0    0     0
[24,]    0    0    0    0    0    0    0    0    0     0
[25,]    1    0    0    1    1    1    1    0    1     1
[26,]    0    0    0    0    0    0    0    0    0     0
[27,]    0    0    0    0    0    0    0    1    0     1
[28,]    1    0    0    1    0    1    0    1    0     0
[29,]    0    0    1    0    0    0    0    0    0     0
[30,]    0    1    1    1    1    1    1    0    1     1
[31,]    1    1    1    1    1    1    1    1    1     1
[32,]    1    0    0    0    1    0    1    1    1     1
[33,]    0    0    0    0    0    0    0    0    0     0
[34,]    0    1    1    0    0    0    1    0    0     1
[35,]    0    0    0    0    0    0    0    0    0     0
[36,]    0    0    0    0    0    0    0    1    0     0
[37,]    0    0    0    0    0    0    0    0    0     0
[38,]    1    0    0    0    0    1    0    0    0     0
[39,]    1    0    0    0    0    0    0    0    0     0
[40,]    0    1    0    0    1    0    1    1    1     1
[1] "dim of scoring matrix is "
[1] 40 10
[1] "DS index stage 2"
[1] 0.5358909
[1] "KI index stage 2"
[1] -Inf
[1] 1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   0.00    0.00    1.00    2.35    4.00   10.00 
[1] "Number of features selected in 1 iterations:"
[1] 26
[1] "Number of features selected in 1 iterations:"
[1] 26
[1] 0.6666667 0.9896907
[1] 0.6666667 0.9896907
[1] "accuracy: 74.6782755411922 num_feat:26 fitness:43.2812308670782"
$fitfunc
[1] -43.28123

$cverror
[1] 74.67828

$cvpermerror
[1] 50

$testacc
[1] 93.90815

$reverseacc
[1] 82.81787

[1] -43.28123
[1] "Number of features selected in 2 iterations:"
[1] 18
[1] 0.7272727 0.9793814
[1] 0.7272727 0.9793814
[1] "accuracy: 77.4126661212699 num_feat:18 fitness:45.5546729742702"
$fitfunc
[1] -45.55467

$cverror
[1] 77.41267

$cvpermerror
[1] 50

$testacc
[1] 93.39269

$reverseacc
[1] 85.33271

[1] -45.55467
[1] "Number of features selected in 3 iterations:"
[1] 12
[1] 0.8181818 0.9793814
[1] 0.8181818 0.9793814
[1] "accuracy: 79.750164677016 num_feat:12 fitness:48.1431682631749"
$fitfunc
[1] -48.14317

$cverror
[1] 79.75016

$cvpermerror
[1] 50.07302

$testacc
[1] 95.93877

$reverseacc
[1] 89.87816

[1] -48.14317
[1] "Number of features selected in 4 iterations:"
[1] 11
[1] 0.8181818 0.9793814
[1] 0.8181818 0.9793814
[1] "accuracy: 81.1813047011922 num_feat:11 fitness:48.7408269488028"
$fitfunc
[1] -48.74083

$cverror
[1] 81.1813

$cvpermerror
[1] 50.06085

$testacc
[1] 93.39269

$reverseacc
[1] 89.87816

[1] -48.74083
[1] "Number of features selected in 5 iterations:"
[1] 9
[1] 0.7878788 0.9690722
[1] 0.7878788 0.9690722
[1] "accuracy: 73.3040952902454 num_feat:9 fitness:42.7813891189588"
$fitfunc
[1] -42.78139

$cverror
[1] 73.3041

$cvpermerror
[1] 50.06085

$testacc
[1] 93.39269

$reverseacc
[1] 87.84755

[1] -42.78139
[1] "Number of features selected in 6 iterations:"
[1] 8
[1] 0.6666667 0.9896907
[1] 0.6666667 0.9896907
[1] "accuracy: 80.9276555268045 num_feat:8 fitness:48.3694201211204"
$fitfunc
[1] -48.36942

$cverror
[1] 80.92766

$cvpermerror
[1] 50.06085

$testacc
[1] 93.87691

$reverseacc
[1] 82.81787

[1] -48.36942
[1] "Number of features selected in 7 iterations:"
[1] 4
[1] 0.6969697 0.9278351
[1] 0.6969697 0.9278351
[1] "accuracy: 65.8757508303941 num_feat:4 fitness:35.4291186523176"
$fitfunc
[1] -35.42912

$cverror
[1] 65.87575

$cvpermerror
[1] 50

$testacc
[1] 85.30147

$reverseacc
[1] 81.24024

[1] -35.42912
[1] "Number of features selected in 8 iterations:"
[1] 3
[1] 0.5757576 0.9587629
[1] 0.5757576 0.9587629
[1] "accuracy: 56.5987147165653 num_feat:3 fitness:25.9957770774034"
$fitfunc
[1] -25.99578

$cverror
[1] 56.59871

$cvpermerror
[1] 50.08114

$testacc
[1] 74.21118

$reverseacc
[1] 76.72602

[1] -25.99578
[1] "Number of features selected in 9 iterations:"
[1] 2
[1] "accuracy: 1 num_feat:2 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
[1] "Number of features selected in 10 iterations:"
[1] 1
[1] "accuracy: 1 num_feat:1 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.7692  0.8462  0.8846  0.8769  0.9231  0.9615 
[1] "Number of features selected in 1 iterations:"
[1] 26
[1] "Modified train 10 fold accuracy using train data is "
[1] 83.84615
[1] "Modified train accuracy is "
[1] 0.9538462
[1] "train confusion matrix is "
          trainclass
pred_train  1  2
         1 30  3
         2  3 94
[1] "Train dimension is "
[1] 130  26
[1] "Test dimension is "
[1] 100  26
[1] "Test confusion matrix is "
    
pred  1  2
   1  7 13
   2  8 72
[1] "Test acc is "
[1] 0.79
[1] "train 10 fold"
[1] 86.15385
[1] "Test confusion matrix is "
    
pred  1  2
   1  7 13
   2  8 72
[1] "Test acc is "
[1] 0.79
[1] "Test AUC:"
[1] 0.6568627
[1] "Train acc is "
[1] 0.9538462
[1] "# of features after CMA:"
NULL
[1] "# of features after PSO:"
[1] 130  27
     user    system   elapsed 
  468.112    20.040 12580.319 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> 
> 
> feat_ind<-psores$bestfeatlist
> feat_names<-psores$bestfeatnames
> 
> scoringmatrix<-as.data.frame(psores$scoringmatrix)
> print(scoringmatrix)
   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
1   0  0  0  0  0  0  0  0  0   0
2   0  0  1  1  1  1  1  1  0   0
3   0  1  0  0  0  0  0  0  1   1
4   1  1  0  0  0  0  0  0  0   0
5   1  0  0  0  0  0  0  0  0   0
6   0  0  0  0  0  0  0  0  0   0
7   0  0  0  0  0  0  0  0  0   0
8   0  0  0  0  0  1  0  0  0   0
9   0  0  1  0  0  0  0  0  0   0
10  0  1  1  1  1  1  1  1  1   1
11  0  1  0  0  0  0  0  0  0   0
12  1  1  1  1  0  1  0  0  0   0
13  0  0  0  0  0  0  0  0  0   0
14  0  0  0  0  0  0  0  0  0   0
15  0  0  0  0  0  0  0  0  0   0
16  0  0  0  0  0  0  0  0  0   0
17  0  0  0  0  0  0  0  0  0   0
18  1  1  1  1  0  1  0  0  0   1
19  1  0  0  0  0  0  0  1  0   0
20  1  0  0  0  0  0  0  0  0   0
21  1  0  0  0  0  0  0  1  0   0
22  1  0  0  1  0  0  0  0  0   0
23  0  0  0  0  0  0  0  0  0   0
24  0  0  0  0  0  0  0  0  0   0
25  1  0  0  1  1  1  1  0  1   1
26  0  0  0  0  0  0  0  0  0   0
27  0  0  0  0  0  0  0  1  0   1
28  1  0  0  1  0  1  0  1  0   0
29  0  0  1  0  0  0  0  0  0   0
30  0  1  1  1  1  1  1  0  1   1
31  1  1  1  1  1  1  1  1  1   1
32  1  0  0  0  1  0  1  1  1   1
33  0  0  0  0  0  0  0  0  0   0
34  0  1  1  0  0  0  1  0  0   1
35  0  0  0  0  0  0  0  0  0   0
36  0  0  0  0  0  0  0  1  0   0
37  0  0  0  0  0  0  0  0  0   0
38  1  0  0  0  0  1  0  0  0   0
39  1  0  0  0  0  0  0  0  0   0
40  0  1  0  0  1  0  1  1  1   1
> print(feat_names[feat_ind])
 [1] "1053_at"     "117_at"      "200711_s_at" "200719_at"   "200811_at"  
 [6] "200934_at"   "201030_x_at" "201508_at"   "201555_at"   "201798_s_at"
[11] "203625_x_at" "203628_at"   "203928_x_at" "203963_at"   "204825_at"  
[16] "205229_s_at" "205478_at"   "205696_s_at" "205713_s_at" "205751_at"  
[21] "206401_s_at" "209603_at"   "212956_at"   "215867_x_at" "216092_s_at"
[26] "219051_x_at"
> 
> save(psores,file="psores.Rda")
> print("Complete")
[1] "Complete"
> 
