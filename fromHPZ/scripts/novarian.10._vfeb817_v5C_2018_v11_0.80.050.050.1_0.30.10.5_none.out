
R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/kuppal3/karan_libs/Rlibs")
> library(snow)
> library(e1071)
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following object is masked from ‘package:pROC’:

    var

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, sd, var, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, cbind, colMeans, colnames,
    colSums, do.call, duplicated, eval, evalq, Filter, Find, get, grep,
    grepl, intersect, is.unsorted, lapply, lengths, Map, mapply, match,
    mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rowMeans, rownames, rowSums, sapply, setdiff, sort,
    table, tapply, union, unique, unsplit, which, which.max, which.min

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

> library(plyr)

Attaching package: ‘plyr’

The following object is masked from ‘package:CMA’:

    join

> library(doParallel)
Loading required package: foreach
Loading required package: iterators
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> 
> #dirloc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/"
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/versionnov2014/OCFS_",args[9],".R",sep="")
> 
> sname<-paste("/home/kuppal2/Documents/Projects/xmsPANDA/Other/scripts/OCFS_",args[9],".R",sep="")
> source(sname)
> print(sname)
[1] "/home/kuppal2/Documents/Projects/xmsPANDA/Other/scripts/OCFS_vfeb817_v5C_2018_v11.R"
> 
> dirloc<-"/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/GSE19711/"
> setwd(dirloc)
> 
> 
> 
> outloc<-paste(dirloc,"/OCFSvmay2415_Ovarian",args[9],"/",sep="")
> 
> 
> sname<-paste(dirloc,"OvarianCancer.Rda",sep="")
> load(sname)
> 
> trainm<-OvarianCancer$X
> testm<-OvarianCancer$Xt
> trainclass<-OvarianCancer$Y #PCRvsRD
> testclass<-OvarianCancer$Yt #PCRvsRD
> 
> trainm<-apply(trainm,2,as.numeric)
> testm<-apply(testm,2,as.numeric)
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/GSE19711//OCFSvmay2415_Ovarianvfeb817_v5C_2018_v11' already exists
> setwd(outloc)
> 
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/GSE19711//OCFSvmay2415_Ovarianvfeb817_v5C_2018_v11' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> print("max num")
[1] "max num"
> print(as.numeric(args[10]))
[1] 10
> 
> #if(FALSE)
> {
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
[1] "dim of trainm is "
[1]   378 27578
[1]   378 27578
[1] "length of factcols"
[1] 0
[1]   378 27578
[1]   162 27578
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 2 2
Levels: 1 2
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] 0.083 0.064 0.071
[1] "norm train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "mean of feat 2"
[1] 0.8129524
[1] "sd of feat 2"
[1] 0.09281371
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   378 27578
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 27578     1
[1] 27578
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  1644  2205  2271  2688  5274  9565 23053 25623 26627 27416
     cg01623438 cg02181506 cg02240622 cg02679745 cg05253159 cg09624565
[1,]      0.196      0.173      0.292      0.244      0.250      0.255
[2,]      0.128      0.132      0.250      0.205      0.189      0.201
[3,]      0.181      0.191      0.287      0.277      0.237      0.271
     cg23090046 cg25634666 cg26661623 cg27485921
[1,]      0.464      0.290      0.470      0.297
[2,]      0.394      0.233      0.400      0.199
[3,]      0.485      0.302      0.384      0.259
     cg01623438 cg02181506 cg02240622 cg02679745 cg05253159 cg09624565
[1,]      0.268      0.207      0.412      0.291      0.309      0.428
[2,]      0.143      0.152      0.192      0.190      0.157      0.201
[3,]      0.241      0.248      0.358      0.293      0.259      0.341
     cg23090046 cg25634666 cg26661623 cg27485921
[1,]      0.602      0.411      0.430      0.375
[2,]      0.372      0.205      0.416      0.183
[3,]      0.534      0.418      0.459      0.341
[1] "numgenes selected:10"
[1] "test acc:0.660493827160494"
[1] "test AUC acc:0.663919413919414"
[1] "10 fold train65.3439153439153"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold   1   2
         1 155  70
         2  41 112
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 59 36
        2 19 48
[1] "train acc:0.706349206349206"
[1] "confusion matrix train"
          nci_y
pred_train   1   2
         1 155  70
         2  41 112
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   378 27578
[1]   378 27578
[1] "length of factcols"
[1] 0
[1]   378 27578
[1]   162 27578
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 2 2
Levels: 1 2
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] 0.083 0.064 0.071
[1] "norm train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "mean of feat 2"
[1] 0.8129524
[1] "sd of feat 2"
[1] 0.09281371
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   378 27578
GeneSelection: iteration 1 
Loaded glmnet 2.0-16


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
14822 16787  6156  4115 22968 24377 24507  2849  9386 15282 27332   684 11301 
   16    14    12    10    10    10    10     8     8     8     8     6     6 
21447 19284   778  2016  3106  3365  5001  5079  6391  6651  7330  7565  7741 
    6     4     2     2     2     2     2     2     2     2     2     2     2 
 8954  9215  9382 11056 15132 17601 18483 18607 19607 20063 20503 22185 22451 
    2     2     2     2     2     2     2     2     2     2     2     2     2 
22565 23494 23770 24224 25647 25697 26020 27465 
    2     2     2     2     2     2     2     2 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 27578     1
[1] 27578
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  2849  4115  6156  9386 14822 15282 16787 22968 24377 24507
     cg02848777 cg04059714 cg06197006 cg09453737 cg14822966 cg15288179
[1,]      0.071      0.111      0.029      0.081      0.039      0.020
[2,]      0.087      0.117      0.026      0.098      0.046      0.019
[3,]      0.089      0.102      0.024      0.111      0.043      0.021
     cg16743781 cg23002907 cg24428042 cg24532669
[1,]      0.024      0.030      0.022      0.034
[2,]      0.019      0.024      0.032      0.039
[3,]      0.024      0.022      0.018      0.033
     cg02848777 cg04059714 cg06197006 cg09453737 cg14822966 cg15288179
[1,]      0.073      0.131      0.023      0.130      0.040      0.022
[2,]      0.094      0.110      0.030      0.109      0.030      0.019
[3,]      0.089      0.089      0.030      0.106      0.037      0.017
     cg16743781 cg23002907 cg24428042 cg24532669
[1,]      0.021      0.064      0.034      0.056
[2,]      0.022      0.023      0.030      0.042
[3,]      0.019      0.042      0.047      0.047
[1] "numgenes selected:10"
[1] "test acc:0.574074074074074"
[1] "test AUC acc:0.5746336996337"
[1] "10 fold train65.6084656084656"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold   1   2
         1 150  44
         2  46 138
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 46 37
        2 32 47
[1] "train acc:0.761904761904762"
[1] "confusion matrix train"
          nci_y
pred_train   1   2
         1 150  44
         2  46 138
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   378 27578
[1]   378 27578
[1] "length of factcols"
[1] 0
[1]   378 27578
[1]   162 27578
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 2 2
Levels: 1 2
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] 0.083 0.064 0.071
[1] "norm train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "mean of feat 2"
[1] 0.8129524
[1] "sd of feat 2"
[1] 0.09281371
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   378 27578
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 27578     1
[1] 27578
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  7307  9343 12361 12885 16179 17927 20005 20487 23028 23580
     cg07327347 cg09419670 cg12437481 cg12943082 cg16106497 cg17901463
[1,]      0.818      0.255      0.466      0.300      0.724      0.262
[2,]      0.783      0.060      0.870      0.556      0.817      0.245
[3,]      0.835      0.444      0.433      0.566      0.614      0.330
     cg20022541 cg20540428 cg23067535 cg23629496
[1,]      0.881      0.526      0.729      0.798
[2,]      0.743      0.467      0.732      0.723
[3,]      0.847      0.571      0.820      0.725
     cg07327347 cg09419670 cg12437481 cg12943082 cg16106497 cg17901463
[1,]      0.705      0.420      0.476      0.598      0.561      0.036
[2,]      0.894      0.377      0.888      0.397      0.874      0.265
[3,]      0.793      0.296      0.888      0.658      0.502      0.032
     cg20022541 cg20540428 cg23067535 cg23629496
[1,]      0.395      0.236      0.740      0.703
[2,]      0.842      0.258      0.807      0.759
[3,]      0.420      0.214      0.789      0.677
[1] "numgenes selected:10"
[1] "test acc:0.481481481481481"
[1] "test AUC acc:0.517857142857143"
[1] "10 fold train58.7301587301587"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold   1   2
         1 158  44
         2  38 138
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 39 45
        2 39 39
[1] "train acc:0.783068783068783"
[1] "confusion matrix train"
          nci_y
pred_train   1   2
         1 158  44
         2  38 138
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   378 27578
[1]   378 27578
[1] "length of factcols"
[1] 0
[1]   378 27578
[1]   162 27578
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 2 2
Levels: 1 2
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] 0.083 0.064 0.071
[1] "norm train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "mean of feat 2"
[1] 0.8129524
[1] "sd of feat 2"
[1] 0.09281371
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   378 27578
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 27578     1
[1] 27578
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  2849  4115  6156  9386 14822 15282 16787 24377 24507 27332
     cg02848777 cg04059714 cg06197006 cg09453737 cg14822966 cg15288179
[1,]      0.071      0.111      0.029      0.081      0.039      0.020
[2,]      0.087      0.117      0.026      0.098      0.046      0.019
[3,]      0.089      0.102      0.024      0.111      0.043      0.021
     cg16743781 cg24428042 cg24532669 cg27394566
[1,]      0.024      0.022      0.034      0.855
[2,]      0.019      0.032      0.039      0.702
[3,]      0.024      0.018      0.033      0.745
     cg02848777 cg04059714 cg06197006 cg09453737 cg14822966 cg15288179
[1,]      0.073      0.131      0.023      0.130      0.040      0.022
[2,]      0.094      0.110      0.030      0.109      0.030      0.019
[3,]      0.089      0.089      0.030      0.106      0.037      0.017
     cg16743781 cg24428042 cg24532669 cg27394566
[1,]      0.021      0.034      0.056      0.822
[2,]      0.022      0.030      0.042      0.748
[3,]      0.019      0.047      0.047      0.734
[1] "numgenes selected:10"
[1] "test acc:0.617283950617284"
[1] "test AUC acc:0.618589743589744"
[1] "10 fold train67.989417989418"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold   1   2
         1 161  47
         2  35 135
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 51 35
        2 27 49
[1] "train acc:0.783068783068783"
[1] "confusion matrix train"
          nci_y
pred_train   1   2
         1 161  47
         2  35 135
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   378 27578
[1]   378 27578
[1] "length of factcols"
[1] 0
[1]   378 27578
[1]   162 27578
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 2 2
Levels: 1 2
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] 0.083 0.064 0.071
[1] "norm train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "mean of feat 2"
[1] 0.8129524
[1] "sd of feat 2"
[1] 0.09281371
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   378 27578
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 27578     1
[1] 27578
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  1644  2205  2271  2688  5274  9565 23053 25623 26627 27416
     cg01623438 cg02181506 cg02240622 cg02679745 cg05253159 cg09624565
[1,]      0.196      0.173      0.292      0.244      0.250      0.255
[2,]      0.128      0.132      0.250      0.205      0.189      0.201
[3,]      0.181      0.191      0.287      0.277      0.237      0.271
     cg23090046 cg25634666 cg26661623 cg27485921
[1,]      0.464      0.290      0.470      0.297
[2,]      0.394      0.233      0.400      0.199
[3,]      0.485      0.302      0.384      0.259
     cg01623438 cg02181506 cg02240622 cg02679745 cg05253159 cg09624565
[1,]      0.268      0.207      0.412      0.291      0.309      0.428
[2,]      0.143      0.152      0.192      0.190      0.157      0.201
[3,]      0.241      0.248      0.358      0.293      0.259      0.341
     cg23090046 cg25634666 cg26661623 cg27485921
[1,]      0.602      0.411      0.430      0.375
[2,]      0.372      0.205      0.416      0.183
[3,]      0.534      0.418      0.459      0.341
[1] "numgenes selected:10"
[1] "test acc:0.660493827160494"
[1] "test AUC acc:0.663919413919414"
[1] "10 fold train65.3439153439153"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold   1   2
         1 155  70
         2  41 112
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 59 36
        2 19 48
[1] "train acc:0.706349206349206"
[1] "confusion matrix train"
          nci_y
pred_train   1   2
         1 155  70
         2  41 112
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
There were 30 warnings (use warnings() to see them)
> 
> 
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   378 27578
[1]   378 27578
[1] "length of factcols"
[1] 0
[1]   378 27578
[1]   162 27578
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 2 2 2
Levels: 1 2
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "orig train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] 0.083 0.064 0.071
[1] "norm train matrix"
     cg00000292 cg00002426 cg00003994 cg00005847 cg00006414 cg00007981
[1,]      0.790      0.765      0.083      0.147      0.091      0.045
[2,]      0.795      0.853      0.064      0.133      0.076      0.028
[3,]      0.810      0.855      0.071      0.148      0.135      0.021
[4,]      0.838      0.852      0.080      0.168      0.101      0.029
[5,]      0.782      0.845      0.057      0.138      0.064      0.037
     cg00008493 cg00008713 cg00009407 cg00010193
[1,]      0.962      0.032      0.062      0.697
[2,]      0.956      0.034      0.079      0.607
[3,]      0.952      0.037      0.058      0.586
[4,]      0.962      0.035      0.070      0.608
[5,]      0.951      0.034      0.075      0.569
[1] "mean of feat 2"
[1] 0.8129524
[1] "sd of feat 2"
[1] 0.09281371
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   378 27578
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
14822 16787  6156  4115 22968 24377 24507  2849  9386 15282 27332   684 11301 
   16    14    12    10    10    10    10     8     8     8     8     6     6 
21447 19284   778  2016  3106  3365  5001  5079  6391  6651  7330  7565  7741 
    6     4     2     2     2     2     2     2     2     2     2     2     2 
 8954  9215  9382 11056 15132 17601 18483 18607 19607 20063 20503 22185 22451 
    2     2     2     2     2     2     2     2     2     2     2     2     2 
22565 23494 23770 24224 25647 25697 26020 27465 
    2     2     2     2     2     2     2     2 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 27578     5
[1] 27578
[1] "DS index stage 1"
[1] 0.19
[1] "bestgenelist"
 [1]  1644  2205  2271  2688  2849  4115  5274  6156  7307  9343  9386  9565
[13] 12361 12885 14822 15282 16179 16787 17927 20005 20487 22968 23028 23053
[25] 23580 24377 24507 25623 26627 27332 27416
     cg01623438 cg02181506 cg02240622 cg02679745 cg02848777 cg04059714
[1,]      0.196      0.173      0.292      0.244      0.071      0.111
[2,]      0.128      0.132      0.250      0.205      0.087      0.117
[3,]      0.181      0.191      0.287      0.277      0.089      0.102
     cg05253159 cg06197006 cg07327347 cg09419670 cg09453737 cg09624565
[1,]      0.250      0.029      0.818      0.255      0.081      0.255
[2,]      0.189      0.026      0.783      0.060      0.098      0.201
[3,]      0.237      0.024      0.835      0.444      0.111      0.271
     cg12437481 cg12943082 cg14822966 cg15288179 cg16106497 cg16743781
[1,]      0.466      0.300      0.039      0.020      0.724      0.024
[2,]      0.870      0.556      0.046      0.019      0.817      0.019
[3,]      0.433      0.566      0.043      0.021      0.614      0.024
     cg17901463 cg20022541 cg20540428 cg23002907 cg23067535 cg23090046
[1,]      0.262      0.881      0.526      0.030      0.729      0.464
[2,]      0.245      0.743      0.467      0.024      0.732      0.394
[3,]      0.330      0.847      0.571      0.022      0.820      0.485
     cg23629496 cg24428042 cg24532669 cg25634666 cg26661623 cg27394566
[1,]      0.798      0.022      0.034      0.290      0.470      0.855
[2,]      0.723      0.032      0.039      0.233      0.400      0.702
[3,]      0.725      0.018      0.033      0.302      0.384      0.745
     cg27485921
[1,]      0.297
[2,]      0.199
[3,]      0.259
     cg01623438 cg02181506 cg02240622 cg02679745 cg02848777 cg04059714
[1,]      0.268      0.207      0.412      0.291      0.073      0.131
[2,]      0.143      0.152      0.192      0.190      0.094      0.110
[3,]      0.241      0.248      0.358      0.293      0.089      0.089
     cg05253159 cg06197006 cg07327347 cg09419670 cg09453737 cg09624565
[1,]      0.309      0.023      0.705      0.420      0.130      0.428
[2,]      0.157      0.030      0.894      0.377      0.109      0.201
[3,]      0.259      0.030      0.793      0.296      0.106      0.341
     cg12437481 cg12943082 cg14822966 cg15288179 cg16106497 cg16743781
[1,]      0.476      0.598      0.040      0.022      0.561      0.021
[2,]      0.888      0.397      0.030      0.019      0.874      0.022
[3,]      0.888      0.658      0.037      0.017      0.502      0.019
     cg17901463 cg20022541 cg20540428 cg23002907 cg23067535 cg23090046
[1,]      0.036      0.395      0.236      0.064      0.740      0.602
[2,]      0.265      0.842      0.258      0.023      0.807      0.372
[3,]      0.032      0.420      0.214      0.042      0.789      0.534
     cg23629496 cg24428042 cg24532669 cg25634666 cg26661623 cg27394566
[1,]      0.703      0.034      0.056      0.411      0.430      0.822
[2,]      0.759      0.030      0.042      0.205      0.416      0.748
[3,]      0.677      0.047      0.047      0.418      0.459      0.734
     cg27485921
[1,]      0.375
[2,]      0.183
[3,]      0.341
[1] "numgenes selected:31"
[1] "test acc:0.666666666666667"
[1] "test AUC acc:0.666666666666667"
[1] "10 fold train77.2486772486773"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold   1   2
         1 177  18
         2  19 164
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 52 28
        2 26 56
[1] "train acc:0.902116402116402"
[1] "confusion matrix train"
          nci_y
pred_train   1   2
         1 177  18
         2  19 164
[1] "DS index stage 1"
[1] 0.19
[1] "KI index stage 1"
[1] 0.5948531
[[1]]
 [1] "var1644"  "var2205"  "var2271"  "var2688"  "var5274"  "var9565" 
 [7] "var23053" "var25623" "var26627" "var27416"

[[2]]
 [1] "var2849"  "var4115"  "var6156"  "var9386"  "var14822" "var15282"
 [7] "var16787" "var22968" "var24377" "var24507"

[[3]]
 [1] "var7307"  "var9343"  "var12361" "var12885" "var16179" "var17927"
 [7] "var20005" "var20487" "var23028" "var23580"

[[4]]
 [1] "var2849"  "var4115"  "var6156"  "var9386"  "var14822" "var15282"
 [7] "var16787" "var24377" "var24507" "var27332"

[[5]]
 [1] "var1644"  "var2205"  "var2271"  "var2688"  "var5274"  "var9565" 
 [7] "var23053" "var25623" "var26627" "var27416"


 Iteration 1 :  Optimal value:  72 
 Optimal List:   var1644,var5274,var4115,var14822,var9565,var2205,var17927,var25623,var24377,var12361 

 Iteration 2 :  Optimal value:  70 
 Optimal List:   var2849,var4115,var2271,var2205,var1644,var16787,var20487,var22968,var25623,var24507 

 Iteration 3 :  Optimal value:  69.6 
 Optimal List:   var2849,var2205,var6156,var2688,var9565,var24377,var5274,var14822,var12885,var4115 

 Iteration 4 :  Optimal value:  68.4 
 Optimal List:   var2849,var2271,var6156,var14822,var4115,var16787,var2688,var9565,var23053,var24377 

 Iteration 5 :  Optimal value:  67.2 
 Optimal List:   var2849,var1644,var4115,var2205,var9565,var5274,var23053,var14822,var2688,var22968 

 Iteration 6 :  Optimal value:  67.6 
 Optimal List:   var2849,var1644,var2205,var2271,var5274,var4115,var7307,var25623,var23053,var26627 

 Iteration 7 :  Optimal value:  66.4 
 Optimal List:   var2849,var1644,var6156,var9386,var5274,var15282,var16787,var9565,var26627,var27332 

 Iteration 8 :  Optimal value:  66 
 Optimal List:   var2849,var2205,var6156,var4115,var9386,var14822,var2271,var9565,var23053,var16787 

 Iteration 9 :  Optimal value:  66 
 Optimal List:   var1644,var2205,var6156,var4115,var5274,var9565,var23053,var25623,var24377,var26627 

 Iteration 10 :  Optimal value:  66 
 Optimal List:   var1644,var4115,var2271,var9386,var14822,var5274,var2849,var23053,var16787,var27416 

 Iteration 11 :  Optimal value:  66 
 Optimal List:   var2849,var4115,var2205,var6156,var14822,var15282,var5274,var2271,var16787,var2688 

 Iteration 12 :  Optimal value:  66 
 Optimal List:   var2849,var2205,var4115,var2271,var6156,var14822,var15282,var25623,var26627,var24377 

 Iteration 13 :  Optimal value:  66 
 Optimal List:   var2849,var2205,var6156,var2688,var5274,var2271,var16787,var15282,var9386,var24507 

 Iteration 14 :  Optimal value:  66 
 Optimal List:   var2849,var4115,var2205,var2688,var1644,var15282,var9565,var25623,var23053,var24377 
[1] "test acc rank aggreg CE:0.648148148148148"
[1] "test AUC acc rank aggreg CE:0.649725274725275"
[1] "10 fold train rank aggreg res CE69.8412698412698"
[1] "confusion matrix train 10 fold rank aggreg CE"
            nci_y
pred10foldRA   1   2
           1 158  53
           2  38 129
[1] "Num itr RA CE"
[1] 14
[1] "Test BER aggreg CE is"
[1] 0.6497253

 Iteration 1 :  Optimal value:  74 
 Optimal List:   var9386,var1644,var14822,var15282,var2271,var12361,var9565,var6156,var4115,var12885 

 Iteration 2 :  Optimal value:  69.6 
 Optimal List:   var2688,var2849,var1644,var2271,var4115,var5274,var14822,var24507,var2205,var9565 

 Iteration 3 :  Optimal value:  74 
 Optimal List:   var2849,var24377,var15282,var4115,var5274,var9565,var2271,var2688,var2205,var20487 

 Iteration 4 :  Optimal value:  72.8 
 Optimal List:   var2205,var2849,var2688,var12885,var9343,var2271,var5274,var1644,var9565,var14822 

 Iteration 5 :  Optimal value:  70.8 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var23028,var12885,var26627 

 Iteration 6 :  Optimal value:  70.8 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var23028,var12885,var26627 

 Iteration 7 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 8 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 9 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 10 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 11 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 12 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 13 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 14 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 15 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 16 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var9386,var5274,var9565,var2271,var2688,var2205,var15282 

 Iteration 17 :  Optimal value:  68.4 
 Optimal List:   var4115,var1644,var14822,var2271,var5274,var9565,var15282,var2205,var25623,var24377 

 Iteration 18 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2271,var2205,var5274,var9565,var2688,var14822,var25623,var24377 

 Iteration 19 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2271,var2205,var5274,var9565,var2688,var14822,var25623,var24377 

 Iteration 20 :  Optimal value:  67.2 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2688,var6156,var25623,var22968 

 Iteration 21 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var6156,var2688,var5274,var9565,var2271,var2205,var25623,var24377 

 Iteration 22 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var6156,var2688,var5274,var9565,var2271,var2205,var25623,var24377 

 Iteration 23 :  Optimal value:  67.2 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var9565,var2688,var6156,var25623,var22968 

 Iteration 24 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var6156,var2849,var14822,var9565,var2271,var2205,var25623,var24377 

 Iteration 25 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var9565,var2271,var25623,var2688,var5274 

 Iteration 26 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var9565,var2271,var25623,var2688,var5274 

 Iteration 27 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var9565,var2688,var6156,var25623,var24377 

 Iteration 28 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var9565,var2688,var6156,var25623,var24377 

 Iteration 29 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var25623,var24377 

 Iteration 30 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var25623,var24377 

 Iteration 31 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var25623,var24377 

 Iteration 32 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var25623,var24377 

 Iteration 33 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var25623,var24377 

 Iteration 34 :  Optimal value:  66.8 
 Optimal List:   var4115,var2849,var2205,var2271,var5274,var6156,var15282,var2688,var9386,var24377 

 Iteration 35 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2271,var9386,var2205,var9565,var2688,var6156,var25623,var24377 

 Iteration 36 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2271,var9386,var2205,var9565,var2688,var6156,var25623,var24377 

 Iteration 37 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var5274,var24377 

 Iteration 38 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var5274,var24377 

 Iteration 39 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2688,var2849,var25623,var24377 

 Iteration 40 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2849,var2271,var6156,var9565,var2688,var5274,var25623,var24377 

 Iteration 41 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2271,var2849,var14822,var9565,var9386,var6156,var25623,var24377 

 Iteration 42 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var9565,var16787,var6156,var25623,var24377 

 Iteration 43 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var5274,var24377 

 Iteration 44 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var6156,var2849,var14822,var9565,var2688,var9386,var25623,var24377 

 Iteration 45 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var5274,var24377 

 Iteration 46 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var2688,var16787,var6156,var25623,var24377 

 Iteration 47 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var2688,var16787,var6156,var25623,var24377 

 Iteration 48 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var14822,var2688,var16787,var6156,var25623,var24377 

 Iteration 49 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2688,var6156,var25623,var24377 

 Iteration 50 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var5274,var24377 

 Iteration 51 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var6156,var9565,var15282,var14822,var25623,var24377 

 Iteration 52 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var5274,var9565,var15282,var6156,var25623,var24377 

 Iteration 53 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var5274,var9565,var9386,var6156,var25623,var24377 

 Iteration 54 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var25623,var24377 

 Iteration 55 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2271,var14822,var9565,var2849,var2688,var25623,var24377 

 Iteration 56 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var5274,var9565,var2688,var9386,var25623,var24377 

 Iteration 57 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var2205,var2849,var5274,var9565,var15282,var6156,var25623,var24377 

 Iteration 58 :  Optimal value:  66.8 
 Optimal List:   var4115,var1644,var6156,var2849,var14822,var9565,var2688,var9386,var25623,var24377 
[1] "test acc rank aggreg GA:0.648148148148148"
[1] "test AUC acc rank aggreg GA:0.647893772893773"
[1] "10 fold train rank aggreg res GA67.1957671957672"
[1] "confusion matrix train 10 fold rank aggreg GA"
            nci_y
pred10foldRA   1   2
           1 154  51
           2  42 131
[1] "Num itr RA GA"
[1] 59
[1] "Test BER aggreg GA is"
[1] 0.6478938
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 378  31
> 
> 
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=10,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.1,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=0.1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=0.8))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 10"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.8"
[1] "weightB: 0.05"
[1] "weightC: 0.05"
[1] "weightD: 0.1"
[1] "featweight.max: 0.1"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.3"
[1] "confusionprob: 0.1"
[1] "leaderprob: 0.5"
[1] "wmax: 1"
[1] "wmin: 0.1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 10"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 1"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 76.71958
[1] "here"
[1] "s"
[1] 302.4
[1] 378  31
[1] 10
[1] "learning sets: 1"
  [1] 208 277 164 209 197  66 293 304 344 366 113 155 374 114  19 151 362  73
 [19] 353 115 275  56 355  12 358  94 336  68 272 260  75 226  32 106 104 322
 [37] 254 159 118 343 142 338 295 231 110  49 150 375   4 253 320  92  35 335
 [55] 112 274  98 349 284 262 143 210   3 199 309 119  69 268 357 228 167 255
 [73] 198 376 237 311 158 373 215 227 168 378 278 214 144  80 369 279 221  42
 [91] 101 103 171 219 186 345 238 204 323  14 126  20 132 165 300 290  90 109
[109] 312  84  83 359 315 148 341 299 289  86 153   8 139 370 149 177   1 131
[127] 169  36 196 182 123 229   9 201 297  24 212  31  47  72 190 328 348 194
[145]  41 280  25  27 264 203 207 163 102 361  74 217 236 259 247 200 321 145
[163] 235 234 364 192  43  22  95  93 193 292 294 180  28  71  18 213 296  51
[181] 225 172 351 125 233 281 244 156 354  97 154 175 271 157 245  91 152  77
[199] 248 266 187 240 363  96 128 377 122 324 265 232 241 339 188 218 116 307
[217] 267 319 282 251 239 170  11 184  85  67 291   7 257 222  52 249   2 352
[235] 342  39 189  40 246 108 211 120 179 371  58 135 347 310 176 368 372 138
[253] 111 261  44 181 325  59 327  46  81 303 160  38  88 298  82 273 308 100
[271]  61 223  89 317 326 337 334 269 313 287 314 205 305  34  76  53 161  17
[289] 286 127  10 332  78 191  64 285 130 146 340 333 134 117
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "iteration number: "
[1] 225
[1] "iteration number: "
[1] 226
[1] "iteration number: "
[1] 227
[1] "iteration number: "
[1] 228
[1] "iteration number: "
[1] 229
[1] "iteration number: "
[1] 230
[1] "iteration number: "
[1] 231
[1] "iteration number: "
[1] 232
[1] "iteration number: "
[1] 233
[1] "iteration number: "
[1] 234
[1] "iteration number: "
[1] 235
[1] "iteration number: "
[1] 236
[1] "iteration number: "
[1] 237
[1] "iteration number: "
[1] 238
[1] "iteration number: "
[1] 239
[1] "iteration number: "
[1] 240
[1] "iteration number: "
[1] 241
[1] "iteration number: "
[1] 242
[1] "iteration number: "
[1] 243
[1] "iteration number: "
[1] 244
[1] "iteration number: "
[1] 245
[1] "iteration number: "
[1] 246
[1] "iteration number: "
[1] 247
[1] "iteration number: "
[1] 248
[1] "iteration number: "
[1] 249
[1] "iteration number: "
[1] 250
[1] "iteration number: "
[1] 251
[1] "iteration number: "
[1] 252
[1] "iteration number: "
[1] 253
[1] "iteration number: "
[1] 254
[1] "iteration number: "
[1] 255
[1] "iteration number: "
[1] 256
[1] "iteration number: "
[1] 257
[1] "iteration number: "
[1] 258
[1] "iteration number: "
[1] 259
[1] "iteration number: "
[1] 260
[1] "iteration number: "
[1] 261
[1] "iteration number: "
[1] 262
[1] "iteration number: "
[1] 263
[1] "iteration number: "
[1] 264
[1] "iteration number: "
[1] 265
[1] "iteration number: "
[1] 266
[1] "iteration number: "
[1] 267
[1] "iteration number: "
[1] 268
[1] "iteration number: "
[1] 269
[1] "iteration number: "
[1] 270
[1] "iteration number: "
[1] 271
[1] "iteration number: "
[1] 272
[1] "iteration number: "
[1] 273
[1] "iteration number: "
[1] 274
[1] "iteration number: "
[1] 275
[1] "iteration number: "
[1] 276
[1] "iteration number: "
[1] 277
[1] "iteration number: "
[1] 278
[1] "iteration number: "
[1] 279
[1] "iteration number: "
[1] 280
[1] "iteration number: "
[1] 281
[1] "iteration number: "
[1] 282
[1] "iteration number: "
[1] 283
[1] "iteration number: "
[1] 284
[1] "iteration number: "
[1] 285
[1] "iteration number: "
[1] 286
[1] "iteration number: "
[1] 287
[1] "iteration number: "
[1] 288
[1] "iteration number: "
[1] 289
[1] "iteration number: "
[1] 290
[1] "iteration number: "
[1] 291
[1] "iteration number: "
[1] 292
[1] "iteration number: "
[1] 293
[1] "iteration number: "
[1] 294
[1] "iteration number: "
[1] 295
[1] "iteration number: "
[1] 296
[1] "iteration number: "
[1] 297
[1] "iteration number: "
[1] 298
[1] "iteration number: "
[1] 299
[1] "iteration number: "
[1] 300
[1] "iteration number: "
[1] 301
[1] "iteration number: "
[1] 302
[1] "iteration number: "
[1] 303
[1] "iteration number: "
[1] 304
[1] "iteration number: "
[1] 305
[1] "iteration number: "
[1] 306
[1] "iteration number: "
[1] 307
[1] "iteration number: "
[1] 308
[1] "iteration number: "
[1] 309
[1] "iteration number: "
[1] 310
[1] "iteration number: "
[1] 311
[1] "iteration number: "
[1] 312
[1] "iteration number: "
[1] 313
[1] "iteration number: "
[1] 314
[1] "iteration number: "
[1] 315
[1] "iteration number: "
[1] 316
[1] "iteration number: "
[1] 317
[1] "iteration number: "
[1] 318
[1] "iteration number: "
[1] 319
[1] "iteration number: "
[1] 320
[1] "iteration number: "
[1] 321
[1] "iteration number: "
[1] 322
[1] "iteration number: "
[1] 323
[1] "iteration number: "
[1] 324
[1] "iteration number: "
[1] 325
[1] "iteration number: "
[1] 326
[1] "iteration number: "
[1] 327
[1] "iteration number: "
[1] 328
[1] "iteration number: "
[1] 329
[1] "iteration number: "
[1] 330
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:1"
[1] "number of features selected using population mean"
[1] 19
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 35.95513
[1] "test acc:0.789473684210526"
[1] "##################################"
[1] "learning sets: 2"
  [1] 184 258 122 171 116 163 146  49  52 292  50 177  53  42 111 341  55 144
 [19] 112 270  51 166 175 359  75  77 143 186 304 251  11 133 135 222  67 158
 [37] 367 159 249 312  78 298 203 375 287 301 136 260 154 378  93  34 206  20
 [55]  14 174 361 160  72 235 110 187 282  69 152  54 362  35 273  96 240  79
 [73]  27 291  56 326 106 314  46 366 179 178 200 167 134 225 190 353 224 274
 [91] 218   4 139 313 271 228 155 303 299 232  89 210  30 323 253 335 285 149
[109] 350 339 265 283  81 365 278  24 113 201  19 347 372 123 267 192 141 223
[127] 308 230  60  64   1 101 243 213 202 183 156 336  48  23  17 138 332 346
[145] 348  87 289 242 165 191  38 162 217 320 151 345 197 185  16 310 226 125
[163] 321 358  43  40  76 126 355 277 324 264  28  85 329  31  66  92  26   8
[181] 374 373 172 357 237 245 204 161 340 107 137 130 238 104 145 198 331 188
[199] 164 280 300 311 319 342 356 275 279  22 276 132 363  68 288 307  80 120
[217] 216 354 117 281 309  86  95 212 316 333 257 327 119  18 233  39 170 246
[235] 315  63 168 199 360 180 102 124  84 173  33  59 369 256  94  21 105  82
[253] 128 181 325  99 330 294 364 296  36 286 376 157 252 377  57 334 129 266
[271] 182 244 255 337 254 343 100  29 261 352  12 259  88 147 153 248  25  90
[289] 234  37 114  45 196 103   3 262  41 302 194 189   6 207
[1] "Starting global iteration number : 2"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "iteration number: "
[1] 225
[1] "iteration number: "
[1] 226
[1] "iteration number: "
[1] 227
[1] "iteration number: "
[1] 228
[1] "iteration number: "
[1] 229
[1] "iteration number: "
[1] 230
[1] "iteration number: "
[1] 231
[1] "iteration number: "
[1] 232
[1] "iteration number: "
[1] 233
[1] "iteration number: "
[1] 234
[1] "iteration number: "
[1] 235
[1] "iteration number: "
[1] 236
[1] "iteration number: "
[1] 237
[1] "iteration number: "
[1] 238
[1] "iteration number: "
[1] 239
[1] "iteration number: "
[1] 240
[1] "iteration number: "
[1] 241
[1] "iteration number: "
[1] 242
[1] "iteration number: "
[1] 243
[1] "iteration number: "
[1] 244
[1] "iteration number: "
[1] 245
[1] "iteration number: "
[1] 246
[1] "iteration number: "
[1] 247
[1] "iteration number: "
[1] 248
[1] "iteration number: "
[1] 249
[1] "iteration number: "
[1] 250
[1] "iteration number: "
[1] 251
[1] "iteration number: "
[1] 252
[1] "iteration number: "
[1] 253
[1] "iteration number: "
[1] 254
[1] "iteration number: "
[1] 255
[1] "iteration number: "
[1] 256
[1] "iteration number: "
[1] 257
[1] "iteration number: "
[1] 258
[1] "iteration number: "
[1] 259
[1] "iteration number: "
[1] 260
[1] "iteration number: "
[1] 261
[1] "iteration number: "
[1] 262
[1] "iteration number: "
[1] 263
[1] "iteration number: "
[1] 264
[1] "iteration number: "
[1] 265
[1] "iteration number: "
[1] 266
[1] "iteration number: "
[1] 267
[1] "iteration number: "
[1] 268
[1] "iteration number: "
[1] 269
[1] "iteration number: "
[1] 270
[1] "iteration number: "
[1] 271
[1] "iteration number: "
[1] 272
[1] "iteration number: "
[1] 273
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:2"
[1] "number of features selected using population mean"
[1] 31
[1] "number of features selected using current global best"
[1] 19
[1] "feat ind length"
[1] 19
[1] "best accuracy"
[1] 34.99348
[1] "test acc:0.723684210526316"
[1] "##################################"
[1] "learning sets: 3"
  [1] 161  66  82 314 140  78 213 245 137 277 321  71 354  62 160 253 239 347
 [19]  56 200 198  52 150 224 139 303 247 177 104  33  74 100 279 292 355 176
 [37] 278 238 275 326 322 174  49 269 368 301 143 313 227  16 103 341  75  64
 [55]  40  47 249 323 120 131 264  28 106 297 235  10 318 151  23 232 350 133
 [73] 114  50 229 211 153  53 369 255  31 141 190 263 112 159 152 170 223 217
 [91] 376 336  37 265 360 108 316 311  19   4 372  29 259  85  41 374 282   8
[109]  36 338 156 335  60 362 169  61  68  15 115  69  77  39 271  57 307 226
[127] 127  97 375 257 205 296 250 276 148 266 325   2 181  20 283 248 128  98
[145] 199 280 378 285 175  22 261 367  94 206 209  46  30 302 129 111 363  27
[163]  32  63 331 119 163 309 246 221  70 319  51 356 142 102 228 317 171 185
[181] 230 173 187 315 337 121 136 101 366 188 184  76 172 215   3 324 144 340
[199] 287 364 339 357  92  45 254  18  96 370 178 373 251 272 293 329 138  34
[217] 147 289   1  59 241   5 122 157  42 327  24 352 242  35 377 118   7  95
[235] 288 312 252  12 304 208  86  43 158 351  81  54 291 345 268  58 116 349
[253] 273 334  25 294 231  26  48 126 244 216 125 281  80  72 195 210 240 365
[271] 262 298  14 358  21 196 267 332   9 109 189 154 346  91 284 236  65  99
[289] 361 286 105 333 258 180 132 371 260 342 183 343  90 348
[1] "Starting global iteration number : 3"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:3"
[1] "number of features selected using population mean"
[1] 19
[1] "number of features selected using current global best"
[1] 19
[1] "feat ind length"
[1] 19
[1] "best accuracy"
[1] 34.97871
[1] "test acc:0.802631578947368"
[1] "##################################"
[1] "learning sets: 4"
  [1] 372 242  89 319 353 337 109  23 293 212 263  10 142 181 113   1 281 135
 [19]  60 222 167  67 121 272 368 165 107 204 115 267  69   6 329  56 101  80
 [37] 289 253 371 221 189 192 235 245 151  40 110 190 226 240 241 298 148  15
 [55] 284 324  25 174 232  14 257 168 250 170  49 312 238 187 330 343 283 350
 [73]  22 280 244 322 261 128 215 105 286 259 277 234 359 162 199 195 122  66
 [91] 141 320 374  74 328 285  98 265 276  97  71  19 219  17 217  65 294  76
[109]  86  16 377  46 269  90 117 347 252  36 124 373 346 302 278  78 108 309
[127]  87 229 193  11 301   2   4 155 348 270 112  95  45 268 303  28 292  84
[145]  75 186 274 223 120 325 236 188 369 237 275 333 255 152 345  34 129 326
[163] 288 130 327 264 114 198 158 111 230  18 137 231 134  64  57 179 344 210
[181]  27 336 156 300 146 316  92 354 282 251 125 154 150 100 201 214  33 220
[199] 310 295 132 248  77 296  42  63 183 262 206 279 138 256 233 144 378  93
[217] 349 191 173  35 218  48 311  85 239 203 247 207  62  94 213  79 338  70
[235]   8 362 306  12  31 367 342 318 216 172 147 375 376 334  47 258  38 366
[253] 140 351 139 356  13 273 127 169 180  53 211 106  68 352  82   5 153 159
[271] 184  32 208 304   3 291  99 103 370 335  21 136  59  43 102 133 177  39
[289] 308 166  26 149  20 185 246 160 363 365  55 227 225 260
[1] "Starting global iteration number : 4"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "iteration number: "
[1] 225
[1] "iteration number: "
[1] 226
[1] "iteration number: "
[1] 227
[1] "iteration number: "
[1] 228
[1] "iteration number: "
[1] 229
[1] "iteration number: "
[1] 230
[1] "iteration number: "
[1] 231
[1] "iteration number: "
[1] 232
[1] "iteration number: "
[1] 233
[1] "iteration number: "
[1] 234
[1] "iteration number: "
[1] 235
[1] "iteration number: "
[1] 236
[1] "iteration number: "
[1] 237
[1] "iteration number: "
[1] 238
[1] "iteration number: "
[1] 239
[1] "iteration number: "
[1] 240
[1] "iteration number: "
[1] 241
[1] "iteration number: "
[1] 242
[1] "iteration number: "
[1] 243
[1] "iteration number: "
[1] 244
[1] "iteration number: "
[1] 245
[1] "iteration number: "
[1] 246
[1] "iteration number: "
[1] 247
[1] "iteration number: "
[1] 248
[1] "iteration number: "
[1] 249
[1] "iteration number: "
[1] 250
[1] "iteration number: "
[1] 251
[1] "iteration number: "
[1] 252
[1] "iteration number: "
[1] 253
[1] "iteration number: "
[1] 254
[1] "iteration number: "
[1] 255
[1] "iteration number: "
[1] 256
[1] "iteration number: "
[1] 257
[1] "iteration number: "
[1] 258
[1] "iteration number: "
[1] 259
[1] "iteration number: "
[1] 260
[1] "iteration number: "
[1] 261
[1] "iteration number: "
[1] 262
[1] "iteration number: "
[1] 263
[1] "iteration number: "
[1] 264
[1] "iteration number: "
[1] 265
[1] "iteration number: "
[1] 266
[1] "iteration number: "
[1] 267
[1] "iteration number: "
[1] 268
[1] "iteration number: "
[1] 269
[1] "iteration number: "
[1] 270
[1] "iteration number: "
[1] 271
[1] "iteration number: "
[1] 272
[1] "iteration number: "
[1] 273
[1] "iteration number: "
[1] 274
[1] "iteration number: "
[1] 275
[1] "iteration number: "
[1] 276
[1] "iteration number: "
[1] 277
[1] "iteration number: "
[1] 278
[1] "iteration number: "
[1] 279
[1] "iteration number: "
[1] 280
[1] "iteration number: "
[1] 281
[1] "iteration number: "
[1] 282
[1] "iteration number: "
[1] 283
[1] "iteration number: "
[1] 284
[1] "iteration number: "
[1] 285
[1] "iteration number: "
[1] 286
[1] "iteration number: "
[1] 287
[1] "iteration number: "
[1] 288
[1] "iteration number: "
[1] 289
[1] "iteration number: "
[1] 290
[1] "iteration number: "
[1] 291
[1] "iteration number: "
[1] 292
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:4"
[1] "number of features selected using population mean"
[1] 21
[1] "number of features selected using current global best"
[1] 21
[1] "feat ind length"
[1] 21
[1] "best accuracy"
[1] 35.9538
[1] "test acc:0.763157894736842"
[1] "##################################"
[1] "learning sets: 5"
  [1] 114 321 220  57 306  56 256 235 314  60 318 148 222 243 362 304 174 108
 [19] 315 179   2 247 158 350  81 361  14  89 295 224 130 268  46 337  68  42
 [37] 214 144 238 141 109 136 273  73 375 124 126  23 282 111  54 127 198 178
 [55] 166 207 105 170 165  19 184  86 267  90 371 342 193  37 281  45  88 123
 [73]  75 169 275 167 368 192 202 110  92  96 187  10  97   7 283  41 276 369
 [91]   4 351 102 173  58  18 271 156 353 349 331  93  21 215 157 131 227   3
[109]  39 354 195 152 128 308  67 226 263 326 358 132 146  12  38  22  51 168
[127]  25 149 287 279 231 118 232 274 319 332 310 100 162 289 374 182 250  69
[145] 309 286 291  65 147  91 327 211  24 104   1  48  77 205 151 221 303 328
[163] 278 300  59 212  80 261  26 322 367 163 244 285 199  72 254  32  34  36
[181] 320 259 233  98 248  31 344 311 317 313 265  49  47 240 356 145 164  44
[199] 138 219 333  66  82  50 122 360 288 372 134 223  43 140 161 216 209 347
[217] 107 183 290  79 294 119 237 305 245 241  11 307 357 334  16 113 340  35
[235] 142 206 230 338 352 364 377  62 103 197 270 312 257 324 139 302 299 125
[253] 191 181  85 323 154 262 159  78 153 272 204 171 239  99 185 177 213  95
[271]  63 348 194 336 112 218  27  74 117 366 133 115 234 200 249 121  13 363
[289] 217 346  28 255 242 225 106 228  33 280 172  87  30 297
[1] "Starting global iteration number : 5"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:5"
[1] "number of features selected using population mean"
[1] 20
[1] "number of features selected using current global best"
[1] 20
[1] "feat ind length"
[1] 20
[1] "best accuracy"
[1] 35.85601
[1] "test acc:0.776315789473684"
[1] "##################################"
[1] "learning sets: 6"
  [1]  31  83 315  33 178 152 180 335  12  26 213 174 114 123 355  42 107 299
 [19] 116 230 216 157  34 201 263 293  57 243  30 304 143 334 264 351 117 203
 [37]  43 220 131 229 176  17 375 209  87 376 298  96 269 344 104  81 271 326
 [55] 179  10 316  59 133 242  29  13 112 322 188 339 309 197 329 139  37 373
 [73] 196  91 257 283 353  76 120 336  60 214  53 362  48 290  68 156 124 368
 [91]  24 289 333  64 194 102 321 146 338 352 314  14 181  63 372  78 291 312
[109]  23  44 185  82  45  38 345 274 115 182  58 306  19 262 273 252 154  11
[127] 165 150 141 342 135 272 301  90 279 266 366 202  74 183 250 110 129 284
[145] 359 103   8 121 195 311 330  97 327 215 108 204 221 111 255 307 341 277
[163] 286 232  99 265 349  36   2  18  73 247 106 177 134 187  66 305 127 190
[181]  89 113 175  65 100 192 300 370 281 205 149 350 155 148  35 189 109 126
[199] 282   6 217  15 292  67  50 285 303 302 256 323 297 240  77  39 248 275
[217]  54  92 361 360 324 239  88 260 374 186 193 137 161 245 132 219  80 354
[235] 363  47  61 276   1 254 160  16 147 369 167 356 267   5 253 172  93   9
[253]  20 235  79 140 227 125 358 371  85  40 236  62 348 199 317 280 207  28
[271] 377  56  21 170   4 218  49 259 159 128 222 144 164   7 224 169  22 142
[289] 378  86 122 367 278 130  52 319 238 118 226 198 295 347
[1] "Starting global iteration number : 6"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "iteration number: "
[1] 225
[1] "iteration number: "
[1] 226
[1] "iteration number: "
[1] 227
[1] "iteration number: "
[1] 228
[1] "iteration number: "
[1] 229
[1] "iteration number: "
[1] 230
[1] "iteration number: "
[1] 231
[1] "iteration number: "
[1] 232
[1] "iteration number: "
[1] 233
[1] "iteration number: "
[1] 234
[1] "iteration number: "
[1] 235
[1] "iteration number: "
[1] 236
[1] "iteration number: "
[1] 237
[1] "iteration number: "
[1] 238
[1] "iteration number: "
[1] 239
[1] "iteration number: "
[1] 240
[1] "iteration number: "
[1] 241
[1] "iteration number: "
[1] 242
[1] "iteration number: "
[1] 243
[1] "iteration number: "
[1] 244
[1] "iteration number: "
[1] 245
[1] "iteration number: "
[1] 246
[1] "iteration number: "
[1] 247
[1] "iteration number: "
[1] 248
[1] "iteration number: "
[1] 249
[1] "iteration number: "
[1] 250
[1] "iteration number: "
[1] 251
[1] "iteration number: "
[1] 252
[1] "iteration number: "
[1] 253
[1] "iteration number: "
[1] 254
[1] "iteration number: "
[1] 255
[1] "iteration number: "
[1] 256
[1] "iteration number: "
[1] 257
[1] "iteration number: "
[1] 258
[1] "iteration number: "
[1] 259
[1] "iteration number: "
[1] 260
[1] "iteration number: "
[1] 261
[1] "iteration number: "
[1] 262
[1] "iteration number: "
[1] 263
[1] "iteration number: "
[1] 264
[1] "iteration number: "
[1] 265
[1] "iteration number: "
[1] 266
[1] "iteration number: "
[1] 267
[1] "iteration number: "
[1] 268
[1] "iteration number: "
[1] 269
[1] "iteration number: "
[1] 270
[1] "iteration number: "
[1] 271
[1] "iteration number: "
[1] 272
[1] "iteration number: "
[1] 273
[1] "iteration number: "
[1] 274
[1] "iteration number: "
[1] 275
[1] "iteration number: "
[1] 276
[1] "iteration number: "
[1] 277
[1] "iteration number: "
[1] 278
[1] "iteration number: "
[1] 279
[1] "iteration number: "
[1] 280
[1] "iteration number: "
[1] 281
[1] "iteration number: "
[1] 282
[1] "iteration number: "
[1] 283
[1] "iteration number: "
[1] 284
[1] "iteration number: "
[1] 285
[1] "iteration number: "
[1] 286
[1] "iteration number: "
[1] 287
[1] "iteration number: "
[1] 288
[1] "iteration number: "
[1] 289
[1] "iteration number: "
[1] 290
[1] "iteration number: "
[1] 291
[1] "iteration number: "
[1] 292
[1] "iteration number: "
[1] 293
[1] "iteration number: "
[1] 294
[1] "iteration number: "
[1] 295
[1] "iteration number: "
[1] 296
[1] "iteration number: "
[1] 297
[1] "iteration number: "
[1] 298
[1] "iteration number: "
[1] 299
[1] "iteration number: "
[1] 300
[1] "iteration number: "
[1] 301
[1] "iteration number: "
[1] 302
[1] "iteration number: "
[1] 303
[1] "iteration number: "
[1] 304
[1] "iteration number: "
[1] 305
[1] "iteration number: "
[1] 306
[1] "iteration number: "
[1] 307
[1] "iteration number: "
[1] 308
[1] "iteration number: "
[1] 309
[1] "iteration number: "
[1] 310
[1] "iteration number: "
[1] 311
[1] "iteration number: "
[1] 312
[1] "iteration number: "
[1] 313
[1] "iteration number: "
[1] 314
[1] "iteration number: "
[1] 315
[1] "iteration number: "
[1] 316
[1] "iteration number: "
[1] 317
[1] "iteration number: "
[1] 318
[1] "iteration number: "
[1] 319
[1] "iteration number: "
[1] 320
[1] "iteration number: "
[1] 321
[1] "iteration number: "
[1] 322
[1] "iteration number: "
[1] 323
[1] "iteration number: "
[1] 324
[1] "iteration number: "
[1] 325
[1] "iteration number: "
[1] 326
[1] "iteration number: "
[1] 327
[1] "iteration number: "
[1] 328
[1] "iteration number: "
[1] 329
[1] "iteration number: "
[1] 330
[1] "iteration number: "
[1] 331
[1] "iteration number: "
[1] 332
[1] "iteration number: "
[1] 333
[1] "iteration number: "
[1] 334
[1] "iteration number: "
[1] 335
[1] "iteration number: "
[1] 336
[1] "iteration number: "
[1] 337
[1] "iteration number: "
[1] 338
[1] "iteration number: "
[1] 339
[1] "iteration number: "
[1] 340
[1] "iteration number: "
[1] 341
[1] "iteration number: "
[1] 342
[1] "iteration number: "
[1] 343
[1] "iteration number: "
[1] 344
[1] "iteration number: "
[1] 345
[1] "iteration number: "
[1] 346
[1] "iteration number: "
[1] 347
[1] "iteration number: "
[1] 348
[1] "iteration number: "
[1] 349
[1] "iteration number: "
[1] 350
[1] "iteration number: "
[1] 351
[1] "iteration number: "
[1] 352
[1] "iteration number: "
[1] 353
[1] "iteration number: "
[1] 354
[1] "iteration number: "
[1] 355
[1] "iteration number: "
[1] 356
[1] "iteration number: "
[1] 357
[1] "iteration number: "
[1] 358
[1] "iteration number: "
[1] 359
[1] "iteration number: "
[1] 360
[1] "iteration number: "
[1] 361
[1] "iteration number: "
[1] 362
[1] "iteration number: "
[1] 363
[1] "iteration number: "
[1] 364
[1] "iteration number: "
[1] 365
[1] "iteration number: "
[1] 366
[1] "iteration number: "
[1] 367
[1] "iteration number: "
[1] 368
[1] "iteration number: "
[1] 369
[1] "iteration number: "
[1] 370
[1] "iteration number: "
[1] 371
[1] "iteration number: "
[1] 372
[1] "iteration number: "
[1] 373
[1] "iteration number: "
[1] 374
[1] "iteration number: "
[1] 375
[1] "iteration number: "
[1] 376
[1] "iteration number: "
[1] 377
[1] "iteration number: "
[1] 378
[1] "iteration number: "
[1] 379
[1] "iteration number: "
[1] 380
[1] "iteration number: "
[1] 381
[1] "iteration number: "
[1] 382
[1] "iteration number: "
[1] 383
[1] "iteration number: "
[1] 384
[1] "iteration number: "
[1] 385
[1] "iteration number: "
[1] 386
[1] "iteration number: "
[1] 387
[1] "iteration number: "
[1] 388
[1] "iteration number: "
[1] 389
[1] "iteration number: "
[1] 390
[1] "iteration number: "
[1] 391
[1] "iteration number: "
[1] 392
[1] "iteration number: "
[1] 393
[1] "iteration number: "
[1] 394
[1] "iteration number: "
[1] 395
[1] "iteration number: "
[1] 396
[1] "iteration number: "
[1] 397
[1] "iteration number: "
[1] 398
[1] "iteration number: "
[1] 399
[1] "iteration number: "
[1] 400
[1] "iteration number: "
[1] 401
[1] "iteration number: "
[1] 402
[1] "iteration number: "
[1] 403
[1] "iteration number: "
[1] 404
[1] "iteration number: "
[1] 405
[1] "iteration number: "
[1] 406
[1] "iteration number: "
[1] 407
[1] "iteration number: "
[1] 408
[1] "iteration number: "
[1] 409
[1] "iteration number: "
[1] 410
[1] "iteration number: "
[1] 411
[1] "iteration number: "
[1] 412
[1] "iteration number: "
[1] 413
[1] "iteration number: "
[1] 414
[1] "iteration number: "
[1] 415
[1] "iteration number: "
[1] 416
[1] "iteration number: "
[1] 417
[1] "iteration number: "
[1] 418
[1] "iteration number: "
[1] 419
[1] "iteration number: "
[1] 420
[1] "iteration number: "
[1] 421
[1] "iteration number: "
[1] 422
[1] "iteration number: "
[1] 423
[1] "iteration number: "
[1] 424
[1] "iteration number: "
[1] 425
[1] "iteration number: "
[1] 426
[1] "iteration number: "
[1] 427
[1] "iteration number: "
[1] 428
[1] "iteration number: "
[1] 429
[1] "iteration number: "
[1] 430
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:6"
[1] "number of features selected using population mean"
[1] 12
[1] "number of features selected using current global best"
[1] 12
[1] "feat ind length"
[1] 12
[1] "best accuracy"
[1] 36.02565
[1] "test acc:0.684210526315789"
[1] "##################################"
[1] "learning sets: 7"
  [1] 309 154 187 268  36 232 226  63  17 299 347 103  58  87 227 136 295  70
 [19] 101  74 207 327 255 349 284 109 256 219  67 348 339 145 294 189 179 290
 [37] 250 133 272  16 134 367 192  80 140  99 282 242  57   4 317 113 215 281
 [55] 336 166   9 283 237   3  46 311  96 335 224 218  34  39 293  40 275   2
 [73]  88 346 163 374 373 334 369  55 209 249 153 193 162 129 340  60 263  22
 [91]  49  59 184 148 315 143 114  92 377  93 251 273  23 220  37  89 102 277
[109]  84  28 276 345  38  98 323  53  54 353  71 168  24 164  33 186 344 333
[127] 321 112 332 326 376 169 331 236 245 350 329  64 100 185 278 337   8  10
[145]  45 241 371 139 366 257 155 246  79 254 248 300 202  72 137  69 270 313
[163]   7 225 115 161 230  61  94  41 247  65 356 370 120 288 322  95 221 128
[181] 316  15 131 303   5  78 375 362 144 157  97 201 292 274  13 330 354  51
[199] 228 182 110  68 264  11 235 175 204 310 195 199 210 165 338 378  42 147
[217] 121 238 265 260 365 174 216 142 291  18 205 132 287 108 269 172 181 355
[235]  62 363 244 107 271 191 146 301 196 217 289 261 149 286 171 229  27 372
[253] 351 194 258 123  52 159 319 156  82 176 126 177  75  14 364 240 361 368
[271]  85  66 117  76  44 262 360 104 302  77 127 208  29  35 152  20 180 297
[289] 352 197 160 305 312 318 239 150 280 304 118 296 234 307
[1] "Starting global iteration number : 7"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "iteration number: "
[1] 225
[1] "iteration number: "
[1] 226
[1] "iteration number: "
[1] 227
[1] "iteration number: "
[1] 228
[1] "iteration number: "
[1] 229
[1] "iteration number: "
[1] 230
[1] "iteration number: "
[1] 231
[1] "iteration number: "
[1] 232
[1] "iteration number: "
[1] 233
[1] "iteration number: "
[1] 234
[1] "iteration number: "
[1] 235
[1] "iteration number: "
[1] 236
[1] "iteration number: "
[1] 237
[1] "iteration number: "
[1] 238
[1] "iteration number: "
[1] 239
[1] "iteration number: "
[1] 240
[1] "iteration number: "
[1] 241
[1] "iteration number: "
[1] 242
[1] "iteration number: "
[1] 243
[1] "iteration number: "
[1] 244
[1] "iteration number: "
[1] 245
[1] "iteration number: "
[1] 246
[1] "iteration number: "
[1] 247
[1] "iteration number: "
[1] 248
[1] "iteration number: "
[1] 249
[1] "iteration number: "
[1] 250
[1] "iteration number: "
[1] 251
[1] "iteration number: "
[1] 252
[1] "iteration number: "
[1] 253
[1] "iteration number: "
[1] 254
[1] "iteration number: "
[1] 255
[1] "iteration number: "
[1] 256
[1] "iteration number: "
[1] 257
[1] "iteration number: "
[1] 258
[1] "iteration number: "
[1] 259
[1] "iteration number: "
[1] 260
[1] "iteration number: "
[1] 261
[1] "iteration number: "
[1] 262
[1] "iteration number: "
[1] 263
[1] "iteration number: "
[1] 264
[1] "iteration number: "
[1] 265
[1] "iteration number: "
[1] 266
[1] "iteration number: "
[1] 267
[1] "iteration number: "
[1] 268
[1] "iteration number: "
[1] 269
[1] "iteration number: "
[1] 270
[1] "iteration number: "
[1] 271
[1] "iteration number: "
[1] 272
[1] "iteration number: "
[1] 273
[1] "iteration number: "
[1] 274
[1] "iteration number: "
[1] 275
[1] "iteration number: "
[1] 276
[1] "iteration number: "
[1] 277
[1] "iteration number: "
[1] 278
[1] "iteration number: "
[1] 279
[1] "iteration number: "
[1] 280
[1] "iteration number: "
[1] 281
[1] "iteration number: "
[1] 282
[1] "iteration number: "
[1] 283
[1] "iteration number: "
[1] 284
[1] "iteration number: "
[1] 285
[1] "iteration number: "
[1] 286
[1] "iteration number: "
[1] 287
[1] "iteration number: "
[1] 288
[1] "iteration number: "
[1] 289
[1] "iteration number: "
[1] 290
[1] "iteration number: "
[1] 291
[1] "iteration number: "
[1] 292
[1] "iteration number: "
[1] 293
[1] "iteration number: "
[1] 294
[1] "iteration number: "
[1] 295
[1] "iteration number: "
[1] 296
[1] "iteration number: "
[1] 297
[1] "iteration number: "
[1] 298
[1] "iteration number: "
[1] 299
[1] "iteration number: "
[1] 300
[1] "iteration number: "
[1] 301
[1] "iteration number: "
[1] 302
[1] "iteration number: "
[1] 303
[1] "iteration number: "
[1] 304
[1] "iteration number: "
[1] 305
[1] "iteration number: "
[1] 306
[1] "iteration number: "
[1] 307
[1] "iteration number: "
[1] 308
[1] "iteration number: "
[1] 309
[1] "iteration number: "
[1] 310
[1] "iteration number: "
[1] 311
[1] "iteration number: "
[1] 312
[1] "iteration number: "
[1] 313
[1] "iteration number: "
[1] 314
[1] "iteration number: "
[1] 315
[1] "iteration number: "
[1] 316
[1] "iteration number: "
[1] 317
[1] "iteration number: "
[1] 318
[1] "iteration number: "
[1] 319
[1] "iteration number: "
[1] 320
[1] "iteration number: "
[1] 321
[1] "iteration number: "
[1] 322
[1] "iteration number: "
[1] 323
[1] "iteration number: "
[1] 324
[1] "iteration number: "
[1] 325
[1] "iteration number: "
[1] 326
[1] "iteration number: "
[1] 327
[1] "iteration number: "
[1] 328
[1] "iteration number: "
[1] 329
[1] "iteration number: "
[1] 330
[1] "iteration number: "
[1] 331
[1] "iteration number: "
[1] 332
[1] "iteration number: "
[1] 333
[1] "iteration number: "
[1] 334
[1] "iteration number: "
[1] 335
[1] "iteration number: "
[1] 336
[1] "iteration number: "
[1] 337
[1] "iteration number: "
[1] 338
[1] "iteration number: "
[1] 339
[1] "iteration number: "
[1] 340
[1] "iteration number: "
[1] 341
[1] "iteration number: "
[1] 342
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:7"
[1] "number of features selected using population mean"
[1] 14
[1] "number of features selected using current global best"
[1] 14
[1] "feat ind length"
[1] 14
[1] "best accuracy"
[1] 37.68323
[1] "test acc:0.763157894736842"
[1] "##################################"
[1] "learning sets: 8"
  [1]  87 314 307  39 116 125 227 192 123 281   6  65 287 348  51 356  68 112
 [19] 292 355 357 213 143 174  27  31 376 221  58 101 253 180 349 122 350 264
 [37] 375  59 269 124 317 206 316 225 130 107  40 212 185 291 331  30  62  33
 [55] 167 369 102  49 144 238 157 190 232 283 224 142 313  66 141  26 249 256
 [73]  77 208 371  83 282  48 239 257 295 377 201 127 147 178 275 191   3  54
 [91] 159 251 215 352  92 319 155 137  20  55 321 182 135 354 341 326 152  18
[109] 364 129  11 240 296 179 220  93 168 303 210 247 266 228 132 121 320 105
[127]  53 342 308 170 315 114 230  12  74 193 235 195 361 311   5 214 106 367
[145] 373 162 100 211 338 165  37 272 265 305 359 333 289 246 332  17 334 163
[163] 378  32 204 345 280 302 353  82 325  73  97 259  67  42 203 136 173 261
[181] 294 222  44 198  21 248 118  28 176  50  43 128 110 336 126 279 169 153
[199] 362 148  75 273 344 196 254 175  98 243 187 202 209 205 244 366 184 337
[217] 340 288 263 250  52 255  63  56 343 199  47  84 262  24 160 219  61 236
[235] 140 285  91 324  10 131   9 278  36  15  22  16 374  89 104  45 103  60
[253] 351 363 133  72 233  80 119 365 145  19 177 146 226 117  88  23 267  95
[271] 186 299 183 286 108 216 194 298  35 309 347  94 370 312 306 181 290 166
[289] 217 327 150 156 276 328 329  99 245 293   4  71 188 242
[1] "Starting global iteration number : 8"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "iteration number: "
[1] 225
[1] "iteration number: "
[1] 226
[1] "iteration number: "
[1] 227
[1] "iteration number: "
[1] 228
[1] "iteration number: "
[1] 229
[1] "iteration number: "
[1] 230
[1] "iteration number: "
[1] 231
[1] "iteration number: "
[1] 232
[1] "iteration number: "
[1] 233
[1] "iteration number: "
[1] 234
[1] "iteration number: "
[1] 235
[1] "iteration number: "
[1] 236
[1] "iteration number: "
[1] 237
[1] "iteration number: "
[1] 238
[1] "iteration number: "
[1] 239
[1] "iteration number: "
[1] 240
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:8"
[1] "number of features selected using population mean"
[1] 24
[1] "number of features selected using current global best"
[1] 18
[1] "feat ind length"
[1] 18
[1] "best accuracy"
[1] 38.87944
[1] "test acc:0.763157894736842"
[1] "##################################"
[1] "learning sets: 9"
  [1] 285 239 187 341   5 331 217 310  33  27  66 194 110 286 320 293 105 166
 [19]  39 135 191 197 275  11 266  47  14 328 175 163 144 319  97  81   9 116
 [37] 148 233 302  77 345 292 185 223 147 195 317 124 300 227 106 232 321  60
 [55] 145 358  51  89 238 156  50 101  20  91 333  92 219   8 209 154 277 295
 [73]  52 240 349 355 213 353 196 378 159 216 351 235  55  45 278 224 299 269
 [91] 257 130 276 108 271 171  15   7 128 316 177  12 146  48 133  62 347 367
[109]  73 325  80  82  72 329  59 368 342  95 263  37 109  40 103 201 251 246
[127]   4  23 111  63 192 137 343 250 294 210 256 330 348 356 258 372  25   6
[145] 229 119 267 242  41  85 322 338 359 366 254  30  29 160 281 170 308 375
[163] 186 127 318 138 176  34 132  17 183 169  67  57 290  36 279 252 241 288
[181] 363 164 174 107 307 354 287 104 206 214  98 153 218 255 369 205 157 361
[199] 234 344 237  93 204  49  83 100 115 244 136  19 261  18 173 168 122 304
[217]  13 120  86 215  71  54 339 134 334 370 158  99 337  10 102 203 336 112
[235]  84 374 350 268 284 247 306 179  96 181 265 314  70 184  42 123  35 371
[253] 165  28  64 376 323  79 172 167 182 303 309 289 150 129  75 280  94 199
[271] 324  16 272 180  38 377  31 220 291 352 360 357 373 141  90  44 260 189
[289]  58 270 365 207 231 125  21 362 274 248 296 212  74 131
[1] "Starting global iteration number : 9"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:9"
[1] "number of features selected using population mean"
[1] 31
[1] "number of features selected using current global best"
[1] 18
[1] "feat ind length"
[1] 18
[1] "best accuracy"
[1] 37.73847
[1] "test acc:0.671052631578947"
[1] "##################################"
[1] "learning sets: 10"
  [1]  73 236  79 298 277 253  42  18 193 299 203 266 302  92 139 335  46 165
 [19] 341   6 121 105 251 160 134 268 331 301 126 213 183 119  90  28 326 102
 [37]  36 347 100 362 189 131 287 104 138 114 132 178 330  69 312 278 375  51
 [55] 254 210 366 345 285  91  65 167 222 288 320 190  24 270 324 245  55 109
 [73] 239 244 350  89   2  52  43  66 151  59  11 310  80 261  78   3 337 155
 [91] 101 353  53  44  88 103 243 186 230  34  40 216 307 296 173 135 262 224
[109]  29 163 367  50 136 325 319 308 177  33 282 209 255 300 220 241 154  95
[127]  70 111  45 142 280  94 122 120 196 333  48 295 205 170 194 116  27 258
[145]   5 292 192 286 338  71 344 201 211 259 274 257  81 356 260 106 200 283
[163] 374   8 273  62  35 140  67 311 306 336 304 327 221 370  12  97 185 249
[181]  83 240 223 113 130  10 218 199  19  72  23  64  13  85  30 369 234 232
[199] 291 313 317  47 343 371 180 377  38 225  57 168  15 228  82  16 191  93
[217] 137 164 349 161 123 264 275 242  17 226 265 279 305 176 108 376 215 237
[235] 175 271 328 303  32 124 248 360  99 314 182  86 204 174 290 115 318 145
[253] 188  76  96 289 378  61 195 171   9 256 231 339 141 128 297  25 294 247
[271] 355 217 276 332  54 219  20 346 323  31 152 133 112 166 284 206 357 181
[289] 365 358  26 110 359 293  56 169  63 233 322 197 125 329
[1] "Starting global iteration number : 10"
[1] "iteration number: "
[1] 1
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "iteration number: "
[1] 213
[1] "iteration number: "
[1] 214
[1] "iteration number: "
[1] 215
[1] "iteration number: "
[1] 216
[1] "iteration number: "
[1] 217
[1] "iteration number: "
[1] 218
[1] "iteration number: "
[1] 219
[1] "iteration number: "
[1] 220
[1] "iteration number: "
[1] 221
[1] "iteration number: "
[1] 222
[1] "iteration number: "
[1] 223
[1] "iteration number: "
[1] 224
[1] "iteration number: "
[1] 225
[1] "iteration number: "
[1] 226
[1] "iteration number: "
[1] 227
[1] "iteration number: "
[1] 228
[1] "iteration number: "
[1] 229
[1] "iteration number: "
[1] 230
[1] "iteration number: "
[1] 231
[1] "iteration number: "
[1] 232
[1] "iteration number: "
[1] 233
[1] "iteration number: "
[1] 234
[1] "iteration number: "
[1] 235
[1] "iteration number: "
[1] 236
[1] "iteration number: "
[1] 237
[1] "iteration number: "
[1] 238
[1] "iteration number: "
[1] 239
[1] "iteration number: "
[1] 240
[1] "iteration number: "
[1] 241
[1] "iteration number: "
[1] 242
[1] "iteration number: "
[1] 243
[1] "iteration number: "
[1] 244
[1] "iteration number: "
[1] 245
[1] "iteration number: "
[1] 246
[1] "iteration number: "
[1] 247
[1] "iteration number: "
[1] 248
[1] "iteration number: "
[1] 249
[1] "iteration number: "
[1] 250
[1] "iteration number: "
[1] 251
[1] "iteration number: "
[1] 252
[1] "iteration number: "
[1] 253
[1] "iteration number: "
[1] 254
[1] "iteration number: "
[1] 255
[1] "iteration number: "
[1] 256
[1] "iteration number: "
[1] 257
[1] "iteration number: "
[1] 258
[1] "iteration number: "
[1] 259
[1] "iteration number: "
[1] 260
[1] "iteration number: "
[1] 261
[1] "iteration number: "
[1] 262
[1] "iteration number: "
[1] 263
[1] "iteration number: "
[1] 264
[1] "iteration number: "
[1] 265
[1] "iteration number: "
[1] 266
[1] "iteration number: "
[1] 267
[1] "iteration number: "
[1] 268
[1] "iteration number: "
[1] 269
[1] "iteration number: "
[1] 270
[1] "iteration number: "
[1] 271
[1] "iteration number: "
[1] 272
[1] "iteration number: "
[1] 273
[1] "iteration number: "
[1] 274
[1] "iteration number: "
[1] 275
[1] "iteration number: "
[1] 276
[1] "iteration number: "
[1] 277
[1] "iteration number: "
[1] 278
[1] "iteration number: "
[1] 279
[1] "iteration number: "
[1] 280
[1] "iteration number: "
[1] 281
[1] "iteration number: "
[1] 282
[1] "iteration number: "
[1] 283
[1] "iteration number: "
[1] 284
[1] "iteration number: "
[1] 285
[1] "iteration number: "
[1] 286
[1] "iteration number: "
[1] 287
[1] "iteration number: "
[1] 288
[1] "iteration number: "
[1] 289
[1] "iteration number: "
[1] 290
[1] "iteration number: "
[1] 291
[1] "iteration number: "
[1] 292
[1] "iteration number: "
[1] 293
[1] "iteration number: "
[1] 294
[1] "iteration number: "
[1] 295
[1] "iteration number: "
[1] 296
[1] "iteration number: "
[1] 297
[1] "iteration number: "
[1] 298
[1] "iteration number: "
[1] 299
[1] "iteration number: "
[1] 300
[1] "iteration number: "
[1] 301
[1] "iteration number: "
[1] 302
[1] "iteration number: "
[1] 303
[1] "iteration number: "
[1] 304
[1] "iteration number: "
[1] 305
[1] "iteration number: "
[1] 306
[1] "iteration number: "
[1] 307
[1] "iteration number: "
[1] 308
[1] "iteration number: "
[1] 309
[1] "iteration number: "
[1] 310
[1] "iteration number: "
[1] 311
[1] "iteration number: "
[1] 312
[1] "iteration number: "
[1] 313
[1] "iteration number: "
[1] 314
[1] "iteration number: "
[1] 315
[1] "iteration number: "
[1] 316
[1] "iteration number: "
[1] 317
[1] "iteration number: "
[1] 318
[1] "iteration number: "
[1] 319
[1] "iteration number: "
[1] 320
[1] "iteration number: "
[1] 321
[1] "iteration number: "
[1] 322
[1] "iteration number: "
[1] 323
[1] "iteration number: "
[1] 324
[1] "iteration number: "
[1] 325
[1] "iteration number: "
[1] 326
[1] "iteration number: "
[1] 327
[1] "iteration number: "
[1] 328
[1] "iteration number: "
[1] 329
[1] "iteration number: "
[1] 330
[1] "iteration number: "
[1] 331
[1] "iteration number: "
[1] 332
[1] "iteration number: "
[1] 333
[1] "iteration number: "
[1] 334
[1] "iteration number: "
[1] 335
[1] "iteration number: "
[1] 336
[1] "iteration number: "
[1] 337
[1] "iteration number: "
[1] 338
[1] "iteration number: "
[1] 339
[1] "iteration number: "
[1] 340
[1] "iteration number: "
[1] 341
[1] "iteration number: "
[1] 342
[1] "iteration number: "
[1] 343
[1] "iteration number: "
[1] 344
[1] "iteration number: "
[1] 345
[1] "iteration number: "
[1] 346
[1] "iteration number: "
[1] 347
[1] "iteration number: "
[1] 348
[1] "iteration number: "
[1] 349
[1] "iteration number: "
[1] 350
[1] "iteration number: "
[1] 351
[1] "iteration number: "
[1] 352
[1] "iteration number: "
[1] 353
[1] "iteration number: "
[1] 354
[1] "iteration number: "
[1] 355
[1] "iteration number: "
[1] 356
[1] "iteration number: "
[1] 357
[1] "iteration number: "
[1] 358
[1] "iteration number: "
[1] 359
[1] "iteration number: "
[1] 360
[1] "iteration number: "
[1] 361
[1] "iteration number: "
[1] 362
[1] "iteration number: "
[1] 363
[1] "iteration number: "
[1] 364
[1] "iteration number: "
[1] 365
[1] "iteration number: "
[1] 366
[1] "iteration number: "
[1] 367
[1] "iteration number: "
[1] 368
[1] "iteration number: "
[1] 369
[1] "iteration number: "
[1] 370
[1] "iteration number: "
[1] 371
[1] "iteration number: "
[1] 372
[1] "iteration number: "
[1] 373
[1] "iteration number: "
[1] 374
[1] "iteration number: "
[1] 375
[1] "iteration number: "
[1] 376
[1] "iteration number: "
[1] 377
[1] "iteration number: "
[1] 378
[1] "iteration number: "
[1] 379
[1] "iteration number: "
[1] 380
[1] "No change for 11 iterations. Exiting PSO."
[1] "##################################"
[1] "Results summary for itr:10"
[1] "number of features selected using population mean"
[1] 27
[1] "number of features selected using current global best"
[1] 27
[1] "feat ind length"
[1] 27
[1] "best accuracy"
[1] 34.07724
[1] "test acc:0.776315789473684"
[1] "##################################"
[1] "testacc"
 [1] 0.7894737 0.7236842 0.8026316 0.7631579 0.7763158 0.6842105 0.7631579
 [8] 0.7631579 0.6710526 0.7763158
[1] 0.7513158
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.6711  0.7336  0.7632  0.7513  0.7763  0.8026 
[1] 0.04405658
           [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
cg01623438    1    1    0    1    0    1    1    1    0     1
cg02181506    0    1    0    1    0    0    1    1    0     1
cg02240622    0    0    0    1    0    0    0    0    0     1
cg02679745    1    0    1    1    0    0    0    1    0     1
cg02848777    0    0    1    1    1    1    1    0    0     1
cg04059714    1    0    1    1    1    1    1    1    1     1
cg05253159    0    0    0    0    1    0    0    1    0     1
cg06197006    1    1    1    1    1    0    0    1    1     1
cg07327347    1    1    1    1    1    0    0    1    1     1
cg09419670    1    0    1    1    1    0    1    1    1     1
cg09453737    1    1    0    1    0    1    1    1    1     1
cg09624565    0    0    0    0    0    0    0    0    0     1
cg12437481    1    1    1    1    0    0    0    0    0     1
cg12943082    0    0    1    1    1    1    0    1    1     1
cg14822966    1    1    0    0    1    0    0    0    0     1
cg15288179    1    0    1    0    1    0    0    0    1     1
cg16106497    0    1    1    0    1    0    1    0    1     1
cg16743781    0    1    0    0    1    0    0    1    1     1
cg17901463    0    1    1    1    0    1    1    0    1     0
cg20022541    0    1    1    1    1    0    1    1    1     1
cg20540428    1    0    1    1    1    1    0    1    0     0
cg23002907    1    1    1    1    1    1    1    1    1     1
cg23067535    1    1    1    1    1    0    1    1    0     1
cg23090046    1    1    1    1    0    1    0    0    1     1
cg23629496    1    0    0    0    1    0    0    0    1     1
cg24428042    0    1    0    0    0    1    0    0    1     1
cg24532669    1    1    1    1    1    0    1    1    0     1
cg25634666    0    1    0    0    1    0    0    0    1     0
cg26661623    0    0    1    1    1    1    1    1    1     1
cg27394566    1    1    1    1    1    1    1    1    1     1
cg27485921    0    1    0    0    0    0    0    0    0     0
[1] "dim of scoring matrix is "
[1] 31 10
[1] "DS index stage 2"
[1] 0.6502866
[1] "KI index stage 2"
[1] -Inf
[1] 1
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15 25
[26] 26  7 28  3 12 31
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 cg23629496 cg24428042 cg05253159 cg25634666 
         5          5          4          4          4          3          3 
cg02240622 cg09624565 cg27485921 
         2          1          1 
 [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1] 0.8928571 0.8241758
[1] 0.8928571 0.8241758
[1] "accuracy: 75.4524594151086 num_feat:31 fitness:59.1050944714686"
$fitfunc
[1] -59.10509

$cverror
[1] 75.45246

$cvpermerror
[1] 51.64973

$testacc
[1] 90.20801

$reverseacc
[1] 85.85165

[1] -59.10509
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15 25
[26] 26  7 28  3 12
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 cg23629496 cg24428042 cg05253159 cg25634666 
         5          5          4          4          4          3          3 
cg02240622 cg09624565 
         2          1 
 [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
[1] 0.8928571 0.8351648
[1] 0.8928571 0.8351648
[1] "accuracy: 75.9555958936736 num_feat:30 fitness:59.0975359399636"
$fitfunc
[1] -59.09754

$cverror
[1] 75.9556

$cvpermerror
[1] 53.44281

$testacc
[1] 90.20801

$reverseacc
[1] 86.4011

[1] -59.09754
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15 25
[26] 26  7 28  3
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 cg23629496 cg24428042 cg05253159 cg25634666 
         5          5          4          4          4          3          3 
cg02240622 
         2 
 [1] 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
[1] 0.8928571 0.8351648
[1] 0.8928571 0.8351648
[1] "accuracy: 76.0049624686279 num_feat:29 fitness:59.1307878163519"
$fitfunc
[1] -59.13079

$cverror
[1] 76.00496

$cvpermerror
[1] 53.6024

$testacc
[1] 90.20801

$reverseacc
[1] 86.4011

[1] -59.13079
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15 25
[26] 26  7 28
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 cg23629496 cg24428042 cg05253159 cg25634666 
         5          5          4          4          4          3          3 
 [1] 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
[1] 0.8928571 0.8186813
[1] 0.8928571 0.8186813
[1] "accuracy: 76.4924197066304 num_feat:28 fitness:59.6308912467847"
$fitfunc
[1] -59.63089

$cverror
[1] 76.49242

$cvpermerror
[1] 53.66069

$testacc
[1] 90.48273

$reverseacc
[1] 85.57692

[1] -59.63089
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15 25
[26] 26  7
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 cg23629496 cg24428042 cg05253159 
         5          5          4          4          4          3 
 [1] 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0
[1] 0.8979592 0.8186813
[1] 0.8979592 0.8186813
[1] "accuracy: 76.5463488830367 num_feat:27 fitness:59.6557861209964"
$fitfunc
[1] -59.65579

$cverror
[1] 76.54635

$cvpermerror
[1] 53.8717

$testacc
[1] 90.73783

$reverseacc
[1] 85.83203

[1] -59.65579
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15 25
[26] 26
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 cg23629496 cg24428042 
         5          5          4          4          4 
 [1] 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0
[1] 0.8877551 0.8186813
[1] 0.8877551 0.8186813
[1] "accuracy: 76.3845404921528 num_feat:26 fitness:59.4134537120348"
$fitfunc
[1] -59.41345

$cverror
[1] 76.38454

$cvpermerror
[1] 54.2792

$testacc
[1] 91.52276

$reverseacc
[1] 85.32182

[1] -59.41345
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15 25
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 cg23629496 
         5          5          4          4 
 [1] 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0
[1] 0.8775510 0.8131868
[1] 0.8775510 0.8131868
[1] "accuracy: 76.5393580224775 num_feat:25 fitness:59.5321622836282"
$fitfunc
[1] -59.53216

$cverror
[1] 76.53936

$cvpermerror
[1] 54.47445

$testacc
[1] 90.69859

$reverseacc
[1] 84.53689

[1] -59.53216
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18 15
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 cg14822966 
         5          5          4 
 [1] 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0
[1] 0.8673469 0.8406593
[1] 0.8673469 0.8406593
[1] "accuracy: 75.8075704961218 num_feat:24 fitness:58.9981240295483"
$fitfunc
[1] -58.99812

$cverror
[1] 75.80757

$cvpermerror
[1] 53.94002

$testacc
[1] 90.48273

$reverseacc
[1] 85.40031

[1] -58.99812
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16 18
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 cg16743781 
         5          5 
 [1] 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0
[1] 0.8571429 0.8296703
[1] 0.8571429 0.8296703
[1] "accuracy: 76.3870606774915 num_feat:23 fitness:59.6922603961285"
$fitfunc
[1] -59.69226

$cverror
[1] 76.38706

$cvpermerror
[1] 53.64673

$testacc
[1] 90.50235

$reverseacc
[1] 84.34066

[1] -59.69226
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13 16
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
cg15288179 
         5 
 [1] 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0
[1] 0.8622449 0.8186813
[1] 0.8622449 0.8186813
[1] "accuracy: 77.0935432959226 num_feat:22 fitness:60.6455721193639"
$fitfunc
[1] -60.64557

$cverror
[1] 77.09354

$cvpermerror
[1] 52.88047

$testacc
[1] 89.67818

$reverseacc
[1] 84.04631

[1] -60.64557
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4 13
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 cg12437481 
         6          6          6          6          5          5          5 
 [1] 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0
[1] 0.8571429 0.8186813
[1] 0.8571429 0.8186813
[1] "accuracy: 77.1704954990452 num_feat:21 fitness:60.9555869934782"
$fitfunc
[1] -60.95559

$cverror
[1] 77.1705

$cvpermerror
[1] 52.16538

$testacc
[1] 88.38305

$reverseacc
[1] 83.79121

[1] -60.95559
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2  4
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 cg02679745 
         6          6          6          6          5          5 
 [1] 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0
[1] 0.8520408 0.8406593
[1] 0.8520408 0.8406593
[1] "accuracy: 78.034413634343 num_feat:20 fitness:61.792793593892"
$fitfunc
[1] -61.79279

$cverror
[1] 78.03441

$cvpermerror
[1] 52.33315

$testacc
[1] 88.38305

$reverseacc
[1] 84.63501

[1] -61.79279
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21  2
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 cg02181506 
         6          6          6          6          5 
 [1] 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0
[1] 0.8520408 0.8461538
[1] 0.8520408 0.8461538
[1] "accuracy: 78.2718382488409 num_feat:19 fitness:61.9174250148054"
$fitfunc
[1] -61.91743

$cverror
[1] 78.27184

$cvpermerror
[1] 52.80874

$testacc
[1] 88.38305

$reverseacc
[1] 84.90973

[1] -61.91743
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19 21
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 cg20540428 
         6          6          6          6 
 [1] 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0
[1] 0.8367347 0.8516484
[1] 0.8367347 0.8516484
[1] "accuracy: 78.4524069826504 num_feat:18 fitness:62.0289531463255"
$fitfunc
[1] -62.02895

$cverror
[1] 78.45241

$cvpermerror
[1] 53.13188

$testacc
[1] 88.12794

$reverseacc
[1] 84.41915

[1] -62.02895
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17 19
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 cg17901463 
         6          6          6 
 [1] 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0
[1] 0.8571429 0.8626374
[1] 0.8571429 0.8626374
[1] "accuracy: 78.1092040685989 num_feat:17 fitness:61.899526319072"
$fitfunc
[1] -61.89953

$cverror
[1] 78.1092

$cvpermerror
[1] 52.54873

$testacc
[1] 88.44192

$reverseacc
[1] 85.98901

[1] -61.89953
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5 17
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 cg16106497 
         6          6 
 [1] 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0
[1] 0.8265306 0.8461538
[1] 0.8265306 0.8461538
[1] "accuracy: 77.9444292281956 num_feat:16 fitness:61.6376948199758"
$fitfunc
[1] -61.63769

$cverror
[1] 77.94443

$cvpermerror
[1] 52.93948

$testacc
[1] 87.06829

$reverseacc
[1] 83.63422

[1] -61.63769
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24  5
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
cg02848777 
         6 
 [1] 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0
[1] 0.8724490 0.8241758
[1] 0.8724490 0.8241758
[1] "accuracy: 77.0030427086752 num_feat:15 fitness:60.8310598357711"
$fitfunc
[1] -60.83106

$cverror
[1] 77.00304

$cvpermerror
[1] 52.62987

$testacc
[1] 87.08791

$reverseacc
[1] 84.83124

[1] -60.83106
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14 24
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 cg23090046 
         8          8          8          8          7          7          7 
 [1] 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0
[1] 0.8214286 0.8021978
[1] 0.8214286 0.8021978
[1] "accuracy: 77.2124487588789 num_feat:14 fitness:61.2017620174035"
$fitfunc
[1] -61.20176

$cverror
[1] 77.21245

$cvpermerror
[1] 52.21631

$testacc
[1] 87.79435

$reverseacc
[1] 81.18132

[1] -61.20176
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1 14
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 cg12943082 
         8          8          8          8          7          7 
 [1] 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0
[1] 0.8163265 0.8186813
[1] 0.8163265 0.8186813
[1] "accuracy: 76.633662377811 num_feat:13 fitness:60.5761118517636"
$fitfunc
[1] -60.57611

$cverror
[1] 76.63366

$cvpermerror
[1] 52.45617

$testacc
[1] 86.49922

$reverseacc
[1] 81.75039

[1] -60.57611
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29  1
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 cg01623438 
         8          8          8          8          7 
 [1] 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0
[1] 0.8163265 0.8021978
[1] 0.8163265 0.8021978
[1] "accuracy: 75.49373522373 num_feat:12 fitness:59.4864403404601"
$fitfunc
[1] -59.48644

$cverror
[1] 75.49374

$cvpermerror
[1] 52.43352

$testacc
[1] 86.47959

$reverseacc
[1] 80.92622

[1] -59.48644
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27 29
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 cg26661623 
         8          8          8          8 
 [1] 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0
[1] 0.8112245 0.7692308
[1] 0.8112245 0.7692308
[1] "accuracy: 71.5062093784341 num_feat:11 fitness:55.5516916214842"
$fitfunc
[1] -55.55169

$cverror
[1] 71.50621

$cvpermerror
[1] 52.40189

$testacc
[1] 83.59498

$reverseacc
[1] 79.02276

[1] -55.55169
[1] "bestgenelist"
 [1] 22 30  6  8  9 10 11 20 23 27
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 cg24532669 
         8          8          8 
 [1] 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0
[1] 0.8061224 0.7252747
[1] 0.8061224 0.7252747
[1] "accuracy: 67.1193972172964 num_feat:10 fitness:50.9015329459493"
$fitfunc
[1] -50.90153

$cverror
[1] 67.1194

$cvpermerror
[1] 53.35882

$testacc
[1] 78.35557

$reverseacc
[1] 76.56986

[1] -50.90153
[1] "bestgenelist"
[1] 22 30  6  8  9 10 11 20 23
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 cg23067535 
         8          8 
 [1] 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0
[1] 0.7857143 0.7472527
[1] 0.7857143 0.7472527
[1] "accuracy: 67.5040046944491 num_feat:9 fitness:51.614831579012"
$fitfunc
[1] -51.61483

$cverror
[1] 67.504

$cvpermerror
[1] 52.38405

$testacc
[1] 79.1405

$reverseacc
[1] 76.64835

[1] -51.61483
[1] "bestgenelist"
[1] 22 30  6  8  9 10 11 20
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
cg20022541 
         8 
 [1] 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
[1] 0.7653061 0.7252747
[1] 0.7653061 0.7252747
[1] "accuracy: 67.3815271111137 num_feat:8 fitness:51.6681772471647"
$fitfunc
[1] -51.66818

$cverror
[1] 67.38153

$cvpermerror
[1] 51.81081

$testacc
[1] 76.17739

$reverseacc
[1] 74.52904

[1] -51.66818
[1] "bestgenelist"
[1] 22 30  6  8  9 10 11
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 cg09453737 
        10         10          9          8          8          8          8 
 [1] 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0
[1] 0.7806122 0.6813187
[1] 0.7806122 0.6813187
[1] "accuracy: 65.6318320473191 num_feat:7 fitness:49.7009239327006"
$fitfunc
[1] -49.70092

$cverror
[1] 65.63183

$cvpermerror
[1] 52.677

$testacc
[1] 75.43171

$reverseacc
[1] 73.09655

[1] -49.70092
[1] "bestgenelist"
[1] 22 30  6  8  9 10
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 cg09419670 
        10         10          9          8          8          8 
 [1] 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0
[1] 0.8367347 0.5769231
[1] 0.8367347 0.5769231
[1] "accuracy: 63.7606299307525 num_feat:6 fitness:48.3836588621239"
$fitfunc
[1] -48.38366

$cverror
[1] 63.76063

$cvpermerror
[1] 50.88532

$testacc
[1] 71.97802

$reverseacc
[1] 70.68289

[1] -48.38366
[1] "bestgenelist"
[1] 22 30  6  8  9
cg23002907 cg27394566 cg04059714 cg06197006 cg07327347 
        10         10          9          8          8 
 [1] 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0
[1] 0.8418367 0.5714286
[1] 0.8418367 0.5714286
[1] "accuracy: 63.0286744250681 num_feat:5 fitness:47.688165094397"
$fitfunc
[1] -47.68817

$cverror
[1] 63.02867

$cvpermerror
[1] 50.85254

$testacc
[1] 70.68289

$reverseacc
[1] 70.66327

[1] -47.68817
[1] "bestgenelist"
[1] 22 30  6  8
cg23002907 cg27394566 cg04059714 cg06197006 
        10         10          9          8 
 [1] 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0
[1] 0.8265306 0.5714286
[1] 0.8265306 0.5714286
[1] "accuracy: 64.0262575095798 num_feat:4 fitness:48.5935397286937"
$fitfunc
[1] -48.59354

$cverror
[1] 64.02626

$cvpermerror
[1] 51.23483

$testacc
[1] 70.70251

$reverseacc
[1] 69.89796

[1] -48.59354
[1] "bestgenelist"
[1] 22 30  6
cg23002907 cg27394566 cg04059714 
        10         10          9 
 [1] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0
[1] 0.7959184 0.5384615
[1] 0.7959184 0.5384615
[1] "accuracy: 62.2749033865205 num_feat:3 fitness:46.518951644094"
$fitfunc
[1] -46.51895

$cverror
[1] 62.2749

$cvpermerror
[1] 52.35586

$testacc
[1] 67.03297

$reverseacc
[1] 66.719

[1] -46.51895
[1] "bestgenelist"
[1] 22 30
cg23002907 cg27394566 
        10         10 
 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0
[1] "accuracy: 1 num_feat:2 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
[1] "bestgenelist"
[1] 22
cg23002907 
        10 
 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
[1] "accuracy: 1 num_feat:1 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
[1] "Number of features selected in 1 iterations:"
[1] 31
[1] "Modified train 10 fold accuracy using train data is "
[1] 77.24868
[1] "Modified train accuracy is "
[1] 0.9021164
[1] "train confusion matrix is "
          trainclass
pred_train   1   2
         1 177  18
         2  19 164
[1] "Train dimension is "
[1] 378  31
[1] "Test dimension is "
[1] 162  31
[1] "Test confusion matrix is "
    
pred  1  2
   1 52 28
   2 26 56
[1] "Test acc is "
[1] 0.6666667
[1] "train 10 fold"
[1] 75.66138
[1] "Test confusion matrix is "
    
pred  1  2
   1 52 28
   2 26 56
[1] "Test acc is "
[1] 0.6666667
[1] "Test AUC:"
[1] 0.6666667
[1] "Train acc is "
[1] 0.9021164
[1] "# of features after PSO:"
[1] 378  32
     user    system   elapsed 
  332.614   269.447 34662.379 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> 
> 
> feat_ind<-psores$bestfeatlist
> feat_names<-psores$bestfeatnames
> 
> scoringmatrix<-as.data.frame(psores$scoringmatrix)
> print(scoringmatrix)
           V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
cg01623438  1  1  0  1  0  1  1  1  0   1
cg02181506  0  1  0  1  0  0  1  1  0   1
cg02240622  0  0  0  1  0  0  0  0  0   1
cg02679745  1  0  1  1  0  0  0  1  0   1
cg02848777  0  0  1  1  1  1  1  0  0   1
cg04059714  1  0  1  1  1  1  1  1  1   1
cg05253159  0  0  0  0  1  0  0  1  0   1
cg06197006  1  1  1  1  1  0  0  1  1   1
cg07327347  1  1  1  1  1  0  0  1  1   1
cg09419670  1  0  1  1  1  0  1  1  1   1
cg09453737  1  1  0  1  0  1  1  1  1   1
cg09624565  0  0  0  0  0  0  0  0  0   1
cg12437481  1  1  1  1  0  0  0  0  0   1
cg12943082  0  0  1  1  1  1  0  1  1   1
cg14822966  1  1  0  0  1  0  0  0  0   1
cg15288179  1  0  1  0  1  0  0  0  1   1
cg16106497  0  1  1  0  1  0  1  0  1   1
cg16743781  0  1  0  0  1  0  0  1  1   1
cg17901463  0  1  1  1  0  1  1  0  1   0
cg20022541  0  1  1  1  1  0  1  1  1   1
cg20540428  1  0  1  1  1  1  0  1  0   0
cg23002907  1  1  1  1  1  1  1  1  1   1
cg23067535  1  1  1  1  1  0  1  1  0   1
cg23090046  1  1  1  1  0  1  0  0  1   1
cg23629496  1  0  0  0  1  0  0  0  1   1
cg24428042  0  1  0  0  0  1  0  0  1   1
cg24532669  1  1  1  1  1  0  1  1  0   1
cg25634666  0  1  0  0  1  0  0  0  1   0
cg26661623  0  0  1  1  1  1  1  1  1   1
cg27394566  1  1  1  1  1  1  1  1  1   1
cg27485921  0  1  0  0  0  0  0  0  0   0
> print(feat_names[feat_ind])
 [1] "cg01623438" "cg02181506" "cg02240622" "cg02679745" "cg02848777"
 [6] "cg04059714" "cg05253159" "cg06197006" "cg07327347" "cg09419670"
[11] "cg09453737" "cg09624565" "cg12437481" "cg12943082" "cg14822966"
[16] "cg15288179" "cg16106497" "cg16743781" "cg17901463" "cg20022541"
[21] "cg20540428" "cg23002907" "cg23067535" "cg23090046" "cg23629496"
[26] "cg24428042" "cg24532669" "cg25634666" "cg26661623" "cg27394566"
[31] "cg27485921"
> 
> save(psores,file="psores.Rda")
> print("Complete")
[1] "Complete"
> 
