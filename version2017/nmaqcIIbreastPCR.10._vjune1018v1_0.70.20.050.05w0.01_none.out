
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/kuppal3/karan_libs/Rlibs")
> library(snow)
Warning message:
package ‘snow’ was built under R version 3.2.5 
> library(e1071)
Warning message:
package ‘e1071’ was built under R version 3.2.5 
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

Warning message:
package ‘pROC’ was built under R version 3.2.5 
> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
Warning message:
package ‘RankAggreg’ was built under R version 3.2.5 
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

Warning message:
package ‘CMA’ was built under R version 3.2.4 
> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

Warning messages:
1: package ‘expm’ was built under R version 3.2.5 
2: package ‘Matrix’ was built under R version 3.2.5 
> 
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> 
> dirloc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/"
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/versionnov2014/OCFS_",args[9],".R",sep="")
> 
> sname<-paste(dirloc,"version2017/OCFS_",args[9],".R",sep="")
> source(sname)
> 
> outloc<-paste(dirloc,"/Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCER",args[9],"/",sep="")
> 
> 
> sname<-paste(dirloc,"Datasets/MAQCII_BreastCancer/MaqcIIbr.Rda",sep="")
> load(sname)
> 
> trainm<-MaqcIIbr$trainx
> testm<-MaqcIIbr$testx
> trainclass<-MaqcIIbr$trainPCRvsRD
> testclass<-MaqcIIbr$testPCRvsRD
> 
> trainm<-trainm[,-c(22284)]
> testm<-testm[,-c(22284)]
> trainm<-apply(trainm,2,as.numeric)
> testm<-apply(testm,2,as.numeric)
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvjune102018_v1' already exists
> setwd(outloc)
> 
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvjune102018_v1' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> #if(FALSE)
> {
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  3155  3455  3490  4352  4752  5927  8667 13543 15240 18415
     203628_at 203928_x_at 203963_at 204825_at 205225_at 206401_s_at 209173_at
[1,]   10.7755      9.6578   12.0638    8.9393   13.0759      9.9796   12.9392
[2,]    9.8410      9.9980   11.3553    7.7652   13.7616      9.9498   14.1501
[3,]    9.4169      6.2526   12.3832    9.9136   12.7360      6.0807   14.5585
     214164_x_at 215867_x_at 219051_x_at
[1,]     12.6474     12.6194      8.5236
[2,]     11.7852     11.5534      8.9626
[3,]     12.7464     12.7285     10.7458
     203628_at 203928_x_at 203963_at 204825_at 205225_at 206401_s_at 209173_at
[1,]    9.4326     10.9860   12.4052    7.9851   13.8754     10.6463   13.2041
[2,]    9.8046      8.1054   10.4033    5.2744   11.7217      8.2532   11.3631
[3,]    7.9079      8.3152    9.8307    5.9481   10.9960      7.4477   11.1800
     214164_x_at 215867_x_at 219051_x_at
[1,]     12.7392     12.5744      9.5138
[2,]     10.9092     11.0575      5.3641
[3,]     10.6696     11.0769      7.1097
[1] "numgenes selected:10"
[1] "test acc:0.75"
[1] "test AUC acc:0.743137254901961"
[1] "10 fold train81.5384615384615"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 22  8
         2 11 89
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 11 21
        2  4 64
[1] "train acc:0.853846153846154"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 22  8
         2 11 89
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
Loaded glmnet 2.0-10


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
 1083 15464  2667  4208  8166 11253 11968  2211  4756  8207 18226  1326  1732 
    9     8     7     7     7     6     6     4     3     3     3     2     2 
 3155  4352  4874  5278 18415 20137  2841  3223  4349  7691  8292  8550 10271 
    2     2     2     2     2     2     1     1     1     1     1     1     1 
10980 12226 12517 16398 16738 18220 18313 18456 18802 19380 20350 20616 21064 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
21615 
    1 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  1083  2211  2667  4208  4756  8166  8207 11253 11968 15464
     201555_at 202683_s_at 203139_at 204681_s_at 205229_s_at 208670_s_at
[1,]    9.9323      8.8393    9.7965      7.5046      6.8695      8.6539
[2,]    9.5628      8.4030    8.3696      8.7229      5.4533      9.5953
[3,]   10.3905      8.3998    9.0933      6.9584      6.2767      9.8134
     208712_at 211864_s_at 212583_at 216092_s_at
[1,]   10.9476     10.7931    6.8476     10.4159
[2,]   11.4622      9.0349    6.8369      9.7648
[3,]   10.4996     10.4934    7.3452      8.3641
     201555_at 202683_s_at 203139_at 204681_s_at 205229_s_at 208670_s_at
[1,]    9.9499      8.8732    8.8140      8.7098      5.2668      8.8319
[2,]    9.6616      8.5511    8.7652      8.1223      7.1769      9.8519
[3,]    9.4638      8.5826    9.4426      7.5006      6.9284      9.3521
     208712_at 211864_s_at 212583_at 216092_s_at
[1,]   10.8225      9.2348    7.5912     10.6963
[2,]    9.8721     10.1938    7.5112      9.3780
[3,]   10.2362      8.4931    4.6920      9.3840
[1] "numgenes selected:10"
[1] "test acc:0.76"
[1] "test AUC acc:0.666666666666667"
[1] "10 fold train90.7692307692308"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 28  2
         2  5 95
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1  8 17
        2  7 68
[1] "train acc:0.946153846153846"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 28  2
         2  5 95
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  4756  5005  5223  5240  5278  5357  5927  8388  8667 13990
     205229_s_at 205478_at 205696_s_at 205713_s_at 205751_at 205830_at
[1,]      6.8695    7.9799     11.6168     10.0607    5.3569    9.0445
[2,]      5.4533    6.0596      9.5737      5.6228    3.7733    9.6145
[3,]      6.2767    5.5057      7.2600      6.8404    2.5009    7.0195
     206401_s_at 208893_s_at 209173_at 214612_x_at
[1,]      9.9796      4.0949   12.9392      6.0516
[2,]      9.9498      9.2703   14.1501      5.7915
[3,]      6.0807      3.9487   14.5585      3.4135
     205229_s_at 205478_at 205696_s_at 205713_s_at 205751_at 205830_at
[1,]      5.2668    4.8386      9.0616      5.2933    5.4450    8.7696
[2,]      7.1769   11.9784      7.7288      4.3142    6.3482    7.0550
[3,]      6.9284   12.5884      7.1560      4.5240    6.0619    6.8984
     206401_s_at 208893_s_at 209173_at 214612_x_at
[1,]     10.6463      7.6049   13.2041      6.2012
[2,]      8.2532      8.9154   11.3631      7.0485
[3,]      7.4477      9.1121   11.1800      5.5564
[1] "numgenes selected:10"
[1] "test acc:0.8"
[1] "test AUC acc:0.635294117647059"
[1] "10 fold train85.3846153846154"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 26  3
         2  7 94
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1  6 11
        2  9 74
[1] "train acc:0.923076923076923"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 26  3
         2  7 94
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  1083  2667  3155  4352  4874  8166  8207 11253 11968 15464
     201555_at 203139_at 203628_at 204825_at 205347_s_at 208670_s_at 208712_at
[1,]    9.9323    9.7965   10.7755    8.9393      7.7184      8.6539   10.9476
[2,]    9.5628    8.3696    9.8410    7.7652      7.0526      9.5953   11.4622
[3,]   10.3905    9.0933    9.4169    9.9136      7.7606      9.8134   10.4996
     211864_s_at 212583_at 216092_s_at
[1,]     10.7931    6.8476     10.4159
[2,]      9.0349    6.8369      9.7648
[3,]     10.4934    7.3452      8.3641
     201555_at 203139_at 203628_at 204825_at 205347_s_at 208670_s_at 208712_at
[1,]    9.9499    8.8140    9.4326    7.9851      8.3232      8.8319   10.8225
[2,]    9.6616    8.7652    9.8046    5.2744      7.4873      9.8519    9.8721
[3,]    9.4638    9.4426    7.9079    5.9481      8.2573      9.3521   10.2362
     211864_s_at 212583_at 216092_s_at
[1,]      9.2348    7.5912     10.6963
[2,]     10.1938    7.5112      9.3780
[3,]      8.4931    4.6920      9.3840
[1] "numgenes selected:10"
[1] "test acc:0.76"
[1] "test AUC acc:0.72156862745098"
[1] "10 fold train86.9230769230769"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 26  3
         2  7 94
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 10 19
        2  5 66
[1] "train acc:0.923076923076923"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 26  3
         2  7 94
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  3155  3490  4352  4752  5927  8667 13543 15240 15464 18415
     203628_at 203963_at 204825_at 205225_at 206401_s_at 209173_at 214164_x_at
[1,]   10.7755   12.0638    8.9393   13.0759      9.9796   12.9392     12.6474
[2,]    9.8410   11.3553    7.7652   13.7616      9.9498   14.1501     11.7852
[3,]    9.4169   12.3832    9.9136   12.7360      6.0807   14.5585     12.7464
     215867_x_at 216092_s_at 219051_x_at
[1,]     12.6194     10.4159      8.5236
[2,]     11.5534      9.7648      8.9626
[3,]     12.7285      8.3641     10.7458
     203628_at 203963_at 204825_at 205225_at 206401_s_at 209173_at 214164_x_at
[1,]    9.4326   12.4052    7.9851   13.8754     10.6463   13.2041     12.7392
[2,]    9.8046   10.4033    5.2744   11.7217      8.2532   11.3631     10.9092
[3,]    7.9079    9.8307    5.9481   10.9960      7.4477   11.1800     10.6696
     215867_x_at 216092_s_at 219051_x_at
[1,]     12.5744     10.6963      9.5138
[2,]     11.0575      9.3780      5.3641
[3,]     11.0769      9.3840      7.1097
[1] "numgenes selected:10"
[1] "test acc:0.73"
[1] "test AUC acc:0.731372549019608"
[1] "10 fold train80.7692307692308"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 26  6
         2  7 91
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 11 23
        2  4 62
[1] "train acc:0.9"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 26  6
         2  7 91
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
There were 33 warnings (use warnings() to see them)
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.5,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
 1083 15464  2667  4208  8166 11253 11968  2211  4756  8207 18226  1326  1732 
    9     8     7     7     7     6     6     4     3     3     3     2     2 
 3155  4352  4874  5278 18415 20137  2841  3223  4349  7691  8292  8550 10271 
    2     2     2     2     2     2     1     1     1     1     1     1     1 
10980 12226 12517 16398 16738 18220 18313 18456 18802 19380 20350 20616 21064 
    1     1     1     1     1     1     1     1     1     1     1     1     1 
21615 
    1 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     5
[1] 22283
[1] "DS index stage 1"
[1] 0.27
[1] "bestgenelist"
 [1]  1083  2211  2667  3155  3455  3490  4208  4352  4752  4756  4874  5005
[13]  5223  5240  5278  5357  5927  8166  8207  8388  8667 11253 11968 13543
[25] 13990 15240 15464 18415
     201555_at 202683_s_at 203139_at 203628_at 203928_x_at 203963_at
[1,]    9.9323      8.8393    9.7965   10.7755      9.6578   12.0638
[2,]    9.5628      8.4030    8.3696    9.8410      9.9980   11.3553
[3,]   10.3905      8.3998    9.0933    9.4169      6.2526   12.3832
     204681_s_at 204825_at 205225_at 205229_s_at 205347_s_at 205478_at
[1,]      7.5046    8.9393   13.0759      6.8695      7.7184    7.9799
[2,]      8.7229    7.7652   13.7616      5.4533      7.0526    6.0596
[3,]      6.9584    9.9136   12.7360      6.2767      7.7606    5.5057
     205696_s_at 205713_s_at 205751_at 205830_at 206401_s_at 208670_s_at
[1,]     11.6168     10.0607    5.3569    9.0445      9.9796      8.6539
[2,]      9.5737      5.6228    3.7733    9.6145      9.9498      9.5953
[3,]      7.2600      6.8404    2.5009    7.0195      6.0807      9.8134
     208712_at 208893_s_at 209173_at 211864_s_at 212583_at 214164_x_at
[1,]   10.9476      4.0949   12.9392     10.7931    6.8476     12.6474
[2,]   11.4622      9.2703   14.1501      9.0349    6.8369     11.7852
[3,]   10.4996      3.9487   14.5585     10.4934    7.3452     12.7464
     214612_x_at 215867_x_at 216092_s_at 219051_x_at
[1,]      6.0516     12.6194     10.4159      8.5236
[2,]      5.7915     11.5534      9.7648      8.9626
[3,]      3.4135     12.7285      8.3641     10.7458
     201555_at 202683_s_at 203139_at 203628_at 203928_x_at 203963_at
[1,]    9.9499      8.8732    8.8140    9.4326     10.9860   12.4052
[2,]    9.6616      8.5511    8.7652    9.8046      8.1054   10.4033
[3,]    9.4638      8.5826    9.4426    7.9079      8.3152    9.8307
     204681_s_at 204825_at 205225_at 205229_s_at 205347_s_at 205478_at
[1,]      8.7098    7.9851   13.8754      5.2668      8.3232    4.8386
[2,]      8.1223    5.2744   11.7217      7.1769      7.4873   11.9784
[3,]      7.5006    5.9481   10.9960      6.9284      8.2573   12.5884
     205696_s_at 205713_s_at 205751_at 205830_at 206401_s_at 208670_s_at
[1,]      9.0616      5.2933    5.4450    8.7696     10.6463      8.8319
[2,]      7.7288      4.3142    6.3482    7.0550      8.2532      9.8519
[3,]      7.1560      4.5240    6.0619    6.8984      7.4477      9.3521
     208712_at 208893_s_at 209173_at 211864_s_at 212583_at 214164_x_at
[1,]   10.8225      7.6049   13.2041      9.2348    7.5912     12.7392
[2,]    9.8721      8.9154   11.3631     10.1938    7.5112     10.9092
[3,]   10.2362      9.1121   11.1800      8.4931    4.6920     10.6696
     214612_x_at 215867_x_at 216092_s_at 219051_x_at
[1,]      6.2012     12.5744     10.6963      9.5138
[2,]      7.0485     11.0575      9.3780      5.3641
[3,]      5.5564     11.0769      9.3840      7.1097
[1] "numgenes selected:28"
[1] "test acc:0.8"
[1] "test AUC acc:0.690196078431373"
[1] "10 fold train93.8461538461538"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 33  1
         2  0 96
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1  8 13
        2  7 72
[1] "train acc:0.992307692307692"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 33  1
         2  0 96
[1] "DS index stage 1"
[1] 0.27
[1] "KI index stage 1"
[1] 0.2696722
[[1]]
 [1] "var3155"  "var3455"  "var3490"  "var4352"  "var4752"  "var5927" 
 [7] "var8667"  "var13543" "var15240" "var18415"

[[2]]
 [1] "var1083"  "var2211"  "var2667"  "var4208"  "var4756"  "var8166" 
 [7] "var8207"  "var11253" "var11968" "var15464"

[[3]]
 [1] "var4756"  "var5005"  "var5223"  "var5240"  "var5278"  "var5357" 
 [7] "var5927"  "var8388"  "var8667"  "var13990"

[[4]]
 [1] "var1083"  "var2667"  "var3155"  "var4352"  "var4874"  "var8166" 
 [7] "var8207"  "var11253" "var11968" "var15464"

[[5]]
 [1] "var3155"  "var3490"  "var4352"  "var4752"  "var5927"  "var8667" 
 [7] "var13543" "var15240" "var15464" "var18415"


 Iteration 1 :  Optimal value:  66.4 
 Optimal List:   var3155,var8207,var2667,var4752,var4352,var8667,var1083,var3455,var18415,var13543 

 Iteration 2 :  Optimal value:  64 
 Optimal List:   var1083,var3155,var3490,var4352,var8667,var13543,var13990,var5927,var2211,var11253 

 Iteration 3 :  Optimal value:  63.6 
 Optimal List:   var3155,var4352,var4752,var2667,var4756,var8207,var3490,var1083,var13543,var5223 

 Iteration 4 :  Optimal value:  63.2 
 Optimal List:   var2667,var3155,var4352,var4752,var8667,var3490,var4756,var1083,var5005,var15240 

 Iteration 5 :  Optimal value:  60.8 
 Optimal List:   var4352,var3155,var3490,var2667,var8667,var5927,var4756,var13543,var8166,var18415 

 Iteration 6 :  Optimal value:  61.2 
 Optimal List:   var1083,var3155,var3490,var2667,var5927,var4352,var8667,var8388,var18415,var4208 

 Iteration 7 :  Optimal value:  60.8 
 Optimal List:   var1083,var3155,var4352,var8166,var3490,var5927,var4752,var8667,var8388,var4208 

 Iteration 8 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var4756,var4352,var4752,var2667,var5927,var8667,var5240,var15464 

 Iteration 9 :  Optimal value:  59.6 
 Optimal List:   var3155,var2667,var4352,var4752,var5927,var4756,var8667,var11253,var15464,var8388 

 Iteration 10 :  Optimal value:  59.2 
 Optimal List:   var1083,var3155,var2667,var4352,var5927,var8166,var13543,var8207,var11968,var4756 

 Iteration 11 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var18415,var5357 

 Iteration 12 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var4352,var3490,var5927,var4752,var8667,var8166,var11968,var5005 

 Iteration 13 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var8667,var8207,var11253,var13543,var15464 

 Iteration 14 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var11253,var15464,var4756 

 Iteration 15 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var4352,var2667,var4756,var5927,var8667,var13543,var15464,var15240 

 Iteration 16 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var5927,var8166,var8667,var4756,var11968,var15464 

 Iteration 17 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8667,var8166,var15240,var15464 

 Iteration 18 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var8166,var8667,var13543,var11968,var15464 

 Iteration 19 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var11253,var11968,var15464 

 Iteration 20 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var4352,var2667,var3490,var5927,var8667,var11253,var11968,var15464 

 Iteration 21 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var8166,var8667,var11253,var13543,var15464 

 Iteration 22 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var8166,var8667,var11253,var11968,var15464 

 Iteration 23 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var4352,var3490,var4752,var5927,var8667,var13543,var11968,var15464 

 Iteration 24 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var8166,var8667,var11253,var11968,var15464 

 Iteration 25 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var4352,var3490,var4756,var5927,var8667,var11253,var13543,var15464 

 Iteration 26 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var3490,var8667,var11253,var11968,var15464 

 Iteration 27 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var4752,var8667,var11253,var11968,var15464 

 Iteration 28 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var4752,var8667,var11253,var11968,var15464 

 Iteration 29 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var8166,var8667,var11253,var11968,var15464 

 Iteration 30 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var5927,var8166,var8667,var8207,var11968,var15464 
[1] "test acc rank aggreg CE:0.74"
[1] "test AUC acc rank aggreg CE:0.709803921568627"
[1] "10 fold train rank aggreg res CE84.6153846153846"
[1] "confusion matrix train 10 fold rank aggreg CE"
            nci_y
pred10foldRA  1  2
           1 28  3
           2  5 94
[1] "Num itr RA CE"
[1] 30
[1] "Test BER aggreg CE is"
[1] 0.7098039

 Iteration 1 :  Optimal value:  68.8 
 Optimal List:   var3155,var4352,var8166,var4752,var5357,var8207,var1083,var2211,var11968,var2667 

 Iteration 2 :  Optimal value:  68.4 
 Optimal List:   var3155,var4352,var8166,var4752,var5357,var8207,var8667,var2211,var11968,var3455 

 Iteration 3 :  Optimal value:  68 
 Optimal List:   var3155,var4874,var4352,var4752,var1083,var15240,var8667,var8207,var8388,var5357 

 Iteration 4 :  Optimal value:  63.6 
 Optimal List:   var3155,var5005,var3490,var4352,var8667,var5927,var8207,var4752,var5357,var2211 

 Iteration 5 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 6 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 7 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 8 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 9 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 10 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 11 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 12 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 13 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 14 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 15 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 16 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 17 :  Optimal value:  59.2 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var2211 

 Iteration 18 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 19 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 20 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 21 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 22 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 23 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 24 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 25 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 26 :  Optimal value:  58.8 
 Optimal List:   var3155,var1083,var3490,var4352,var8667,var5927,var8207,var4752,var15464,var11968 

 Iteration 27 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 28 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 29 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 30 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 31 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 32 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 33 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 34 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 35 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 36 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 37 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 38 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 39 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 40 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 41 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 42 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 43 :  Optimal value:  58 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2211 

 Iteration 44 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 45 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 46 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 47 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 48 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 49 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 50 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 51 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var11968,var13543 

 Iteration 52 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 53 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 54 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var15464,var13543 

 Iteration 55 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 56 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var15464,var13543 

 Iteration 57 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var15464,var13543 

 Iteration 58 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 59 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 60 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var15464,var13543 

 Iteration 61 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var15464,var13543 

 Iteration 62 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var11968 

 Iteration 63 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var15464,var13543 

 Iteration 64 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 65 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var13543,var15464 

 Iteration 66 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var13543,var15464 

 Iteration 67 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var13543,var15464 

 Iteration 68 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var13543,var15464 

 Iteration 69 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var4756,var8667,var13543,var15464 

 Iteration 70 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 71 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 72 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 73 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 74 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 75 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var15464,var13543 

 Iteration 76 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 77 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 78 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 79 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 80 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8667,var8207,var15464,var13543 

 Iteration 81 :  Optimal value:  57.6 
 Optimal List:   var1083,var3155,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 82 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 83 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 84 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 85 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 86 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 87 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 88 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 89 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 90 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 91 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 92 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 93 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 94 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8166,var8667,var4756,var4752 

 Iteration 95 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var13543 

 Iteration 96 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var2667,var4352,var3490,var5927,var8207,var8667,var15464,var13543 

 Iteration 97 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var13543,var15464 

 Iteration 98 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var13543,var15464 

 Iteration 99 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var13543,var15464 

 Iteration 100 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 101 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 102 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 103 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 104 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 105 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 106 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 107 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 108 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 109 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 110 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 111 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 112 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 113 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 114 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 115 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 116 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 117 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 118 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 119 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 120 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 121 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 122 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var2667,var15464 

 Iteration 123 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var2667,var15464 

 Iteration 124 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 125 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 126 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 127 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 128 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 129 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var15240 

 Iteration 130 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 131 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 132 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 133 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 134 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 135 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 136 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 137 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 138 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 139 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 140 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 141 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 142 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 143 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 144 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 145 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 146 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8667,var8207,var15464,var4752 

 Iteration 147 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var4752,var15464 

 Iteration 148 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var4752,var15464 

 Iteration 149 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 150 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8667,var8207,var15464,var4752 

 Iteration 151 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 152 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 153 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 154 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 155 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 156 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 157 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 158 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 159 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var11968 

 Iteration 160 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 161 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 162 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 163 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 164 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var2667,var15464 

 Iteration 165 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 166 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8667,var8207,var15464,var13543 

 Iteration 167 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 168 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 169 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var11253,var13543 

 Iteration 170 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 171 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 172 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 173 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 174 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var2667,var5927,var8207,var8667,var15464,var4752 

 Iteration 175 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8207,var8667,var15464,var4752 

 Iteration 176 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 177 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 178 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 179 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 180 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 181 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var11968 

 Iteration 182 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 183 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 184 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 185 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var13543 

 Iteration 186 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 187 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 188 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 189 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 190 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 191 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 192 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 193 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 194 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 195 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 196 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 197 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 198 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 199 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 200 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var15464,var13543 

 Iteration 201 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 202 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var4756,var13543 

 Iteration 203 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 204 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 205 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 206 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 207 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var13543,var15464 

 Iteration 208 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 209 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 210 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 211 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 212 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 213 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4756,var5927,var8166,var8667,var15464,var15240 

 Iteration 214 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 215 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var15464 

 Iteration 216 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 217 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var15240 

 Iteration 218 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 219 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var2667 

 Iteration 220 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 221 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var15240 

 Iteration 222 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 223 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 224 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var15240 

 Iteration 225 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var13543 

 Iteration 226 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var15240 

 Iteration 227 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 228 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 229 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 230 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 231 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 232 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 233 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 234 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 235 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var15464,var15240 

 Iteration 236 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 237 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 238 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 239 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 240 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var13543 

 Iteration 241 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 242 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 243 :  Optimal value:  57.2 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var15464 

 Iteration 244 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var8166,var5927,var8667,var8207,var13543 

 Iteration 245 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 

 Iteration 246 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var4756,var2667 

 Iteration 247 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 248 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 249 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 250 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 251 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var15464,var13543 

 Iteration 252 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 253 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 254 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 255 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var2667 

 Iteration 256 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var2667 

 Iteration 257 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 258 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 259 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var8207 

 Iteration 260 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 261 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 262 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var8207 

 Iteration 263 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var8207 

 Iteration 264 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var13543 

 Iteration 265 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var8207 

 Iteration 266 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var13543 

 Iteration 267 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var8207 

 Iteration 268 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var8207 

 Iteration 269 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var2667 

 Iteration 270 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var2667 

 Iteration 271 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var2667,var11253 

 Iteration 272 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var11253 

 Iteration 273 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var8207,var11253 

 Iteration 274 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var2667 

 Iteration 275 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8166,var8667,var11253,var2667 

 Iteration 276 :  Optimal value:  57.6 
 Optimal List:   var3155,var1083,var3490,var4352,var4752,var5927,var8207,var8667,var11253,var2667 
[1] "test acc rank aggreg GA:0.73"
[1] "test AUC acc rank aggreg GA:0.676470588235294"
[1] "10 fold train rank aggreg res GA85.3846153846154"
[1] "confusion matrix train 10 fold rank aggreg GA"
            nci_y
pred10foldRA  1  2
           1 26  4
           2  7 93
[1] "Num itr RA GA"
[1] 277
[1] "Test BER aggreg GA is"
[1] 0.6764706
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 130  28
> 
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=5,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.01,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=0.8))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 5"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.7"
[1] "weightB: 0.2"
[1] "weightC: 0.05"
[1] "weightD: 0.05"
[1] "featweight.max: 0.01"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.45"
[1] "confusionprob: 0.2"
[1] "leaderprob: 0.25"
[1] "wmax: 1"
[1] "wmin: 1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 10"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 10"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 92.30769
[1] "here"
[1] "s"
[1] 104
[1] 130  28
[1] 10
[1] "learning sets: 1"
  [1] 110 106  24 109  32  30  33 120 103  74  41  93  54   8  91  14  31  22
 [19]  15  29  89  66  78  43  17  46  67  49 125  58 112  36 130  92 101 123
 [37] 115  65  52  25  40  85  42 126  63 116  48 118  69   1  20   2  50  96
 [55]  73  60  68  87 102  59  82  75 114 113  16   5  34  13 111  39  28  86
 [73]  44  95  51 105  10 121  21 100  72  11  47  38  53 108  61   4 104  18
 [91]  55  64  70 124  79 122   7  77  84 127  81 107   6  71
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -41.62952
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 13
[1] "Best fitness updated to:"
[1] -42.74739
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0
[1] 6
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 12
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 11
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 11
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 11
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 11
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 11
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 11
[1] "No change for 8 iterations. Exiting PSO."
 [1]  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25 26 27 28
[1] 1
[1] "##################################"
[1] "Results summary for itr:1"
[1] "number of features selected using population mean"
[1] 11
[1] "number of features selected using current global best"
[1] 25
[1] "feat ind length"
[1] 25
[1] "best accuracy"
[1] 42.74739
[1] "test acc:0.884615384615385"
[1] "##################################"
[1] "learning sets: 2"
  [1] 120  41  14  56  22  74  66  93  54  31  91   8  43  90  46  15  24 110
 [19]  33 106   9  99  12  78  98  32  51   5  37  62  58  34 129 104  23  48
 [37]  75  39   2  18  52  27 119 117  82  36  77 116  79   3 111  38  95  70
 [55]  20  13 112  87  49  21  28  57 114  40 101 122 100  84  86  10 123  67
 [73]   6 113  44  61  68  85 118  97   7  71  45  16  47  19   4  76  53 128
 [91]  88  11  35  59  25 130  60  96  65  42  64  94 124  69
[1] "Starting global iteration number : 2"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -35.76395
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -35.85416
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1
[1] 12
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -36.75355
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0
[1] 8
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -39.93489
[1] "Best solution:"
 [1] 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0
[1] 21
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 6
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 5
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 5
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 5
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 5
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 5
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 5
[1] "No change for 8 iterations. Exiting PSO."
 [1]  2  3  5  7  8  9 10 12 13 15 16 17 18 19 21 22 23 24 25 26 27
[1] 2
[1] "##################################"
[1] "Results summary for itr:2"
[1] "number of features selected using population mean"
[1] 5
[1] "number of features selected using current global best"
[1] 21
[1] "feat ind length"
[1] 21
[1] "best accuracy"
[1] 39.93489
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 3"
  [1]   8  14  78 109 110  24  29  56   9  91  46  12  89  90  54  66  99  74
 [19]  98  17 120  32  31  93 103  30  40  45  88 102  36   6   7 105 129 111
 [37] 112 119  58  73 108  50  81  76 127  82  92 101  35 117  57 113  69  13
 [55]  20 125  10  96  47  18 130   1 115  68  75  71  87  60  72  86  42 104
 [73]  63   4  64  95  26  94  77  85  23  70  21  37  49 128   3 126  65  61
 [91] 118  39 121  38 124 107  80 114 122  79  19  28  34  11
[1] "Starting global iteration number : 3"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -42.15939
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 12
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 12
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 12
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 12
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 12
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 12
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 12
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28
[1] 3
[1] "##################################"
[1] "Results summary for itr:3"
[1] "number of features selected using population mean"
[1] 12
[1] "number of features selected using current global best"
[1] 28
[1] "feat ind length"
[1] 28
[1] "best accuracy"
[1] 42.15939
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 4"
  [1]  54  22   9  14  46  99 120  29  43  74  66  91  41 106  32  56  83  93
 [19]  78  33  12  17 109   8  31  24  42  81  20  36 113   6  73 130  94  18
 [37]  26  75   7  28  71  72 121 107 129  59  27 127  92 112  39  67  97  79
 [55] 101  50 115 102  38  10  37  64  47  96 124  86  11  61  52  95 104  35
 [73]  23   4  70   3   1 118  16  49  88 119  58  68  45 100 117  77 116  63
 [91]  69  87  34 128 108 114 122   2  48  21  85  53  80  60
[1] "Starting global iteration number : 4"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -33.19357
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -34.71711
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1
[1] 10
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -37.79518
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1
[1] 10
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -37.93558
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0
[1] 8
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 10
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -39.35233
[1] "Best solution:"
 [1] 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0
[1] 7
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 4
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 4
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 4
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 4
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 4
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 4
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 4
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 4
[1] "No change for 8 iterations. Exiting PSO."
[1]  2  3  9 13 14 15 16
[1] 4
[1] "##################################"
[1] "Results summary for itr:4"
[1] "number of features selected using population mean"
[1] 4
[1] "number of features selected using current global best"
[1] 7
[1] "feat ind length"
[1] 7
[1] "best accuracy"
[1] 39.35233
[1] "test acc:0.846153846153846"
[1] "##################################"
[1] "learning sets: 5"
  [1]  41 109  74  78  24  32  15  22  46  33  43  54 106  17  99   8  91  12
 [19] 103  29  66  93   9 110  89  98  25  23  86 108 114  77 112   4  26   6
 [37]  11 122  21  38 101  50 124  84 130  80 115  62   1  69  75  82  58  19
 [55]  18  61   2  60   3 100 113 121  28  65 117 116  57 129  63  27 125  51
 [73]  55  47  72  16  70  13 127  92  79  10  96  94  34   7   5  88  20  68
 [91]  45  48  49  81 118 107 105  39 111  42  40  35 102  59
[1] "Starting global iteration number : 5"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -38.71626
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -39.01875
[1] "Best solution:"
 [1] 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1
[1] 12
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 15
[1] "Best fitness updated to:"
[1] -40.87145
[1] "Best solution:"
 [1] 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1
[1] 25
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 10
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 9
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 9
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 9
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 9
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 9
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 9
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 9
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  5  7  8  9 10 12 13 15 16 17 18 20 21 22 23 24 25 26 27 28
[1] 5
[1] "##################################"
[1] "Results summary for itr:5"
[1] "number of features selected using population mean"
[1] 9
[1] "number of features selected using current global best"
[1] 22
[1] "feat ind length"
[1] 22
[1] "best accuracy"
[1] 40.87145
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 6"
  [1]   8  24  31  78  33  93 106  14  99  17  91  15 110 109  29  43  74  83
 [19]  54  12  90  66  98 103  32   9  49  72  23  77 118  96  70 111  35  28
 [37]  47  76 130  45  10  61  68  20  87  58 129   6 119  42  75  95 114  53
 [55]  82  73  63  34  80 121   1 123  51  40  26   3  60  69  84 102  44   4
 [73]  52 116  88 100 127 108 128  36  19  71 104  85  92 105  59  64 126   7
 [91]  11 117  67  27  65 124  39  21  97  86  94  79   5  55
[1] "Starting global iteration number : 6"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -38.68399
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 11
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 10
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 10
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 10
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 10
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28
[1] 6
[1] "##################################"
[1] "Results summary for itr:6"
[1] "number of features selected using population mean"
[1] 10
[1] "number of features selected using current global best"
[1] 28
[1] "feat ind length"
[1] 28
[1] "best accuracy"
[1] 38.68399
[1] "test acc:0.884615384615385"
[1] "##################################"
[1] "learning sets: 7"
  [1]  90  83  54  17  22 110  56  91  41  98 106  14  74  30  12  78   8  93
 [19]  99 120 103  29  89  15 109  66  59  75 128   1  84 123   6  87 113 129
 [37] 125 118  62  19  69  20   5 100 111  85  68  92  81  51  23 112 115  10
 [55]  13  67  82  16  71  73  47  18  70  61  28 124  27  25   7  63 114  48
 [73]  57 117  58 119   4  52  21  88  64  53  49  95  55  94 116 102  37 121
 [91]   3  40  39 122 105 104  60  80  97  42 101  76  44  35
[1] "Starting global iteration number : 7"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -41.00651
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -41.57754
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0
[1] 6
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 10
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 10
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 10
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 10
[1] "No change for 8 iterations. Exiting PSO."
 [1]  2  4  5  7  8  9 10 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26 27 28
[1] 7
[1] "##################################"
[1] "Results summary for itr:7"
[1] "number of features selected using population mean"
[1] 10
[1] "number of features selected using current global best"
[1] 24
[1] "feat ind length"
[1] 24
[1] "best accuracy"
[1] 41.57754
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 8"
  [1]  41  66  90  46  12  31  22  33  91  98  54 110 106 109  30  83  14  43
 [19]   9   8 103  74  56  99  24  93  13  57  26 113  39  68  36  80  82 112
 [37]  69 127 116  51  92  48  16 104  49  75 100 126 107  85  44  64  88  84
 [55] 119 117 105  96   7 111 121 125  28  47  70  95  71  61  76 128  11  63
 [73]  79  94 114  53 108  73  34 129  55 124  60  45 123 130  19  50   3  65
 [91]  23  20  62  10  58 122  25  67   2  81 118 102  97   4
[1] "Starting global iteration number : 8"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -39.90689
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -40.10796
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0
[1] 6
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 10
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 10
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 10
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 10
[1] "No change for 8 iterations. Exiting PSO."
 [1]  2  4  5  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25 26 27 28
[1] 8
[1] "##################################"
[1] "Results summary for itr:8"
[1] "number of features selected using population mean"
[1] 10
[1] "number of features selected using current global best"
[1] 24
[1] "feat ind length"
[1] 24
[1] "best accuracy"
[1] 40.10796
[1] "test acc:0.884615384615385"
[1] "##################################"
[1] "learning sets: 9"
  [1]  14  66  43  91 106 109  78  22  31  93  29  30   9 120  41 110 103  74
 [19]  83  99  33  32  90  54  46  24  27  40 126  59  87   2 107 118 130  49
 [37] 122  52 114 102  55  73  82 104  39 123  69  25  67  63  13 127  38  64
 [55]  18  72 129 115  21 119  61  62  58   6  48 121   7  37 113  88 124  84
 [73] 117  76  97  45  47   5  79  42  60 100 128  35  70  81  92  36 108 116
 [91] 105  71  77  11  51  20  96  65 112  28  34  57  23   4
[1] "Starting global iteration number : 9"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -37.54944
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 13
[1] "Best fitness updated to:"
[1] -42.01851
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0
[1] 6
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 11
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 10
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 10
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 10
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 10
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 10
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 10
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 10
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  5  7  8  9 10 12 13 15 16 17 18 20 21 22 23 24 25 26 27 28
[1] 9
[1] "##################################"
[1] "Results summary for itr:9"
[1] "number of features selected using population mean"
[1] 10
[1] "number of features selected using current global best"
[1] 22
[1] "feat ind length"
[1] 22
[1] "best accuracy"
[1] 42.01851
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "learning sets: 10"
  [1]  66  99  15  32 106  98  89  31  17  43  91  56  14  12  41  74 120  93
 [19]  29 110 103  78  22  30  83  90 121  11  53  92  40  20  39 112  49  97
 [37]   5  35  96 123  52   7  70  68  51  79  57 102 129   3  77 126 114 130
 [55] 101  45  36   4 104 117  72  61  21  18  81  60 127  88   6 107  67  58
 [73]  85  80  65 116  34 108  84  64  55  59  71  62 119  13   1  47  87 122
 [91]  76 118  38 128  27  25 105 125   2  23 100 113  63  86
[1] "Starting global iteration number : 10"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -39.03974
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 28
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 12
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 12
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 12
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 12
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 12
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 7
[1] 5
[1] 12
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "RE-INITIALIZING..."
[1] 8
[1] 5
[1] 12
[1] "No change for 8 iterations. Exiting PSO."
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28
[1] 10
[1] "##################################"
[1] "Results summary for itr:10"
[1] "number of features selected using population mean"
[1] 12
[1] "number of features selected using current global best"
[1] 28
[1] "feat ind length"
[1] 28
[1] "best accuracy"
[1] 39.03974
[1] "test acc:0.923076923076923"
[1] "##################################"
[1] "testacc"
 [1] 0.8846154 0.9615385 0.9615385 0.8461538 0.9615385 0.8846154 1.0000000
 [8] 0.8846154 0.9230769 0.9230769
[1] 0.9230769
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8462  0.8846  0.9231  0.9231  0.9615  1.0000 
[1] 0.04796997
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    0    1    0    1    1    0    0    1     1
 [2,]    1    1    1    1    1    1    1    1    1     1
 [3,]    1    1    1    1    0    1    0    0    0     1
 [4,]    1    0    1    0    0    1    1    1    0     1
 [5,]    1    1    1    0    1    1    1    1    1     1
 [6,]    0    0    1    0    0    1    0    0    0     1
 [7,]    1    1    1    0    1    1    1    1    1     1
 [8,]    1    1    1    0    1    1    1    1    1     1
 [9,]    1    1    1    1    1    1    1    1    1     1
[10,]    1    1    1    0    1    1    1    1    1     1
[11,]    1    0    1    0    0    1    1    1    0     1
[12,]    1    1    1    0    1    1    1    1    1     1
[13,]    1    1    1    1    1    1    1    1    1     1
[14,]    1    0    1    1    0    1    0    1    0     1
[15,]    1    1    1    1    1    1    1    1    1     1
[16,]    1    1    1    1    1    1    1    1    1     1
[17,]    1    1    1    0    1    1    1    1    1     1
[18,]    1    1    1    0    1    1    1    1    1     1
[19,]    0    1    1    0    0    1    1    0    0     1
[20,]    1    0    1    0    1    1    1    1    1     1
[21,]    1    1    1    0    1    1    1    1    1     1
[22,]    1    1    1    0    1    1    1    1    1     1
[23,]    1    1    1    0    1    1    1    1    1     1
[24,]    1    1    1    0    1    1    1    1    1     1
[25,]    1    1    1    0    1    1    1    1    1     1
[26,]    1    1    1    0    1    1    1    1    1     1
[27,]    1    1    1    0    1    1    1    1    1     1
[28,]    1    0    1    0    1    1    1    1    1     1
[1] "dim of scoring matrix is "
[1] 28 10
[1] "DS index stage 2"
[1] 0.8082652
[1] "KI index stage 2"
[1] -Inf
[1] 1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  3.000   7.500   9.000   8.179   9.000  10.000 
[1] "Number of features selected in 1 iterations:"
[1] 28
[1] "Number of features selected in 1 iterations:"
[1] 28
[1] 0.7878788 0.9896907
[1] 0.7878788 0.9896907
[1] "accuracy: 85.0803653550534 num_feat:28 fitness:52.1511050066056"
$fitfunc
[1] -52.15111

$cverror
[1] 85.08037

$cvpermerror
[1] 50

$testacc
[1] 99.48454

$reverseacc
[1] 88.87848

[1] -52.15111
[1] "Number of features selected in 2 iterations:"
[1] 28
[1] 0.7878788 0.9896907
[1] 0.7878788 0.9896907
[1] "accuracy: 85.0803653550534 num_feat:28 fitness:52.1511050066056"
$fitfunc
[1] -52.15111

$cverror
[1] 85.08037

$cvpermerror
[1] 50

$testacc
[1] 99.48454

$reverseacc
[1] 88.87848

[1] -52.15111
[1] "Number of features selected in 3 iterations:"
[1] 28
[1] 0.7878788 0.9896907
[1] 0.7878788 0.9896907
[1] "accuracy: 85.0803653550534 num_feat:28 fitness:52.1511050066056"
$fitfunc
[1] -52.15111

$cverror
[1] 85.08037

$cvpermerror
[1] 50

$testacc
[1] 99.48454

$reverseacc
[1] 88.87848

[1] -52.15111
[1] "Number of features selected in 4 iterations:"
[1] 27
[1] 0.7878788 0.9896907
[1] 0.7878788 0.9896907
[1] "accuracy: 84.0692760932773 num_feat:27 fitness:51.4285023459878"
$fitfunc
[1] -51.4285

$cverror
[1] 84.06928

$cvpermerror
[1] 50

$testacc
[1] 99.48454

$reverseacc
[1] 88.87848

[1] -51.4285
[1] "Number of features selected in 5 iterations:"
[1] 27
[1] 0.7878788 0.9896907
[1] 0.7878788 0.9896907
[1] "accuracy: 84.0692760932773 num_feat:27 fitness:51.4285023459878"
$fitfunc
[1] -51.4285

$cverror
[1] 84.06928

$cvpermerror
[1] 50

$testacc
[1] 99.48454

$reverseacc
[1] 88.87848

[1] -51.4285
[1] "Number of features selected in 6 iterations:"
[1] 25
[1] 0.7272727 0.9896907
[1] 0.7272727 0.9896907
[1] "accuracy: 82.5886511086619 num_feat:25 fitness:49.8318239409042"
$fitfunc
[1] -49.83182

$cverror
[1] 82.58865

$cvpermerror
[1] 50

$testacc
[1] 97.45392

$reverseacc
[1] 85.84817

[1] -49.83182
[1] "Number of features selected in 7 iterations:"
[1] 21
[1] 0.8181818 0.9896907
[1] 0.8181818 0.9896907
[1] "accuracy: 79.8325953530994 num_feat:21 fitness:48.1349119943622"
$fitfunc
[1] -48.13491

$cverror
[1] 79.8326

$cvpermerror
[1] 50

$testacc
[1] 97.45392

$reverseacc
[1] 90.39363

[1] -48.13491
[1] "Number of features selected in 8 iterations:"
[1] 21
[1] 0.8181818 0.9896907
[1] 0.8181818 0.9896907
[1] "accuracy: 79.8325953530994 num_feat:21 fitness:48.1349119943622"
$fitfunc
[1] -48.13491

$cverror
[1] 79.8326

$cvpermerror
[1] 50

$testacc
[1] 97.45392

$reverseacc
[1] 90.39363

[1] -48.13491
[1] "Number of features selected in 9 iterations:"
[1] 19
[1] 0.6969697 0.9896907
[1] 0.6969697 0.9896907
[1] "accuracy: 81.6060449745324 num_feat:19 fitness:48.9303671758049"
$fitfunc
[1] -48.93037

$cverror
[1] 81.60604

$cvpermerror
[1] 50

$testacc
[1] 95.93877

$reverseacc
[1] 84.33302

[1] -48.93037
[1] "Number of features selected in 10 iterations:"
[1] 5
[1] 0.6060606 0.9484536
[1] 0.6060606 0.9484536
[1] "accuracy: 65.7263547968732 num_feat:5 fitness:31.833572815524"
$fitfunc
[1] -31.83357

$cverror
[1] 65.72635

$cvpermerror
[1] 55.04604

$testacc
[1] 86.81662

$reverseacc
[1] 77.72571

[1] -31.83357
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8462  0.8846  0.9231  0.9231  0.9615  1.0000 
[1] "Number of features selected in 1 iterations:"
[1] 28
[1] "Modified train 10 fold accuracy using train data is "
[1] 93.84615
[1] "Modified train accuracy is "
[1] 0.9923077
[1] "train confusion matrix is "
          trainclass
pred_train  1  2
         1 33  1
         2  0 96
[1] "Train dimension is "
[1] 130  28
[1] "Test dimension is "
[1] 100  28
[1] "Test confusion matrix is "
    
pred  1  2
   1  8 13
   2  7 72
[1] "Test acc is "
[1] 0.8
[1] "train 10 fold"
[1] 90.76923
[1] "Test confusion matrix is "
    
pred  1  2
   1  8 13
   2  7 72
[1] "Test acc is "
[1] 0.8
[1] "Test AUC:"
[1] 0.6901961
[1] "Train acc is "
[1] 0.9923077
[1] "# of features after CMA:"
NULL
[1] "# of features after PSO:"
[1] 130  29
     user    system   elapsed 
  207.591    29.143 12313.359 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> 
> 
> feat_ind<-psores$bestfeatlist
> feat_names<-psores$bestfeatnames
> 
> scoringmatrix<-as.data.frame(psores$scoringmatrix)
> print(scoringmatrix)
   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
1   0  0  1  0  1  1  0  0  1   1
2   1  1  1  1  1  1  1  1  1   1
3   1  1  1  1  0  1  0  0  0   1
4   1  0  1  0  0  1  1  1  0   1
5   1  1  1  0  1  1  1  1  1   1
6   0  0  1  0  0  1  0  0  0   1
7   1  1  1  0  1  1  1  1  1   1
8   1  1  1  0  1  1  1  1  1   1
9   1  1  1  1  1  1  1  1  1   1
10  1  1  1  0  1  1  1  1  1   1
11  1  0  1  0  0  1  1  1  0   1
12  1  1  1  0  1  1  1  1  1   1
13  1  1  1  1  1  1  1  1  1   1
14  1  0  1  1  0  1  0  1  0   1
15  1  1  1  1  1  1  1  1  1   1
16  1  1  1  1  1  1  1  1  1   1
17  1  1  1  0  1  1  1  1  1   1
18  1  1  1  0  1  1  1  1  1   1
19  0  1  1  0  0  1  1  0  0   1
20  1  0  1  0  1  1  1  1  1   1
21  1  1  1  0  1  1  1  1  1   1
22  1  1  1  0  1  1  1  1  1   1
23  1  1  1  0  1  1  1  1  1   1
24  1  1  1  0  1  1  1  1  1   1
25  1  1  1  0  1  1  1  1  1   1
26  1  1  1  0  1  1  1  1  1   1
27  1  1  1  0  1  1  1  1  1   1
28  1  0  1  0  1  1  1  1  1   1
> print(feat_names[feat_ind])
 [1] "201555_at"   "202683_s_at" "203139_at"   "203628_at"   "203928_x_at"
 [6] "203963_at"   "204681_s_at" "204825_at"   "205225_at"   "205229_s_at"
[11] "205347_s_at" "205478_at"   "205696_s_at" "205713_s_at" "205751_at"  
[16] "205830_at"   "206401_s_at" "208670_s_at" "208712_at"   "208893_s_at"
[21] "209173_at"   "211864_s_at" "212583_at"   "214164_x_at" "214612_x_at"
[26] "215867_x_at" "216092_s_at" "219051_x_at"
> 
> save(psores,file="psores.Rda")
> print("Complete")
[1] "Complete"
> 
