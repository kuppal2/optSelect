
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/kuppal3/karan_libs/Rlibs")
> library(snow)
Warning message:
package ‘snow’ was built under R version 3.2.5 
> library(e1071)
Warning message:
package ‘e1071’ was built under R version 3.2.5 
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

Warning message:
package ‘pROC’ was built under R version 3.2.5 
> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
Warning message:
package ‘RankAggreg’ was built under R version 3.2.5 
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

Warning message:
package ‘CMA’ was built under R version 3.2.4 
> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

Warning messages:
1: package ‘expm’ was built under R version 3.2.5 
2: package ‘Matrix’ was built under R version 3.2.5 
> 
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> 
> dirloc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/"
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/versionnov2014/OCFS_",args[9],".R",sep="")
> 
> sname<-paste(dirloc,"version2017/OCFS_",args[9],".R",sep="")
> source(sname)
> 
> outloc<-paste(dirloc,"/Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCER",args[9],"/",sep="")
> 
> 
> sname<-paste(dirloc,"Datasets/MAQCII_BreastCancer/MaqcIIbr.Rda",sep="")
> load(sname)
> 
> trainm<-MaqcIIbr$trainx
> testm<-MaqcIIbr$testx
> trainclass<-MaqcIIbr$trainER #PCRvsRD
> testclass<-MaqcIIbr$testER #PCRvsRD
> 
> trainm<-trainm[,-c(22284)]
> testm<-testm[,-c(22284)]
> trainm<-apply(trainm,2,as.numeric)
> testm<-apply(testm,2,as.numeric)
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvmarch62018_v1' already exists
> setwd(outloc)
> 
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/MAQCII_BreastCancer/OCFSvmay2415_MAQCERvmarch62018_v1' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> print("max num")
[1] "max num"
> print(as.numeric(args[10]))
[1] 3
> 
> #if(FALSE)
> {
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 3
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.8888889 0.9444444
[1] 0.8888889 0.9444444
[1] "accuracy: 90.4486418236017 num_feat:3 fitness:50.7373733352966"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 90.4035631150127 num_feat:3 fitness:57.2951904780243"
[1] 0.8478261 0.9718310
[1] 0.8478261 0.9718310
[1] "accuracy: 90.1431391878992 num_feat:3 fitness:53.0004303423874"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 87.8836668129665 num_feat:3 fitness:53.2840440493714"
[1] 0.3125 1.0000
[1] 0.3125 1.0000
[1] "accuracy: 90.4853166323684 num_feat:3 fitness:50.0495658054656"
[1] 0.8000000 0.9861111
[1] 0.8000000 0.9861111
[1] "accuracy: 89.2117149678133 num_feat:3 fitness:55.0707916824415"
[1] 0.8913043 0.9577465
[1] 0.8913043 0.9577465
[1] "accuracy: 88.9893365729665 num_feat:3 fitness:51.5264550805026"
[1] 0.9347826 0.9295775
[1] 0.9347826 0.9295775
[1] "accuracy: 88.3377036959034 num_feat:3 fitness:55.7865297701398"
[1] 0.9302326 0.9189189
[1] 0.9302326 0.9189189
[1] "accuracy: 90.9032946097029 num_feat:3 fitness:54.9430721609983"
[1] 0.9090909 0.8904110
[1] 0.9090909 0.8904110
[1] "accuracy: 91.3868863441962 num_feat:3 fitness:54.5198655056273"
[1] "limma:3:53.6213318210255"
[1] "limma:3:53.6213318210255"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 89.9286502866994 num_feat:4 fitness:49.8895370533526"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 89.4618748326284 num_feat:4 fitness:56.4761393798954"
[1] 0.9130435 0.9436620
[1] 0.9130435 0.9436620
[1] "accuracy: 88.0584321197878 num_feat:4 fitness:50.9682741717827"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 88.6240573478727 num_feat:4 fitness:53.8392920732903"
[1] 0.4375 1.0000
[1] 0.4375 1.0000
[1] "accuracy: 88.5553518761645 num_feat:4 fitness:49.2885546256331"
[1] 0.8666667 0.9444444
[1] 0.8666667 0.9444444
[1] "accuracy: 88.3264576399487 num_feat:4 fitness:55.7724414986965"
[1] 0.9130435 0.9154930
[1] 0.9130435 0.9154930
[1] "accuracy: 89.1228869776201 num_feat:4 fitness:52.9887869881156"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 87.8113436133162 num_feat:4 fitness:55.1319098571817"
[1] 0.9767442 0.8918919
[1] 0.9767442 0.8918919
[1] "accuracy: 89.9676400134939 num_feat:4 fitness:54.2899978387808"
[1] 0.9545455 0.8904110
[1] 0.9545455 0.8904110
[1] "accuracy: 90.6884665158078 num_feat:4 fitness:55.6749512219338"
[1] "limma:4:53.4319884708663"
[1] "limma:3:53.6213318210255"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1] 4752 9093 9094
     205225_at 209603_at 209604_s_at
[1,]   13.0759   10.5793     14.3763
[2,]   13.7616   10.5772     14.0214
[3,]   12.7360   11.1181     14.5222
     205225_at 209603_at 209604_s_at
[1,]   13.8754   11.9790     15.0625
[2,]   11.7217   10.8744     14.4978
[3,]   10.9960    8.0211     12.4583
[1] "numgenes selected:3"
[1] "test acc:0.88"
[1] "test AUC acc:0.883144178226145"
[1] "10 fold train93.8461538461538"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 44  1
         2  6 79
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  8
        2  4 53
[1] "train acc:0.946153846153846"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 44  1
         2  6 79
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 3
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
Loaded glmnet 2.0-10


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
 4752 15102  4035  9093 12339  7147 
   10     6     5     5     3     1 
[1] "varselmethod"
[1] "forward"
[1] 0.9111111 0.9166667
[1] 0.9111111 0.9166667
[1] "accuracy: 92.1205891298858 num_feat:3 fitness:54.042094383913"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 92.4155750008531 num_feat:3 fitness:56.5379905374843"
[1] 0.7608696 0.8591549
[1] 0.7608696 0.8591549
[1] "accuracy: 95.0160876452755 num_feat:3 fitness:51.919599778952"
[1] 0.8571429 0.9866667
[1] 0.8571429 0.9866667
[1] "accuracy: 92.7199277234056 num_feat:3 fitness:58.6710760201398"
[1] 0.5833333 1.0000000
[1] 0.5833333 1.0000000
[1] "accuracy: 93.1403960080781 num_feat:3 fitness:55.165133526321"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 90.7062355883729 num_feat:3 fitness:55.2171184356428"
[1] 0.9565217 0.9436620
[1] 0.9565217 0.9436620
[1] "accuracy: 93.0957477167814 num_feat:3 fitness:52.0733662374269"
[1] 0.8695652 0.9859155
[1] 0.8695652 0.9859155
[1] "accuracy: 93.2790416462191 num_feat:3 fitness:54.1498930819865"
[1] 0.9069767 0.9324324
[1] 0.9069767 0.9324324
[1] "accuracy: 92.2730382248742 num_feat:3 fitness:55.5674581982784"
[1] 0.9545455 0.9726027
[1] 0.9545455 0.9726027
[1] "accuracy: 91.0970596284195 num_feat:3 fitness:55.7848564151928"
[1] "lasso:3:54.9128586615337"
[1] "lasso:3:54.9128586615337"
[1] 0.8888889 0.9305556
[1] 0.8888889 0.9305556
[1] "accuracy: 92.1205891298858 num_feat:4 fitness:53.8997716526576"
[1] 0.8000000 0.9861111
[1] 0.8000000 0.9861111
[1] "accuracy: 92.4526144737287 num_feat:4 fitness:56.0083467443283"
[1] 0.8043478 0.8732394
[1] 0.8043478 0.8732394
[1] "accuracy: 92.4201234482819 num_feat:4 fitness:53.4067797615335"
[1] 0.7857143 0.9866667
[1] 0.7857143 0.9866667
[1] "accuracy: 92.7199277234056 num_feat:4 fitness:58.4924597143077"
[1] 0.5416667 1.0000000
[1] 0.5416667 1.0000000
[1] "accuracy: 93.5395974778074 num_feat:4 fitness:52.9548660206808"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 90.4038137163816 num_feat:4 fitness:56.0506177996106"
[1] 0.9782609 0.9295775
[1] 0.9782609 0.9295775
[1] "accuracy: 93.0957477167814 num_feat:4 fitness:54.5940801227233"
[1] 0.8913043 0.9859155
[1] 0.8913043 0.9859155
[1] "accuracy: 91.9914982571884 num_feat:4 fitness:50.3070636557997"
[1] 0.9069767 0.9189189
[1] 0.9069767 0.9189189
[1] "accuracy: 91.4441644510644 num_feat:4 fitness:56.1343357517265"
[1] 0.9545455 0.9041096
[1] 0.9545455 0.9041096
[1] "accuracy: 91.0970596284195 num_feat:4 fitness:56.2856574155642"
[1] "lasso:4:54.8133978638932"
[1] "lasso:4:54.9128586615337"
[1] 0.8888889 0.9722222
[1] 0.8888889 0.9722222
[1] "accuracy: 93.0372650256383 num_feat:5 fitness:53.0205382467425"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 93.1078638255406 num_feat:5 fitness:59.0410796374977"
[1] 0.8695652 0.9014085
[1] 0.8695652 0.9014085
[1] "accuracy: 96.5645079347596 num_feat:5 fitness:52.727434881785"
[1] 0.7380952 0.9866667
[1] 0.7380952 0.9866667
[1] "accuracy: 93.3300225202481 num_feat:5 fitness:59.2494173651965"
[1] 0.5625 1.0000
[1] 0.5625 1.0000
[1] "accuracy: 92.406768119853 num_feat:5 fitness:51.3154165662323"
[1] 0.9333333 0.9444444
[1] 0.9333333 0.9444444
[1] "accuracy: 93.1556088323933 num_feat:5 fitness:59.3246588833775"
[1] 0.9782609 0.9295775
[1] 0.9782609 0.9295775
[1] "accuracy: 94.647583029022 num_feat:5 fitness:58.3624703414128"
[1] 0.8043478 0.9859155
[1] 0.8043478 0.9859155
[1] "accuracy: 94.0550026077057 num_feat:5 fitness:51.3322584861296"
[1] 0.9767442 0.9189189
[1] 0.9767442 0.9189189
[1] "accuracy: 93.7106236032917 num_feat:5 fitness:58.5017867534445"
[1] 0.9772727 0.9041096
[1] 0.9772727 0.9041096
[1] "accuracy: 91.7647998232995 num_feat:5 fitness:58.4751292165775"
[1] "lasso:5:56.1350190378396"
[1] "lasso:5:56.1350190378396"
[1] 0.9333333 1.0000000
[1] 0.9333333 1.0000000
[1] "accuracy: 94.5040452500974 num_feat:6 fitness:56.1685934694153"
[1] 0.9111111 0.9861111
[1] 0.9111111 0.9861111
[1] "accuracy: 96.0132106587576 num_feat:6 fitness:60.7583849548483"
[1] 0.8913043 0.9154930
[1] 0.8913043 0.9154930
[1] "accuracy: 95.9030021243663 num_feat:6 fitness:54.8114184275205"
[1] 0.8095238 0.9866667
[1] 0.8095238 0.9866667
[1] "accuracy: 96.1632949789673 num_feat:6 fitness:61.579500247512"
[1] 0.4791667 1.0000000
[1] 0.4791667 1.0000000
[1] "accuracy: 94.3786321114787 num_feat:6 fitness:50.4708342507938"
[1] 0.9555556 0.9583333
[1] 0.9555556 0.9583333
[1] "accuracy: 94.2086429035681 num_feat:6 fitness:60.537275859185"
[1] 0.9782609 0.9436620
[1] 0.9782609 0.9436620
[1] "accuracy: 95.4705316292655 num_feat:6 fitness:53.7160735063309"
[1] 0.8913043 0.9859155
[1] 0.8913043 0.9859155
[1] "accuracy: 95.7601636380204 num_feat:6 fitness:55.2093783347175"
[1] 0.9302326 0.9729730
[1] 0.9302326 0.9729730
[1] "accuracy: 94.7915495208274 num_feat:6 fitness:55.423897368528"
[1] 0.9772727 0.9315068
[1] 0.9772727 0.9315068
[1] "accuracy: 94.1391126349151 num_feat:6 fitness:59.7375716705582"
[1] "lasso:6:56.8412928089409"
[1] "lasso:6:56.8412928089409"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]  4035  4752  7147  9093 12339 15102
     204508_s_at 205225_at 207626_s_at 209603_at 212956_at 215729_s_at
[1,]     10.1763   13.0759      7.4760   10.5793   13.3600      2.9565
[2,]      9.3275   13.7616      3.5539   10.5772   13.2925      1.5807
[3,]      9.9200   12.7360      7.2242   11.1181   12.3582      5.6368
     204508_s_at 205225_at 207626_s_at 209603_at 212956_at 215729_s_at
[1,]      9.8038   13.8754      8.5889   11.9790   13.5201      1.9565
[2,]      7.9689   11.7217      7.0887   10.8744   12.5480      5.3426
[3,]      7.6789   10.9960      5.7342    8.0211   11.2917      5.3609
[1] "numgenes selected:6"
[1] "test acc:0.88"
[1] "test AUC acc:0.878520386717108"
[1] "10 fold train97.6923076923077"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 48  1
         2  2 79
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 34  7
        2  5 54
[1] "train acc:0.976923076923077"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 48  1
         2  2 79
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 3
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.8222222 0.9444444
[1] 0.8222222 0.9444444
[1] "accuracy: 89.2012577722263 num_feat:3 fitness:49.5061983969338"
[1] 0.8666667 0.9583333
[1] 0.8666667 0.9583333
[1] "accuracy: 87.9814316788695 num_feat:3 fitness:53.7238023545267"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 88.6310906521622 num_feat:3 fitness:50.3237290691674"
[1] 0.8571429 0.9600000
[1] 0.8571429 0.9600000
[1] "accuracy: 88.9392352452095 num_feat:3 fitness:56.0620669798166"
[1] 0.625 1.000
[1] 0.625 1.000
[1] "accuracy: 92.9377733437002 num_feat:3 fitness:52.1219362028038"
[1] 0.8888889 0.9583333
[1] 0.8888889 0.9583333
[1] "accuracy: 86.3162823031702 num_feat:3 fitness:52.5140267385568"
[1] 0.8478261 1.0000000
[1] 0.8478261 1.0000000
[1] "accuracy: 88.3674303026873 num_feat:3 fitness:48.2546050402129"
[1] 0.8478261 0.9859155
[1] 0.8478261 0.9859155
[1] "accuracy: 92.2447155911586 num_feat:3 fitness:53.8338601815381"
[1] 0.9302326 0.8783784
[1] 0.9302326 0.8783784
[1] "accuracy: 88.7916618546222 num_feat:3 fitness:52.978032521513"
[1] 0.9545455 0.9315068
[1] 0.9545455 0.9315068
[1] "accuracy: 90.6236678110033 num_feat:3 fitness:55.123808045487"
[1] "rfe:3:52.4442065530556"
[1] "rfe:3:52.4442065530556"
[1] 0.8444444 0.9861111
[1] 0.8444444 0.9861111
[1] "accuracy: 90.232612169377 num_feat:4 fitness:44.6263256330331"
[1] 0.8000000 0.9583333
[1] 0.8000000 0.9583333
[1] "accuracy: 91.0713045088413 num_feat:4 fitness:55.7000075378628"
[1] 0.9130435 0.9154930
[1] 0.9130435 0.9154930
[1] "accuracy: 91.1201689407563 num_feat:4 fitness:52.7926768125162"
[1] 0.7857143 1.0000000
[1] 0.7857143 1.0000000
[1] "accuracy: 92.6713508868494 num_feat:4 fitness:58.9515140763844"
[1] 0.6458333 1.0000000
[1] 0.6458333 1.0000000
[1] "accuracy: 93.6087455638296 num_feat:4 fitness:48.9478279767925"
[1] 0.8888889 0.9722222
[1] 0.8888889 0.9722222
[1] "accuracy: 91.1515282114512 num_feat:4 fitness:53.4233376232829"
[1] 0.8478261 0.8732394
[1] 0.8478261 0.8732394
[1] "accuracy: 90.4226738282845 num_feat:4 fitness:47.6214442970826"
[1] 0.8913043 1.0000000
[1] 0.8913043 1.0000000
[1] "accuracy: 93.0288404326578 num_feat:4 fitness:51.5388392535644"
[1] 0.9534884 0.8783784
[1] 0.9534884 0.8783784
[1] "accuracy: 91.4174808081844 num_feat:4 fitness:49.0857566147958"
[1] 0.8863636 0.9315068
[1] 0.8863636 0.9315068
[1] "accuracy: 90.3755247205393 num_feat:4 fitness:55.0652597624102"
[1] "rfe:4:51.7752989587725"
[1] "rfe:3:52.4442065530556"
[1] 0.8444444 0.9861111
[1] 0.8444444 0.9861111
[1] "accuracy: 91.9864332153027 num_feat:5 fitness:50.6910774976781"
[1] 0.8000000 0.9444444
[1] 0.8000000 0.9444444
[1] "accuracy: 91.8517089943549 num_feat:5 fitness:57.494604034316"
[1] 0.9347826 0.9154930
[1] 0.9347826 0.9154930
[1] "accuracy: 91.7354156456302 num_feat:5 fitness:53.1786645617558"
[1] 0.7142857 1.0000000
[1] 0.7142857 1.0000000
[1] "accuracy: 91.2555795366781 num_feat:5 fitness:55.918667878732"
[1] 0.6041667 0.9855072
[1] 0.6041667 0.9855072
[1] "accuracy: 92.8554348803753 num_feat:5 fitness:48.5489068534142"
[1] 0.8666667 0.9722222
[1] 0.8666667 0.9722222
[1] "accuracy: 90.4074822500239 num_feat:5 fitness:50.122575631781"
[1] 0.7826087 0.9014085
[1] 0.7826087 0.9014085
[1] "accuracy: 90.4541978922392 num_feat:5 fitness:47.9923721790149"
[1] 0.8913043 1.0000000
[1] 0.8913043 1.0000000
[1] "accuracy: 92.7246125431532 num_feat:5 fitness:55.6758206309228"
[1] 0.9069767 0.9054054
[1] 0.9069767 0.9054054
[1] "accuracy: 91.4689832529937 num_feat:5 fitness:48.8480031491565"
[1] 0.8863636 0.9452055
[1] 0.8863636 0.9452055
[1] "accuracy: 92.1321156514596 num_feat:5 fitness:58.3339364252763"
[1] "rfe:5:52.6804628842048"
[1] "rfe:5:52.6804628842048"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]  4752  4967  6280  6325 15102
     205225_at 205440_s_at 206754_s_at 206799_at 215729_s_at
[1,]   13.0759      8.6216     12.4854    3.1490      2.9565
[2,]   13.7616     10.7598     10.5188   14.9688      1.5807
[3,]   12.7360      7.7832     11.6232   11.6974      5.6368
     205225_at 205440_s_at 206754_s_at 206799_at 215729_s_at
[1,]   13.8754     10.5785     11.4867    7.9310      1.9565
[2,]   11.7217      8.5134      7.4297   10.6196      5.3426
[3,]   10.9960      9.3702      5.9013    6.2148      5.3609
[1] "numgenes selected:5"
[1] "test acc:0.87"
[1] "test AUC acc:0.870323665405633"
[1] "10 fold train96.1538461538462"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 47  0
         2  3 80
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 34  8
        2  5 53
[1] "train acc:0.976923076923077"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 47  0
         2  3 80
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 3
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.9333333 0.9166667
[1] 0.9333333 0.9166667
[1] "accuracy: 91.9304610872923 num_feat:3 fitness:51.8859688033789"
[1] 0.8000000 0.9861111
[1] 0.8000000 0.9861111
[1] "accuracy: 91.0769358399376 num_feat:3 fitness:57.504980190782"
[1] 0.8478261 0.9295775
[1] 0.8478261 0.9295775
[1] "accuracy: 88.7333327036511 num_feat:3 fitness:51.1613217876073"
[1] 0.7857143 0.9866667
[1] 0.7857143 0.9866667
[1] "accuracy: 89.2488506266845 num_feat:3 fitness:56.3674557191837"
[1] 0.4166667 1.0000000
[1] 0.4166667 1.0000000
[1] "accuracy: 91.4055666491101 num_feat:3 fitness:49.0381691689271"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 89.8655353660024 num_feat:3 fitness:56.8759653913953"
[1] 0.9565217 0.9436620
[1] 0.9565217 0.9436620
[1] "accuracy: 89.452905803709 num_feat:3 fitness:55.4537388658838"
[1] 0.8695652 0.9577465
[1] 0.8695652 0.9577465
[1] "accuracy: 87.5760384659168 num_feat:3 fitness:46.1576042590278"
[1] 0.9534884 0.7567568
[1] 0.9534884 0.7567568
[1] "accuracy: 92.020000556766 num_feat:3 fitness:55.433335750774"
[1] 0.9545455 0.9178082
[1] 0.9545455 0.9178082
[1] "accuracy: 91.3868863441962 num_feat:3 fitness:54.5769615964557"
[1] "elasticnet:3:53.4455501533416"
[1] "elasticnet:3:53.4455501533416"
[1] 0.9333333 0.9166667
[1] 0.9333333 0.9166667
[1] "accuracy: 89.9366548469678 num_feat:4 fitness:48.3639696599349"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 90.6378053372548 num_feat:4 fitness:57.6155309695516"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 90.2344359541136 num_feat:4 fitness:47.8694032309082"
[1] 0.7857143 0.9866667
[1] 0.7857143 0.9866667
[1] "accuracy: 90.3723717460111 num_feat:4 fitness:55.210051681418"
[1] 0.5 1.0
[1] 0.5 1.0
[1] "accuracy: 90.5733053563279 num_feat:4 fitness:50.0605272704117"
[1] 0.9111111 0.9444444
[1] 0.9111111 0.9444444
[1] "accuracy: 89.305493937337 num_feat:4 fitness:56.6178298328489"
[1] 0.9565217 0.9295775
[1] 0.9565217 0.9295775
[1] "accuracy: 89.847294279755 num_feat:4 fitness:55.2333327212984"
[1] 0.7391304 0.9577465
[1] 0.7391304 0.9577465
[1] "accuracy: 89.0732405423527 num_feat:4 fitness:49.9756555232207"
[1] 0.9534884 0.8513514
[1] 0.9534884 0.8513514
[1] "accuracy: 91.1351212416169 num_feat:4 fitness:54.8511219278691"
[1] 0.9545455 0.9178082
[1] 0.9545455 0.9178082
[1] "accuracy: 91.0140086429936 num_feat:4 fitness:54.0010630685879"
[1] "elasticnet:4:52.9798485886049"
[1] "elasticnet:3:53.4455501533416"
[1] 0.7777778 0.9861111
[1] 0.7777778 0.9861111
[1] "accuracy: 84.9978659106935 num_feat:5 fitness:44.4758014835158"
[1] 0.7555556 1.0000000
[1] 0.7555556 1.0000000
[1] "accuracy: 87.6086698272529 num_feat:5 fitness:46.4337002359133"
[1] 0.8043478 0.9154930
[1] 0.8043478 0.9154930
[1] "accuracy: 87.3078214954935 num_feat:5 fitness:48.909350050266"
[1] 0.7380952 1.0000000
[1] 0.7380952 1.0000000
[1] "accuracy: 87.0009932151425 num_feat:5 fitness:54.5274387339019"
[1] 0.6041667 1.0000000
[1] 0.6041667 1.0000000
[1] "accuracy: 87.2286787170267 num_feat:5 fitness:48.687699354949"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 86.7098314920183 num_feat:5 fitness:51.7547987372653"
[1] 0.9347826 0.9718310
[1] 0.9347826 0.9718310
[1] "accuracy: 85.6655369564479 num_feat:5 fitness:51.5808954350587"
[1] 0.7608696 0.9436620
[1] 0.7608696 0.9436620
[1] "accuracy: 90.6733382406825 num_feat:5 fitness:45.5612384787868"
[1] 0.8604651 0.9324324
[1] 0.8604651 0.9324324
[1] "accuracy: 87.6129271097056 num_feat:5 fitness:52.1906618091413"
[1] 0.9545455 0.9178082
[1] 0.9545455 0.9178082
[1] "accuracy: 88.6918515469354 num_feat:5 fitness:52.37665443831"
[1] "elasticnet:5:49.6498238757108"
[1] "elasticnet:3:53.4455501533416"
[1] 0.7555556 0.9861111
[1] 0.7555556 0.9861111
[1] "accuracy: 86.439701649592 num_feat:6 fitness:45.5015778548734"
[1] 0.7555556 0.9861111
[1] 0.7555556 0.9861111
[1] "accuracy: 86.2430735147824 num_feat:6 fitness:45.4544820033323"
[1] 0.8913043 0.9295775
[1] 0.8913043 0.9295775
[1] "accuracy: 86.7551749955421 num_feat:6 fitness:49.1585399859792"
[1] 0.7619048 1.0000000
[1] 0.7619048 1.0000000
[1] "accuracy: 85.6030841655894 num_feat:6 fitness:53.5384858790001"
[1] 0.5416667 1.0000000
[1] 0.5416667 1.0000000
[1] "accuracy: 86.801063686925 num_feat:6 fitness:48.3779576481219"
[1] 0.8888889 0.9722222
[1] 0.8888889 0.9722222
[1] "accuracy: 86.885321231661 num_feat:6 fitness:51.9158366085894"
[1] 0.9130435 0.9577465
[1] 0.9130435 0.9577465
[1] "accuracy: 85.9779813042041 num_feat:6 fitness:51.0513210832428"
[1] 0.8260870 0.9295775
[1] 0.8260870 0.9295775
[1] "accuracy: 89.1000697966942 num_feat:6 fitness:43.9277909723748"
[1] 0.8604651 0.9189189
[1] 0.8604651 0.9189189
[1] "accuracy: 88.3455094384495 num_feat:6 fitness:52.7904001455342"
[1] 0.9545455 0.9178082
[1] 0.9545455 0.9178082
[1] "accuracy: 88.4222233366955 num_feat:6 fitness:52.0665867545785"
[1] "elasticnet:6:49.3782978935627"
[1] "elasticnet:3:53.4455501533416"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 91.8982173971202 num_feat:7 fitness:55.3335856060177"
[1] 0.7777778 0.9861111
[1] 0.7777778 0.9861111
[1] "accuracy: 92.6778439262118 num_feat:7 fitness:55.4013549216467"
[1] 0.8478261 0.9295775
[1] 0.8478261 0.9295775
[1] "accuracy: 93.0235855437722 num_feat:7 fitness:52.380090292178"
[1] 0.7619048 1.0000000
[1] 0.7619048 1.0000000
[1] "accuracy: 91.7719917937007 num_feat:7 fitness:58.2334416092126"
[1] 0.5833333 1.0000000
[1] 0.5833333 1.0000000
[1] "accuracy: 90.7776935791672 num_feat:7 fitness:51.7270541080055"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 90.3248709872775 num_feat:7 fitness:55.2801307195422"
[1] 0.9347826 0.9295775
[1] 0.9347826 0.9295775
[1] "accuracy: 94.449734398891 num_feat:7 fitness:58.271624379325"
[1] 0.8913043 0.9859155
[1] 0.8913043 0.9859155
[1] "accuracy: 92.1745411120422 num_feat:7 fitness:51.7282012428425"
[1] 0.9302326 0.9729730
[1] 0.9302326 0.9729730
[1] "accuracy: 90.2293776607539 num_feat:7 fitness:55.981492941106"
[1] 0.9318182 0.9178082
[1] 0.9318182 0.9178082
[1] "accuracy: 93.5681886537179 num_feat:7 fitness:58.054092345189"
[1] "elasticnet:7:55.2391068165065"
[1] "elasticnet:7:55.2391068165065"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1]     1  4035  4752  9093  9094 12339 15102
     1007_s_at 204508_s_at 205225_at 209603_at 209604_s_at 212956_at
[1,]   12.4440     10.1763   13.0759   10.5793     14.3763   13.3600
[2,]   12.2005      9.3275   13.7616   10.5772     14.0214   13.2925
[3,]   12.6709      9.9200   12.7360   11.1181     14.5222   12.3582
     215729_s_at
[1,]      2.9565
[2,]      1.5807
[3,]      5.6368
     1007_s_at 204508_s_at 205225_at 209603_at 209604_s_at 212956_at
[1,]   12.3446      9.8038   13.8754   11.9790     15.0625   13.5201
[2,]   12.0376      7.9689   11.7217   10.8744     14.4978   12.5480
[3,]   10.9684      7.6789   10.9960    8.0211     12.4583   11.2917
     215729_s_at
[1,]      1.9565
[2,]      5.3426
[3,]      5.3609
[1] "numgenes selected:7"
[1] "test acc:0.89"
[1] "test AUC acc:0.891340899537621"
[1] "10 fold train96.1538461538462"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 47  1
         2  3 79
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  7
        2  4 54
[1] "train acc:0.969230769230769"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 47  1
         2  3 79
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 3
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.8888889 0.9444444
[1] 0.8888889 0.9444444
[1] "accuracy: 90.4486418236017 num_feat:3 fitness:50.7373733352966"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 90.4035631150127 num_feat:3 fitness:57.2951904780243"
[1] 0.8478261 0.9718310
[1] 0.8478261 0.9718310
[1] "accuracy: 90.1431391878992 num_feat:3 fitness:53.0004303423874"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 87.8836668129665 num_feat:3 fitness:53.2840440493714"
[1] 0.3125 1.0000
[1] 0.3125 1.0000
[1] "accuracy: 90.4853166323684 num_feat:3 fitness:50.0495658054656"
[1] 0.8000000 0.9861111
[1] 0.8000000 0.9861111
[1] "accuracy: 89.2117149678133 num_feat:3 fitness:55.0707916824415"
[1] 0.8913043 0.9577465
[1] 0.8913043 0.9577465
[1] "accuracy: 88.9893365729665 num_feat:3 fitness:51.5264550805026"
[1] 0.9347826 0.9295775
[1] 0.9347826 0.9295775
[1] "accuracy: 88.3377036959034 num_feat:3 fitness:55.7865297701398"
[1] 0.9302326 0.9189189
[1] 0.9302326 0.9189189
[1] "accuracy: 90.9032946097029 num_feat:3 fitness:54.9430721609983"
[1] 0.9090909 0.8904110
[1] 0.9090909 0.8904110
[1] "accuracy: 91.3868863441962 num_feat:3 fitness:54.5198655056273"
[1] "f.test:3:53.6213318210255"
[1] "f.test:3:53.6213318210255"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 89.9286502866994 num_feat:4 fitness:49.8895370533526"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 89.4618748326284 num_feat:4 fitness:56.4761393798954"
[1] 0.9130435 0.9436620
[1] 0.9130435 0.9436620
[1] "accuracy: 88.0584321197878 num_feat:4 fitness:50.9682741717827"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 88.6240573478727 num_feat:4 fitness:53.8392920732903"
[1] 0.4375 1.0000
[1] 0.4375 1.0000
[1] "accuracy: 88.5553518761645 num_feat:4 fitness:49.2885546256331"
[1] 0.8666667 0.9444444
[1] 0.8666667 0.9444444
[1] "accuracy: 88.3264576399487 num_feat:4 fitness:55.7724414986965"
[1] 0.9130435 0.9154930
[1] 0.9130435 0.9154930
[1] "accuracy: 89.1228869776201 num_feat:4 fitness:52.9887869881156"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 87.8113436133162 num_feat:4 fitness:55.1319098571817"
[1] 0.9767442 0.8918919
[1] 0.9767442 0.8918919
[1] "accuracy: 89.9676400134939 num_feat:4 fitness:54.2899978387808"
[1] 0.9545455 0.8904110
[1] 0.9545455 0.8904110
[1] "accuracy: 90.6884665158078 num_feat:4 fitness:55.6749512219338"
[1] "f.test:4:53.4319884708663"
[1] "f.test:3:53.6213318210255"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
[1] 4752 9093 9094
     205225_at 209603_at 209604_s_at
[1,]   13.0759   10.5793     14.3763
[2,]   13.7616   10.5772     14.0214
[3,]   12.7360   11.1181     14.5222
     205225_at 209603_at 209604_s_at
[1,]   13.8754   11.9790     15.0625
[2,]   11.7217   10.8744     14.4978
[3,]   10.9960    8.0211     12.4583
[1] "numgenes selected:3"
[1] "test acc:0.88"
[1] "test AUC acc:0.883144178226145"
[1] "10 fold train93.8461538461538"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 44  1
         2  6 79
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  8
        2  4 53
[1] "train acc:0.946153846153846"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 44  1
         2  6 79
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
There were 32 warnings (use warnings() to see them)
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod=args[11],
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "maxnum is "
[1] 3
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.8888889 0.9444444
[1] 0.8888889 0.9444444
[1] "accuracy: 90.4486418236017 num_feat:3 fitness:50.7373733352966"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 90.4035631150127 num_feat:3 fitness:57.2951904780243"
[1] 0.8478261 0.9718310
[1] 0.8478261 0.9718310
[1] "accuracy: 90.1431391878992 num_feat:3 fitness:53.0004303423874"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 87.8836668129665 num_feat:3 fitness:53.2840440493714"
[1] 0.3125 1.0000
[1] 0.3125 1.0000
[1] "accuracy: 90.4853166323684 num_feat:3 fitness:50.0495658054656"
[1] 0.8000000 0.9861111
[1] 0.8000000 0.9861111
[1] "accuracy: 89.2117149678133 num_feat:3 fitness:55.0707916824415"
[1] 0.8913043 0.9577465
[1] 0.8913043 0.9577465
[1] "accuracy: 88.9893365729665 num_feat:3 fitness:51.5264550805026"
[1] 0.9347826 0.9295775
[1] 0.9347826 0.9295775
[1] "accuracy: 88.3377036959034 num_feat:3 fitness:55.7865297701398"
[1] 0.9302326 0.9189189
[1] 0.9302326 0.9189189
[1] "accuracy: 90.9032946097029 num_feat:3 fitness:54.9430721609983"
[1] 0.9090909 0.8904110
[1] 0.9090909 0.8904110
[1] "accuracy: 91.3868863441962 num_feat:3 fitness:54.5198655056273"
[1] "limma:3:53.6213318210255"
[1] "limma:3:53.6213318210255"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 89.9286502866994 num_feat:4 fitness:49.8895370533526"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 89.4618748326284 num_feat:4 fitness:56.4761393798954"
[1] 0.9130435 0.9436620
[1] 0.9130435 0.9436620
[1] "accuracy: 88.0584321197878 num_feat:4 fitness:50.9682741717827"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 88.6240573478727 num_feat:4 fitness:53.8392920732903"
[1] 0.4375 1.0000
[1] 0.4375 1.0000
[1] "accuracy: 88.5553518761645 num_feat:4 fitness:49.2885546256331"
[1] 0.8666667 0.9444444
[1] 0.8666667 0.9444444
[1] "accuracy: 88.3264576399487 num_feat:4 fitness:55.7724414986965"
[1] 0.9130435 0.9154930
[1] 0.9130435 0.9154930
[1] "accuracy: 89.1228869776201 num_feat:4 fitness:52.9887869881156"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 87.8113436133162 num_feat:4 fitness:55.1319098571817"
[1] 0.9767442 0.8918919
[1] 0.9767442 0.8918919
[1] "accuracy: 89.9676400134939 num_feat:4 fitness:54.2899978387808"
[1] 0.9545455 0.8904110
[1] 0.9545455 0.8904110
[1] "accuracy: 90.6884665158078 num_feat:4 fitness:55.6749512219338"
[1] "limma:4:53.4319884708663"
[1] "limma:3:53.6213318210255"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
 4752 15102  4035  9093 12339     1  7147 13819 
   10     9     7     6     5     1     1     1 
[1] "varselmethod"
[1] "forward"
[1] 0.9111111 0.9166667
[1] 0.9111111 0.9166667
[1] "accuracy: 92.1205891298858 num_feat:3 fitness:54.042094383913"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 92.4155750008531 num_feat:3 fitness:56.5379905374843"
[1] 0.7608696 0.8591549
[1] 0.7608696 0.8591549
[1] "accuracy: 95.0160876452755 num_feat:3 fitness:51.919599778952"
[1] 0.8571429 0.9866667
[1] 0.8571429 0.9866667
[1] "accuracy: 92.7199277234056 num_feat:3 fitness:58.6710760201398"
[1] 0.5833333 1.0000000
[1] 0.5833333 1.0000000
[1] "accuracy: 93.1403960080781 num_feat:3 fitness:55.165133526321"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 90.7062355883729 num_feat:3 fitness:55.2171184356428"
[1] 0.9565217 0.9436620
[1] 0.9565217 0.9436620
[1] "accuracy: 93.0957477167814 num_feat:3 fitness:52.0733662374269"
[1] 0.8695652 0.9859155
[1] 0.8695652 0.9859155
[1] "accuracy: 93.2790416462191 num_feat:3 fitness:54.1498930819865"
[1] 0.9069767 0.9324324
[1] 0.9069767 0.9324324
[1] "accuracy: 92.2730382248742 num_feat:3 fitness:55.5674581982784"
[1] 0.9545455 0.9726027
[1] 0.9545455 0.9726027
[1] "accuracy: 91.0970596284195 num_feat:3 fitness:55.7848564151928"
[1] "lasso:3:54.9128586615337"
[1] "lasso:3:54.9128586615337"
[1] 0.8888889 0.9305556
[1] 0.8888889 0.9305556
[1] "accuracy: 92.1205891298858 num_feat:4 fitness:53.8997716526576"
[1] 0.8000000 0.9861111
[1] 0.8000000 0.9861111
[1] "accuracy: 92.4526144737287 num_feat:4 fitness:56.0083467443283"
[1] 0.8043478 0.8732394
[1] 0.8043478 0.8732394
[1] "accuracy: 92.4201234482819 num_feat:4 fitness:53.4067797615335"
[1] 0.7857143 0.9866667
[1] 0.7857143 0.9866667
[1] "accuracy: 92.7199277234056 num_feat:4 fitness:58.4924597143077"
[1] 0.5416667 1.0000000
[1] 0.5416667 1.0000000
[1] "accuracy: 93.5395974778074 num_feat:4 fitness:52.9548660206808"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 90.4038137163816 num_feat:4 fitness:56.0506177996106"
[1] 0.9782609 0.9295775
[1] 0.9782609 0.9295775
[1] "accuracy: 93.0957477167814 num_feat:4 fitness:54.5940801227233"
[1] 0.8913043 0.9859155
[1] 0.8913043 0.9859155
[1] "accuracy: 91.9914982571884 num_feat:4 fitness:50.3070636557997"
[1] 0.9069767 0.9189189
[1] 0.9069767 0.9189189
[1] "accuracy: 91.4441644510644 num_feat:4 fitness:56.1343357517265"
[1] 0.9545455 0.9041096
[1] 0.9545455 0.9041096
[1] "accuracy: 91.0970596284195 num_feat:4 fitness:56.2856574155642"
[1] "lasso:4:54.8133978638932"
[1] "lasso:4:54.9128586615337"
[1] 0.8888889 0.9722222
[1] 0.8888889 0.9722222
[1] "accuracy: 93.0372650256383 num_feat:5 fitness:53.0205382467425"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 93.1078638255406 num_feat:5 fitness:59.0410796374977"
[1] 0.8695652 0.9014085
[1] 0.8695652 0.9014085
[1] "accuracy: 96.5645079347596 num_feat:5 fitness:52.727434881785"
[1] 0.7380952 0.9866667
[1] 0.7380952 0.9866667
[1] "accuracy: 93.3300225202481 num_feat:5 fitness:59.2494173651965"
[1] 0.5625 1.0000
[1] 0.5625 1.0000
[1] "accuracy: 92.406768119853 num_feat:5 fitness:51.3154165662323"
[1] 0.9333333 0.9444444
[1] 0.9333333 0.9444444
[1] "accuracy: 93.1556088323933 num_feat:5 fitness:59.3246588833775"
[1] 0.9782609 0.9295775
[1] 0.9782609 0.9295775
[1] "accuracy: 94.647583029022 num_feat:5 fitness:58.3624703414128"
[1] 0.8043478 0.9859155
[1] 0.8043478 0.9859155
[1] "accuracy: 94.0550026077057 num_feat:5 fitness:51.3322584861296"
[1] 0.9767442 0.9189189
[1] 0.9767442 0.9189189
[1] "accuracy: 93.7106236032917 num_feat:5 fitness:58.5017867534445"
[1] 0.9772727 0.9041096
[1] 0.9772727 0.9041096
[1] "accuracy: 91.7647998232995 num_feat:5 fitness:58.4751292165775"
[1] "lasso:5:56.1350190378396"
[1] "lasso:5:56.1350190378396"
[1] 0.8444444 0.9722222
[1] 0.8444444 0.9722222
[1] "accuracy: 90.1400225201103 num_feat:6 fitness:53.6896260660978"
[1] 0.8 1.0
[1] 0.8 1.0
[1] "accuracy: 92.3263447304579 num_feat:6 fitness:55.5174561406217"
[1] 0.826087 0.915493
[1] 0.826087 0.915493
[1] "accuracy: 95.0784890005887 num_feat:6 fitness:52.3164819439256"
[1] 0.7857143 1.0000000
[1] 0.7857143 1.0000000
[1] "accuracy: 90.3113709176389 num_feat:6 fitness:56.9612768398922"
[1] 0.6041667 1.0000000
[1] 0.6041667 1.0000000
[1] "accuracy: 92.3307186825819 num_feat:6 fitness:52.7691683024858"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 89.8526593224587 num_feat:6 fitness:55.0184052035488"
[1] 0.9565217 0.9014085
[1] 0.9565217 0.9014085
[1] "accuracy: 93.2580014810452 num_feat:6 fitness:57.1707509103467"
[1] 0.8260870 0.9859155
[1] 0.8260870 0.9859155
[1] "accuracy: 92.1533240911136 num_feat:6 fitness:50.7666922453848"
[1] 0.9302326 0.9729730
[1] 0.9302326 0.9729730
[1] "accuracy: 91.4818538758329 num_feat:6 fitness:56.9371447573782"
[1] 0.9545455 0.9452055
[1] 0.9545455 0.9452055
[1] "accuracy: 94.5592617921404 num_feat:6 fitness:57.092123305074"
[1] "lasso:6:54.8239125714756"
[1] "lasso:5:56.1350190378396"
[1] 0.8444444 1.0000000
[1] 0.8444444 1.0000000
[1] "accuracy: 92.8987181563349 num_feat:7 fitness:56.2089295455566"
[1] 0.9111111 1.0000000
[1] 0.9111111 1.0000000
[1] "accuracy: 95.9461085234536 num_feat:7 fitness:55.5403685936582"
[1] 0.8695652 0.9436620
[1] 0.8695652 0.9436620
[1] "accuracy: 95.7227037225976 num_feat:7 fitness:57.2222285778657"
[1] 0.7857143 1.0000000
[1] 0.7857143 1.0000000
[1] "accuracy: 92.9251164950705 num_feat:7 fitness:59.163197636896"
[1] 0.5833333 1.0000000
[1] 0.5833333 1.0000000
[1] "accuracy: 95.1736297733211 num_feat:7 fitness:56.8690612646523"
[1] 0.9333333 0.9861111
[1] 0.9333333 0.9861111
[1] "accuracy: 94.1210026428208 num_feat:7 fitness:59.76019532601"
[1] 0.9565217 0.9436620
[1] 0.9565217 0.9436620
[1] "accuracy: 96.2995129954601 num_feat:7 fitness:54.9845113400761"
[1] 0.8913043 0.9718310
[1] 0.8913043 0.9718310
[1] "accuracy: 93.6300892077176 num_feat:7 fitness:53.1476027867115"
[1] 0.9302326 0.9594595
[1] 0.9302326 0.9594595
[1] "accuracy: 95.5829467383063 num_feat:7 fitness:55.8517393255912"
[1] 0.9545455 0.9178082
[1] 0.9545455 0.9178082
[1] "accuracy: 94.6022985586136 num_feat:7 fitness:58.6485940489601"
[1] "lasso:7:56.7396428445978"
[1] "lasso:7:56.7396428445978"
[1] 0.8 1.0
[1] 0.8 1.0
[1] "accuracy: 91.7278458170607 num_feat:8 fitness:51.8281632950153"
[1] 0.9111111 0.9861111
[1] 0.9111111 0.9861111
[1] "accuracy: 94.4505274719142 num_feat:8 fitness:55.9160484348763"
[1] 0.8478261 0.9577465
[1] 0.8478261 0.9577465
[1] "accuracy: 94.8521577623602 num_feat:8 fitness:56.6450702851564"
[1] 0.8095238 1.0000000
[1] 0.8095238 1.0000000
[1] "accuracy: 92.9251164950705 num_feat:8 fitness:59.1608290820243"
[1] 0.5833333 1.0000000
[1] 0.5833333 1.0000000
[1] "accuracy: 96.1411923774438 num_feat:8 fitness:57.4518490694953"
[1] 0.9333333 0.9861111
[1] 0.9333333 0.9861111
[1] "accuracy: 93.3775985934258 num_feat:8 fitness:59.2427953357554"
[1] 0.9565217 0.9436620
[1] 0.9565217 0.9436620
[1] "accuracy: 96.2526807157903 num_feat:8 fitness:57.9156555029039"
[1] 0.8913043 0.9718310
[1] 0.8913043 0.9718310
[1] "accuracy: 95.3576655324973 num_feat:8 fitness:54.4972254395024"
[1] 0.9767442 0.9324324
[1] 0.9767442 0.9324324
[1] "accuracy: 95.3304182262 num_feat:8 fitness:56.1217506784407"
[1] 0.9772727 0.9452055
[1] 0.9772727 0.9452055
[1] "accuracy: 93.8189124715982 num_feat:8 fitness:57.9111401648566"
[1] "lasso:8:56.6690527288027"
[1] "lasso:8:56.7396428445978"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.9111111 0.9166667
[1] 0.9111111 0.9166667
[1] "accuracy: 92.1205891298858 num_feat:3 fitness:54.042094383913"
[1] 0.8666667 0.9861111
[1] 0.8666667 0.9861111
[1] "accuracy: 92.4155750008531 num_feat:3 fitness:56.5379905374843"
[1] 0.7608696 0.8591549
[1] 0.7608696 0.8591549
[1] "accuracy: 95.0160876452755 num_feat:3 fitness:51.919599778952"
[1] 0.8571429 0.9866667
[1] 0.8571429 0.9866667
[1] "accuracy: 92.7199277234056 num_feat:3 fitness:58.6710760201398"
[1] 0.5833333 1.0000000
[1] 0.5833333 1.0000000
[1] "accuracy: 93.1403960080781 num_feat:3 fitness:55.165133526321"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 90.7062355883729 num_feat:3 fitness:55.2171184356428"
[1] 0.9565217 0.9436620
[1] 0.9565217 0.9436620
[1] "accuracy: 93.0957477167814 num_feat:3 fitness:52.0733662374269"
[1] 0.8695652 0.9859155
[1] 0.8695652 0.9859155
[1] "accuracy: 93.2790416462191 num_feat:3 fitness:54.1498930819865"
[1] 0.9069767 0.9324324
[1] 0.9069767 0.9324324
[1] "accuracy: 92.2730382248742 num_feat:3 fitness:55.5674581982784"
[1] 0.9545455 0.9726027
[1] 0.9545455 0.9726027
[1] "accuracy: 91.0970596284195 num_feat:3 fitness:55.7848564151928"
[1] "rfe:3:54.9128586615337"
[1] "rfe:3:54.9128586615337"
[1] 0.8666667 0.9305556
[1] 0.8666667 0.9305556
[1] "accuracy: 90.3904637865151 num_feat:4 fitness:52.2334891133735"
[1] 0.8000000 0.9722222
[1] 0.8000000 0.9722222
[1] "accuracy: 89.6364376417377 num_feat:4 fitness:55.5093724969337"
[1] 0.8478261 0.9295775
[1] 0.8478261 0.9295775
[1] "accuracy: 92.1387959958268 num_feat:4 fitness:50.9112208012047"
[1] 0.8571429 0.9866667
[1] 0.8571429 0.9866667
[1] "accuracy: 90.7571010606724 num_feat:4 fitness:57.0421333100997"
[1] 0.5625 1.0000
[1] 0.5625 1.0000
[1] "accuracy: 92.8554348803753 num_feat:4 fitness:54.4342392987315"
[1] 0.8888889 0.9583333
[1] 0.8888889 0.9583333
[1] "accuracy: 89.4691247760095 num_feat:4 fitness:53.6267234012087"
[1] 0.9347826 0.9859155
[1] 0.9347826 0.9859155
[1] "accuracy: 89.0592575646454 num_feat:4 fitness:49.3763289469924"
[1] 0.9347826 0.9859155
[1] 0.9347826 0.9859155
[1] "accuracy: 92.0011152800856 num_feat:4 fitness:53.2993504582221"
[1] 0.9534884 0.8648649
[1] 0.9534884 0.8648649
[1] "accuracy: 87.8998810815473 num_feat:4 fitness:52.5182247511595"
[1] 0.9545455 0.9315068
[1] 0.9545455 0.9315068
[1] "accuracy: 91.1809631352024 num_feat:4 fitness:56.1864485506066"
[1] "rfe:4:53.5137531128532"
[1] "rfe:3:54.9128586615337"
[1] 0.8666667 0.9305556
[1] 0.8666667 0.9305556
[1] "accuracy: 90.5593941216583 num_feat:5 fitness:49.4308015097371"
[1] 0.7111111 0.9861111
[1] 0.7111111 0.9861111
[1] "accuracy: 92.4766123171217 num_feat:5 fitness:57.959674590736"
[1] 0.7608696 0.9295775
[1] 0.7608696 0.9295775
[1] "accuracy: 92.33134592077 num_feat:5 fitness:42.6066898812732"
[1] 0.8809524 0.9600000
[1] 0.8809524 0.9600000
[1] "accuracy: 89.8491637557609 num_feat:5 fitness:56.988996090769"
[1] 0.5416667 1.0000000
[1] 0.5416667 1.0000000
[1] "accuracy: 92.8554348803753 num_feat:5 fitness:49.9090330642497"
[1] 0.9111111 0.9583333
[1] 0.9111111 0.9583333
[1] "accuracy: 88.3745477838999 num_feat:5 fitness:53.4967163413457"
[1] 0.9347826 0.9577465
[1] 0.9347826 0.9577465
[1] "accuracy: 90.7320041006693 num_feat:5 fitness:50.3311585173666"
[1] 0.9130435 0.9859155
[1] 0.9130435 0.9859155
[1] "accuracy: 92.2033433176433 num_feat:5 fitness:55.6367297607642"
[1] 0.9534884 0.8648649
[1] 0.9534884 0.8648649
[1] "accuracy: 89.061608624666 num_feat:5 fitness:54.9125932416217"
[1] 0.9545455 0.9315068
[1] 0.9545455 0.9315068
[1] "accuracy: 91.2522918895411 num_feat:5 fitness:55.159544126935"
[1] "rfe:5:52.6431937124798"
[1] "rfe:3:54.9128586615337"
[1] 0.8666667 0.9166667
[1] 0.8666667 0.9166667
[1] "accuracy: 91.3267546812431 num_feat:6 fitness:49.1411350919533"
[1] 0.7555556 0.9722222
[1] 0.7555556 0.9722222
[1] "accuracy: 89.6323416357871 num_feat:6 fitness:55.2575051895433"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 91.5742605125436 num_feat:6 fitness:46.9975248502981"
[1] 0.8571429 0.9866667
[1] 0.8571429 0.9866667
[1] "accuracy: 87.2661289868163 num_feat:6 fitness:55.060606993102"
[1] 0.5416667 1.0000000
[1] 0.5416667 1.0000000
[1] "accuracy: 92.8554348803753 num_feat:6 fitness:52.8748979388831"
[1] 0.9111111 0.9583333
[1] 0.9111111 0.9583333
[1] "accuracy: 86.3958497601791 num_feat:6 fitness:53.9387943964134"
[1] 0.9347826 0.8450704
[1] 0.9347826 0.8450704
[1] "accuracy: 92.4592581227909 num_feat:6 fitness:52.1972231623558"
[1] 0.8695652 0.9859155
[1] 0.8695652 0.9859155
[1] "accuracy: 92.435559239335 num_feat:6 fitness:54.3167353278045"
[1] 0.9302326 0.8918919
[1] 0.9302326 0.8918919
[1] "accuracy: 90.7592992728118 num_feat:6 fitness:54.5802871969875"
[1] 0.9545455 0.9178082
[1] 0.9545455 0.9178082
[1] "accuracy: 88.8053340110683 num_feat:6 fitness:56.6673098785057"
[1] "rfe:6:53.1032020025847"
[1] "rfe:3:54.9128586615337"
[1] 0.8444444 0.9722222
[1] 0.8444444 0.9722222
[1] "accuracy: 93.3195846438592 num_feat:7 fitness:50.6369733409411"
[1] 0.7555556 0.9722222
[1] 0.7555556 0.9722222
[1] "accuracy: 94.8738345766908 num_feat:7 fitness:56.8415830208677"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 93.4818915855863 num_feat:7 fitness:51.9333807379641"
[1] 0.8809524 1.0000000
[1] 0.8809524 1.0000000
[1] "accuracy: 92.0040052805378 num_feat:7 fitness:58.7123034035111"
[1] 0.5416667 1.0000000
[1] 0.5416667 1.0000000
[1] "accuracy: 91.9329758775018 num_feat:7 fitness:47.8194311129384"
[1] 0.8888889 0.9583333
[1] 0.8888889 0.9583333
[1] "accuracy: 92.2117509857193 num_feat:7 fitness:43.9349519904288"
[1] 0.9347826 0.9014085
[1] 0.9347826 0.9014085
[1] "accuracy: 93.6461675663409 num_feat:7 fitness:54.1129993269327"
[1] 0.8695652 1.0000000
[1] 0.8695652 1.0000000
[1] "accuracy: 94.5390425189825 num_feat:7 fitness:50.8601588335038"
[1] 0.9534884 0.8513514
[1] 0.9534884 0.8513514
[1] "accuracy: 95.1429735870554 num_feat:7 fitness:55.094419389847"
[1] 0.9318182 0.9452055
[1] 0.9318182 0.9452055
[1] "accuracy: 93.2582621178447 num_feat:7 fitness:59.117637027334"
[1] "rfe:7:52.9063838184269"
[1] "rfe:3:54.9128586615337"
[1] 0.8222222 0.9444444
[1] 0.8222222 0.9444444
[1] "accuracy: 92.8726574578967 num_feat:8 fitness:50.5812850031351"
[1] 0.7111111 0.9722222
[1] 0.7111111 0.9722222
[1] "accuracy: 94.8738345766908 num_feat:8 fitness:56.2124068810304"
[1] 0.8478261 0.9436620
[1] 0.8478261 0.9436620
[1] "accuracy: 93.4818915855863 num_feat:8 fitness:49.7829981966486"
[1] 0.8809524 1.0000000
[1] 0.8809524 1.0000000
[1] "accuracy: 89.9309524451317 num_feat:8 fitness:57.0934466213748"
[1] 0.5208333 1.0000000
[1] 0.5208333 1.0000000
[1] "accuracy: 92.6688976717021 num_feat:8 fitness:50.2889628039626"
[1] 0.8888889 0.9583333
[1] 0.8888889 0.9583333
[1] "accuracy: 92.9911026364776 num_feat:8 fitness:47.9987508957981"
[1] 0.9347826 0.8873239
[1] 0.9347826 0.8873239
[1] "accuracy: 93.6461675663409 num_feat:8 fitness:51.022464833342"
[1] 0.7826087 1.0000000
[1] 0.7826087 1.0000000
[1] "accuracy: 94.5578216379976 num_feat:8 fitness:45.9737380813274"
[1] 0.9534884 0.8513514
[1] 0.9534884 0.8513514
[1] "accuracy: 94.7425878363533 num_feat:8 fitness:52.0765139313735"
[1] 0.9318182 0.9315068
[1] 0.9318182 0.9315068
[1] "accuracy: 93.2582621178447 num_feat:8 fitness:58.6913793273414"
[1] "rfe:8:51.9721946575334"
[1] "rfe:3:54.9128586615337"
[1] 0.8888889 0.9861111
[1] 0.8888889 0.9861111
[1] "accuracy: 93.1443199774769 num_feat:9 fitness:51.0883038072256"
[1] 0.7333333 0.9722222
[1] 0.7333333 0.9722222
[1] "accuracy: 94.1250879808666 num_feat:9 fitness:55.7301767771687"
[1] 0.8913043 0.9295775
[1] 0.8913043 0.9295775
[1] "accuracy: 94.045661288725 num_feat:9 fitness:53.1856033095267"
[1] 0.9047619 0.9866667
[1] 0.9047619 0.9866667
[1] "accuracy: 90.7334254892454 num_feat:9 fitness:57.7184567495683"
[1] 0.4791667 1.0000000
[1] 0.4791667 1.0000000
[1] "accuracy: 93.6087455638296 num_feat:9 fitness:53.4729496324477"
[1] 0.8888889 0.9583333
[1] 0.8888889 0.9583333
[1] "accuracy: 93.1908385183336 num_feat:9 fitness:49.1099971625733"
[1] 0.9347826 0.8732394
[1] 0.9347826 0.8732394
[1] "accuracy: 91.5350975328732 num_feat:9 fitness:48.4271056822385"
[1] 0.8043478 0.9859155
[1] 0.8043478 0.9859155
[1] "accuracy: 94.2040483936487 num_feat:9 fitness:48.1769961599905"
[1] 0.9302326 0.8918919
[1] 0.9302326 0.8918919
[1] "accuracy: 93.7847851763971 num_feat:9 fitness:57.8917132054484"
[1] 0.9090909 0.9452055
[1] 0.9090909 0.9452055
[1] "accuracy: 91.3722513696388 num_feat:9 fitness:55.4152277131868"
[1] "rfe:9:53.0216530199374"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.5333333 0.6388889
[1] 0.5333333 0.6388889
[1] "accuracy: 53.8313701191575 num_feat:3 fitness:19.0232594755506"
[1] 0.4000000 0.6111111
[1] 0.4000000 0.6111111
[1] "accuracy: 51.328938995194 num_feat:3 fitness:19.723527689626"
[1] 0.2391304 0.8450704
[1] 0.2391304 0.8450704
[1] "accuracy: 51.9328205911101 num_feat:3 fitness:12.7033387666973"
[1] 0.6190476 0.3866667
[1] 0.6190476 0.3866667
[1] "accuracy: 46.2842274703505 num_feat:3 fitness:11.3842331501173"
[1] 0.1458333 0.8260870
[1] 0.1458333 0.8260870
[1] "accuracy: 61.3201709186662 num_feat:3 fitness:14.6620046867404"
[1] 0.4222222 0.6527778
[1] 0.4222222 0.6527778
[1] "accuracy: 49.7894422422176 num_feat:3 fitness:13.480034254308"
[1] 0.1304348 0.8169014
[1] 0.1304348 0.8169014
[1] "accuracy: 53.4703305799842 num_feat:3 fitness:11.3497545005328"
[1] 0.2173913 0.8309859
[1] 0.2173913 0.8309859
[1] "accuracy: 50.6147817560985 num_feat:3 fitness:16.2162062367666"
[1] 0.7441860 0.3648649
[1] 0.7441860 0.3648649
[1] "accuracy: 51.3064862863671 num_feat:3 fitness:12.8217454160306"
[1] 0.2954545 0.7534247
[1] 0.2954545 0.7534247
[1] "accuracy: 53.7999107956501 num_feat:3 fitness:13.5067241351097"
[1] "elasticnet:3:14.4870828311479"
[1] "elasticnet:3:14.4870828311479"
[1] 0.3555556 0.7222222
[1] 0.3555556 0.7222222
[1] "accuracy: 61.9980584427644 num_feat:4 fitness:25.9478865860143"
[1] 0.4444444 0.7222222
[1] 0.4444444 0.7222222
[1] "accuracy: 56.5145482714487 num_feat:4 fitness:22.9318476455312"
[1] 0.3260870 0.7042254
[1] 0.3260870 0.7042254
[1] "accuracy: 57.8656887121527 num_feat:4 fitness:21.1559403349799"
[1] 0.5952381 0.5600000
[1] 0.5952381 0.5600000
[1] "accuracy: 54.5492659830153 num_feat:4 fitness:23.1383593418973"
[1] 0.1250000 0.8695652
[1] 0.1250000 0.8695652
[1] "accuracy: 61.2694847073598 num_feat:4 fitness:16.827553850157"
[1] 0.3333333 0.7222222
[1] 0.3333333 0.7222222
[1] "accuracy: 62.9215152176969 num_feat:4 fitness:19.513201281892"
[1] 0.5434783 0.6056338
[1] 0.5434783 0.6056338
[1] "accuracy: 61.7584084846237 num_feat:4 fitness:24.3208982424685"
[1] 0.3478261 0.8591549
[1] 0.3478261 0.8591549
[1] "accuracy: 59.2535278313398 num_feat:4 fitness:15.531451418475"
[1] 0.7209302 0.4729730
[1] 0.7209302 0.4729730
[1] "accuracy: 61.1207038008748 num_feat:4 fitness:20.1613958113013"
[1] 0.1363636 0.8082192
[1] 0.1363636 0.8082192
[1] "accuracy: 58.6725080203423 num_feat:4 fitness:17.2265184182865"
[1] "elasticnet:4:20.6755052931003"
[1] "elasticnet:4:20.6755052931003"
[1] 0.3333333 0.7777778
[1] 0.3333333 0.7777778
[1] "accuracy: 59.9273078564979 num_feat:5 fitness:20.8961455356083"
[1] 0.3333333 0.8055556
[1] 0.3333333 0.8055556
[1] "accuracy: 58.4582292616633 num_feat:5 fitness:24.0818539332778"
[1] 0.3478261 0.7746479
[1] 0.3478261 0.7746479
[1] "accuracy: 58.1505435170665 num_feat:5 fitness:19.8323788451016"
[1] 0.5714286 0.5466667
[1] 0.5714286 0.5466667
[1] "accuracy: 54.7976128148324 num_feat:5 fitness:21.4298615143581"
[1] 0.04166667 0.98550725
[1] 0.04166667 0.98550725
[1] "accuracy: 59.4492203591459 num_feat:5 fitness:17.8819832006904"
[1] 0.1111111 0.7916667
[1] 0.1111111 0.7916667
[1] "accuracy: 58.3360409697902 num_feat:5 fitness:13.7445281667149"
[1] 0.4565217 0.5633803
[1] 0.4565217 0.5633803
[1] "accuracy: 59.7488136781059 num_feat:5 fitness:14.9487476171128"
[1] 0.3478261 0.7887324
[1] 0.3478261 0.7887324
[1] "accuracy: 57.9608820961484 num_feat:5 fitness:19.8803243773"
[1] 0.8139535 0.4459459
[1] 0.8139535 0.4459459
[1] "accuracy: 61.0032701783594 num_feat:5 fitness:19.2373237664105"
[1] 0.1590909 0.8630137
[1] 0.1590909 0.8630137
[1] "accuracy: 59.9547813171738 num_feat:5 fitness:23.5847711939165"
[1] "elasticnet:5:19.5517918150491"
[1] "elasticnet:4:20.6755052931003"
[1] 0.3111111 0.5972222
[1] 0.3111111 0.5972222
[1] "accuracy: 53.2991279875237 num_feat:6 fitness:15.1912252053356"
[1] 0.2000000 0.8194444
[1] 0.2000000 0.8194444
[1] "accuracy: 51.1042448676895 num_feat:6 fitness:20.0571328522231"
[1] 0.2173913 0.7746479
[1] 0.2173913 0.7746479
[1] "accuracy: 52.7652584444489 num_feat:6 fitness:18.1675288011381"
[1] 0.5714286 0.4666667
[1] 0.5714286 0.4666667
[1] "accuracy: 46.2804924474672 num_feat:6 fitness:10.5579985439753"
[1] 0.02083333 0.97101449
[1] 0.02083333 0.97101449
[1] "accuracy: 53.5551059234459 num_feat:6 fitness:12.8101862080779"
[1] 0.1111111 0.8194444
[1] 0.1111111 0.8194444
[1] "accuracy: 56.5346368898114 num_feat:6 fitness:13.1092793118008"
[1] 0.3695652 0.5774648
[1] 0.3695652 0.5774648
[1] "accuracy: 53.6907016677661 num_feat:6 fitness:9.58256680905963"
[1] 0.3695652 0.8169014
[1] 0.3695652 0.8169014
[1] "accuracy: 54.0114904736431 num_feat:6 fitness:16.905993165539"
[1] 0.7906977 0.4324324
[1] 0.7906977 0.4324324
[1] "accuracy: 52.7227190005248 num_feat:6 fitness:12.229755889824"
[1] 0.09090909 0.79452055
[1] 0.09090909 0.79452055
[1] "accuracy: 56.1658191398252 num_feat:6 fitness:17.5248657796312"
[1] "elasticnet:6:14.6136532566605"
[1] "elasticnet:4:20.6755052931003"
[1] 0.2444444 0.6944444
[1] 0.2444444 0.6944444
[1] "accuracy: 53.2037974370394 num_feat:7 fitness:14.6262666026987"
[1] 0.2222222 0.8333333
[1] 0.2222222 0.8333333
[1] "accuracy: 49.3321621466924 num_feat:7 fitness:20.0324780215725"
[1] 0.3478261 0.7042254
[1] 0.3478261 0.7042254
[1] "accuracy: 48.659551944432 num_feat:7 fitness:14.8067711797299"
[1] 0.5238095 0.5600000
[1] 0.5238095 0.5600000
[1] "accuracy: 46.5404602917069 num_feat:7 fitness:8.98853138078254"
[1] 0.02083333 0.91304348
[1] 0.02083333 0.91304348
[1] "accuracy: 49.0593439177443 num_feat:7 fitness:9.25136691676319"
[1] 0.1333333 0.6388889
[1] 0.1333333 0.6388889
[1] "accuracy: 53.6593436112649 num_feat:7 fitness:10.1402383354425"
[1] 0.4347826 0.5633803
[1] 0.4347826 0.5633803
[1] "accuracy: 52.7702487649931 num_feat:7 fitness:10.2224317542246"
[1] 0.3043478 0.7887324
[1] 0.3043478 0.7887324
[1] "accuracy: 50.3290976418272 num_feat:7 fitness:13.5946346699562"
[1] 0.7906977 0.4054054
[1] 0.7906977 0.4054054
[1] "accuracy: 51.5735465387621 num_feat:7 fitness:9.80388881687783"
[1] 0.1136364 0.7397260
[1] 0.1136364 0.7397260
[1] "accuracy: 53.0571364332637 num_feat:7 fitness:13.3923659569306"
[1] "elasticnet:7:12.4858973634978"
[1] "elasticnet:4:20.6755052931003"
[1] 0.1777778 0.8611111
[1] 0.1777778 0.8611111
[1] "accuracy: 58.5096423498935 num_feat:8 fitness:21.693715259542"
[1] 0.1777778 0.8750000
[1] 0.1777778 0.8750000
[1] "accuracy: 54.5091267592077 num_feat:8 fitness:22.3557504874509"
[1] 0.1739130 0.7887324
[1] 0.1739130 0.7887324
[1] "accuracy: 59.8499057367782 num_feat:8 fitness:20.0943737130119"
[1] 0.6428571 0.6000000
[1] 0.6428571 0.6000000
[1] "accuracy: 53.5281519964083 num_feat:8 fitness:18.3451179473591"
[1] 0.02083333 0.91304348
[1] 0.02083333 0.91304348
[1] "accuracy: 58.3288214797094 num_feat:8 fitness:24.3949968391864"
[1] 0.1777778 0.8333333
[1] 0.1777778 0.8333333
[1] "accuracy: 61.2149795958197 num_feat:8 fitness:21.0218391210541"
[1] 0.5000000 0.5633803
[1] 0.5000000 0.5633803
[1] "accuracy: 54.9815139291142 num_feat:8 fitness:8.25618221270467"
[1] 0.2391304 0.8309859
[1] 0.2391304 0.8309859
[1] "accuracy: 59.6165249295048 num_feat:8 fitness:20.1760993196134"
[1] 0.7674419 0.4729730
[1] 0.7674419 0.4729730
[1] "accuracy: 50.6607079021624 num_feat:8 fitness:14.5879130563953"
[1] 0.09090909 0.78082192
[1] 0.09090909 0.78082192
[1] "accuracy: 58.8858376301808 num_feat:8 fitness:19.8816419382804"
[1] "elasticnet:8:19.0807629894598"
[1] "elasticnet:4:20.6755052931003"
[1] 0.2222222 0.8611111
[1] 0.2222222 0.8611111
[1] "accuracy: 58.3121502269812 num_feat:9 fitness:23.1230144922565"
[1] 0.2666667 0.8611111
[1] 0.2666667 0.8611111
[1] "accuracy: 56.9715177986664 num_feat:9 fitness:24.1738185583575"
[1] 0.2391304 0.8169014
[1] 0.2391304 0.8169014
[1] "accuracy: 59.788670638824 num_feat:9 fitness:21.0111135855595"
[1] 0.7142857 0.6133333
[1] 0.7142857 0.6133333
[1] "accuracy: 54.3410439745586 num_feat:9 fitness:21.5712963042813"
[1] 0.1666667 0.9710145
[1] 0.1666667 0.9710145
[1] "accuracy: 58.3441589438159 num_feat:9 fitness:24.3355227209264"
[1] 0.2000000 0.8472222
[1] 0.2000000 0.8472222
[1] "accuracy: 62.8429155228415 num_feat:9 fitness:21.6941312622551"
[1] 0.4565217 0.6056338
[1] 0.4565217 0.6056338
[1] "accuracy: 60.2913875199384 num_feat:9 fitness:14.4602104131043"
[1] 0.2391304 0.9295775
[1] 0.2391304 0.9295775
[1] "accuracy: 63.1958060556745 num_feat:9 fitness:27.3076627355026"
[1] 0.8604651 0.3918919
[1] 0.8604651 0.3918919
[1] "accuracy: 57.0362019577361 num_feat:9 fitness:21.1982718524489"
[1] 0.06818182 0.75342466
[1] 0.06818182 0.75342466
[1] "accuracy: 63.0251926356299 num_feat:9 fitness:20.1120697698702"
[1] "elasticnet:9:21.8987111694562"
[1] "elasticnet:9:21.8987111694562"
[1] 0.2666667 0.8750000
[1] 0.2666667 0.8750000
[1] "accuracy: 62.059111645214 num_feat:10 fitness:24.7516658067677"
[1] 0.3111111 0.8611111
[1] 0.3111111 0.8611111
[1] "accuracy: 63.7213755714065 num_feat:10 fitness:27.6200870101979"
[1] 0.2391304 0.8450704
[1] 0.2391304 0.8450704
[1] "accuracy: 67.793076755948 num_feat:10 fitness:23.5095904097333"
[1] 0.7380952 0.6533333
[1] 0.7380952 0.6533333
[1] "accuracy: 55.4546824674638 num_feat:10 fitness:24.1931951132289"
[1] 0.1041667 1.0000000
[1] 0.1041667 1.0000000
[1] "accuracy: 63.6786435151998 num_feat:10 fitness:34.2781730545964"
[1] 0.1111111 0.9305556
[1] 0.1111111 0.9305556
[1] "accuracy: 71.1430549900352 num_feat:10 fitness:26.7651224712828"
[1] 0.4565217 0.6197183
[1] 0.4565217 0.6197183
[1] "accuracy: 64.9967823420938 num_feat:10 fitness:22.7368494601792"
[1] 0.2826087 0.9577465
[1] 0.2826087 0.9577465
[1] "accuracy: 64.6887567986574 num_feat:10 fitness:24.0801838111792"
[1] 0.6976744 0.6081081
[1] 0.6976744 0.6081081
[1] "accuracy: 60.3474194565042 num_feat:10 fitness:24.1519618614506"
[1] 0.1136364 0.8219178
[1] 0.1136364 0.8219178
[1] "accuracy: 65.150808025918 num_feat:10 fitness:24.1785821972776"
[1] "elasticnet:10:25.6265411195893"
[1] "elasticnet:10:25.6265411195893"
[1] 0.2444444 0.8750000
[1] 0.2444444 0.8750000
[1] "accuracy: 63.5968541526105 num_feat:11 fitness:25.8096881822672"
[1] 0.400 0.875
[1] 0.400 0.875
[1] "accuracy: 63.4969702603984 num_feat:11 fitness:28.6045103663937"
[1] 0.2173913 0.8591549
[1] 0.2173913 0.8591549
[1] "accuracy: 65.8260654344921 num_feat:11 fitness:26.6803460301751"
[1] 0.7619048 0.6133333
[1] 0.7619048 0.6133333
[1] "accuracy: 63.8277664755313 num_feat:11 fitness:27.1208324561622"
[1] 0.02083333 1.00000000
[1] 0.02083333 1.00000000
[1] "accuracy: 68.2687781233645 num_feat:11 fitness:27.602797992011"
[1] 0.1555556 0.9166667
[1] 0.1555556 0.9166667
[1] "accuracy: 64.1174364405425 num_feat:11 fitness:26.1892540626537"
[1] 0.4130435 0.7464789
[1] 0.4130435 0.7464789
[1] "accuracy: 66.303702626254 num_feat:11 fitness:26.6851003562361"
[1] 0.1956522 0.9295775
[1] 0.1956522 0.9295775
[1] "accuracy: 67.3094774104238 num_feat:11 fitness:27.3244347061454"
[1] 0.6046512 0.6621622
[1] 0.6046512 0.6621622
[1] "accuracy: 61.4350591301841 num_feat:11 fitness:25.1664847102045"
[1] 0.1136364 0.8219178
[1] 0.1136364 0.8219178
[1] "accuracy: 70.6056118144121 num_feat:11 fitness:30.5425328679692"
[1] "elasticnet:11:27.1725981730218"
[1] "elasticnet:11:27.1725981730218"
[1] 0.1555556 0.9444444
[1] 0.1555556 0.9444444
[1] "accuracy: 63.1505260505225 num_feat:12 fitness:25.5197431420857"
[1] 0.4000000 0.8888889
[1] 0.4000000 0.8888889
[1] "accuracy: 62.2717567051068 num_feat:12 fitness:27.7557962451433"
[1] 0.1956522 0.8591549
[1] 0.1956522 0.8591549
[1] "accuracy: 67.8002688839348 num_feat:12 fitness:26.2803569903998"
[1] 0.7857143 0.6533333
[1] 0.7857143 0.6533333
[1] "accuracy: 61.5449698757301 num_feat:12 fitness:27.7861693845003"
[1] 0.02083333 1.00000000
[1] 0.02083333 1.00000000
[1] "accuracy: 66.278237240654 num_feat:12 fitness:27.1035974909237"
[1] 0.1555556 0.9305556
[1] 0.1555556 0.9305556
[1] "accuracy: 68.3005297599572 num_feat:12 fitness:27.8330142252757"
[1] 0.3695652 0.7605634
[1] 0.3695652 0.7605634
[1] "accuracy: 64.7202169853265 num_feat:12 fitness:23.6886055109596"
[1] 0.1956522 0.9436620
[1] 0.1956522 0.9436620
[1] "accuracy: 65.8657060367645 num_feat:12 fitness:25.1608545997082"
[1] 0.6046512 0.6891892
[1] 0.6046512 0.6891892
[1] "accuracy: 60.4142289296825 num_feat:12 fitness:26.137064616864"
[1] 0.04545455 0.83561644
[1] 0.04545455 0.83561644
[1] "accuracy: 66.6901844021369 num_feat:12 fitness:23.7698039107256"
[1] "elasticnet:12:26.1035006116586"
[1] "elasticnet:11:27.1725981730218"
[1] 0.1333333 0.9444444
[1] 0.1333333 0.9444444
[1] "accuracy: 63.1976742600232 num_feat:13 fitness:25.6626974835631"
[1] 0.3777778 0.8888889
[1] 0.3777778 0.8888889
[1] "accuracy: 60.1845921142286 num_feat:13 fitness:24.3390710848231"
[1] 0.5217391 0.7746479
[1] 0.5217391 0.7746479
[1] "accuracy: 68.2753504627873 num_feat:13 fitness:25.6934574951802"
[1] 0.7619048 0.6400000
[1] 0.7619048 0.6400000
[1] "accuracy: 61.3161208231087 num_feat:13 fitness:27.8088072274295"
[1] 0.02083333 1.00000000
[1] 0.02083333 1.00000000
[1] "accuracy: 66.2535670344836 num_feat:13 fitness:28.1361235568375"
[1] 0.1555556 0.9305556
[1] 0.1555556 0.9305556
[1] "accuracy: 65.935310288734 num_feat:13 fitness:25.4126672094532"
[1] 0.4130435 0.7183099
[1] 0.4130435 0.7183099
[1] "accuracy: 64.6438686012575 num_feat:13 fitness:22.1134875901968"
[1] 0.1956522 0.9295775
[1] 0.1956522 0.9295775
[1] "accuracy: 65.4442953272117 num_feat:13 fitness:23.0361917715662"
[1] 0.7441860 0.5675676
[1] 0.7441860 0.5675676
[1] "accuracy: 60.4324213506341 num_feat:13 fitness:26.3022971704275"
[1] 0.06818182 0.84931507
[1] 0.06818182 0.84931507
[1] "accuracy: 67.2397880504018 num_feat:13 fitness:20.4581651427111"
[1] "elasticnet:13:24.8962965732188"
[1] "elasticnet:11:27.1725981730218"
[1] 0.3333333 0.9583333
[1] 0.3333333 0.9583333
[1] "accuracy: 82.5344488069156 num_feat:14 fitness:46.1563052915057"
[1] 0.4666667 0.9305556
[1] 0.4666667 0.9305556
[1] "accuracy: 85.0066594593478 num_feat:14 fitness:47.1784997993414"
[1] 0.6739130 0.8873239
[1] 0.6739130 0.8873239
[1] "accuracy: 83.4263742383847 num_feat:14 fitness:45.4510482023684"
[1] 0.8571429 0.7733333
[1] 0.8571429 0.7733333
[1] "accuracy: 80.174867089989 num_feat:14 fitness:47.2041717055319"
[1] 0.0625 1.0000
[1] 0.0625 1.0000
[1] "accuracy: 84.5990805086479 num_feat:14 fitness:44.3930188042345"
[1] 0.3111111 0.9861111
[1] 0.3111111 0.9861111
[1] "accuracy: 83.9022859029449 num_feat:14 fitness:46.3701877482416"
[1] 0.6304348 0.9577465
[1] 0.6304348 0.9577465
[1] "accuracy: 83.4004568682311 num_feat:14 fitness:42.7588451571981"
[1] 0.3043478 0.9718310
[1] 0.3043478 0.9718310
[1] "accuracy: 81.0021044983493 num_feat:14 fitness:39.5671584382231"
[1] 0.9534884 0.6351351
[1] 0.9534884 0.6351351
[1] "accuracy: 86.3019854654032 num_feat:14 fitness:47.7256609399897"
[1] 0.5454545 0.9178082
[1] 0.5454545 0.9178082
[1] "accuracy: 85.5041968263351 num_feat:14 fitness:41.9595378167728"
[1] "elasticnet:14:44.8764433903407"
[1] "elasticnet:14:44.8764433903407"
[1] 0.3777778 0.9861111
[1] 0.3777778 0.9861111
[1] "accuracy: 81.7173111622075 num_feat:15 fitness:46.4477812894311"
[1] 0.4444444 0.8611111
[1] 0.4444444 0.8611111
[1] "accuracy: 86.037894735938 num_feat:15 fitness:48.6907037621179"
[1] 0.7173913 0.9577465
[1] 0.7173913 0.9577465
[1] "accuracy: 83.4263742383847 num_feat:15 fitness:42.6578446770747"
[1] 0.8809524 0.7733333
[1] 0.8809524 0.7733333
[1] "accuracy: 81.5425362212514 num_feat:15 fitness:47.0582574482936"
[1] 0.08333333 1.00000000
[1] 0.08333333 1.00000000
[1] "accuracy: 85.4606200076049 num_feat:15 fitness:45.6468491349865"
[1] 0.3111111 1.0000000
[1] 0.3111111 1.0000000
[1] "accuracy: 83.8947630589789 num_feat:15 fitness:47.8409527896164"
[1] 0.6086957 0.9718310
[1] 0.6086957 0.9718310
[1] "accuracy: 84.0330399901558 num_feat:15 fitness:43.9759880636724"
[1] 0.326087 0.971831
[1] 0.326087 0.971831
[1] "accuracy: 80.4596985843238 num_feat:15 fitness:42.4639998046067"
[1] 0.7441860 0.7972973
[1] 0.7441860 0.7972973
[1] "accuracy: 85.0596900793034 num_feat:15 fitness:46.530247914002"
[1] 0.5454545 0.9178082
[1] 0.5454545 0.9178082
[1] "accuracy: 84.2509036942125 num_feat:15 fitness:41.6388272629385"
[1] "elasticnet:15:45.295145214674"
[1] "elasticnet:15:45.295145214674"
[1] 0.4444444 0.9861111
[1] 0.4444444 0.9861111
[1] "accuracy: 85.1219699417156 num_feat:16 fitness:46.3599562417863"
[1] 0.4666667 0.9305556
[1] 0.4666667 0.9305556
[1] "accuracy: 87.2756081452066 num_feat:16 fitness:50.7030040613428"
[1] 0.7173913 0.9718310
[1] 0.7173913 0.9718310
[1] "accuracy: 84.5401809006823 num_feat:16 fitness:44.6200549136567"
[1] 0.8571429 0.8533333
[1] 0.8571429 0.8533333
[1] "accuracy: 80.9353236989985 num_feat:16 fitness:47.4968472841468"
[1] 0.0625 1.0000
[1] 0.0625 1.0000
[1] "accuracy: 89.1235525059673 num_feat:16 fitness:46.8088256194504"
[1] 0.4222222 1.0000000
[1] 0.4222222 1.0000000
[1] "accuracy: 84.5177562760837 num_feat:16 fitness:46.7492447172862"
[1] 0.8478261 0.9859155
[1] 0.8478261 0.9859155
[1] "accuracy: 82.1982758424007 num_feat:16 fitness:45.1225707793115"
[1] 0.5217391 0.9295775
[1] 0.5217391 0.9295775
[1] "accuracy: 82.7378145945524 num_feat:16 fitness:46.705023395587"
[1] 0.7209302 0.8378378
[1] 0.7209302 0.8378378
[1] "accuracy: 87.6895538864264 num_feat:16 fitness:49.1635646391701"
[1] 0.7727273 0.9452055
[1] 0.7727273 0.9452055
[1] "accuracy: 86.1313519579101 num_feat:16 fitness:44.1586303542781"
[1] "elasticnet:16:46.7887722006016"
[1] "elasticnet:16:46.7887722006016"
[1] 0.4444444 0.9861111
[1] 0.4444444 0.9861111
[1] "accuracy: 86.2329193642318 num_feat:17 fitness:47.9079907244988"
[1] 0.4888889 0.9583333
[1] 0.4888889 0.9583333
[1] "accuracy: 87.9187874160946 num_feat:17 fitness:50.824808218548"
[1] 0.7173913 0.9718310
[1] 0.7173913 0.9718310
[1] "accuracy: 85.6686029568051 num_feat:17 fitness:46.328166748615"
[1] 0.8571429 0.8933333
[1] 0.8571429 0.8933333
[1] "accuracy: 82.9374002082041 num_feat:17 fitness:47.852271995004"
[1] 0.0625 1.0000
[1] 0.0625 1.0000
[1] "accuracy: 89.2672003263585 num_feat:17 fitness:46.6554599223542"
[1] 0.5333333 1.0000000
[1] 0.5333333 1.0000000
[1] "accuracy: 86.1723662399479 num_feat:17 fitness:49.8040781377852"
[1] 0.8695652 0.9859155
[1] 0.8695652 0.9859155
[1] "accuracy: 83.5159069233924 num_feat:17 fitness:46.3425244208588"
[1] 0.5652174 0.9295775
[1] 0.5652174 0.9295775
[1] "accuracy: 84.9611899969429 num_feat:17 fitness:45.7250045844504"
[1] 0.7209302 0.8378378
[1] 0.7209302 0.8378378
[1] "accuracy: 89.0184935040268 num_feat:17 fitness:50.1602244751098"
[1] 0.7500000 0.9589041
[1] 0.7500000 0.9589041
[1] "accuracy: 88.8390533726966 num_feat:17 fitness:45.5099612314247"
[1] "elasticnet:17:47.7110490458649"
[1] "elasticnet:17:47.7110490458649"
[1] 0.4222222 0.9861111
[1] 0.4222222 0.9861111
[1] "accuracy: 88.4531759043184 num_feat:18 fitness:48.0333165495065"
[1] 0.5111111 0.9722222
[1] 0.5111111 0.9722222
[1] "accuracy: 88.0790129831379 num_feat:18 fitness:51.1906308430253"
[1] 0.7608696 0.9859155
[1] 0.7608696 0.9859155
[1] "accuracy: 86.3942043654563 num_feat:18 fitness:46.6589944716548"
[1] 0.8571429 0.9333333
[1] 0.8571429 0.9333333
[1] "accuracy: 86.1938784703837 num_feat:18 fitness:50.3945858143781"
[1] 0.125 1.000
[1] 0.125 1.000
[1] "accuracy: 91.7435802324789 num_feat:18 fitness:49.451209835294"
[1] 0.5777778 1.0000000
[1] 0.5777778 1.0000000
[1] "accuracy: 87.8974573771162 num_feat:18 fitness:50.001115626038"
[1] 0.8913043 0.9718310
[1] 0.8913043 0.9718310
[1] "accuracy: 86.5367396080973 num_feat:18 fitness:50.0524844704279"
[1] 0.5652174 0.9154930
[1] 0.5652174 0.9154930
[1] "accuracy: 86.2520770032452 num_feat:18 fitness:50.1579046615199"
[1] 0.7674419 0.8783784
[1] 0.7674419 0.8783784
[1] "accuracy: 89.6258102768611 num_feat:18 fitness:51.8905875894677"
[1] 0.8636364 0.9178082
[1] 0.8636364 0.9178082
[1] "accuracy: 89.1398531052841 num_feat:18 fitness:48.8424990638171"
[1] "elasticnet:18:49.6673328925129"
[1] "elasticnet:18:49.6673328925129"
[1] 0.4888889 0.9861111
[1] 0.4888889 0.9861111
[1] "accuracy: 87.8957772968784 num_feat:19 fitness:47.0996337738415"
[1] 0.5111111 0.9722222
[1] 0.5111111 0.9722222
[1] "accuracy: 89.2261316768506 num_feat:19 fitness:51.8034407716409"
[1] 0.7173913 0.9859155
[1] 0.7173913 0.9859155
[1] "accuracy: 86.3942043654563 num_feat:19 fitness:50.8708103066424"
[1] 0.8571429 0.9333333
[1] 0.8571429 0.9333333
[1] "accuracy: 86.1938784703837 num_feat:19 fitness:50.0614399758263"
[1] 0.1041667 1.0000000
[1] 0.1041667 1.0000000
[1] "accuracy: 91.588218188793 num_feat:19 fitness:49.6162202070081"
[1] 0.5777778 1.0000000
[1] 0.5777778 1.0000000
[1] "accuracy: 89.142449963545 num_feat:19 fitness:50.608209925779"
[1] 0.8695652 0.9859155
[1] 0.8695652 0.9859155
[1] "accuracy: 86.1896344167245 num_feat:19 fitness:48.8535081555222"
[1] 0.5652174 0.9154930
[1] 0.5652174 0.9154930
[1] "accuracy: 86.8697799343166 num_feat:19 fitness:51.3059737445899"
[1] 0.7674419 0.8648649
[1] 0.7674419 0.8648649
[1] "accuracy: 89.6258102768611 num_feat:19 fitness:51.7305334322084"
[1] 0.8409091 0.9452055
[1] 0.8409091 0.9452055
[1] "accuracy: 89.9854226633618 num_feat:19 fitness:46.7146880070243"
[1] "elasticnet:19:49.8664458300083"
[1] "elasticnet:19:49.8664458300083"
[1] 0.5111111 1.0000000
[1] 0.5111111 1.0000000
[1] "accuracy: 89.5463588466775 num_feat:20 fitness:53.0743004097278"
[1] 0.5555556 0.9722222
[1] 0.5555556 0.9722222
[1] "accuracy: 90.2041730702736 num_feat:20 fitness:52.0836000260843"
[1] 0.7173913 0.9859155
[1] 0.7173913 0.9859155
[1] "accuracy: 88.0960382760265 num_feat:20 fitness:48.4487113800098"
[1] 0.8571429 0.9466667
[1] 0.8571429 0.9466667
[1] "accuracy: 86.9580380016316 num_feat:20 fitness:51.7759025005335"
[1] 0.125 1.000
[1] 0.125 1.000
[1] "accuracy: 88.7342100294327 num_feat:20 fitness:50.4667768620605"
[1] 0.5777778 1.0000000
[1] 0.5777778 1.0000000
[1] "accuracy: 87.7305529071009 num_feat:20 fitness:50.194093334722"
[1] 0.8695652 1.0000000
[1] 0.8695652 1.0000000
[1] "accuracy: 88.4373552055327 num_feat:20 fitness:50.6670498105793"
[1] 0.6956522 0.9577465
[1] 0.6956522 0.9577465
[1] "accuracy: 88.2395570111611 num_feat:20 fitness:51.6220896484605"
[1] 0.9069767 0.8108108
[1] 0.9069767 0.8108108
[1] "accuracy: 91.5377504715743 num_feat:20 fitness:53.18243495881"
[1] 0.8863636 0.9315068
[1] 0.8863636 0.9315068
[1] "accuracy: 90.000574893522 num_feat:20 fitness:48.4933403609315"
[1] "elasticnet:20:51.0008299291919"
[1] "elasticnet:20:51.0008299291919"
[1] 0.4666667 1.0000000
[1] 0.4666667 1.0000000
[1] "accuracy: 88.8532046323596 num_feat:21 fitness:50.95760040927"
[1] 0.5777778 0.9722222
[1] 0.5777778 0.9722222
[1] "accuracy: 89.1010805358178 num_feat:21 fitness:51.0493381373204"
[1] 0.7391304 0.9859155
[1] 0.7391304 0.9859155
[1] "accuracy: 89.359239033211 num_feat:21 fitness:49.4105054866025"
[1] 0.8571429 0.9733333
[1] 0.8571429 0.9733333
[1] "accuracy: 88.5090017935246 num_feat:21 fitness:54.8535467762623"
[1] 0.1666667 1.0000000
[1] 0.1666667 1.0000000
[1] "accuracy: 90.8572074823366 num_feat:21 fitness:50.054077207624"
[1] 0.5777778 1.0000000
[1] 0.5777778 1.0000000
[1] "accuracy: 89.6587445873649 num_feat:21 fitness:51.4952379310599"
[1] 0.8695652 1.0000000
[1] 0.8695652 1.0000000
[1] "accuracy: 88.8748887387629 num_feat:21 fitness:50.3136969932905"
[1] 0.6956522 0.9295775
[1] 0.6956522 0.9295775
[1] "accuracy: 87.1513956210778 num_feat:21 fitness:49.6481932610925"
[1] 0.9069767 0.8243243
[1] 0.9069767 0.8243243
[1] "accuracy: 88.7806104255839 num_feat:21 fitness:50.7906140971297"
[1] 0.8409091 0.9315068
[1] 0.8409091 0.9315068
[1] "accuracy: 89.9141918317339 num_feat:21 fitness:49.9121914292669"
[1] "elasticnet:21:50.8485001728919"
[1] "elasticnet:20:51.0008299291919"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "forward"
[1] 0.8666667 0.9027778
[1] 0.8666667 0.9027778
[1] "accuracy: 87.147834432023 num_feat:3 fitness:45.3546971785617"
[1] 0.7555556 0.9583333
[1] 0.7555556 0.9583333
[1] "accuracy: 83.5913634726461 num_feat:3 fitness:51.6861775641077"
[1] 0.7608696 0.9154930
[1] 0.7608696 0.9154930
[1] "accuracy: 86.0523280907411 num_feat:3 fitness:44.5977966209884"
[1] 0.7142857 0.9600000
[1] 0.7142857 0.9600000
[1] "accuracy: 80.4845821874592 num_feat:3 fitness:46.0998527348288"
[1] 0.4375 1.0000
[1] 0.4375 1.0000
[1] "accuracy: 85.7087959658562 num_feat:3 fitness:44.4297076894457"
[1] 0.8222222 0.8750000
[1] 0.8222222 0.8750000
[1] "accuracy: 84.4250530340046 num_feat:3 fitness:47.2180929951669"
[1] 0.7608696 0.9577465
[1] 0.7608696 0.9577465
[1] "accuracy: 84.1799327751162 num_feat:3 fitness:47.7702445388098"
[1] 0.7391304 0.9014085
[1] 0.7391304 0.9014085
[1] "accuracy: 81.9955479603096 num_feat:3 fitness:47.7733427053493"
[1] 0.9767442 0.7027027
[1] 0.9767442 0.7027027
[1] "accuracy: 86.6817370086106 num_feat:3 fitness:50.7582667293136"
[1] 0.7727273 0.8767123
[1] 0.7727273 0.8767123
[1] "accuracy: 81.0872964016804 num_feat:3 fitness:48.2747608357389"
[1] "f.test:3:47.3962939592311"
[1] "f.test:3:47.3962939592311"
[1] 0.8666667 0.9166667
[1] 0.8666667 0.9166667
[1] "accuracy: 85.7896060627712 num_feat:4 fitness:44.368160967161"
[1] 0.7555556 0.9305556
[1] 0.7555556 0.9305556
[1] "accuracy: 81.3447791610664 num_feat:4 fitness:50.0330975699377"
[1] 0.5869565 0.9295775
[1] 0.5869565 0.9295775
[1] "accuracy: 83.4889331161046 num_feat:4 fitness:41.2873524122353"
[1] 0.7142857 0.9466667
[1] 0.7142857 0.9466667
[1] "accuracy: 80.2806740734037 num_feat:4 fitness:44.9983238142113"
[1] 0.4583333 1.0000000
[1] 0.4583333 1.0000000
[1] "accuracy: 84.9701232323684 num_feat:4 fitness:40.6550360705496"
[1] 0.8666667 0.8472222
[1] 0.8666667 0.8472222
[1] "accuracy: 83.3883064579493 num_feat:4 fitness:46.0090756745317"
[1] 0.7826087 0.9577465
[1] 0.7826087 0.9577465
[1] "accuracy: 84.4004806295823 num_feat:4 fitness:48.4075522029247"
[1] 0.6956522 0.9154930
[1] 0.6956522 0.9154930
[1] "accuracy: 81.1183383878091 num_feat:4 fitness:45.447008399677"
[1] 0.9767442 0.6891892
[1] 0.9767442 0.6891892
[1] "accuracy: 83.6884506330591 num_feat:4 fitness:47.0508959498339"
[1] 0.7727273 0.8904110
[1] 0.7727273 0.8904110
[1] "accuracy: 79.1884692207183 num_feat:4 fitness:46.8137340494595"
[1] "f.test:4:45.5070237110522"
[1] "f.test:3:47.3962939592311"
[1] 0.9333333 0.9166667
[1] 0.9333333 0.9166667
[1] "accuracy: 89.530705651535 num_feat:5 fitness:48.2897601393019"
[1] 0.8222222 0.9583333
[1] 0.8222222 0.9583333
[1] "accuracy: 90.2747335745771 num_feat:5 fitness:57.1009446261488"
[1] 0.8695652 0.9295775
[1] 0.8695652 0.9295775
[1] "accuracy: 90.2194111969334 num_feat:5 fitness:52.9217064170175"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 89.2450951338135 num_feat:5 fitness:54.2453108057565"
[1] 0.4583333 1.0000000
[1] 0.4583333 1.0000000
[1] "accuracy: 89.4013716424704 num_feat:5 fitness:45.8680353857237"
[1] 0.8444444 0.9583333
[1] 0.8444444 0.9583333
[1] "accuracy: 89.8428802212114 num_feat:5 fitness:53.2219736176736"
[1] 0.8695652 0.9859155
[1] 0.8695652 0.9859155
[1] "accuracy: 89.5403220037799 num_feat:5 fitness:53.0939492714171"
[1] 0.7391304 0.9577465
[1] 0.7391304 0.9577465
[1] "accuracy: 87.1296715767881 num_feat:5 fitness:51.2505521551077"
[1] 0.9767442 0.6891892
[1] 0.9767442 0.6891892
[1] "accuracy: 90.8981016342652 num_feat:5 fitness:53.8519006232508"
[1] 0.8409091 0.8767123
[1] 0.8409091 0.8767123
[1] "accuracy: 90.0587843026199 num_feat:5 fitness:54.7954635103805"
[1] "f.test:5:52.4639596551778"
[1] "f.test:5:52.4639596551778"
[1] 0.9333333 0.9027778
[1] 0.9333333 0.9027778
[1] "accuracy: 90.4006786167916 num_feat:6 fitness:49.6225960673161"
[1] 0.8444444 0.9722222
[1] 0.8444444 0.9722222
[1] "accuracy: 90.6812254305915 num_feat:6 fitness:57.2177669798032"
[1] 0.7826087 0.9154930
[1] 0.7826087 0.9154930
[1] "accuracy: 90.002676737011 num_feat:6 fitness:51.2303540996555"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 89.1806543314488 num_feat:6 fitness:54.4455302534233"
[1] 0.4166667 1.0000000
[1] 0.4166667 1.0000000
[1] "accuracy: 89.6984998518278 num_feat:6 fitness:47.0141944091298"
[1] 0.8666667 0.9583333
[1] 0.8666667 0.9583333
[1] "accuracy: 89.2330283039339 num_feat:6 fitness:55.4961879932893"
[1] 0.8913043 0.9859155
[1] 0.8913043 0.9859155
[1] "accuracy: 89.2476347389362 num_feat:6 fitness:51.197998773906"
[1] 0.7391304 0.9577465
[1] 0.7391304 0.9577465
[1] "accuracy: 87.1296715767881 num_feat:6 fitness:51.0401856421357"
[1] 0.9767442 0.7027027
[1] 0.9767442 0.7027027
[1] "accuracy: 90.9644605266777 num_feat:6 fitness:54.094428464174"
[1] 0.8863636 0.9178082
[1] 0.8863636 0.9178082
[1] "accuracy: 89.9781844380709 num_feat:6 fitness:54.6353995850339"
[1] "f.test:6:52.5994642267867"
[1] "f.test:6:52.5994642267867"
[1] 0.9333333 0.9027778
[1] 0.9333333 0.9027778
[1] "accuracy: 90.4006786167916 num_feat:7 fitness:48.2769550688739"
[1] 0.8222222 0.9861111
[1] 0.8222222 0.9861111
[1] "accuracy: 90.6378053372548 num_feat:7 fitness:56.9838509494631"
[1] 0.7608696 0.9295775
[1] 0.7608696 0.9295775
[1] "accuracy: 90.2344359541136 num_feat:7 fitness:51.6548729993457"
[1] 0.7857143 0.9866667
[1] 0.7857143 0.9866667
[1] "accuracy: 89.1806543314488 num_feat:7 fitness:54.2478091023245"
[1] 0.3958333 1.0000000
[1] 0.3958333 1.0000000
[1] "accuracy: 89.6984998518278 num_feat:7 fitness:46.9134530209508"
[1] 0.8666667 0.9583333
[1] 0.8666667 0.9583333
[1] "accuracy: 89.2330283039339 num_feat:7 fitness:54.7312325534986"
[1] 0.8913043 0.9859155
[1] 0.8913043 0.9859155
[1] "accuracy: 89.1228869776201 num_feat:7 fitness:50.6734934812969"
[1] 0.7608696 0.9577465
[1] 0.7608696 0.9577465
[1] "accuracy: 87.1636189906885 num_feat:7 fitness:50.5309425032444"
[1] 0.9767442 0.7027027
[1] 0.9767442 0.7027027
[1] "accuracy: 90.0054899326829 num_feat:7 fitness:53.4786859734286"
[1] 0.8636364 0.9315068
[1] 0.8636364 0.9315068
[1] "accuracy: 90.1579618548292 num_feat:7 fitness:55.2002290136451"
[1] "f.test:7:52.2691524666072"
[1] "f.test:6:52.5994642267867"
[1] 0.9111111 0.9027778
[1] 0.9111111 0.9027778
[1] "accuracy: 90.1742006725584 num_feat:8 fitness:47.9393561928066"
[1] 0.8222222 0.9722222
[1] 0.8222222 0.9722222
[1] "accuracy: 90.6378053372548 num_feat:8 fitness:56.9490838499802"
[1] 0.7608696 0.9295775
[1] 0.7608696 0.9295775
[1] "accuracy: 90.2344359541136 num_feat:8 fitness:50.8084603402771"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 88.6180482315631 num_feat:8 fitness:53.8346057270154"
[1] 0.3958333 1.0000000
[1] 0.3958333 1.0000000
[1] "accuracy: 89.6984998518278 num_feat:8 fitness:46.0812686975818"
[1] 0.8666667 0.9583333
[1] 0.8666667 0.9583333
[1] "accuracy: 89.152036530466 num_feat:8 fitness:53.7787175283872"
[1] 0.8913043 0.9718310
[1] 0.8913043 0.9718310
[1] "accuracy: 89.1228869776201 num_feat:8 fitness:52.7535834346605"
[1] 0.8695652 0.9577465
[1] 0.8695652 0.9577465
[1] "accuracy: 87.1636189906885 num_feat:8 fitness:50.8748541677521"
[1] 0.9767442 0.7027027
[1] 0.9767442 0.7027027
[1] "accuracy: 90.0054899326829 num_feat:8 fitness:53.797408875684"
[1] 0.8636364 0.9315068
[1] 0.8636364 0.9315068
[1] "accuracy: 90.1579618548292 num_feat:8 fitness:55.2001841363845"
[1] "f.test:8:52.2017522950529"
[1] "f.test:6:52.5994642267867"
[1] 0.8666667 0.9166667
[1] 0.8666667 0.9166667
[1] "accuracy: 90.4006786167916 num_feat:9 fitness:48.3270445491691"
[1] 0.8222222 0.9583333
[1] 0.8222222 0.9583333
[1] "accuracy: 90.779028987455 num_feat:9 fitness:56.9218788175297"
[1] 0.7826087 0.9436620
[1] 0.7826087 0.9436620
[1] "accuracy: 88.3562821637916 num_feat:9 fitness:48.1834923848218"
[1] 0.7857143 0.9866667
[1] 0.7857143 0.9866667
[1] "accuracy: 88.6180482315631 num_feat:9 fitness:53.8940846592785"
[1] 0.375 1.000
[1] 0.375 1.000
[1] "accuracy: 89.7018950933652 num_feat:9 fitness:47.58621689948"
[1] 0.8666667 0.9583333
[1] 0.8666667 0.9583333
[1] "accuracy: 89.152036530466 num_feat:9 fitness:53.915138013067"
[1] 0.8913043 0.9295775
[1] 0.8913043 0.9295775
[1] "accuracy: 89.1228869776201 num_feat:9 fitness:54.0242559067122"
[1] 0.8695652 0.9577465
[1] 0.8695652 0.9577465
[1] "accuracy: 87.0704224750366 num_feat:9 fitness:52.4252435975493"
[1] 0.9767442 0.7297297
[1] 0.9767442 0.7297297
[1] "accuracy: 90.0469177400331 num_feat:9 fitness:53.7777335189504"
[1] 0.8636364 0.9315068
[1] 0.8636364 0.9315068
[1] "accuracy: 90.0569025475115 num_feat:9 fitness:54.1701481695062"
[1] "f.test:9:52.3225236516064"
[1] "f.test:6:52.5994642267867"
[1] 0.8666667 0.9444444
[1] 0.8666667 0.9444444
[1] "accuracy: 89.8901838212271 num_feat:10 fitness:47.6777035905927"
[1] 0.8222222 0.9583333
[1] 0.8222222 0.9583333
[1] "accuracy: 89.7490990626859 num_feat:10 fitness:56.2630615766351"
[1] 0.8043478 0.9295775
[1] 0.8043478 0.9295775
[1] "accuracy: 89.1845386633008 num_feat:10 fitness:47.7139977291664"
[1] 0.7619048 0.9866667
[1] 0.7619048 0.9866667
[1] "accuracy: 87.4811744911586 num_feat:10 fitness:52.9818606671906"
[1] 0.4583333 1.0000000
[1] 0.4583333 1.0000000
[1] "accuracy: 88.939794544247 num_feat:10 fitness:47.5791509369604"
[1] 0.8666667 0.9305556
[1] 0.8666667 0.9305556
[1] "accuracy: 87.2080723248815 num_feat:10 fitness:52.3649938892507"
[1] 0.8913043 0.9436620
[1] 0.8913043 0.9436620
[1] "accuracy: 89.2194604792989 num_feat:10 fitness:55.5036878196712"
[1] 0.8043478 0.9577465
[1] 0.8043478 0.9577465
[1] "accuracy: 87.656071550576 num_feat:10 fitness:52.4476167602217"
[1] 0.9767442 0.7567568
[1] 0.9767442 0.7567568
[1] "accuracy: 90.8746763111309 num_feat:10 fitness:54.4660751375806"
[1] 0.8636364 0.9041096
[1] 0.8636364 0.9041096
[1] "accuracy: 89.3161443508698 num_feat:10 fitness:53.5460414940793"
[1] "f.test:10:52.0544189601349"
[1] "f.test:6:52.5994642267867"
[1] 0.8888889 0.9305556
[1] 0.8888889 0.9305556
[1] "accuracy: 89.2072803023983 num_feat:11 fitness:47.7714819026191"
[1] 0.8222222 0.9444444
[1] 0.8222222 0.9444444
[1] "accuracy: 89.8360045493464 num_feat:11 fitness:56.309299486724"
[1] 0.8260870 0.9295775
[1] 0.8260870 0.9295775
[1] "accuracy: 89.2300646716563 num_feat:11 fitness:45.280641749292"
[1] 0.7857143 0.9866667
[1] 0.7857143 0.9866667
[1] "accuracy: 87.7679784434762 num_feat:11 fitness:53.2564425636919"
[1] 0.4375 1.0000
[1] 0.4375 1.0000
[1] "accuracy: 88.939794544247 num_feat:11 fitness:47.7909164075523"
[1] 0.9111111 0.9166667
[1] 0.9111111 0.9166667
[1] "accuracy: 87.02998683335 num_feat:11 fitness:52.3666649540744"
[1] 0.8913043 0.9436620
[1] 0.8913043 0.9436620
[1] "accuracy: 88.2099054649208 num_feat:11 fitness:54.4087193382345"
[1] 0.7608696 0.9577465
[1] 0.7608696 0.9577465
[1] "accuracy: 86.6767464702963 num_feat:11 fitness:51.1731524739385"
[1] 0.9767442 0.7837838
[1] 0.9767442 0.7837838
[1] "accuracy: 89.8869688250648 num_feat:11 fitness:53.724123157116"
[1] 0.8636364 0.9178082
[1] 0.8636364 0.9178082
[1] "accuracy: 89.3161443508698 num_feat:11 fitness:53.1754070079572"
[1] "f.test:11:51.52568490412"
[1] "f.test:6:52.5994642267867"
[1] 0.9111111 0.9166667
[1] 0.9111111 0.9166667
[1] "accuracy: 89.3789347700244 num_feat:12 fitness:47.9207298227728"
[1] 0.8222222 0.9444444
[1] 0.8222222 0.9444444
[1] "accuracy: 89.8360045493464 num_feat:12 fitness:56.3092546094633"
[1] 0.826087 0.915493
[1] 0.826087 0.915493
[1] "accuracy: 89.2300646716563 num_feat:12 fitness:47.4473958806505"
[1] 0.7380952 0.9866667
[1] 0.7380952 0.9866667
[1] "accuracy: 87.7679784434762 num_feat:12 fitness:53.1373500673836"
[1] 0.4583333 1.0000000
[1] 0.4583333 1.0000000
[1] "accuracy: 88.939794544247 num_feat:12 fitness:46.9032299324053"
[1] 0.9111111 0.9305556
[1] 0.9111111 0.9305556
[1] "accuracy: 87.02998683335 num_feat:12 fitness:52.9723001114238"
[1] 0.8695652 0.9436620
[1] 0.8695652 0.9436620
[1] "accuracy: 87.3711912949224 num_feat:12 fitness:52.9307328796759"
[1] 0.7173913 0.9577465
[1] 0.7173913 0.9577465
[1] "accuracy: 86.6767464702963 num_feat:12 fitness:50.960132899697"
[1] 0.9767442 0.7432432
[1] 0.9767442 0.7432432
[1] "accuracy: 89.8869688250648 num_feat:12 fitness:53.622726928504"
[1] 0.8636364 0.9178082
[1] 0.8636364 0.9178082
[1] "accuracy: 89.3161443508698 num_feat:12 fitness:53.5801983149004"
[1] "f.test:12:51.5784051446877"
[1] "dim of scoring matrix is "
[1] 22283     5
[1] 22283
[1] "DS index stage 1"
[1] 0.3212005
[1] "bestgenelist"
 [1]     1     2     3     4     5     6     7     8     9    10    11    12
[13]    13    14    15  1616  1617  3490  4035  4752  7147  9092  9093  9094
[25] 12339 13819 15102
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
     1405_i_at 1431_at 1438_at 1487_at 1494_f_at 1598_g_at 160020_at 202088_at
[1,]    6.2325  6.8450  7.5774  9.3080    8.5992   10.6707    9.2059   14.6123
[2,]    6.9047  5.8878  9.8562  8.8356    8.3173   10.0085    9.2157   14.9213
[3,]    6.5940  5.6843  7.4038  9.5398    8.7748    9.9406    8.8970   12.9683
     202089_s_at 203963_at 204508_s_at 205225_at 207626_s_at 209602_s_at
[1,]     14.1629   12.0638     10.1763   13.0759      7.4760     11.1535
[2,]     14.5094   11.3553      9.3275   13.7616      3.5539     10.8437
[3,]     11.7586   12.3832      9.9200   12.7360      7.2242     10.7019
     209603_at 209604_s_at 212956_at 214440_at 215729_s_at
[1,]   10.5793     14.3763   13.3600   12.6295      2.9565
[2,]   10.5772     14.0214   13.2925   13.4492      1.5807
[3,]   11.1181     14.5222   12.3582   12.3205      5.6368
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327  9.2305  8.1481  6.1196
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568  9.1180  8.3105  7.1575
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579  9.3514  8.1214  7.7247
     1405_i_at 1431_at 1438_at 1487_at 1494_f_at 1598_g_at 160020_at 202088_at
[1,]    4.2718  7.1375  8.5984  8.9272    9.0705   10.3643   10.1083   14.9541
[2,]    8.4540  6.6935  8.5378  8.8336    8.7718   11.4333    9.9977   13.8916
[3,]    9.9479  7.7319  8.2890  9.4868    9.9207   11.6336   10.1420   11.1969
     202089_s_at 203963_at 204508_s_at 205225_at 207626_s_at 209602_s_at
[1,]     14.0631   12.4052      9.8038   13.8754      8.5889     11.9413
[2,]     12.7077   10.4033      7.9689   11.7217      7.0887     11.0319
[3,]     10.1126    9.8307      7.6789   10.9960      5.7342      8.8487
     209603_at 209604_s_at 212956_at 214440_at 215729_s_at
[1,]   11.9790     15.0625   13.5201   14.4201      1.9565
[2,]   10.8744     14.4978   12.5480    9.4904      5.3426
[3,]    8.0211     12.4583   11.2917    9.9120      5.3609
[1] "numgenes selected:27"
[1] "test acc:0.87"
[1] "test AUC acc:0.870323665405633"
[1] "10 fold train96.1538461538462"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 49  1
         2  1 79
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 34  8
        2  5 53
[1] "train acc:0.984615384615385"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 49  1
         2  1 79
[1] "DS index stage 1"
[1] 0.3212005
[1] "KI index stage 1"
[1] 0.06515635
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 130  27
> 
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=5,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.01,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=0.8))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 5"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.7"
[1] "weightB: 0.2"
[1] "weightC: 0.05"
[1] "weightD: 0.05"
[1] "featweight.max: 0.01"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.45"
[1] "confusionprob: 0.2"
[1] "leaderprob: 0.25"
[1] "wmax: 1"
[1] "wmin: 1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 3"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 1"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 96.92308
[1] "here"
[1] "s"
[1] 104
[1] 130  27
[1] 10
[1] "learning sets: 1"
  [1] 118 110  23 129  33  31  43  24  42  78  54  30  72   6  46  16  83  29
 [19]  18 104  73  71  66  76  90  98  51  74   8 103  13  68  45  32  22  15
 [37] 109   5  17  14  12  96 126  39  95 123  70  19  36  28  82 122 101  55
 [55]  27  85 121  38  75  84 119   4   7 105  37  86 128 125  44  58 116 107
 [73]  62  88 106  61  65  69  25  40  81  93  50  10  11   3 114 100 102  63
 [91]  26   1  52  67  92  41 113  35  64  77  21 130  34   2
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -53.89113
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -59.81315
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -62.02252
[1] "Best solution:"
 [1] 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0
[1] 12
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "Best fitness updated to:"
[1] -62.54488
[1] "Best solution:"
 [1] 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1
[1] 12
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 26
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 26
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "Best fitness updated to:"
[1] -63.18831
[1] "Best solution:"
 [1] 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1
[1] 15
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 24
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 67
[1] "Best fitness updated to:"
[1] -63.37021
[1] "Best solution:"
 [1] 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1
[1] 13
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "Best fitness updated to:"
[1] -63.79746
[1] "Best solution:"
 [1] 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1
[1] 14
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "Best fitness updated to:"
[1] -64.36104
[1] "Best solution:"
 [1] 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1
[1] 12
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 22
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 21
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 20
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 19
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 18
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 17
[1] "No change for 6 iterations. Exiting PSO."
 [1]  4  6  8 10 13 15 17 19 21 25 26 27
[1] 1
[1] "##################################"
[1] "Results summary for itr:1"
[1] "number of features selected using population mean"
[1] 12
[1] "number of features selected using current global best"
[1] 12
[1] "feat ind length"
[1] 12
[1] "best accuracy"
[1] 64.36104
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 2"
  [1]  98  29  46  94  90  31  15 110  18  16 118  22   5   9  51  83  13  17
 [19] 103  45   6  72  42   8  43  71  91  73 129  66  74 117  89 109  32  23
 [37] 104  30 120  49 124  41  55  19  92  81  48  95  50  70 100  36  10 119
 [55]  58 127 102  88  84  86  26  35  34  59  96  85  53  82 125  39  28  56
 [73]  11  25  67   3 123  27 112 114 126  47   4 130 128  62   7  57  44 101
 [91]  12  63  65 106 122  97 113  38  77  21 116  69 121   2
[1] "Starting global iteration number : 2"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -51.56858
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -54.26436
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -56.5689
[1] "Best solution:"
 [1] 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0
[1] 9
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -59.80596
[1] "Best solution:"
 [1] 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1
[1] 20
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "Best fitness updated to:"
[1] -60.85646
[1] "Best solution:"
 [1] 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1
[1] 11
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "Best fitness updated to:"
[1] -61.75904
[1] "Best solution:"
 [1] 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1
[1] 11
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "Best fitness updated to:"
[1] -62.59519
[1] "Best solution:"
 [1] 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1
[1] 10
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 24
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 22
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 19
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "Best fitness updated to:"
[1] -62.82405
[1] "Best solution:"
 [1] 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1
[1] 11
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 17
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 17
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 16
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 14
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 14
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 14
[1] "No change for 6 iterations. Exiting PSO."
 [1]  2 10 11 12 16 19 21 23 24 25 26 27
[1] 2
[1] "##################################"
[1] "Results summary for itr:2"
[1] "number of features selected using population mean"
[1] 12
[1] "number of features selected using current global best"
[1] 12
[1] "feat ind length"
[1] 12
[1] "best accuracy"
[1] 62.82405
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 3"
  [1]   9  15  60 110  68  29  66  80  78 104 118 120  49  83  72  42  87  73
 [19]  14  31  74   8  98  94  22  51  76  54 117  17 129  46  23  45  91  89
 [37] 109  43  16   5  55 101  67 123 115  20  25  97  82  59 125  53  39   7
 [55] 114   3   1  85  28  81  50  47  99  40  75 113  19  26 130  34  10  65
 [73]  57 112 128  61  35 111  70 105  69  21 122  58  11  86  41  52 116  38
 [91] 102   2  79  84  64  96 127  62  56  95 100 106   4  93
[1] "Starting global iteration number : 3"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -51.48613
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -51.70755
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -53.5097
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1
[1] 16
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -57.7158
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1
[1] 16
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -59.25717
[1] "Best solution:"
 [1] 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1
[1] 21
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -59.73125
[1] "Best solution:"
 [1] 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1
[1] 18
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "Best fitness updated to:"
[1] -60.07383
[1] "Best solution:"
 [1] 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "Best fitness updated to:"
[1] -60.68507
[1] "Best solution:"
 [1] 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1
[1] 19
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "Best fitness updated to:"
[1] -61.35807
[1] "Best solution:"
 [1] 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1
[1] 18
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "Best fitness updated to:"
[1] -62.1047
[1] "Best solution:"
 [1] 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1
[1] 18
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "Best fitness updated to:"
[1] -62.60431
[1] "Best solution:"
 [1] 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1
[1] 16
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 26
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 24
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 21
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 21
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 19
[1] "No change for 6 iterations. Exiting PSO."
 [1]  1  2  3  5  7 10 12 16 18 19 21 22 23 25 26 27
[1] 3
[1] "##################################"
[1] "Results summary for itr:3"
[1] "number of features selected using population mean"
[1] 16
[1] "number of features selected using current global best"
[1] 16
[1] "feat ind length"
[1] 16
[1] "best accuracy"
[1] 62.60431
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 4"
  [1] 117  15  60  73  98  66  16  46  87  45   5  18  29 118  31  76 110   9
 [19]  80 104  13 120  90  89  24  94  83  71  51  74  17 109  42  68  30   8
 [37]  22  43  49 103 125  81   1  92  99 108  70  27  26  79   2  77   3 124
 [55] 111  11  39  86  34  48  69  35  82  38 102  63  67  58 123  25  97  20
 [73] 106 114 105  19 122 128  41  12   7 119  28 126  93  59  62 107  37  84
 [91] 116  53  57 101  55  47  61  64  44  88   4 113  50 121
[1] "Starting global iteration number : 4"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -52.13258
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -54.0327
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -55.95152
[1] "Best solution:"
 [1] 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1
[1] 15
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -57.60449
[1] "Best solution:"
 [1] 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1
[1] 20
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -58.55529
[1] "Best solution:"
 [1] 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1
[1] 16
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "Best fitness updated to:"
[1] -59.18079
[1] "Best solution:"
 [1] 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1
[1] 19
[1] "iteration number: "
[1] 11
[1] "Best fitness updated to:"
[1] -59.98082
[1] "Best solution:"
 [1] 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1
[1] 14
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 26
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 26
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 26
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 25
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 24
[1] "No change for 6 iterations. Exiting PSO."
 [1]  1  2  5  8  9 10 11 12 14 16 18 19 21 22 23 25 27
[1] 4
[1] "##################################"
[1] "Results summary for itr:4"
[1] "number of features selected using population mean"
[1] 17
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 59.98082
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 5"
  [1]  22  90  74 104  60  78  23  16 120  43  13  46   6 118  17  54  32  51
 [19]  30  29   8  18 117  31  94  73  72  83  91 129 110  14  80  87  24  98
 [37] 103  15  76  45  79 116  37  36  52  85  53  48  11  63  75  25  97  61
 [55]  81  10  50  44  82 101  62  56  88 130  64 126 124  35   1  84 123  40
 [73]  27   2  59  67  28  95  41   3  86 107  34 108  58 105 115  93  20  69
 [91] 128  92  21   4  55  99  38   7 111 122 127 112 113  47
[1] "Starting global iteration number : 5"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -56.15398
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -57.43533
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -58.86512
[1] "Best solution:"
 [1] 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1
[1] 16
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -59.99386
[1] "Best solution:"
 [1] 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1
[1] 21
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "Best fitness updated to:"
[1] -60.34086
[1] "Best solution:"
 [1] 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1
[1] 18
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "Best fitness updated to:"
[1] -60.36557
[1] "Best solution:"
 [1] 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1
[1] 22
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "Best fitness updated to:"
[1] -60.45065
[1] "Best solution:"
 [1] 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1
[1] 19
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "Best fitness updated to:"
[1] -60.59408
[1] "Best solution:"
 [1] 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1
[1] 19
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "Best fitness updated to:"
[1] -61.34373
[1] "Best solution:"
 [1] 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1
[1] 19
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 27
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 27
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "Best fitness updated to:"
[1] -61.4597
[1] "Best solution:"
 [1] 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1
[1] 15
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 24
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 24
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 24
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "Best fitness updated to:"
[1] -61.76521
[1] "Best solution:"
 [1] 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1
[1] 12
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 23
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 23
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 21
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 19
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 18
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 18
[1] "No change for 6 iterations. Exiting PSO."
 [1]  1  2  5  7 10 12 13 15 16 17 18 21 22 23 25 27
[1] 5
[1] "##################################"
[1] "Results summary for itr:5"
[1] "number of features selected using population mean"
[1] 16
[1] "number of features selected using current global best"
[1] 16
[1] "feat ind length"
[1] 16
[1] "best accuracy"
[1] 61.76521
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 6"
  [1]  13   5  17  66  94 103  80  30  14  51  42  76  74  91 117 118 109 104
 [19]  23  29   6  98  43  68  31  71  60 110  45  46  24  73  16  49  18  87
 [37]   8 129  83  22 126  77  67 106   2  20  36  39  55  69 116   1  81 112
 [55]   7  82 101  65 114 105  57  19  61 124   3  86  95  75  58  79 127  41
 [73]  21 111 102 113  11 121  64 128 130  92  37  12  93  47  25   4  84  99
 [91] 107  44 119  35  38  40  48  28 125  34  52  88  85 123
[1] "Starting global iteration number : 6"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -50.42167
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -54.51075
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -57.23425
[1] "Best solution:"
 [1] 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1
[1] 15
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -57.72621
[1] "Best solution:"
 [1] 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1
[1] 16
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "Best fitness updated to:"
[1] -57.74497
[1] "Best solution:"
 [1] 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1
[1] 13
[1] "iteration number: "
[1] 10
[1] "Best fitness updated to:"
[1] -57.97959
[1] "Best solution:"
 [1] 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1
[1] 13
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -59.76398
[1] "Best solution:"
 [1] 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1
[1] 16
[1] "iteration number: "
[1] 15
[1] "Best fitness updated to:"
[1] -59.9693
[1] "Best solution:"
 [1] 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1
[1] 18
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 26
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 23
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 22
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 21
[1] "No change for 6 iterations. Exiting PSO."
 [1]  1  2 10 12 16 18 19 21 22 27
[1] 6
[1] "##################################"
[1] "Results summary for itr:6"
[1] "number of features selected using population mean"
[1] 10
[1] "number of features selected using current global best"
[1] 10
[1] "feat ind length"
[1] 10
[1] "best accuracy"
[1] 59.9693
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 7"
  [1]  98  43  22  68 118  80  15  14  73  13  76  60  49  31  74  17  45  83
 [19]  18  91  30 129 117  23  89 104  24  32  33  87 120 110  16   9 103  66
 [37]  94  51  54   8 107  36 124 108  50 121  86  28   7 102 100  20 130  99
 [55]  55  85  52 105  75  81  62 111  10  44  21  84 122 126  27  59  61  79
 [73]  93  77 114  37 119  35 116  65 106  96  82  26 123 112  92  40  64  69
 [91]  58  95  97  48   3  63 128 101  12  56 113  67  41  88
[1] "Starting global iteration number : 7"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -50.54725
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -53.40269
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -57.21414
[1] "Best solution:"
 [1] 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0
[1] 11
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -58.36693
[1] "Best solution:"
 [1] 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1
[1] 19
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -58.45574
[1] "Best solution:"
 [1] 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1
[1] 19
[1] "iteration number: "
[1] 8
[1] "Best fitness updated to:"
[1] -60.93652
[1] "Best solution:"
 [1] 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1
[1] 19
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "Best fitness updated to:"
[1] -61.19918
[1] "Best solution:"
 [1] 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0 0 1
[1] 12
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "Best fitness updated to:"
[1] -61.41634
[1] "Best solution:"
 [1] 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 1
[1] 15
[1] "iteration number: "
[1] 18
[1] "Best fitness updated to:"
[1] -61.54592
[1] "Best solution:"
 [1] 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1
[1] 16
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "Best fitness updated to:"
[1] -61.75282
[1] "Best solution:"
 [1] 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1
[1] 15
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "Best fitness updated to:"
[1] -61.94388
[1] "Best solution:"
 [1] 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1
[1] 16
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "Best fitness updated to:"
[1] -62.56356
[1] "Best solution:"
 [1] 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1
[1] 9
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 24
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "Best fitness updated to:"
[1] -62.57245
[1] "Best solution:"
 [1] 1 1 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1
[1] 16
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "Best fitness updated to:"
[1] -63.0388
[1] "Best solution:"
 [1] 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1
[1] 17
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "Best fitness updated to:"
[1] -63.15349
[1] "Best solution:"
 [1] 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1
[1] 11
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "Best fitness updated to:"
[1] -63.31858
[1] "Best solution:"
 [1] 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1
[1] 11
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 22
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "Best fitness updated to:"
[1] -63.33873
[1] "Best solution:"
 [1] 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1
[1] 16
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 22
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "Best fitness updated to:"
[1] -63.44499
[1] "Best solution:"
 [1] 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1
[1] 14
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 22
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 22
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 22
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "Best fitness updated to:"
[1] -63.92289
[1] "Best solution:"
 [1] 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 1
[1] 13
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 21
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 20
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 21
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 180
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 19
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 191
[1] "iteration number: "
[1] 192
[1] "iteration number: "
[1] 193
[1] "iteration number: "
[1] 194
[1] "iteration number: "
[1] 195
[1] "iteration number: "
[1] 196
[1] "iteration number: "
[1] 197
[1] "iteration number: "
[1] 198
[1] "iteration number: "
[1] 199
[1] "iteration number: "
[1] 200
[1] "iteration number: "
[1] 201
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 19
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 202
[1] "iteration number: "
[1] 203
[1] "iteration number: "
[1] 204
[1] "iteration number: "
[1] 205
[1] "iteration number: "
[1] 206
[1] "iteration number: "
[1] 207
[1] "iteration number: "
[1] 208
[1] "iteration number: "
[1] 209
[1] "iteration number: "
[1] 210
[1] "iteration number: "
[1] 211
[1] "iteration number: "
[1] 212
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 19
[1] "No change for 6 iterations. Exiting PSO."
 [1]  1  2  4  5  7 10 13 14 16 17 18 19 21 23 26 27
[1] 7
[1] "##################################"
[1] "Results summary for itr:7"
[1] "number of features selected using population mean"
[1] 16
[1] "number of features selected using current global best"
[1] 16
[1] "feat ind length"
[1] 16
[1] "best accuracy"
[1] 63.92289
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 8"
  [1]  45  73  74   5  17 117 129 103  76  54  72  90 109  51  80 120  78  30
 [19]  14   8  22 118  49  24  18  43  29  23  31 104   9  98  71  89  16  83
 [37]  91 110  68  13 106  50  26 112 123  93  84  99 126 128  57 105 102  63
 [55] 113  85 122  34  39 108   7  36  52  44  10 127  28  64 116  48   3  97
 [73]  41 124  55  12  19  96  69 101 100   1  58  61  79  75  62  27  56  67
 [91]  82  37  40  88  77  25 107 114  81 121  86  21  11  53
[1] "Starting global iteration number : 8"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -54.08858
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -57.01005
[1] "Best solution:"
 [1] 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0
[1] 7
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -57.25434
[1] "Best solution:"
 [1] 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1
[1] 18
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -59.01978
[1] "Best solution:"
 [1] 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1
[1] 22
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "Best fitness updated to:"
[1] -59.1774
[1] "Best solution:"
 [1] 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1
[1] 22
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "Best fitness updated to:"
[1] -59.49036
[1] "Best solution:"
 [1] 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1
[1] 20
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "Best fitness updated to:"
[1] -59.94503
[1] "Best solution:"
 [1] 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1
[1] 17
[1] "iteration number: "
[1] 44
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 55
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 27
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 66
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 26
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 77
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 26
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 26
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 24
[1] "No change for 6 iterations. Exiting PSO."
 [1]  1  2  5  7  8 10 11 12 15 17 19 20 21 22 23 25 27
[1] 8
[1] "##################################"
[1] "Results summary for itr:8"
[1] "number of features selected using population mean"
[1] 17
[1] "number of features selected using current global best"
[1] 17
[1] "feat ind length"
[1] 17
[1] "best accuracy"
[1] 59.94503
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 9"
  [1]  66  13  80  31  51  83  98  23  14  43  18  73  49  89  45  78  17 118
 [19] 103   6  16  29  74 104  90 109 120  76  71  15   5   8  72   9  22  94
 [37] 117  32  87  60  26 105  57  77  36  40  86  92  82  11  64  65  19  52
 [55]  84  81 102  93 111  53  56  63 116   7  69  59 107 122  37 113 112  12
 [73]  61  55 108  75 124 100  20  25 127  38 119  70  97 128 106 114  41  99
 [91]  50   3  21 115  85   4  79  39  58  35   2  96  28  67
[1] "Starting global iteration number : 9"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -43.64238
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -53.02095
[1] "Best solution:"
 [1] 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0
[1] 6
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -54.24205
[1] "Best solution:"
 [1] 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1
[1] 15
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -57.83032
[1] "Best solution:"
 [1] 0 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1
[1] 16
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "Best fitness updated to:"
[1] -58.54935
[1] "Best solution:"
 [1] 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "Best fitness updated to:"
[1] -58.58991
[1] "Best solution:"
 [1] 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1
[1] 15
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 26
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 24
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 24
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 23
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "Best fitness updated to:"
[1] -59.18038
[1] "Best solution:"
 [1] 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0
[1] 11
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 21
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "iteration number: "
[1] 94
[1] "Best fitness updated to:"
[1] -59.3168
[1] "Best solution:"
 [1] 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1
[1] 11
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "iteration number: "
[1] 105
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 21
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "iteration number: "
[1] 116
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 20
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "Best fitness updated to:"
[1] -59.67308
[1] "Best solution:"
 [1] 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1
[1] 12
[1] "iteration number: "
[1] 126
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 20
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 137
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 20
 [1] 4 1 3 1 4 2 2 3 2 2 1 2 3 2 1 2 2 3 2 2
[1] "iteration number: "
[1] 148
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 19
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 159
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 18
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 170
[1] "iteration number: "
[1] 171
[1] "iteration number: "
[1] 172
[1] "iteration number: "
[1] 173
[1] "iteration number: "
[1] 174
[1] "iteration number: "
[1] 175
[1] "iteration number: "
[1] 176
[1] "iteration number: "
[1] 177
[1] "iteration number: "
[1] 178
[1] "iteration number: "
[1] 179
[1] "iteration number: "
[1] 180
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 21
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 181
[1] "iteration number: "
[1] 182
[1] "iteration number: "
[1] 183
[1] "iteration number: "
[1] 184
[1] "iteration number: "
[1] 185
[1] "iteration number: "
[1] 186
[1] "iteration number: "
[1] 187
[1] "iteration number: "
[1] 188
[1] "iteration number: "
[1] 189
[1] "iteration number: "
[1] 190
[1] "iteration number: "
[1] 191
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 21
[1] "No change for 6 iterations. Exiting PSO."
 [1]  4  6  8 13 15 19 20 21 23 25 27
[1] 9
[1] "##################################"
[1] "Results summary for itr:9"
[1] "number of features selected using population mean"
[1] 11
[1] "number of features selected using current global best"
[1] 11
[1] "feat ind length"
[1] 11
[1] "best accuracy"
[1] 59.67308
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "learning sets: 10"
  [1]  90   6  91  32 109  76  17  15 120 118  45 104  23  49  22  31  83 129
 [19]  29  46 110  13  72  54   8  16  74  94  51  68  89  14  60  33  43   9
 [37]  78  71  98  18  61  11  85  84  58  97  64 119  19   3  96  48  10 128
 [55] 116  52  40   4 121 113  86  69  27  25  99  67 108 107 114  63  79 123
 [73] 102  21  77  81  38  65 112  75  62 127  88 101   7 106   1 111  12  55
 [91] 122 126  95  59  35  28  56 124   2 100  44  36  57  92
[1] "Starting global iteration number : 10"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -56.87946
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -57.95203
[1] "Best solution:"
 [1] 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0
[1] 7
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -59.47303
[1] "Best solution:"
 [1] 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1
[1] 19
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -60.03434
[1] "Best solution:"
 [1] 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1
[1] 19
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -60.4244
[1] "Best solution:"
 [1] 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0
[1] 17
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "Best fitness updated to:"
[1] -60.74963
[1] "Best solution:"
 [1] 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1
[1] 23
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "Best fitness updated to:"
[1] -60.88501
[1] "Best solution:"
 [1] 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1
[1] 14
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1] "iteration number: "
[1] 34
[1] "iteration number: "
[1] 35
[1] "iteration number: "
[1] 36
[1] "iteration number: "
[1] 37
[1] "iteration number: "
[1] 38
[1] "iteration number: "
[1] 39
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 26
 [1] 2 2 2 4 1 2 3 1 4 2 3 3 2 3 3 2 3 2 3 2
[1] "iteration number: "
[1] 40
[1] "iteration number: "
[1] 41
[1] "iteration number: "
[1] 42
[1] "iteration number: "
[1] 43
[1] "iteration number: "
[1] 44
[1] "Best fitness updated to:"
[1] -61.16888
[1] "Best solution:"
 [1] 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1
[1] 23
[1] "iteration number: "
[1] 45
[1] "iteration number: "
[1] 46
[1] "iteration number: "
[1] 47
[1] "iteration number: "
[1] 48
[1] "iteration number: "
[1] 49
[1] "iteration number: "
[1] 50
[1] "iteration number: "
[1] 51
[1] "iteration number: "
[1] 52
[1] "iteration number: "
[1] 53
[1] "iteration number: "
[1] 54
[1] "iteration number: "
[1] 55
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 27
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 56
[1] "iteration number: "
[1] 57
[1] "iteration number: "
[1] 58
[1] "iteration number: "
[1] 59
[1] "iteration number: "
[1] 60
[1] "iteration number: "
[1] 61
[1] "iteration number: "
[1] 62
[1] "iteration number: "
[1] 63
[1] "iteration number: "
[1] 64
[1] "iteration number: "
[1] 65
[1] "iteration number: "
[1] 66
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 26
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 67
[1] "iteration number: "
[1] 68
[1] "iteration number: "
[1] 69
[1] "iteration number: "
[1] 70
[1] "iteration number: "
[1] 71
[1] "iteration number: "
[1] 72
[1] "iteration number: "
[1] 73
[1] "iteration number: "
[1] 74
[1] "iteration number: "
[1] 75
[1] "iteration number: "
[1] 76
[1] "iteration number: "
[1] 77
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 25
 [1] 2 3 2 3 4 1 3 1 2 2 2 3 2 2 2 3 3 2 1 3
[1] "iteration number: "
[1] 78
[1] "iteration number: "
[1] 79
[1] "iteration number: "
[1] 80
[1] "iteration number: "
[1] 81
[1] "iteration number: "
[1] 82
[1] "Best fitness updated to:"
[1] -61.9013
[1] "Best solution:"
 [1] 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1
[1] 19
[1] "iteration number: "
[1] 83
[1] "iteration number: "
[1] 84
[1] "iteration number: "
[1] 85
[1] "iteration number: "
[1] 86
[1] "iteration number: "
[1] 87
[1] "iteration number: "
[1] 88
[1] "iteration number: "
[1] 89
[1] "iteration number: "
[1] 90
[1] "iteration number: "
[1] 91
[1] "iteration number: "
[1] 92
[1] "iteration number: "
[1] 93
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 25
 [1] 3 2 3 4 2 1 1 2 1 3 2 4 3 3 1 3 2 1 1 1
[1] "iteration number: "
[1] 94
[1] "iteration number: "
[1] 95
[1] "iteration number: "
[1] 96
[1] "iteration number: "
[1] 97
[1] "iteration number: "
[1] 98
[1] "iteration number: "
[1] 99
[1] "iteration number: "
[1] 100
[1] "iteration number: "
[1] 101
[1] "iteration number: "
[1] 102
[1] "iteration number: "
[1] 103
[1] "iteration number: "
[1] 104
[1] "Best fitness updated to:"
[1] -62.06566
[1] "Best solution:"
 [1] 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1
[1] 16
[1] "iteration number: "
[1] 105
[1] "iteration number: "
[1] 106
[1] "iteration number: "
[1] 107
[1] "iteration number: "
[1] 108
[1] "iteration number: "
[1] 109
[1] "iteration number: "
[1] 110
[1] "iteration number: "
[1] 111
[1] "iteration number: "
[1] 112
[1] "iteration number: "
[1] 113
[1] "iteration number: "
[1] 114
[1] "iteration number: "
[1] 115
[1] "RE-INITIALIZING..."
[1] 1
[1] 5
[1] 23
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 116
[1] "iteration number: "
[1] 117
[1] "iteration number: "
[1] 118
[1] "iteration number: "
[1] 119
[1] "iteration number: "
[1] 120
[1] "iteration number: "
[1] 121
[1] "iteration number: "
[1] 122
[1] "iteration number: "
[1] 123
[1] "iteration number: "
[1] 124
[1] "iteration number: "
[1] 125
[1] "iteration number: "
[1] 126
[1] "RE-INITIALIZING..."
[1] 2
[1] 5
[1] 23
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 127
[1] "iteration number: "
[1] 128
[1] "iteration number: "
[1] 129
[1] "iteration number: "
[1] 130
[1] "iteration number: "
[1] 131
[1] "iteration number: "
[1] 132
[1] "iteration number: "
[1] 133
[1] "iteration number: "
[1] 134
[1] "iteration number: "
[1] 135
[1] "iteration number: "
[1] 136
[1] "iteration number: "
[1] 137
[1] "RE-INITIALIZING..."
[1] 3
[1] 5
[1] 22
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 138
[1] "iteration number: "
[1] 139
[1] "iteration number: "
[1] 140
[1] "iteration number: "
[1] 141
[1] "iteration number: "
[1] 142
[1] "iteration number: "
[1] 143
[1] "iteration number: "
[1] 144
[1] "iteration number: "
[1] 145
[1] "iteration number: "
[1] 146
[1] "iteration number: "
[1] 147
[1] "iteration number: "
[1] 148
[1] "RE-INITIALIZING..."
[1] 4
[1] 5
[1] 21
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 149
[1] "iteration number: "
[1] 150
[1] "iteration number: "
[1] 151
[1] "iteration number: "
[1] 152
[1] "iteration number: "
[1] 153
[1] "iteration number: "
[1] 154
[1] "iteration number: "
[1] 155
[1] "iteration number: "
[1] 156
[1] "iteration number: "
[1] 157
[1] "iteration number: "
[1] 158
[1] "iteration number: "
[1] 159
[1] "RE-INITIALIZING..."
[1] 5
[1] 5
[1] 21
 [1] 2 2 1 2 2 3 1 1 3 1 2 2 2 2 2 2 2 1 2 4
[1] "iteration number: "
[1] 160
[1] "iteration number: "
[1] 161
[1] "iteration number: "
[1] 162
[1] "iteration number: "
[1] 163
[1] "iteration number: "
[1] 164
[1] "iteration number: "
[1] 165
[1] "iteration number: "
[1] 166
[1] "iteration number: "
[1] 167
[1] "iteration number: "
[1] 168
[1] "iteration number: "
[1] 169
[1] "iteration number: "
[1] 170
[1] "RE-INITIALIZING..."
[1] 6
[1] 5
[1] 21
[1] "No change for 6 iterations. Exiting PSO."
 [1]  2  4  7  8 10 11 12 16 17 18 19 21 22 25 26 27
[1] 10
[1] "##################################"
[1] "Results summary for itr:10"
[1] "number of features selected using population mean"
[1] 16
[1] "number of features selected using current global best"
[1] 16
[1] "feat ind length"
[1] 16
[1] "best accuracy"
[1] 62.06566
[1] "test acc:0.961538461538462"
[1] "##################################"
[1] "testacc"
 [1] 0.9615385 1.0000000 1.0000000 1.0000000 1.0000000 0.9615385 0.9615385
 [8] 1.0000000 0.9615385 0.9615385
[1] 0.9807692
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.9615  0.9615  0.9808  0.9808  1.0000  1.0000 
[1] 0.02027101
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    0    1    1    1    1    1    1    0     0
 [2,]    0    1    1    1    1    1    1    1    0     1
 [3,]    0    0    1    0    0    0    0    0    0     0
 [4,]    1    0    0    0    0    0    1    0    1     1
 [5,]    0    0    1    1    1    0    1    1    0     0
 [6,]    1    0    0    0    0    0    0    0    1     0
 [7,]    0    0    1    0    1    0    1    1    0     1
 [8,]    1    0    0    1    0    0    0    1    1     1
 [9,]    0    0    0    1    0    0    0    0    0     0
[10,]    1    1    1    1    1    1    1    1    0     1
[11,]    0    1    0    1    0    0    0    1    0     1
[12,]    0    1    1    1    1    1    0    1    0     1
[13,]    1    0    0    0    1    0    1    0    1     0
[14,]    0    0    0    1    0    0    1    0    0     0
[15,]    1    0    0    0    1    0    0    1    1     0
[16,]    0    1    1    1    1    1    1    0    0     1
[17,]    1    0    0    0    1    0    1    1    0     1
[18,]    0    0    1    1    1    1    1    0    0     1
[19,]    1    1    1    1    0    1    1    1    1     1
[20,]    0    0    0    0    0    0    0    1    1     0
[21,]    1    1    1    1    1    1    1    1    1     1
[22,]    0    0    1    1    1    1    0    1    0     1
[23,]    0    1    1    1    1    0    1    1    1     0
[24,]    0    1    0    0    0    0    0    0    0     0
[25,]    1    1    1    1    1    0    0    1    1     1
[26,]    1    1    1    0    0    0    1    0    0     1
[27,]    1    1    1    1    1    1    1    1    1     1
[1] "dim of scoring matrix is "
[1] 27 10
[1] "DS index stage 2"
[1] 0.6168734
[1] "KI index stage 2"
[1] -Inf
[1] 1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   4.000   5.000   5.296   7.000  10.000 
[1] "Number of features selected in 1 iterations:"
[1] 27
[1] "Number of features selected in 1 iterations:"
[1] 27
[1] 0.98 1.00
[1] 0.98 1.00
[1] "accuracy: 93.0810244685836 num_feat:27 fitness:52.0465719027357"
$fitfunc
[1] -52.04657

$cverror
[1] 93.08102

$cvpermerror
[1] 59.12742

$testacc
[1] 98.375

$reverseacc
[1] 99

[1] -52.04657
[1] "Number of features selected in 2 iterations:"
[1] 24
[1] 0.96 1.00
[1] 0.96 1.00
[1] "accuracy: 95.6011015865428 num_feat:24 fitness:53.3170344269431"
$fitfunc
[1] -53.31703

$cverror
[1] 95.6011

$cvpermerror
[1] 60.09986

$testacc
[1] 98.375

$reverseacc
[1] 98

[1] -53.31703
[1] "Number of features selected in 3 iterations:"
[1] 21
[1] 0.98 1.00
[1] 0.98 1.00
[1] "accuracy: 94.8993884703489 num_feat:21 fitness:51.8692634985611"
$fitfunc
[1] -51.86926

$cverror
[1] 94.89939

$cvpermerror
[1] 61.64643

$testacc
[1] 98.375

$reverseacc
[1] 99

[1] -51.86926
[1] "Number of features selected in 4 iterations:"
[1] 21
[1] 0.98 1.00
[1] 0.98 1.00
[1] "accuracy: 94.8993884703489 num_feat:21 fitness:51.8692634985611"
$fitfunc
[1] -51.86926

$cverror
[1] 94.89939

$cvpermerror
[1] 61.64643

$testacc
[1] 98.375

$reverseacc
[1] 99

[1] -51.86926
[1] "Number of features selected in 5 iterations:"
[1] 17
[1] 0.9600 0.9875
[1] 0.9600 0.9875
[1] "accuracy: 93.8995269004585 num_feat:17 fitness:51.1339349284632"
$fitfunc
[1] -51.13393

$cverror
[1] 93.89953

$cvpermerror
[1] 61.72119

$testacc
[1] 98.375

$reverseacc
[1] 97.375

[1] -51.13393
[1] "Number of features selected in 6 iterations:"
[1] 12
[1] 0.96 1.00
[1] 0.96 1.00
[1] "accuracy: 95.1587192152097 num_feat:12 fitness:57.3784991232245"
$fitfunc
[1] -57.3785

$cverror
[1] 95.15872

$cvpermerror
[1] 54.45871

$testacc
[1] 98.375

$reverseacc
[1] 98

[1] -57.3785
[1] "Number of features selected in 7 iterations:"
[1] 9
[1] 0.9600 0.9875
[1] 0.9600 0.9875
[1] "accuracy: 94.7994631523423 num_feat:9 fitness:58.147953146716"
$fitfunc
[1] -58.14795

$cverror
[1] 94.79946

$cvpermerror
[1] 52.91009

$testacc
[1] 97.75

$reverseacc
[1] 97.375

[1] -58.14795
[1] "Number of features selected in 8 iterations:"
[1] 6
[1] 0.9000 0.9875
[1] 0.9000 0.9875
[1] "accuracy: 93.7122216952665 num_feat:6 fitness:58.990533236946"
$fitfunc
[1] -58.99053

$cverror
[1] 93.71222

$cvpermerror
[1] 50.3788

$testacc
[1] 97.375

$reverseacc
[1] 94.375

[1] -58.99053
[1] "Number of features selected in 9 iterations:"
[1] 4
[1] 0.8200 0.9875
[1] 0.8200 0.9875
[1] "accuracy: 84.9068805462152 num_feat:4 fitness:52.3965040424386"
$fitfunc
[1] -52.3965

$cverror
[1] 84.90688

$cvpermerror
[1] 48.64894

$testacc
[1] 92

$reverseacc
[1] 90.375

[1] -52.3965
[1] "Number of features selected in 10 iterations:"
[1] 2
[1] "accuracy: 1 num_feat:2 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.9615  0.9615  0.9808  0.9808  1.0000  1.0000 
[1] "Number of features selected in 8 iterations:"
[1] 6
[1] "Modified train 10 fold accuracy using train data is "
[1] 96.15385
[1] "Modified train accuracy is "
[1] 0.9769231
[1] "train confusion matrix is "
          trainclass
pred_train  1  2
         1 48  1
         2  2 79
[1] "Train dimension is "
[1] 130   6
[1] "Test dimension is "
[1] 100   6
[1] "Test confusion matrix is "
    
pred  1  2
   1 32  7
   2  7 54
[1] "Test acc is "
[1] 0.86
[1] "train 10 fold"
[1] 96.15385
[1] "Test confusion matrix is "
    
pred  1  2
   1 32  7
   2  7 54
[1] "Test acc is "
[1] 0.86
[1] "Test AUC:"
[1] 0.8528794
[1] "Train acc is "
[1] 0.9769231
[1] "# of features after CMA:"
NULL
[1] "# of features after PSO:"
[1] 130   7
     user    system   elapsed 
  159.308    23.064 12730.232 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> 
> 
> feat_ind<-psores$bestfeatlist
> feat_names<-psores$bestfeatnames
> 
> scoringmatrix<-as.data.frame(psores$scoringmatrix)
> print(scoringmatrix)
   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
1   0  0  1  1  1  1  1  1  0   0
2   0  1  1  1  1  1  1  1  0   1
3   0  0  1  0  0  0  0  0  0   0
4   1  0  0  0  0  0  1  0  1   1
5   0  0  1  1  1  0  1  1  0   0
6   1  0  0  0  0  0  0  0  1   0
7   0  0  1  0  1  0  1  1  0   1
8   1  0  0  1  0  0  0  1  1   1
9   0  0  0  1  0  0  0  0  0   0
10  1  1  1  1  1  1  1  1  0   1
11  0  1  0  1  0  0  0  1  0   1
12  0  1  1  1  1  1  0  1  0   1
13  1  0  0  0  1  0  1  0  1   0
14  0  0  0  1  0  0  1  0  0   0
15  1  0  0  0  1  0  0  1  1   0
16  0  1  1  1  1  1  1  0  0   1
17  1  0  0  0  1  0  1  1  0   1
18  0  0  1  1  1  1  1  0  0   1
19  1  1  1  1  0  1  1  1  1   1
20  0  0  0  0  0  0  0  1  1   0
21  1  1  1  1  1  1  1  1  1   1
22  0  0  1  1  1  1  0  1  0   1
23  0  1  1  1  1  0  1  1  1   0
24  0  1  0  0  0  0  0  0  0   0
25  1  1  1  1  1  0  0  1  1   1
26  1  1  1  0  0  0  1  0  0   1
27  1  1  1  1  1  1  1  1  1   1
> print(feat_names[feat_ind])
[1] "1053_at"     "1431_at"     "204508_s_at" "207626_s_at" "212956_at"  
[6] "215729_s_at"
> 
> save(psores,file="psores.Rda")
> print("Complete")
[1] "Complete"
> 
