
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/stu/kuppal3/karan_libs/Rlibs")
> library(snow)
> library(e1071)
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/stu/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

> 
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/version2016/OCFS_",args[9],".R",sep="")
> #sname<-paste("/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/version2016/OCFS_",args[9],".R",sep="")
> 
> sname<-paste("/home/kuppal2/Documents/Projects/xmsPANDA/Other/scripts/OCFS_",args[9],".R",sep="")
> source(sname)
> print(sname)
[1] "/home/kuppal2/Documents/Projects/xmsPANDA/Other/scripts/OCFS_vfeb817_v2.R"
> 
> #data_loc<-"/home/stu/kuppal3/Research/Feature_selection/Datasets/MAQCII_BreastCancer/" 
> #data_loc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/Datasets/MAQCII_BreastCancer/"
> 
> data_loc<-"/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/MAQCII_BreastCancer/"
> setwd(data_loc)
> #load("/home/stu/kuppal3/Research/Feature_selection/Datasets/MAQCII_BreastCancer/MaqcIIbr.Rda")
> 
> load("MaqcIIbr.Rda")
> 
> outloc<-paste(data_loc,"OCFSv062016_v32_ER_sensitivity_itr",args[9],"/",sep="")
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/MAQCII_BreastCancer/OCFSv062016_v32_ER_sensitivity_itrvfeb817_v2' already exists
> setwd(outloc)
> 
> trainm<-MaqcIIbr$trainx
> testm<-MaqcIIbr$testx
> trainclass<-MaqcIIbr$trainER #PCRvsRD
> testclass<-MaqcIIbr$testER #PCRvsRD
> 
> #trainclass<-MaqcIIbr$trainPCRvsRD
> #testclass<-MaqcIIbr$testPCRvsRD
> 
> trainm<-trainm[,-c(22284)]
> testm<-testm[,-c(22284)]
> trainm<-apply(trainm,2,as.numeric)
> testm<-apply(testm,2,as.numeric)
> 
> 
> 
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> 
> 
> 
> 
> 
> #OCFSvmay2415v2reg_itr1_LassoRFELIMMAELpres1backwsel_l0.25f0.45c0.25_top10pctmaxitrs100minselmedianrandbehavfeatw0.01_CV2accA100B1wrand6methodsmax100wrand/"
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/MAQCII_BreastCancer/OCFSv062016_v32_ER_sensitivity_itrvfeb817_v2' already exists
> setwd(outloc)
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/MAQCII_BreastCancer/OCFSv062016_v32_ER_sensitivity_itrvfeb817_v2' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 1 2 2
Levels: 1 2
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] 6.7866 8.0963 7.4812
[1] "norm train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "mean of feat 2"
[1] 8.273493
[1] "sd of feat 2"
[1] 0.7010279
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  3490  4035  4752  9092  9093  9094 12339 12343 13543 15240
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.0638     10.1763   13.0759     11.1535   10.5793     14.3763
[2,]   11.3553      9.3275   13.7616     10.8437   10.5772     14.0214
[3,]   12.3832      9.9200   12.7360     10.7019   11.1181     14.5222
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.3600   10.8422     12.6474     12.6194
[2,]   13.2925   10.5720     11.7852     11.5534
[3,]   12.3582    9.8482     12.7464     12.7285
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.4052      9.8038   13.8754     11.9413   11.9790     15.0625
[2,]   10.4033      7.9689   11.7217     11.0319   10.8744     14.4978
[3,]    9.8307      7.6789   10.9960      8.8487    8.0211     12.4583
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.5201   11.4301     12.7392     12.5744
[2,]   12.5480   10.2569     10.9092     11.0575
[3,]   11.2917    9.3181     10.6696     11.0769
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.87494745691467"
[1] "10 fold train92.3076923076923"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 44  2
         2  6 78
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  9
        2  4 52
[1] "train acc:0.938461538461538"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 44  2
         2  6 78
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
4: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
5: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
6: In mean.default(KI_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
> 
> 
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 1 2 2
Levels: 1 2
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] 6.7866 8.0963 7.4812
[1] "norm train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "mean of feat 2"
[1] 8.273493
[1] "sd of feat 2"
[1] 0.7010279
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
Loaded glmnet 2.0-5


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
    1  4752 15102  4035     2     3     4  9093     5 12339  3155     6  7147 
   20    20    20    18    16    14    14    14    12    10     8     6     6 
13819 10447 17203     7  1511  9279 11605 
    6     4     4     2     2     2     2 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]     1     2     3     4     5  4035  4752  9093 12339 15102
     1007_s_at 1053_at 117_at  121_at 1255_g_at 204508_s_at 205225_at 209603_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064     10.1763   13.0759   10.5793
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582      9.3275   13.7616   10.5772
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332      9.9200   12.7360   11.1181
     212956_at 215729_s_at
[1,]   13.3600      2.9565
[2,]   13.2925      1.5807
[3,]   12.3582      5.6368
     1007_s_at 1053_at 117_at  121_at 1255_g_at 204508_s_at 205225_at 209603_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327      9.8038   13.8754   11.9790
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568      7.9689   11.7217   10.8744
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579      7.6789   10.9960    8.0211
     212956_at 215729_s_at
[1,]   13.5201      1.9565
[2,]   12.5480      5.3426
[3,]   11.2917      5.3609
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.870323665405633"
[1] "10 fold train94.6153846153846"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 49  0
         2  1 80
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 34  8
        2  5 53
[1] "train acc:0.992307692307692"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 49  0
         2  1 80
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
4: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
5: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
6: In mean.default(KI_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
> 
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 1 2 2
Levels: 1 2
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] 6.7866 8.0963 7.4812
[1] "norm train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "mean of feat 2"
[1] 8.273493
[1] "sd of feat 2"
[1] 0.7010279
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  4035  4536  4556  4752  4967  6280  6325  8667 12583 15102
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]     10.1763   13.2850      2.9025   13.0759      8.6216     12.4854
[2,]      9.3275   14.4107      2.2747   13.7616     10.7598     10.5188
[3,]      9.9200   14.7836      0.9203   12.7360      7.7832     11.6232
     206799_at 209173_at 213201_s_at 215729_s_at
[1,]    3.1490   12.9392      4.2884      2.9565
[2,]   14.9688   14.1501      4.8678      1.5807
[3,]   11.6974   14.5585      8.3652      5.6368
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]      9.8038   14.3747      3.0068   13.8754     10.5785     11.4867
[2,]      7.9689   11.2149      3.3895   11.7217      8.5134      7.4297
[3,]      7.6789    9.8209      4.9401   10.9960      9.3702      5.9013
     206799_at 209173_at 213201_s_at 215729_s_at
[1,]    7.9310   13.2041      7.5478      1.9565
[2,]   10.6196   11.3631      5.0501      5.3426
[3,]    6.2148   11.1800      5.0025      5.3609
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.87494745691467"
[1] "10 fold train96.1538461538462"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 48  0
         2  2 80
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  9
        2  4 52
[1] "train acc:0.984615384615385"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 48  0
         2  2 80
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
4: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
5: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
6: In mean.default(KI_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
> 
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 1 2 2
Levels: 1 2
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] 6.7866 8.0963 7.4812
[1] "norm train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "mean of feat 2"
[1] 8.273493
[1] "sd of feat 2"
[1] 0.7010279
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]    1    2    3    4    5    6    7 4035 4752 9093
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 204508_s_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356     10.1763
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581      9.3275
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061      9.9200
     205225_at 209603_at
[1,]   13.0759   10.5793
[2,]   13.7616   10.5772
[3,]   12.7360   11.1181
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 204508_s_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327  9.2305  8.1481      9.8038
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568  9.1180  8.3105      7.9689
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579  9.3514  8.1214      7.6789
     205225_at 209603_at
[1,]   13.8754   11.9790
[2,]   11.7217   10.8744
[3,]   10.9960    8.0211
[1] "numgenes selected:10"
[1] "test acc:0.89"
[1] "test AUC acc:0.886717108028583"
[1] "10 fold train92.3076923076923"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 46  0
         2  4 80
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 34  6
        2  5 55
[1] "train acc:0.969230769230769"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 46  0
         2  4 80
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
4: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
5: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
6: In mean.default(KI_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
> 
> if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
> 
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 1 2 2
Levels: 1 2
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] 6.7866 8.0963 7.4812
[1] "norm train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "mean of feat 2"
[1] 8.273493
[1] "sd of feat 2"
[1] 0.7010279
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     1
[1] 22283
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  3490  4035  4752  9092  9093  9094 12339 12343 13543 15240
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.0638     10.1763   13.0759     11.1535   10.5793     14.3763
[2,]   11.3553      9.3275   13.7616     10.8437   10.5772     14.0214
[3,]   12.3832      9.9200   12.7360     10.7019   11.1181     14.5222
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.3600   10.8422     12.6474     12.6194
[2,]   13.2925   10.5720     11.7852     11.5534
[3,]   12.3582    9.8482     12.7464     12.7285
     203963_at 204508_s_at 205225_at 209602_s_at 209603_at 209604_s_at
[1,]   12.4052      9.8038   13.8754     11.9413   11.9790     15.0625
[2,]   10.4033      7.9689   11.7217     11.0319   10.8744     14.4978
[3,]    9.8307      7.6789   10.9960      8.8487    8.0211     12.4583
     212956_at 212960_at 214164_x_at 215867_x_at
[1,]   13.5201   11.4301     12.7392     12.5744
[2,]   12.5480   10.2569     10.9092     11.0575
[3,]   11.2917    9.3181     10.6696     11.0769
[1] "numgenes selected:10"
[1] "test acc:0.87"
[1] "test AUC acc:0.87494745691467"
[1] "10 fold train92.3076923076923"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 44  2
         2  6 78
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 35  9
        2  4 52
[1] "train acc:0.938461538461538"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 44  2
         2  6 78
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
4: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
5: In mean.default(DS_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
6: In mean.default(KI_res, na.rm = TRUE) :
  argument is not numeric or logical: returning NA
> 
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   130 22283
[1]   130 22283
[1] "length of factcols"
[1] 0
[1]   130 22283
[1]   100 22283
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
[1] 2 1 2 2
Levels: 1 2
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "orig train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] 6.7866 8.0963 7.4812
[1] "norm train matrix"
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 1320_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356  6.6745
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581  6.4607
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061  7.0932
[4,]   11.6619  8.2557 7.9923 10.7705    6.3296  9.3777  8.4776  6.5878
[5,]   11.8397  8.7971 7.8321 10.2869    5.8389  7.0841  7.3419  7.3167
     1405_i_at 1431_at
[1,]    6.2325  6.8450
[2,]    6.9047  5.8878
[3,]    6.5940  5.6843
[4,]    6.0877  6.5169
[5,]    6.3456  6.1708
[1] "mean of feat 2"
[1] 8.273493
[1] "sd of feat 2"
[1] 0.7010279
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   130 22283
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
    1  4752 15102  4035     2     3     4  9093     5 12339  3155     6  7147 
   20    20    20    18    16    14    14    14    12    10     8     6     6 
13819 10447 17203     7  1511  9279 11605 
    6     4     4     2     2     2     2 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 22283     5
[1] 22283
[1] "DS index stage 1"
[1] 0.41
[1] "bestgenelist"
 [1]     1     2     3     4     5     6     7  3490  4035  4536  4556  4752
[13]  4967  6280  6325  8667  9092  9093  9094 12339 12343 12583 13543 15102
[25] 15240
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 203963_at
[1,]   12.4440  8.3774 6.7866 10.2851    5.9064  8.3767  8.0356   12.0638
[2,]   12.2005  7.8592 8.0963 10.4624    4.9582  9.2973  7.0581   11.3553
[3,]   12.6709  8.6762 7.4812 10.1887    5.2332  9.1721  8.6061   12.3832
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]     10.1763   13.2850      2.9025   13.0759      8.6216     12.4854
[2,]      9.3275   14.4107      2.2747   13.7616     10.7598     10.5188
[3,]      9.9200   14.7836      0.9203   12.7360      7.7832     11.6232
     206799_at 209173_at 209602_s_at 209603_at 209604_s_at 212956_at 212960_at
[1,]    3.1490   12.9392     11.1535   10.5793     14.3763   13.3600   10.8422
[2,]   14.9688   14.1501     10.8437   10.5772     14.0214   13.2925   10.5720
[3,]   11.6974   14.5585     10.7019   11.1181     14.5222   12.3582    9.8482
     213201_s_at 214164_x_at 215729_s_at 215867_x_at
[1,]      4.2884     12.6474      2.9565     12.6194
[2,]      4.8678     11.7852      1.5807     11.5534
[3,]      8.3652     12.7464      5.6368     12.7285
     1007_s_at 1053_at 117_at  121_at 1255_g_at 1294_at 1316_at 203963_at
[1,]   12.3446  7.0781 7.5017 10.6764    6.4327  9.2305  8.1481   12.4052
[2,]   12.0376  7.6011 7.3458 10.5366    6.5568  9.1180  8.3105   10.4033
[3,]   10.9684  7.4696 8.3759 11.1175    7.0579  9.3514  8.1214    9.8307
     204508_s_at 205009_at 205029_s_at 205225_at 205440_s_at 206754_s_at
[1,]      9.8038   14.3747      3.0068   13.8754     10.5785     11.4867
[2,]      7.9689   11.2149      3.3895   11.7217      8.5134      7.4297
[3,]      7.6789    9.8209      4.9401   10.9960      9.3702      5.9013
     206799_at 209173_at 209602_s_at 209603_at 209604_s_at 212956_at 212960_at
[1,]    7.9310   13.2041     11.9413   11.9790     15.0625   13.5201   11.4301
[2,]   10.6196   11.3631     11.0319   10.8744     14.4978   12.5480   10.2569
[3,]    6.2148   11.1800      8.8487    8.0211     12.4583   11.2917    9.3181
     213201_s_at 214164_x_at 215729_s_at 215867_x_at
[1,]      7.5478     12.7392      1.9565     12.5744
[2,]      5.0501     10.9092      5.3426     11.0575
[3,]      5.0025     10.6696      5.3609     11.0769
[1] "numgenes selected:25"
[1] "test acc:0.87"
[1] "test AUC acc:0.865699873896595"
[1] "10 fold train95.3846153846154"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold  1  2
         1 49  1
         2  1 79
[1] "confusion matrix test"
         test_y
pred_test  1  2
        1 33  7
        2  6 54
[1] "train acc:0.984615384615385"
[1] "confusion matrix train"
          nci_y
pred_train  1  2
         1 49  1
         2  1 79
[1] "DS index stage 1"
[1] 0.41
[1] "KI index stage 1"
[1] 0.4097351
[[1]]
 [1] "var3490"  "var4035"  "var4752"  "var9092"  "var9093"  "var9094" 
 [7] "var12339" "var12343" "var13543" "var15240"

[[2]]
 [1] "var1"     "var2"     "var3"     "var4"     "var5"     "var4035" 
 [7] "var4752"  "var9093"  "var12339" "var15102"

[[3]]
 [1] "var4035"  "var4536"  "var4556"  "var4752"  "var4967"  "var6280" 
 [7] "var6325"  "var8667"  "var12583" "var15102"

[[4]]
 [1] "var1"    "var2"    "var3"    "var4"    "var5"    "var6"    "var7"   
 [8] "var4035" "var4752" "var9093"

[[5]]
 [1] "var3490"  "var4035"  "var4752"  "var9092"  "var9093"  "var9094" 
 [7] "var12339" "var12343" "var13543" "var15240"


 Iteration 1 :  Optimal value:  58.8 
 Optimal List:   var1,var3490,var3,var4035,var4967,var2,var9093,var13543,var4752,var12339 

 Iteration 2 :  Optimal value:  58.8 
 Optimal List:   var4035,var9094,var9093,var1,var4752,var3,var4536,var4,var12339,var3490 

 Iteration 3 :  Optimal value:  56.8 
 Optimal List:   var4035,var4967,var4752,var3490,var3,var9093,var4,var1,var12339,var5 

 Iteration 4 :  Optimal value:  55.2 
 Optimal List:   var2,var4035,var4752,var9093,var9092,var1,var12339,var13543,var4556,var7 

 Iteration 5 :  Optimal value:  55.2 
 Optimal List:   var3490,var4035,var9093,var4752,var2,var12339,var4,var9094,var8667,var4967 

 Iteration 6 :  Optimal value:  53.6 
 Optimal List:   var4035,var4752,var3490,var2,var9093,var9094,var5,var9092,var12343,var15102 

 Iteration 7 :  Optimal value:  53.2 
 Optimal List:   var3490,var4035,var4752,var2,var5,var9092,var1,var4,var12339,var13543 

 Iteration 8 :  Optimal value:  53.6 
 Optimal List:   var4035,var2,var4752,var3490,var1,var4,var3,var12343,var12339,var13543 

 Iteration 9 :  Optimal value:  53.2 
 Optimal List:   var4035,var2,var4752,var4,var9092,var9093,var3490,var9094,var1,var6 

 Iteration 10 :  Optimal value:  53.2 
 Optimal List:   var4035,var2,var4752,var4,var9093,var5,var12339,var4536,var13543,var15240 

 Iteration 11 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var4,var3,var9094,var12339,var9093,var2,var5 

 Iteration 12 :  Optimal value:  52.4 
 Optimal List:   var4035,var3490,var4752,var2,var9093,var4,var9094,var12339,var3,var6 

 Iteration 13 :  Optimal value:  52 
 Optimal List:   var4035,var1,var2,var4752,var9092,var9093,var9094,var12339,var13543,var3 

 Iteration 14 :  Optimal value:  52 
 Optimal List:   var4035,var1,var4752,var2,var9093,var5,var3490,var12339,var13543,var15240 

 Iteration 15 :  Optimal value:  52 
 Optimal List:   var4035,var2,var4752,var1,var5,var9092,var9093,var12339,var12343,var15240 

 Iteration 16 :  Optimal value:  52 
 Optimal List:   var4035,var1,var4752,var2,var9093,var3,var9094,var12339,var4,var15240 

 Iteration 17 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var2,var9092,var9093,var4,var12339,var12343,var15240 

 Iteration 18 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var3,var9093,var9094,var12339,var9092,var13543,var15240 

 Iteration 19 :  Optimal value:  52 
 Optimal List:   var4035,var3490,var4752,var2,var3,var9094,var12339,var9093,var12343,var13543 
[1] "test acc rank aggreg CE:0.87"
[1] "test AUC acc rank aggreg CE:0.870323665405633"
[1] "10 fold train rank aggreg res CE93.0769230769231"
[1] "confusion matrix train 10 fold rank aggreg CE"
            nci_y
pred10foldRA  1  2
           1 46  2
           2  4 78
[1] "Num itr RA CE"
[1] 19
[1] "Test BER aggreg CE is"
[1] 0.8703237

 Iteration 1 :  Optimal value:  61.6 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var9093,var6280,var6325,var4536 

 Iteration 2 :  Optimal value:  61.2 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var9093,var6280,var6325,var15240 

 Iteration 3 :  Optimal value:  60.8 
 Optimal List:   var3490,var4035,var2,var5,var3,var9092,var9093,var6280,var6325,var4536 

 Iteration 4 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 5 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 6 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 7 :  Optimal value:  58.8 
 Optimal List:   var3490,var4035,var9092,var5,var3,var2,var4752,var6280,var6325,var15240 

 Iteration 8 :  Optimal value:  58 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var8667,var9093,var15240 

 Iteration 9 :  Optimal value:  58 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var8667,var9093,var15240 

 Iteration 10 :  Optimal value:  57.6 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var9093,var8667,var4,var15240 

 Iteration 11 :  Optimal value:  57.6 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var13543,var9093,var15240 

 Iteration 12 :  Optimal value:  58 
 Optimal List:   var4035,var4752,var3,var4556,var5,var1,var4,var8667,var9093,var15240 

 Iteration 13 :  Optimal value:  56.8 
 Optimal List:   var4035,var4752,var3,var4,var5,var1,var4556,var8667,var9093,var15240 

 Iteration 14 :  Optimal value:  56.8 
 Optimal List:   var4035,var4752,var3,var4,var5,var1,var4556,var8667,var9093,var15240 

 Iteration 15 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 16 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 17 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 18 :  Optimal value:  55.6 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var4556 

 Iteration 19 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var15240 

 Iteration 20 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var4752,var5,var3,var1,var9092,var9093,var6325,var15240 

 Iteration 21 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var4,var8667,var9093,var15240 

 Iteration 22 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 23 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 24 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 25 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 26 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 27 :  Optimal value:  54.8 
 Optimal List:   var3490,var2,var4752,var5,var4035,var3,var9092,var1,var9093,var4 

 Iteration 28 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var9092,var4752,var3,var2,var5,var1,var9093,var12583 

 Iteration 29 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var9092,var4752,var3,var2,var5,var1,var9093,var12583 

 Iteration 30 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var9092,var4752,var3,var2,var5,var1,var9093,var12583 

 Iteration 31 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var2,var9092,var4,var8667,var9093,var15240 

 Iteration 32 :  Optimal value:  55.2 
 Optimal List:   var4035,var4752,var3,var3490,var5,var2,var4,var8667,var9093,var15240 

 Iteration 33 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var9092,var4752,var5,var2,var3,var1,var9093,var15240 

 Iteration 34 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var9092,var4752,var5,var2,var3,var1,var9093,var15240 

 Iteration 35 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var3,var5,var2,var4752,var1,var9093,var15240 

 Iteration 36 :  Optimal value:  54.8 
 Optimal List:   var3490,var4752,var3,var4035,var5,var1,var9093,var2,var6325,var15240 

 Iteration 37 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 38 :  Optimal value:  54.4 
 Optimal List:   var4035,var4752,var3,var3490,var5,var1,var9093,var2,var6325,var15240 

 Iteration 39 :  Optimal value:  54.8 
 Optimal List:   var3490,var4035,var9092,var5,var4752,var1,var3,var2,var9093,var15240 

 Iteration 40 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var9092,var1,var9093,var15240 

 Iteration 41 :  Optimal value:  53.6 
 Optimal List:   var4035,var3490,var9092,var4752,var3,var2,var12339,var1,var9093,var12583 

 Iteration 42 :  Optimal value:  53.6 
 Optimal List:   var4035,var3490,var9092,var4752,var3,var2,var12339,var1,var9093,var12583 

 Iteration 43 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var4752,var5,var3,var1,var9092,var2,var9093,var15240 

 Iteration 44 :  Optimal value:  54 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var9092,var1,var9093,var15240 

 Iteration 45 :  Optimal value:  53.6 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var9092,var1,var9093,var15240 

 Iteration 46 :  Optimal value:  53.2 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var12339,var1,var9093,var15240 

 Iteration 47 :  Optimal value:  53.2 
 Optimal List:   var3490,var4035,var3,var5,var4752,var2,var12339,var1,var9093,var15240 

 Iteration 48 :  Optimal value:  52.8 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var1,var9093,var15240 

 Iteration 49 :  Optimal value:  52.8 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var1,var9093,var15240 

 Iteration 50 :  Optimal value:  52.8 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var1,var9093,var15240 

 Iteration 51 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 52 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 53 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 54 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 55 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 56 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 57 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 58 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var12343,var9093,var15240 

 Iteration 59 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var12343,var9093,var15240 

 Iteration 60 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var12343,var9093,var15240 

 Iteration 61 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var3,var5,var2,var12339,var9094,var9093,var15240 

 Iteration 62 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var3,var5,var2,var12339,var9094,var9093,var15240 

 Iteration 63 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 64 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 65 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 66 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 67 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var4752,var5,var3,var2,var12339,var9093,var1,var15240 

 Iteration 68 :  Optimal value:  52.4 
 Optimal List:   var4035,var3490,var4752,var3,var5,var2,var12339,var1,var9093,var15240 

 Iteration 69 :  Optimal value:  52.4 
 Optimal List:   var4035,var3490,var4752,var4,var3,var2,var12339,var9093,var1,var4536 

 Iteration 70 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var4,var4752,var1,var12339,var2,var9093,var15240 

 Iteration 71 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 72 :  Optimal value:  52.4 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var1,var9093,var15240 

 Iteration 73 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 74 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 75 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 76 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 77 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 78 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 79 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var15240 

 Iteration 80 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var9094 

 Iteration 81 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var9094 

 Iteration 82 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var1,var12339,var9093,var5,var9094 

 Iteration 83 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 84 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4752,var2,var1,var12339,var9093,var5,var6280 

 Iteration 85 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var2,var4752,var5,var12339,var9093,var1,var15240 

 Iteration 86 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4,var4752,var2,var12339,var9093,var1,var15240 

 Iteration 87 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 88 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 89 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var12339,var9093,var5,var15240 

 Iteration 90 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 91 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 92 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 93 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 94 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var15240 

 Iteration 95 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 96 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var3,var4752,var4,var2,var12339,var9093,var1,var15240 

 Iteration 97 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var4 

 Iteration 98 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var4 

 Iteration 99 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var15240 

 Iteration 100 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var15240 

 Iteration 101 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var5,var9093,var12339,var15240 

 Iteration 102 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9093,var12339,var9092,var1,var4 

 Iteration 103 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var1,var9093,var15102 

 Iteration 104 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var12339,var9093,var5,var4967 

 Iteration 105 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4,var4752,var2,var12339,var9093,var1,var15240 

 Iteration 106 :  Optimal value:  52 
 Optimal List:   var3490,var4035,var3,var4,var4752,var2,var12339,var9093,var1,var15240 

 Iteration 107 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 108 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 109 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 110 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 111 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var4 

 Iteration 112 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var4,var3,var2,var12339,var9093,var1,var15240 

 Iteration 113 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var1,var12339,var9093,var5,var9094 

 Iteration 114 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 115 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var9093,var1,var12339,var9094 

 Iteration 116 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var4 

 Iteration 117 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var5,var12339,var9093,var2,var4 

 Iteration 118 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var12339,var9093,var5,var1 

 Iteration 119 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var4,var12339,var9093,var5,var1 

 Iteration 120 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var4 

 Iteration 121 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var2,var12339,var9093,var5,var15240 

 Iteration 122 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var2,var12339,var9093,var5,var15240 

 Iteration 123 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var2,var12339,var9093,var5,var15240 

 Iteration 124 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var12339,var9093,var1,var12343 

 Iteration 125 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var9093,var12339,var1,var15240 

 Iteration 126 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var9093,var12339,var1,var15240 

 Iteration 127 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9093,var12339,var5,var2,var15240 

 Iteration 128 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9093,var12339,var5,var2,var15240 

 Iteration 129 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 130 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 131 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 132 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 133 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 134 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 135 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 136 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var9092,var3,var9093,var12339,var5,var1,var4 

 Iteration 137 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 138 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 139 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 140 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 141 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 142 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 143 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 144 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 145 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 146 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var9093,var12339,var1,var12343 

 Iteration 147 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9092,var12339,var9093,var2,var13543 

 Iteration 148 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 149 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 150 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 151 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var3,var9092,var12339,var9093,var2,var13543 

 Iteration 152 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 153 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 154 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 155 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 156 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var9093,var12339,var1,var13543 

 Iteration 157 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var9092,var12339,var9093,var1,var13543 

 Iteration 158 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 159 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 160 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 161 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 162 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 163 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var9092,var12339,var3,var1,var13543 

 Iteration 164 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 165 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 166 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 167 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var1,var9093,var5,var12339,var3,var2,var13543 

 Iteration 168 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 169 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 170 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 171 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 172 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 173 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 174 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9092,var3,var12339,var9093,var9094,var13543 

 Iteration 175 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var13543 

 Iteration 176 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var13543 

 Iteration 177 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var3,var5,var1,var9093,var12339,var13543 

 Iteration 178 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 179 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 180 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9092,var9093,var12339,var3,var1,var13543 

 Iteration 181 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 182 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 183 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 184 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 185 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 186 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 

 Iteration 187 :  Optimal value:  51.6 
 Optimal List:   var3490,var4035,var4752,var2,var9093,var5,var12339,var3,var1,var13543 
[1] "test acc rank aggreg GA:0.88"
[1] "test AUC acc rank aggreg GA:0.878520386717108"
[1] "10 fold train rank aggreg res GA93.8461538461538"
[1] "confusion matrix train 10 fold rank aggreg GA"
            nci_y
pred10foldRA  1  2
           1 46  0
           2  4 80
[1] "Num itr RA GA"
[1] 188
[1] "Test BER aggreg GA is"
[1] 0.8785204
Warning messages:
1: In if (is.na(boostweight) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
3: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 130  25
> 
> #2 call run_pso function()
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=3,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.01,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=as.numeric(args[11]),min.iter.select=1))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 3"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.4"
[1] "weightB: 0.4"
[1] "weightC: 0.05"
[1] "weightD: 0.15"
[1] "featweight.max: 0.01"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.45"
[1] "confusionprob: 0.2"
[1] "leaderprob: 0.25"
[1] "wmax: 1"
[1] "wmin: 1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 10"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 1"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 96.15385
[1] "here"
[1] "s"
[1] 104
[1] 130  25
[1] 10
[1] "learning sets: 1"
  [1] 118 110  23 129  33  31  43  24  42  78  54  30  72   6  46  16  83  29
 [19]  18 104  73  71  66  76  90  98  51  74   8 103  13  68  45  32  22  15
 [37] 109   5  17  14  12  96 126  39  95 123  70  19  36  28  82 122 101  55
 [55]  27  85 121  38  75  84 119   4   7 105  37  86 128 125  44  58 116 107
 [73]  62  88 106  61  65  69  25  40  81  93  50  10  11   3 114 100 102  63
 [91]  26   1  52  67  92  41 113  35  64  77  21 130  34   2
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
Error in checkForRemoteErrors(val) : 
  20 nodes produced errors; first error: Model is empty!
Calls: system.time ... clusterApply -> staticClusterApply -> checkForRemoteErrors
In addition: Warning messages:
1: In if (is.na(testm) == TRUE) { :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(testclass) == TRUE) { :
  the condition has length > 1 and only the first element will be used
Timing stopped at: 0.088 0.148 102.278 
Execution halted
