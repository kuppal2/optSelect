
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> #.libPaths("/home/kuppal3/karan_libs/Rlibs")
> library(snow)
Warning message:
package ‘snow’ was built under R version 3.2.5 
> library(e1071)
Warning message:
package ‘e1071’ was built under R version 3.2.5 
> library(yaImpute)

Attaching package: ‘yaImpute’

The following object is masked from ‘package:e1071’:

    impute

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

Warning message:
package ‘pROC’ was built under R version 3.2.5 
> library(bioDist)
Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘parallel’

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
    parCapply, parLapply, parRapply, parSapply, splitIndices,
    stopCluster


Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:snow’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parRapply, parSapply

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> #library(CMA, lib="/home/kuppal3/karan_libs/Rlibs/")
> library(RankAggreg)
Warning message:
package ‘RankAggreg’ was built under R version 3.2.5 
> library(CMA)

Attaching package: ‘CMA’

The following object is masked from ‘package:pROC’:

    roc

The following object is masked from ‘package:e1071’:

    tune

Warning message:
package ‘CMA’ was built under R version 3.2.4 
> library(expm)
Loading required package: Matrix

Attaching package: ‘expm’

The following object is masked from ‘package:Matrix’:

    expm

Warning messages:
1: package ‘expm’ was built under R version 3.2.5 
2: package ‘Matrix’ was built under R version 3.2.5 
> 
> cl<-makeCluster(1)
> 
> 
> args<-commandArgs(trailingOnly=TRUE)
> 
> dirloc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/"
> #sname<-paste("/home/stu/kuppal3/Research/Feature_selection/Rcode/versionnov2014/OCFS_",args[9],".R",sep="")
> 
> sname<-paste(dirloc,"version2017/OCFS_",args[9],".R",sep="")
> source(sname)
> 
> outloc<-paste(dirloc,"/Datasets/Golub/OCFSvmay2415_Golub",args[9],"/",sep="")
> 
> 
> sname<-paste(dirloc,"Datasets/Golub/Golub.Rda",sep="")
> load(sname)
> 
> #data_loc<-"/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO/Datasets/Golub/"
> #data_loc<-"/home/kuppal2/Documents/Projects/xmsPANDA/Other/Datasets/Golub/"
> #load("/home/kuppal3/Research/Feature_selection/Datasets/Golub/Golub.rda")
> #load("Golub.rda")
> 
> trainm<-Golub$X
> testm<-Golub$Xt
> trainclass<-Golub$y
> testclass<-Golub$yt
> 
> cnames<-paste("var",seq(1,dim(trainm)[2]),sep="")
> colnames(trainm)<-cnames
> colnames(testm)<-cnames
> 
> trainm<-t(trainm)
> testm<-t(testm)
> 
> 
> 
> trainm[trainm < 100] <- 100
> trainm[trainm > 16000] <- 16000
> 
> testm[testm < 100] <- 100
> testm[testm > 16000] <- 16000
> 
> mmfilt <- function(x,r = 5, d = 500, na.rm = TRUE) {
+  minval <- min(x, na.rm = na.rm)
+  maxval <- max(x, na.rm = na.rm)
+  (maxval/minval > r) && (maxval - minval > d)
+ }
> 
> #mmfun <- mmfilt()
> #ffun <- filterfun(mmfun)
> #good <- genefilter(X, ffun)
> 
> good<-apply(trainm,1,mmfilt)
> 
> 
> trainm<-trainm[good,]
> 
> print(dim(trainm))
[1] 3051   38
> testm<-testm[good,]
> 
> 
> trainm<-log10(trainm+1)
>  testm<-log10(testm+1)
> 
> 
> trainm<-t(trainm)
> testm<-t(testm)
> 
> trainm<-cbind(trainclass,trainm)
> testm<-cbind(testclass,testm)
> 
> trainm<-na.omit(trainm)
> testm<-na.omit(testm)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/Golub/OCFSvmay2415_Golubvjan92018_v2' already exists
> setwd(outloc)
> 
> trainm<-as.matrix(trainm)
> testm<-as.matrix(testm)
> trainclass<-trainm[,1] #CMAres$modtrainclass
> testclass<-testm[,1] #CMAres$modtestclass
> trainm<-trainm[,-c(1)] #CMAres$modtrainmata
> testm<-testm[,-c(1)] #CMAres$modtestmata
> 
> #a: Confusions
> #b: Neighbors
> #c: Global
> #d: Death
> 
> a<-c(0.25,0.25,0.25,0.25)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0.25,0.25,0.5,0)
> d<-c(0.9,0.1,0,0.1)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.3,0.1,0.4,0.1)
> c<-c(0,0.5,0.5,0)
> d<-c(0.9,0.1,0,0)
> 
> a<-c(0,0.4,0.1,0.5)
> b<-c(0.2,0.3,0.4,0.1)
> c<-c(0,0.4,0.4,0.2)
> d<-c(0.9,0.1,0,0)
> 
> transition_matrix<-rbind(a,b,c,d)
> 
> 
> dir.create(outloc)
Warning message:
In dir.create(outloc) :
  '/Users/karanuppal/Documents/Gatech/Projects/Algorithms/TwostagePSO//Datasets/Golub/OCFSvmay2415_Golubvjan92018_v2' already exists
> setwd(outloc)
> temp2=t(trainm)
> temp2=apply(temp2, 2, function(x){which(x=="MD")})
> temp2=unlist(temp2)
> temp2=unique(temp2)
> if(length(temp2)>1)
+ {
+ 	trainm=trainm[,-c(temp2)]
+ 
+ 	rm(temp2)
+ }
> 
> boostweight=rep(0,dim(trainm)[2])
> 
> #if(FALSE)
> {
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("lasso"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rfe"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("elasticnet"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ 
+ if(FALSE){
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("rf"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
+ 
+ CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
+ }
[1] "dim of trainm is "
[1]   38 3051
[1]   38 3051
[1] "length of factcols"
[1] 0
[1]   38 3051
[1]   34 3051
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
V1 V2 V3 V4 
-1 -1 -1 -1 
Levels: -1 1
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] 2.902003 2.637490 3.168792
[1] "norm train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "mean of feat 2"
[1] 2.241856
[1] "sd of feat 2"
[1] 0.2932821
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   38 3051
GeneSelection: iteration 1 

Attaching package: ‘limma’

The following object is masked from ‘package:BiocGenerics’:

    plotMA

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 3051    1
[1] 3051
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  378  808  829 1009 1448 2124 2489 2663 2664 2670
       var760  var1834  var1882  var2288  var3320  var4847  var5772  var6200
[1,] 2.209515 2.418301 2.482874 2.004321 3.051153 2.475671 3.492201 2.466868
[2,] 2.770115 2.008600 3.133219 2.004321 3.026533 2.488551 3.048830 3.314499
[3,] 2.318063 2.491362 2.406540 2.004321 3.145818 2.491362 3.657438 2.004321
      var6201  var6218
[1,] 2.523746 2.004321
[2,] 3.728029 2.004321
[3,] 2.480007 2.004321
       var760  var1834  var1882  var2288  var3320  var4847  var5772  var6200
[1,] 2.004321 2.227887 2.004321 2.004321 3.050380 2.252853 3.309204 2.526339
[2,] 2.004321 2.389166 2.004321 2.004321 3.007321 2.025306 3.175512 2.222716
[3,] 2.356026 2.004321 2.004321 2.004321 2.632457 2.403121 3.627468 2.178977
      var6201  var6218
[1,] 2.870404 2.037426
[2,] 2.303196 2.230449
[3,] 2.004321 2.584331
[1] "numgenes selected:10"
[1] "test acc:0.970588235294118"
[1] "test AUC acc:0.964285714285714"
[1] "10 fold train89.4736842105263"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold -1  1
        -1 27  0
        1   0 11
[1] "confusion matrix test"
         test_y
pred_test -1  1
       -1 20  1
       1   0 13
[1] "train acc:1"
[1] "confusion matrix train"
          nci_y
pred_train -1  1
        -1 27  0
        1   0 11
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   38 3051
[1]   38 3051
[1] "length of factcols"
[1] 0
[1]   38 3051
[1]   34 3051
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
V1 V2 V3 V4 
-1 -1 -1 -1 
Levels: -1 1
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] 2.902003 2.637490 3.168792
[1] "norm train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "mean of feat 2"
[1] 2.241856
[1] "sd of feat 2"
[1] 0.2932821
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   38 3051
GeneSelection: iteration 1 
Loaded glmnet 2.0-10


Attaching package: ‘glmnet’

The following object is masked from ‘package:pROC’:

    auc

GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
   1    2    3  829  808 2670    4  523 2124    5 2813 1448  792 1995 2198    6 
  20   20   20   20   18   16   14   12   10    8    8    6    4    4    4    2 
 140  378  894 1413 1977 2663 2750 
   2    2    2    2    2    2    2 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 3051    1
[1] 3051
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]    1    2    3    4    5  523  808  829 2124 2670
        var36    var37    var38    var39    var40  var1144  var1834  var1882
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 2.786041 2.418301 2.482874
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 2.967548 2.008600 3.133219
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.229938 2.491362 2.406540
      var4847  var6218
[1,] 2.475671 2.004321
[2,] 2.488551 2.004321
[3,] 2.491362 2.004321
        var36    var37    var38    var39    var40  var1144  var1834  var1882
[1,] 2.004321 2.133539 2.428135 2.004321 2.004321 2.895975 2.227887 2.004321
[2,] 2.004321 2.004321 2.572872 2.004321 2.004321 2.997823 2.389166 2.004321
[3,] 2.004321 2.004321 2.220108 2.021189 2.004321 2.789581 2.004321 2.004321
      var4847  var6218
[1,] 2.252853 2.037426
[2,] 2.025306 2.230449
[3,] 2.403121 2.584331
[1] "numgenes selected:10"
[1] "test acc:1"
[1] "test AUC acc:1"
[1] "10 fold train100"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold -1  1
        -1 27  0
        1   0 11
[1] "confusion matrix test"
         test_y
pred_test -1  1
       -1 20  0
       1   0 14
[1] "train acc:1"
[1] "confusion matrix train"
          nci_y
pred_train -1  1
        -1 27  0
        1   0 11
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   38 3051
[1]   38 3051
[1] "length of factcols"
[1] 0
[1]   38 3051
[1]   34 3051
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
V1 V2 V3 V4 
-1 -1 -1 -1 
Levels: -1 1
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] 2.902003 2.637490 3.168792
[1] "norm train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "mean of feat 2"
[1] 2.241856
[1] "sd of feat 2"
[1] 0.2932821
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   38 3051
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 3051    1
[1] 3051
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  773  829 1009 1038 1162 2124 2402 2600 2670 2945
      var1779  var1882  var2288  var2349  var2642  var4847  var5552  var6041
[1,] 2.004321 2.482874 2.004321 2.220108 3.969742 2.475671 3.961184 3.108903
[2,] 2.004321 3.133219 2.004321 2.703291 2.952308 2.488551 3.611829 2.733197
[3,] 2.004321 2.406540 2.004321 2.004321 2.798651 2.491362 3.504199 2.374748
      var6218  var6884
[1,] 2.004321 2.079181
[2,] 2.004321 2.004321
[3,] 2.004321 2.238046
      var1779  var1882  var2288  var2349  var2642  var4847  var5552  var6041
[1,] 2.691081 2.004321 2.004321 2.313867 4.112906 2.252853 3.792392 2.004321
[2,] 2.004321 2.004321 2.004321 2.004321 3.258637 2.025306 2.492760 2.557507
[3,] 2.004321 2.004321 2.004321 2.004321 3.559667 2.403121 3.720325 2.752816
      var6218  var6884
[1,] 2.037426 2.184691
[2,] 2.230449 2.604226
[3,] 2.584331 2.004321
[1] "numgenes selected:10"
[1] "test acc:0.970588235294118"
[1] "test AUC acc:0.964285714285714"
[1] "10 fold train92.1052631578947"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold -1  1
        -1 27  0
        1   0 11
[1] "confusion matrix test"
         test_y
pred_test -1  1
       -1 20  1
       1   0 13
[1] "train acc:1"
[1] "confusion matrix train"
          nci_y
pred_train -1  1
        -1 27  0
        1   0 11
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   38 3051
[1]   38 3051
[1] "length of factcols"
[1] 0
[1]   38 3051
[1]   34 3051
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
V1 V2 V3 V4 
-1 -1 -1 -1 
Levels: -1 1
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] 2.902003 2.637490 3.168792
[1] "norm train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "mean of feat 2"
[1] 2.241856
[1] "sd of feat 2"
[1] 0.2932821
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   38 3051
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 3051    1
[1] 3051
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]    1    2    3    4    5    6  808  829 2124 2670
        var36    var37    var38    var39    var40    var41  var1834  var1882
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 2.418301 2.482874
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 2.008600 3.133219
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 2.491362 2.406540
      var4847  var6218
[1,] 2.475671 2.004321
[2,] 2.488551 2.004321
[3,] 2.491362 2.004321
        var36    var37    var38    var39    var40    var41  var1834  var1882
[1,] 2.004321 2.133539 2.428135 2.004321 2.004321 2.004321 2.227887 2.004321
[2,] 2.004321 2.004321 2.572872 2.004321 2.004321 2.004321 2.389166 2.004321
[3,] 2.004321 2.004321 2.220108 2.021189 2.004321 2.004321 2.004321 2.004321
      var4847  var6218
[1,] 2.252853 2.037426
[2,] 2.025306 2.230449
[3,] 2.403121 2.584331
[1] "numgenes selected:10"
[1] "test acc:0.970588235294118"
[1] "test AUC acc:0.964285714285714"
[1] "10 fold train94.7368421052632"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold -1  1
        -1 27  0
        1   0 11
[1] "confusion matrix test"
         test_y
pred_test -1  1
       -1 20  1
       1   0 13
[1] "train acc:1"
[1] "confusion matrix train"
          nci_y
pred_train -1  1
        -1 27  0
        1   0 11
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
[1] "dim of trainm is "
[1]   38 3051
[1]   38 3051
[1] "length of factcols"
[1] 0
[1]   38 3051
[1]   34 3051
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
V1 V2 V3 V4 
-1 -1 -1 -1 
Levels: -1 1
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] 2.902003 2.637490 3.168792
[1] "norm train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "mean of feat 2"
[1] 2.241856
[1] "sd of feat 2"
[1] 0.2932821
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   38 3051
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 3051    1
[1] 3051
[1] "DS index stage 1"
[1] NA
[1] "bestgenelist"
 [1]  378  808  829 1009 1448 2124 2198 2489 2663 2670
       var760  var1834  var1882  var2288  var3320  var4847  var5039  var5772
[1,] 2.209515 2.418301 2.482874 2.004321 3.051153 2.475671 2.778874 3.492201
[2,] 2.770115 2.008600 3.133219 2.004321 3.026533 2.488551 2.528917 3.048830
[3,] 2.318063 2.491362 2.406540 2.004321 3.145818 2.491362 2.759668 3.657438
      var6200  var6218
[1,] 2.466868 2.004321
[2,] 3.314499 2.004321
[3,] 2.004321 2.004321
       var760  var1834  var1882  var2288  var3320  var4847  var5039  var5772
[1,] 2.004321 2.227887 2.004321 2.004321 3.050380 2.252853 2.668386 3.309204
[2,] 2.004321 2.389166 2.004321 2.004321 3.007321 2.025306 2.806180 3.175512
[3,] 2.356026 2.004321 2.004321 2.004321 2.632457 2.403121 2.309630 3.627468
      var6200  var6218
[1,] 2.526339 2.037426
[2,] 2.222716 2.230449
[3,] 2.178977 2.584331
[1] "numgenes selected:10"
[1] "test acc:0.970588235294118"
[1] "test AUC acc:0.964285714285714"
[1] "10 fold train97.3684210526316"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold -1  1
        -1 27  0
        1   0 11
[1] "confusion matrix test"
         test_y
pred_test -1  1
       -1 20  1
       1   0 13
[1] "train acc:1"
[1] "confusion matrix train"
          nci_y
pred_train -1  1
        -1 27  0
        1   0 11
[1] "DS index stage 1"
[1] NA
[1] "KI index stage 1"
[1] NA
There were 40 warnings (use warnings() to see them)
> #1
> CMAres<-performCMA(trainm, trainclass, testm, testclass,outloc,
+ maxnum=as.numeric(args[10]),
+ minnum=3,
+ stepitr=1,
+ gsmethods=c("limma","lasso","rfe","elasticnet", "f.test"), #"lasso","elasticnet","kruskal.test"), #"f.test", "f.test", "elasticnet", "wilcox.test", "welch.test"),
+ pct_train=0.40,
+ accuracyweight=1,
+ featweight=0.06,
+ minpresent=1,
+ kname="radial",
+ norm_method="none",
+ tolerance=0.1,
+ maxitrs=5,
+ classindex=1,
+ numfacts=0,
+ evalmethod="CV",
+ numfolds=10,
+ CVfoldthresh=0.7,
+ varselmethod="none",
+ scheme_val="one-vs-all",
+ iter_learn=1,boostweight=rep(0,dim(trainm)[2]))
[1] "dim of trainm is "
[1]   38 3051
[1]   38 3051
[1] "length of factcols"
[1] 0
[1]   38 3051
[1]   34 3051
integer(0)
character(0)
NULL
[1] "ok"
[1] "test class"
V1 V2 V3 V4 
-1 -1 -1 -1 
Levels: -1 1
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "orig train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] 2.902003 2.637490 3.168792
[1] "norm train matrix"
        var36    var37    var38    var39    var40    var41    var42    var43
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 4.178315 4.046378
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 4.204147 4.132548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 4.204147 4.204147
[4,] 2.004321 2.193125 2.619093 3.685831 3.360593 3.409933 4.173798 4.058426
[5,] 2.004321 2.089905 2.684845 3.108903 3.436481 2.501059 4.165956 4.176988
        var45    var46
[1,] 4.204147 4.204147
[2,] 4.204147 4.204147
[3,] 4.204147 4.204147
[4,] 4.197859 4.204147
[5,] 4.204147 4.204147
[1] "mean of feat 2"
[1] 2.241856
[1] "sd of feat 2"
[1] 0.2932821
[1] "maxnum is "
[1] 10
[1] "# of genes left after filtering:"
[1]   38 3051
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
genelist
   1    2    3  829  808 2670    4  523 2124    5 2813 1448  792 1995 2198    6 
  20   20   20   20   18   16   14   12   10    8    8    6    4    4    4    2 
 140  378  894 1413 1977 2663 2750 
   2    2    2    2    2    2    2 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
GeneSelection: iteration 1 
GeneSelection: iteration 2 
GeneSelection: iteration 3 
GeneSelection: iteration 4 
GeneSelection: iteration 5 
GeneSelection: iteration 6 
GeneSelection: iteration 7 
GeneSelection: iteration 8 
GeneSelection: iteration 9 
GeneSelection: iteration 10 
[1] "varselmethod"
[1] "none"
[1] "dim of scoring matrix is "
[1] 3051    5
[1] 3051
[1] "DS index stage 1"
[1] 0.48
[1] "bestgenelist"
 [1]    1    2    3    4    5    6  378  523  773  808  829 1009 1038 1162 1448
[16] 2124 2198 2402 2489 2600 2663 2664 2670 2945
        var36    var37    var38    var39    var40    var41   var760  var1144
[1,] 2.004321 2.334454 2.902003 4.162535 3.988514 3.930949 2.209515 2.786041
[2,] 2.004321 2.068186 2.637490 2.789581 2.064458 3.181558 2.770115 2.967548
[3,] 2.021189 2.678518 3.168792 3.753583 3.514946 3.564548 2.318063 3.229938
      var1779  var1834  var1882  var2288  var2349  var2642  var3320  var4847
[1,] 2.004321 2.418301 2.482874 2.004321 2.220108 3.969742 3.051153 2.475671
[2,] 2.004321 2.008600 3.133219 2.004321 2.703291 2.952308 3.026533 2.488551
[3,] 2.004321 2.491362 2.406540 2.004321 2.004321 2.798651 3.145818 2.491362
      var5039  var5552  var5772  var6041  var6200  var6201  var6218  var6884
[1,] 2.778874 3.961184 3.492201 3.108903 2.466868 2.523746 2.004321 2.079181
[2,] 2.528917 3.611829 3.048830 2.733197 3.314499 3.728029 2.004321 2.004321
[3,] 2.759668 3.504199 3.657438 2.374748 2.004321 2.480007 2.004321 2.238046
        var36    var37    var38    var39    var40    var41   var760  var1144
[1,] 2.004321 2.133539 2.428135 2.004321 2.004321 2.004321 2.004321 2.895975
[2,] 2.004321 2.004321 2.572872 2.004321 2.004321 2.004321 2.004321 2.997823
[3,] 2.004321 2.004321 2.220108 2.021189 2.004321 2.004321 2.356026 2.789581
      var1779  var1834  var1882  var2288  var2349  var2642  var3320  var4847
[1,] 2.691081 2.227887 2.004321 2.004321 2.313867 4.112906 3.050380 2.252853
[2,] 2.004321 2.389166 2.004321 2.004321 2.004321 3.258637 3.007321 2.025306
[3,] 2.004321 2.004321 2.004321 2.004321 2.004321 3.559667 2.632457 2.403121
      var5039  var5552  var5772  var6041  var6200  var6201  var6218  var6884
[1,] 2.668386 3.792392 3.309204 2.004321 2.526339 2.870404 2.037426 2.184691
[2,] 2.806180 2.492760 3.175512 2.557507 2.222716 2.303196 2.230449 2.604226
[3,] 2.309630 3.720325 3.627468 2.752816 2.178977 2.004321 2.584331 2.004321
[1] "numgenes selected:24"
[1] "test acc:0.970588235294118"
[1] "test AUC acc:0.964285714285714"
[1] "10 fold train100"
[1] "confusion matrix train 10 fold"
          nci_y
pred10fold -1  1
        -1 27  0
        1   0 11
[1] "confusion matrix test"
         test_y
pred_test -1  1
       -1 20  1
       1   0 13
[1] "train acc:1"
[1] "confusion matrix train"
          nci_y
pred_train -1  1
        -1 27  0
        1   0 11
[1] "DS index stage 1"
[1] 0.48
[1] "KI index stage 1"
[1] 0.47829
[[1]]
 [1] "var378"  "var808"  "var829"  "var1009" "var1448" "var2124" "var2489"
 [8] "var2663" "var2664" "var2670"

[[2]]
 [1] "var1"    "var2"    "var3"    "var4"    "var5"    "var523"  "var808" 
 [8] "var829"  "var2124" "var2670"

[[3]]
 [1] "var773"  "var829"  "var1009" "var1038" "var1162" "var2124" "var2402"
 [8] "var2600" "var2670" "var2945"

[[4]]
 [1] "var1"    "var2"    "var3"    "var4"    "var5"    "var6"    "var808" 
 [8] "var829"  "var2124" "var2670"

[[5]]
 [1] "var378"  "var808"  "var829"  "var1009" "var1448" "var2124" "var2198"
 [8] "var2489" "var2663" "var2670"


 Iteration 1 :  Optimal value:  58 
 Optimal List:   var3,var5,var808,var4,var1009,var378,var2124,var829,var2,var1038 

 Iteration 2 :  Optimal value:  56.4 
 Optimal List:   var378,var829,var2600,var1009,var4,var2124,var808,var2670,var3,var1 

 Iteration 3 :  Optimal value:  56.4 
 Optimal List:   var378,var808,var829,var1009,var2124,var2402,var4,var773,var1038,var2945 

 Iteration 4 :  Optimal value:  53.6 
 Optimal List:   var1009,var1,var829,var808,var2,var2124,var378,var2670,var1038,var5 

 Iteration 5 :  Optimal value:  55.2 
 Optimal List:   var1,var1009,var829,var808,var3,var2124,var1162,var2600,var2663,var523 

 Iteration 6 :  Optimal value:  55.2 
 Optimal List:   var808,var2124,var829,var1009,var4,var2,var1,var2670,var2489,var6 

 Iteration 7 :  Optimal value:  53.2 
 Optimal List:   var378,var808,var829,var1009,var2663,var2124,var4,var2489,var2670,var523 

 Iteration 8 :  Optimal value:  52.4 
 Optimal List:   var829,var2,var808,var1009,var378,var2124,var5,var2670,var3,var2402 

 Iteration 9 :  Optimal value:  50.4 
 Optimal List:   var1,var829,var808,var1009,var5,var2124,var3,var1448,var2670,var4 

 Iteration 10 :  Optimal value:  51.6 
 Optimal List:   var808,var1,var1009,var829,var378,var2,var2124,var1448,var3,var2670 

 Iteration 11 :  Optimal value:  51.6 
 Optimal List:   var1,var829,var808,var1009,var378,var2124,var4,var1162,var2670,var2663 

 Iteration 12 :  Optimal value:  52 
 Optimal List:   var829,var2,var1009,var3,var4,var2124,var808,var2489,var2670,var2945 

 Iteration 13 :  Optimal value:  51.2 
 Optimal List:   var1,var829,var808,var1009,var3,var2124,var4,var2670,var2663,var2 

 Iteration 14 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var1009,var1,var2124,var2489,var6,var1448,var2670 

 Iteration 15 :  Optimal value:  50.8 
 Optimal List:   var378,var2,var829,var1009,var808,var2124,var4,var2663,var1038,var2670 

 Iteration 16 :  Optimal value:  51.2 
 Optimal List:   var378,var829,var808,var1009,var3,var4,var2124,var1,var773,var2670 

 Iteration 17 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var1009,var829,var4,var2124,var2,var1,var2670,var2402 

 Iteration 18 :  Optimal value:  50.4 
 Optimal List:   var378,var829,var808,var1009,var1448,var2124,var3,var4,var2670,var2489 

 Iteration 19 :  Optimal value:  50.8 
 Optimal List:   var1,var829,var808,var1009,var5,var2124,var4,var2663,var2670,var378 

 Iteration 20 :  Optimal value:  50.8 
 Optimal List:   var808,var829,var1,var1009,var3,var2124,var4,var2489,var2663,var2670 

 Iteration 21 :  Optimal value:  50.4 
 Optimal List:   var1,var829,var378,var1009,var3,var2124,var808,var4,var2670,var5 

 Iteration 22 :  Optimal value:  50.4 
 Optimal List:   var378,var829,var808,var1009,var3,var2124,var1,var5,var2670,var2 

 Iteration 23 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var1009,var3,var2124,var1448,var2489,var2670,var5 

 Iteration 24 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var1009,var4,var2124,var1448,var2663,var2,var2670 

 Iteration 25 :  Optimal value:  50.4 
 Optimal List:   var808,var378,var829,var1009,var5,var2124,var1,var2489,var2,var2670 

 Iteration 26 :  Optimal value:  50.4 
 Optimal List:   var1,var829,var1009,var378,var5,var2124,var808,var2489,var2,var2670 

 Iteration 27 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var2,var3,var2124,var1448,var2489,var2663,var2670 

 Iteration 28 :  Optimal value:  50 
 Optimal List:   var378,var829,var808,var1009,var4,var2124,var5,var1,var2489,var2670 

 Iteration 29 :  Optimal value:  50.8 
 Optimal List:   var829,var808,var378,var1009,var3,var2124,var1448,var5,var2663,var2670 

 Iteration 30 :  Optimal value:  50.8 
 Optimal List:   var808,var829,var2,var1009,var3,var2124,var5,var1,var2663,var2670 

 Iteration 31 :  Optimal value:  50.8 
 Optimal List:   var808,var829,var1,var1009,var3,var2124,var5,var378,var2489,var2670 

 Iteration 32 :  Optimal value:  50.8 
 Optimal List:   var808,var829,var3,var1009,var5,var2124,var1448,var2489,var2663,var2670 

 Iteration 33 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var1009,var3,var2124,var4,var2489,var2670,var2663 

 Iteration 34 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var2,var3,var2124,var1448,var2489,var2663,var2670 

 Iteration 35 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var2,var5,var2124,var1448,var2489,var2663,var2670 

 Iteration 36 :  Optimal value:  50.8 
 Optimal List:   var829,var808,var2,var1009,var5,var2124,var1448,var2489,var2663,var2670 

 Iteration 37 :  Optimal value:  50.8 
 Optimal List:   var808,var829,var3,var1009,var5,var2124,var378,var2489,var2663,var2670 

 Iteration 38 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var2,var5,var2124,var1448,var2489,var2663,var2670 

 Iteration 39 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var4,var5,var2124,var378,var2489,var2663,var2670 

 Iteration 40 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var2,var3,var2124,var1448,var2489,var2663,var2670 

 Iteration 41 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var3,var5,var2124,var1448,var2489,var2663,var2670 

 Iteration 42 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var2,var3,var2124,var1448,var2489,var2663,var2670 

 Iteration 43 :  Optimal value:  51.2 
 Optimal List:   var829,var808,var1009,var4,var3,var2124,var1448,var2489,var2663,var2670 

 Iteration 44 :  Optimal value:  51.2 
 Optimal List:   var808,var829,var1009,var2,var5,var2124,var1448,var2489,var2663,var2670 
[1] "test acc rank aggreg CE:0.970588235294118"
[1] "test AUC acc rank aggreg CE:0.964285714285714"
[1] "10 fold train rank aggreg res CE97.3684210526316"
[1] "confusion matrix train 10 fold rank aggreg CE"
            nci_y
pred10foldRA -1  1
          -1 27  0
          1   0 11
[1] "Num itr RA CE"
[1] 44
[1] "Test BER aggreg CE is"
[1] 0.9642857

 Iteration 1 :  Optimal value:  66.8 
 Optimal List:   var2664,var1009,var3,var829,var808,var2670,var1448,var773,var523,var4 

 Iteration 2 :  Optimal value:  64.4 
 Optimal List:   var378,var2,var3,var2124,var2670,var808,var1,var2663,var773,var1448 

 Iteration 3 :  Optimal value:  64.4 
 Optimal List:   var378,var2,var3,var2124,var2670,var808,var1,var2663,var773,var1448 

 Iteration 4 :  Optimal value:  61.2 
 Optimal List:   var523,var808,var829,var3,var378,var2,var1009,var4,var1038,var2670 

 Iteration 5 :  Optimal value:  61.2 
 Optimal List:   var523,var808,var829,var3,var378,var2,var1009,var4,var1038,var2670 

 Iteration 6 :  Optimal value:  61.2 
 Optimal List:   var523,var808,var829,var3,var378,var2,var1009,var4,var1038,var2670 

 Iteration 7 :  Optimal value:  59.6 
 Optimal List:   var378,var808,var829,var3,var523,var2,var1009,var4,var1038,var2198 

 Iteration 8 :  Optimal value:  58.4 
 Optimal List:   var1448,var808,var829,var3,var378,var2,var1009,var4,var1038,var2670 

 Iteration 9 :  Optimal value:  58.4 
 Optimal List:   var1448,var808,var829,var3,var378,var2,var1009,var4,var1038,var2670 

 Iteration 10 :  Optimal value:  58 
 Optimal List:   var1448,var808,var829,var3,var378,var1009,var2,var4,var1038,var2670 

 Iteration 11 :  Optimal value:  54.8 
 Optimal List:   var378,var808,var829,var3,var1448,var1009,var2,var4,var1038,var2670 

 Iteration 12 :  Optimal value:  56 
 Optimal List:   var2,var808,var829,var3,var378,var1448,var1009,var4,var1038,var2670 

 Iteration 13 :  Optimal value:  56 
 Optimal List:   var1009,var808,var829,var3,var378,var2,var1448,var4,var1038,var2670 

 Iteration 14 :  Optimal value:  55.2 
 Optimal List:   var1448,var808,var829,var3,var378,var2,var1009,var4,var2124,var2670 

 Iteration 15 :  Optimal value:  52.8 
 Optimal List:   var2,var808,var829,var3,var378,var1448,var1009,var4,var2124,var2670 

 Iteration 16 :  Optimal value:  54 
 Optimal List:   var2,var808,var829,var3,var378,var1448,var1009,var773,var2124,var2670 

 Iteration 17 :  Optimal value:  52.8 
 Optimal List:   var1009,var808,var829,var3,var378,var1448,var2124,var4,var1038,var2670 

 Iteration 18 :  Optimal value:  52.8 
 Optimal List:   var2,var808,var829,var3,var378,var1448,var1009,var4,var2124,var2670 

 Iteration 19 :  Optimal value:  52.4 
 Optimal List:   var2,var808,var829,var3,var378,var1009,var2124,var4,var1038,var2670 

 Iteration 20 :  Optimal value:  52.4 
 Optimal List:   var2,var808,var829,var3,var378,var1009,var1448,var4,var2124,var2670 

 Iteration 21 :  Optimal value:  52.4 
 Optimal List:   var2,var808,var829,var3,var378,var1009,var1448,var4,var2124,var2670 

 Iteration 22 :  Optimal value:  52.4 
 Optimal List:   var2,var808,var829,var3,var378,var1009,var1448,var4,var2124,var2670 

 Iteration 23 :  Optimal value:  52.4 
 Optimal List:   var2,var808,var829,var3,var378,var1009,var1448,var4,var2124,var2670 

 Iteration 24 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var2,var1448,var4,var2124,var2670 

 Iteration 25 :  Optimal value:  51.6 
 Optimal List:   var378,var808,var829,var3,var2,var1009,var1448,var4,var2124,var2670 

 Iteration 26 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1448,var2,var4,var2124,var2670 

 Iteration 27 :  Optimal value:  51.6 
 Optimal List:   var378,var808,var829,var3,var2,var1009,var1448,var4,var2124,var2670 

 Iteration 28 :  Optimal value:  51.6 
 Optimal List:   var378,var808,var829,var3,var2,var1009,var1448,var4,var2124,var2670 

 Iteration 29 :  Optimal value:  51.6 
 Optimal List:   var378,var808,var829,var3,var4,var1009,var1448,var2,var2124,var2670 

 Iteration 30 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var2,var1448,var4,var2124,var2670 

 Iteration 31 :  Optimal value:  51.6 
 Optimal List:   var1,var808,var829,var3,var2,var1009,var1448,var4,var2124,var2670 

 Iteration 32 :  Optimal value:  51.6 
 Optimal List:   var378,var808,var829,var3,var2,var1009,var1448,var4,var2124,var2670 

 Iteration 33 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var2,var2124,var1009,var4,var1448,var2670 

 Iteration 34 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var2,var2124,var1009,var4,var1448,var2670 

 Iteration 35 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var2,var2124,var1009,var4,var1448,var2670 

 Iteration 36 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1448,var2,var4,var2124,var2670 

 Iteration 37 :  Optimal value:  50.8 
 Optimal List:   var2,var808,var829,var3,var1009,var2124,var1448,var4,var378,var2670 

 Iteration 38 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var2,var1448,var4,var2124,var2670 

 Iteration 39 :  Optimal value:  51.2 
 Optimal List:   var2,var808,var829,var3,var1009,var1448,var2124,var4,var378,var2670 

 Iteration 40 :  Optimal value:  51.2 
 Optimal List:   var2,var808,var829,var3,var1009,var1448,var2124,var4,var378,var2670 

 Iteration 41 :  Optimal value:  51.2 
 Optimal List:   var1,var808,var829,var3,var2,var1009,var1448,var2124,var378,var2670 

 Iteration 42 :  Optimal value:  50.8 
 Optimal List:   var1,var808,var829,var3,var1009,var2124,var1448,var4,var2670,var1038 

 Iteration 43 :  Optimal value:  50.8 
 Optimal List:   var1,var808,var829,var3,var1009,var2124,var1448,var4,var2670,var1038 

 Iteration 44 :  Optimal value:  51.2 
 Optimal List:   var1,var808,var829,var3,var2124,var1009,var1448,var4,var378,var2670 

 Iteration 45 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var2124,var1009,var1448,var2489,var1,var2670 

 Iteration 46 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var2124,var1009,var1448,var2489,var1,var2670 

 Iteration 47 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var2124,var1009,var1448,var2489,var1,var2670 

 Iteration 48 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1,var1448,var2,var2124,var2670 

 Iteration 49 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1,var1448,var2,var2124,var2670 

 Iteration 50 :  Optimal value:  51.2 
 Optimal List:   var1,var808,var829,var3,var1009,var378,var1448,var2,var2124,var2670 

 Iteration 51 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1,var1448,var2,var2124,var2670 

 Iteration 52 :  Optimal value:  51.2 
 Optimal List:   var1,var808,var829,var3,var2124,var1009,var1448,var2,var378,var2670 

 Iteration 53 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1,var1009,var2124,var1448,var2,var2670 

 Iteration 54 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var2124,var1009,var2,var4,var1448,var2670 

 Iteration 55 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var2124,var1009,var2,var4,var1448,var2670 

 Iteration 56 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var2,var2124,var1009,var3,var4,var1448,var2670 

 Iteration 57 :  Optimal value:  50.8 
 Optimal List:   var1,var808,var1009,var3,var829,var2124,var1448,var2,var378,var2670 

 Iteration 58 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1,var1448,var2,var2124,var2670 

 Iteration 59 :  Optimal value:  51.2 
 Optimal List:   var1,var808,var829,var3,var1009,var2,var378,var4,var2124,var2670 

 Iteration 60 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1,var1448,var2,var2124,var2670 

 Iteration 61 :  Optimal value:  50.4 
 Optimal List:   var378,var808,var829,var1009,var2124,var3,var1448,var4,var2,var2670 

 Iteration 62 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var1,var1448,var4,var2124,var2670 

 Iteration 63 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var2,var1448,var4,var2124,var2670 

 Iteration 64 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var2,var1448,var4,var2124,var2670 

 Iteration 65 :  Optimal value:  51.2 
 Optimal List:   var378,var808,var829,var3,var1009,var2,var1,var4,var2124,var2670 

 Iteration 66 :  Optimal value:  50.4 
 Optimal List:   var378,var808,var829,var3,var1009,var2,var2124,var4,var1448,var2670 

 Iteration 67 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1448,var2124,var1009,var4,var2,var2670 

 Iteration 68 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1448,var2124,var1009,var4,var2,var2670 

 Iteration 69 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1448,var2124,var1009,var4,var2,var2670 

 Iteration 70 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1448,var1009,var2124,var4,var2,var2670 

 Iteration 71 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1448,var2124,var1009,var4,var2,var2670 

 Iteration 72 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1448,var2124,var1009,var4,var2,var2670 

 Iteration 73 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var829,var3,var1448,var2124,var1009,var4,var2,var2670 

 Iteration 74 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var1009,var829,var1448,var2,var2124,var4,var3,var2670 

 Iteration 75 :  Optimal value:  50.8 
 Optimal List:   var378,var808,var1009,var829,var1448,var4,var2124,var2,var3,var2670 

 Iteration 76 :  Optimal value:  50.4 
 Optimal List:   var378,var808,var1009,var829,var3,var2124,var1,var4,var2,var2670 

 Iteration 77 :  Optimal value:  50.4 
 Optimal List:   var378,var808,var1009,var829,var3,var2124,var1,var4,var2,var2670 

 Iteration 78 :  Optimal value:  50.4 
 Optimal List:   var378,var808,var1009,var829,var3,var2124,var1,var4,var2,var2670 

 Iteration 79 :  Optimal value:  50.4 
 Optimal List:   var378,var808,var1009,var829,var3,var2124,var1,var4,var2,var2670 

 Iteration 80 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 81 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var3,var4,var2,var2670 

 Iteration 82 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 83 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var4,var1009,var2124,var1448,var2,var3,var2670 

 Iteration 84 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 85 :  Optimal value:  50.4 
 Optimal List:   var378,var808,var1009,var829,var3,var2124,var1,var4,var2,var2670 

 Iteration 86 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 87 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 88 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 89 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 90 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 91 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 92 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 93 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 94 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 95 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 96 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 97 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 98 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 99 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 100 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 101 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 102 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 103 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 104 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 105 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 106 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 107 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 108 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var2,var1009,var2124,var1448,var4,var3,var2670 

 Iteration 109 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var1009,var1448,var2,var2124,var4,var3,var2670 

 Iteration 110 :  Optimal value:  50 
 Optimal List:   var378,var808,var829,var3,var1009,var2124,var1448,var4,var2,var2670 

 Iteration 111 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 112 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 113 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 114 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 115 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1,var2124,var1448,var4,var2,var2670 

 Iteration 116 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1,var2124,var1448,var4,var2,var2670 

 Iteration 117 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 118 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 119 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var3,var4,var2,var2670 

 Iteration 120 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 121 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 122 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var3,var1,var2,var2670 

 Iteration 123 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 124 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 125 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 126 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 127 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 128 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 129 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 130 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 131 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 132 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var4,var3,var2670 

 Iteration 133 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var2,var2124,var1448,var1,var3,var2670 

 Iteration 134 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 135 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 136 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 137 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 138 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var1448,var2124,var2,var1,var3,var2670 

 Iteration 139 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var2,var2124,var1448,var1,var3,var2670 

 Iteration 140 :  Optimal value:  49.6 
 Optimal List:   var378,var808,var829,var1009,var2,var2124,var1448,var1,var3,var2670 
[1] "test acc rank aggreg GA:0.970588235294118"
[1] "test AUC acc rank aggreg GA:0.964285714285714"
[1] "10 fold train rank aggreg res GA97.3684210526316"
[1] "confusion matrix train 10 fold rank aggreg GA"
            nci_y
pred10foldRA -1  1
          -1 27  0
          1   0 11
[1] "Num itr RA GA"
[1] 141
[1] "Test BER aggreg GA is"
[1] 0.9642857
There were 11 warnings (use warnings() to see them)
> 
> cma_feat_list<-colnames(trainm)
> 
> save(CMAres,file="CMAres.Rda")
> write.table(cma_feat_list,file="selected_cma_feat_list.txt",sep="t",row.names=FALSE)
> 
> # modtraindata=modtrain, modtestdata=modtest, blindtest=testacc, modtrainclass=nci_y, modtestclass=test_y
> #if(FALSE)
> {
+ trainm<-CMAres$modtraindata
+ testm<-CMAres$modtestdata
+ trainclass<-CMAres$modtrainclass
+ testclass<-CMAres$modtestclass
+ learningsets<-CMAres$learningsets
+ }
> 
> if(FALSE)
+ {
+ trainclass<-trainm[,1] #CMAres$modtrainclass
+ testclass<-testm[,1] #CMAres$modtestclass
+ trainm<-trainm[,-c(1)] #CMAres$modtrainmata
+ testm<-testm[,-c(1)] #CMAres$modtestmata
+ 
+ }
> 
> d_dim<-dim(trainm)
> 
> print("Original dimension")
[1] "Original dimension"
> print(d_dim)
[1] 38 24
> 
> system.time(psores<-run_pso(outloc=outloc,trainm,trainclass,testm,testclass,transition_matrix,c1=2.05,
+ c2=2.05,
+ itr=10,
+ globalpso_maxitr=10,
+ global_max_itr=5,
+ num_part=20,
+ kname="radial",
+ errortype="BER",
+ weightA<-as.numeric(args[1]),
+ weightB<-as.numeric(args[2]),
+ weightC<-as.numeric(args[3]),
+ weightD<-as.numeric(args[4]),
+ featweight.max=0.01,
+ featweight.min=0.01,
+ numfolds=10,
+ followerprob=as.numeric(args[6]),
+ confusionprob=as.numeric(args[7]),
+ leaderprob=as.numeric(args[8]),
+ wmax=1,
+ wmin=1,
+ behavior_reset_itr=5,
+ maxitrreset=10,
+ num_neighbors=3,
+ minselect.pct=0.5,
+ evalMode="CV2",
+ minfitnessthresh=50,
+ maxnum=as.numeric(args[10]),minnum=3,inertia_method=args[5],particlebehav_method="randbased",constriction_factor=1,
+ select.global.best=TRUE,numnodes=4,evalFunc=eval_fit_kfold_diff,itr.terminate=FALSE,train.pct=0.8))
[1] "c1: 2.05"
[1] "c2: 2.05"
[1] "itr: 10"
[1] "globalpso_maxitr: 10"
[1] "global_max_itr: 5"
[1] "num_part: 20"
[1] "kname: radial"
[1] "errortype: BER"
[1] "weightA: 0.7"
[1] "weightB: 0.2"
[1] "weightC: 0.05"
[1] "weightD: 0.05"
[1] "featweight.max: 0.01"
[1] "featweight.min: 0.01"
[1] "numfolds: 10"
[1] "followerprob: 0.45"
[1] "confusionprob: 0.2"
[1] "leaderprob: 0.25"
[1] "wmax: 1"
[1] "wmin: 1"
[1] "behavior_reset_itr: 5"
[1] "maxitrreset: 10"
[1] "num_neighbors: 3"
[1] "minselect.pct: 0.5"
[1] "minfitnessthresh: 50"
[1] "maxnum: 10"
[1] "minnum: 3"
[1] "inertia_method: global"
[1] "particlebehav_method: randbased"
[1] "constriction_factor: 1"
[1] "select.global.best: TRUE"
[1] "train 10 fold"
[1] 100
[1] "here"
[1] "s"
[1] 30.4
[1] 38 24
[1] 10
[1] "learning sets: 1"
 [1]  6 28 12  2 16  7 25 20 29 13 15  3 19  9 30 26 21 38 27 10  5 14 23 34  8
[26] 24  4 31 36  1
[1] "Starting global iteration number : 1"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -34.46906
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -37.59406
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -40.13711
[1] "Best solution:"
 [1] 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0
[1] 9
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1] "iteration number: "
[1] 7
[1] "Best fitness updated to:"
[1] -40.17877
[1] "Best solution:"
 [1] 0 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0
[1] 10
[1] "iteration number: "
[1] 8
[1] "iteration number: "
[1] 9
[1] "iteration number: "
[1] 10
[1] "iteration number: "
[1] 11
[1] "iteration number: "
[1] 12
[1] "iteration number: "
[1] 13
[1] "iteration number: "
[1] 14
[1] "Best fitness updated to:"
[1] -40.26211
[1] "Best solution:"
 [1] 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1
[1] 12
[1] "iteration number: "
[1] 15
[1] "iteration number: "
[1] 16
[1] "iteration number: "
[1] 17
[1] "iteration number: "
[1] 18
[1] "iteration number: "
[1] 19
[1] "iteration number: "
[1] 20
[1] "iteration number: "
[1] 21
[1] "Best fitness updated to:"
[1] -40.51765
[1] "Best solution:"
 [1] 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1
[1] 10
[1] "iteration number: "
[1] 22
[1] "iteration number: "
[1] 23
[1] "iteration number: "
[1] 24
[1] "iteration number: "
[1] 25
[1] "Best fitness updated to:"
[1] -40.55932
[1] "Best solution:"
 [1] 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1
[1] 9
[1] "iteration number: "
[1] 26
[1] "iteration number: "
[1] 27
[1] "iteration number: "
[1] 28
[1] "iteration number: "
[1] 29
[1] "iteration number: "
[1] 30
[1] "iteration number: "
[1] 31
[1] "iteration number: "
[1] 32
[1] "iteration number: "
[1] 33
[1]  4  5  6 10 14 16 20 23 24
[1] 1
[1] "##################################"
[1] "Results summary for itr:1"
[1] "number of features selected using population mean"
[1] 11
[1] "number of features selected using current global best"
[1] 9
[1] "feat ind length"
[1] 9
[1] "best accuracy"
[1] 40.55932
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 2"
 [1] 10 18 16  8  2 28  6 11 19  9  1  4 12 32 17 33 24  7 15  3 14 23 37 25 36
[26] 38 30 34 22 29
[1] "Starting global iteration number : 2"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -35.72801
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -43.94821
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -43.95905
[1] "Best solution:"
 [1] 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1
[1] 16
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
 [1]  4  5  7  8  9 10 11 12 13 14 15 18 19 20 22 23
[1] 2
[1] "##################################"
[1] "Results summary for itr:2"
[1] "number of features selected using population mean"
[1] 23
[1] "number of features selected using current global best"
[1] 16
[1] "feat ind length"
[1] 16
[1] "best accuracy"
[1] 43.95905
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 3"
 [1] 20  9 12 22 11 15 34 37 13 38  8  4 28 23  3  7 30 19 36 31 32  6 24 16 18
[26] 27 10 35  2 26
[1] "Starting global iteration number : 3"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -41.796
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -44.45305
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1]  5 10 11 12 13 16 17 23
[1] 3
[1] "##################################"
[1] "Results summary for itr:3"
[1] "number of features selected using population mean"
[1] 24
[1] "number of features selected using current global best"
[1] 8
[1] "feat ind length"
[1] 8
[1] "best accuracy"
[1] 44.45305
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 4"
 [1]  4 26 36 10 25 33 18 38  8  7 19 31 23 11  5 32  6 29 14 15 24  2 17 13 37
[26] 12 34 28 20 22
[1] "Starting global iteration number : 4"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -44.74945
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -48.05214
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1]  5  6  7  8 13 18 22 23
[1] 4
[1] "##################################"
[1] "Results summary for itr:4"
[1] "number of features selected using population mean"
[1] 23
[1] "number of features selected using current global best"
[1] 8
[1] "feat ind length"
[1] 8
[1] "best accuracy"
[1] 48.05214
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 5"
 [1] 36 15 27 25 32 26 28 30  9 16 37 23 19  4  5  2  3 35 10 21  8  1 29 13 34
[26] 12  7 31 20 38
[1] "Starting global iteration number : 5"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -51.17195
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -55.64416
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -56.35874
[1] "Best solution:"
 [1] 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0
[1] 9
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1]  5 13 14 15 17 19 22
[1] 5
[1] "##################################"
[1] "Results summary for itr:5"
[1] "number of features selected using population mean"
[1] 21
[1] "number of features selected using current global best"
[1] 7
[1] "feat ind length"
[1] 7
[1] "best accuracy"
[1] 56.35874
[1] "test acc:0.875"
[1] "##################################"
[1] "learning sets: 6"
 [1] 20 16 32  3 36 10 13  4 21 18 33 38 28 15 27  6  2 14 26  9 17 30 34 37 35
[26] 31 25  7 24  8
[1] "Starting global iteration number : 6"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -36.06341
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -44.0089
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -45.64951
[1] "Best solution:"
 [1] 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1
[1] 8
[1] "iteration number: "
[1] 6
 [1]  1  3  7 11 12 14 15 16 19 22 24
[1] 6
[1] "##################################"
[1] "Results summary for itr:6"
[1] "number of features selected using population mean"
[1] 15
[1] "number of features selected using current global best"
[1] 11
[1] "feat ind length"
[1] 11
[1] "best accuracy"
[1] 45.64951
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 7"
 [1] 21 33 36 15 10 38  5  8 27  2 17  9 20  4 32 35 29 24 13 26  3 28 12 31 25
[26] 14 11 18 19  6
[1] "Starting global iteration number : 7"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -31.53913
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -39.97929
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -40.35431
[1] "Best solution:"
 [1] 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0
[1] 9
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "Best fitness updated to:"
[1] -40.52097
[1] "Best solution:"
 [1] 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1
[1] 15
[1] "iteration number: "
[1] 6
[1] "Best fitness updated to:"
[1] -42.99884
[1] "Best solution:"
 [1] 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 0
[1] 15
[1]  6  7  8 16 17 23 24
[1] 7
[1] "##################################"
[1] "Results summary for itr:7"
[1] "number of features selected using population mean"
[1] 16
[1] "number of features selected using current global best"
[1] 7
[1] "feat ind length"
[1] 7
[1] "best accuracy"
[1] 42.99884
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 8"
 [1] 38 31 14 18 26 10 13  4 12 22 15 34 24 37 25 35 28 33 20  8  6  2 23  1 29
[26] 11  3  9  5 27
[1] "Starting global iteration number : 8"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -42.87916
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -43.9415
[1] "Best solution:"
 [1] 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0
[1] 14
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
 [1]  1  5  8  9 10 13 15 16 17 19 20 21 24
[1] 8
[1] "##################################"
[1] "Results summary for itr:8"
[1] "number of features selected using population mean"
[1] 24
[1] "number of features selected using current global best"
[1] 13
[1] "feat ind length"
[1] 13
[1] "best accuracy"
[1] 43.9415
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 9"
 [1] 37 14 28  3  6  8 18 10  4 23 19 12 38 20  9  2 22 13 21 34 29 15 35 16 31
[26] 11 25  7 24  1
[1] "Starting global iteration number : 9"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -30.3119
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -38.07253
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -40.57253
[1] "Best solution:"
 [1] 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0
[1] 9
[1] "iteration number: "
[1] 4
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1]  5 10 11 12 13 16 17 19 23
[1] 9
[1] "##################################"
[1] "Results summary for itr:9"
[1] "number of features selected using population mean"
[1] 11
[1] "number of features selected using current global best"
[1] 9
[1] "feat ind length"
[1] 9
[1] "best accuracy"
[1] 40.57253
[1] "test acc:1"
[1] "##################################"
[1] "learning sets: 10"
 [1]  8  3  4  7  6 10 28 13 30 23 34 21 25 15  1 16 17 18 12 36 19 11 24 33 29
[26] 31 20  2 27 38
[1] "Starting global iteration number : 10"
[1] "iteration number: "
[1] 1
[1] "Best fitness updated to:"
[1] -27.9236
[1] "Best solution:"
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[1] 0
[1] "iteration number: "
[1] 2
[1] "Best fitness updated to:"
[1] -34.92717
[1] "Best solution:"
 [1] 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0
[1] 8
[1] "iteration number: "
[1] 3
[1] "Best fitness updated to:"
[1] -42.03399
[1] "Best solution:"
 [1] 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0
[1] 7
[1] "iteration number: "
[1] 4
[1] "Best fitness updated to:"
[1] -46.32594
[1] "Best solution:"
 [1] 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0
[1] 7
[1] "iteration number: "
[1] 5
[1] "iteration number: "
[1] 6
[1]  5  6 13 15 17 19 23
[1] 10
[1] "##################################"
[1] "Results summary for itr:10"
[1] "number of features selected using population mean"
[1] 12
[1] "number of features selected using current global best"
[1] 7
[1] "feat ind length"
[1] 7
[1] "best accuracy"
[1] 46.32594
[1] "test acc:1"
[1] "##################################"
[1] "testacc"
 [1] 1.000 1.000 1.000 1.000 0.875 1.000 1.000 1.000 1.000 1.000
[1] 0.9875
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8750  1.0000  1.0000  0.9875  1.0000  1.0000 
[1] 0.03952847
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    0    0    0    0    1    0    1    0     0
 [2,]    0    0    0    0    0    0    0    0    0     0
 [3,]    0    0    0    0    0    1    0    0    0     0
 [4,]    1    1    0    0    0    0    0    0    0     0
 [5,]    1    1    1    1    1    0    0    1    1     1
 [6,]    1    0    0    1    0    0    1    0    0     1
 [7,]    0    1    0    1    0    1    1    0    0     0
 [8,]    0    1    0    1    0    0    1    1    0     0
 [9,]    0    1    0    0    0    0    0    1    0     0
[10,]    1    1    1    0    0    0    0    1    1     0
[11,]    0    1    1    0    0    1    0    0    1     0
[12,]    0    1    1    0    0    1    0    0    1     0
[13,]    0    1    1    1    1    0    0    1    1     1
[14,]    1    1    0    0    1    1    0    0    0     0
[15,]    0    1    0    0    1    1    0    1    0     1
[16,]    1    0    1    0    0    1    1    1    1     0
[17,]    0    0    1    0    1    0    1    1    1     1
[18,]    0    1    0    1    0    0    0    0    0     0
[19,]    0    1    0    0    1    1    0    1    1     1
[20,]    1    1    0    0    0    0    0    1    0     0
[21,]    0    0    0    0    0    0    0    1    0     0
[22,]    0    1    0    1    1    1    0    0    0     0
[23,]    1    1    1    1    0    0    1    0    1     1
[24,]    1    0    0    0    0    1    1    1    0     0
[1] "dim of scoring matrix is "
[1] 24 10
[1] "DS index stage 2"
[1] 0.4414147
[1] "KI index stage 2"
[1] -Inf
[1] 1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.000   2.000   4.000   3.958   5.250   8.000 
[1] "Number of features selected in 1 iterations:"
[1] 23
[1] "Number of features selected in 1 iterations:"
[1] 23
[1] 1 1
[1] 1 1
[1] "accuracy: 100 num_feat:23 fitness:48.1601453339772"
$fitfunc
[1] -48.16015

$cverror
[1] 100

$cvpermerror
[1] 72.68789

$testacc
[1] 100

$reverseacc
[1] 100

[1] -48.16015
[1] "Number of features selected in 2 iterations:"
[1] 21
[1] 1 1
[1] 1 1
[1] "accuracy: 100 num_feat:21 fitness:48.2434786673105"
$fitfunc
[1] -48.24348

$cverror
[1] 100

$cvpermerror
[1] 72.68789

$testacc
[1] 100

$reverseacc
[1] 100

[1] -48.24348
[1] "Number of features selected in 3 iterations:"
[1] 17
[1] 1 1
[1] 1 1
[1] "accuracy: 100 num_feat:17 fitness:48.4101453339772"
$fitfunc
[1] -48.41015

$cverror
[1] 100

$cvpermerror
[1] 72.68789

$testacc
[1] 100

$reverseacc
[1] 100

[1] -48.41015
[1] "Number of features selected in 4 iterations:"
[1] 16
[1] 1 1
[1] 1 1
[1] "accuracy: 100 num_feat:16 fitness:48.5873898744909"
$fitfunc
[1] -48.58739

$cverror
[1] 100

$cvpermerror
[1] 72.4942

$testacc
[1] 100

$reverseacc
[1] 100

[1] -48.58739
[1] "Number of features selected in 5 iterations:"
[1] 8
[1] 1 1
[1] 1 1
[1] "accuracy: 100 num_feat:8 fitness:47.9106525773576"
$fitfunc
[1] -47.91065

$cverror
[1] 100

$cvpermerror
[1] 73.93716

$testacc
[1] 100

$reverseacc
[1] 100

[1] -47.91065
[1] "Number of features selected in 6 iterations:"
[1] 6
[1] 1 1
[1] 1 1
[1] "accuracy: 100 num_feat:6 fitness:47.0202541964748"
$fitfunc
[1] -47.02025

$cverror
[1] 100

$cvpermerror
[1] 75.32821

$testacc
[1] 100

$reverseacc
[1] 100

[1] -47.02025
[1] "Number of features selected in 7 iterations:"
[1] 3
[1] 1.0000000 0.8181818
[1] 1.0000000 0.8181818
[1] "accuracy: 86.2269493586307 num_feat:3 fitness:34.7958985713166"
$fitfunc
[1] -34.7959

$cverror
[1] 86.22695

$cvpermerror
[1] 74.96655

$testacc
[1] 90.90909

$reverseacc
[1] 90.90909

[1] -34.7959
[1] "Number of features selected in 8 iterations:"
[1] 1
[1] "accuracy: 1 num_feat:1 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
[1] "Number of features selected in 9 iterations:"
[1] 0
[1] "accuracy: 1 num_feat:0 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
[1] "Number of features selected in 10 iterations:"
[1] 0
[1] "accuracy: 1 num_feat:0 fitness:-100"
$fitfunc
[1] 100

$cverror
[1] 1

$cvpermerror
[1] 100

$testacc
[1] 1

$reverseacc
[1] 1

[1] 100
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8750  1.0000  1.0000  0.9875  1.0000  1.0000 
[1] "Number of features selected in 1 iterations:"
[1] 23
[1] "Modified train 10 fold accuracy using train data is "
[1] 100
[1] "Modified train accuracy is "
[1] 1
[1] "train confusion matrix is "
          trainclass
pred_train -1  1
        -1 27  0
        1   0 11
[1] "Train dimension is "
[1] 38 23
[1] "Test dimension is "
[1] 34 23
[1] "Test confusion matrix is "
    
pred -1  1
  -1 20  1
  1   0 13
[1] "Test acc is "
[1] 0.9705882
[1] "train 10 fold"
[1] 100
[1] "Test confusion matrix is "
    
pred -1  1
  -1 20  1
  1   0 13
[1] "Test acc is "
[1] 0.9705882
[1] "Test AUC:"
[1] 0.9642857
[1] "Train acc is "
[1] 1
[1] "# of features after CMA:"
NULL
[1] "# of features after PSO:"
[1] 38 24
   user  system elapsed 
 14.187   1.255 588.459 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> 
> 
> feat_ind<-psores$bestfeatlist
> feat_names<-psores$bestfeatnames
> 
> scoringmatrix<-as.data.frame(psores$scoringmatrix)
> print(scoringmatrix)
   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
1   0  0  0  0  0  1  0  1  0   0
2   0  0  0  0  0  0  0  0  0   0
3   0  0  0  0  0  1  0  0  0   0
4   1  1  0  0  0  0  0  0  0   0
5   1  1  1  1  1  0  0  1  1   1
6   1  0  0  1  0  0  1  0  0   1
7   0  1  0  1  0  1  1  0  0   0
8   0  1  0  1  0  0  1  1  0   0
9   0  1  0  0  0  0  0  1  0   0
10  1  1  1  0  0  0  0  1  1   0
11  0  1  1  0  0  1  0  0  1   0
12  0  1  1  0  0  1  0  0  1   0
13  0  1  1  1  1  0  0  1  1   1
14  1  1  0  0  1  1  0  0  0   0
15  0  1  0  0  1  1  0  1  0   1
16  1  0  1  0  0  1  1  1  1   0
17  0  0  1  0  1  0  1  1  1   1
18  0  1  0  1  0  0  0  0  0   0
19  0  1  0  0  1  1  0  1  1   1
20  1  1  0  0  0  0  0  1  0   0
21  0  0  0  0  0  0  0  1  0   0
22  0  1  0  1  1  1  0  0  0   0
23  1  1  1  1  0  0  1  0  1   1
24  1  0  0  0  0  1  1  1  0   0
> print(feat_names[feat_ind])
 [1] "var36"   "var38"   "var39"   "var40"   "var41"   "var760"  "var1144"
 [8] "var1779" "var1834" "var1882" "var2288" "var2349" "var2642" "var3320"
[15] "var4847" "var5039" "var5552" "var5772" "var6041" "var6200" "var6201"
[22] "var6218" "var6884"
> 
> save(psores,file="psores.Rda")
> print("Complete")
[1] "Complete"
> 
